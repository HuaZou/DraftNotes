[{"path":"index.html","id":"介绍","chapter":"1 介绍","heading":"1 介绍","text":"学习了很多东西，但是不成体系，又不知道记录在哪里，就随手创建了这个bookdown。暂时的想法是记录日常学习到的一些东西，后期有时间再重新梳理成博客，并将它们分门别类发布出来。希望这里是自己学习的天堂～加油～","code":""},{"path":"index.html","id":"输入数据","chapter":"1 介绍","heading":"1.1 输入数据","text":"这些笔记的输入数据统一路径都在InputData对应的子目录下面。如果想测试某些代码或者复现结果，可到对应的子目录内下载相关的数据。InputData: https://github.com/HuaZou/DraftNotes/blob/main/InputData/","code":""},{"path":"index.html","id":"需要额外安装的r包","chapter":"1 介绍","heading":"1.2 需要额外安装的R包","text":"MicrobiomeAnalysis提供一些数据预处理的方法如impute_abundance等","code":"\nif (!requireNamespace(c(\"remotes\", \"devtools\"), quietly=TRUE)) {\n  install.packages(c(\"devtools\", \"remotes\"))\n}\n\nremotes::install_github(\"HuaZou/MicrobiomeAnalysis\")\n\n# library(MicrobiomeAnalysis)"},{"path":"ZeybelDataset.html","id":"ZeybelDataset","chapter":"2 Zeybel Dataset","heading":"2 Zeybel Dataset","text":"该数据集是来自于Zeybel 2022年发布的文章_Multiomics Analysis Reveals Impact Microbiota Host Metabolism Hepatic Steatosis_，它包含了多种组学数据，如微生物组（粪便和口腔）微生物组（粪便和口腔）宿主人体学指标宿主人体学指标宿主临床学指标宿主临床学指标宿主血浆代谢组宿主血浆代谢组宿主血浆靶向免疫因子宿主血浆靶向免疫因子22位患者纵向时间序列数据22位患者纵向时间序列数据本脚本目的是生成符合数据分析的下游数据对象，主要有如下两类：phyloseq: phyloseq-class object\notu table\ntaxa table\nsample table\ntree file\nRepresentative sequences (ASV OTU)\nphyloseq: phyloseq-class objectotu tableotu tabletaxa tabletaxa tablesample tablesample tabletree filetree fileRepresentative sequences (ASV OTU)Representative sequences (ASV OTU)SummarizedExperiment: SummarizedExperiment-class object\notu table\ntaxa table\nsample table\nSummarizedExperiment: SummarizedExperiment-class objectotu tableotu tabletaxa tabletaxa tablesample tablesample table","code":""},{"path":"ZeybelDataset.html","id":"加载r包","chapter":"2 Zeybel Dataset","heading":"2.1 加载R包","text":"","code":"\nknitr::opts_chunk$set(message = FALSE, warning = FALSE)\nlibrary(dplyr)\nlibrary(tibble)\nlibrary(phyloseq)\nlibrary(SummarizedExperiment)\n\n# rm(list = ls())\noptions(stringsAsFactors = F)\noptions(future.globals.maxSize = 1000 * 1024^2)"},{"path":"ZeybelDataset.html","id":"importing-data","chapter":"2 Zeybel Dataset","heading":"2.2 Importing Data","text":"可以点击此处下载数据OmicsDataSet-Zeybel et al. - 2022.xlsx","code":""},{"path":"ZeybelDataset.html","id":"cross-section-data","chapter":"2 Zeybel Dataset","heading":"2.2.1 cross-section data","text":"56 participantsmetadata\nPatients’ Phenotypic information (sheet 2)\nClinical Physical variables (sheet 3)\nmetadataPatients’ Phenotypic information (sheet 2)Patients’ Phenotypic information (sheet 2)Clinical Physical variables (sheet 3)Clinical Physical variables (sheet 3)taxa fecal samples\nMetaphlan2 profile Gut microbiota (sheet 4)\nMetaphlan2 profile Oral microbiota (sheet 5)\ntaxa fecal samplesMetaphlan2 profile Gut microbiota (sheet 4)Metaphlan2 profile Gut microbiota (sheet 4)Metaphlan2 profile Oral microbiota (sheet 5)Metaphlan2 profile Oral microbiota (sheet 5)metabolites fecal samples\nMetabolomics Patients’ plasma samples (sheet 6)\nmetabolites fecal samplesMetabolomics Patients’ plasma samples (sheet 6)proteomics host plasma\nInflammatory Proteomics Patients’ plasma samples (sheet 7)\nproteomics host plasmaInflammatory Proteomics Patients’ plasma samples (sheet 7)","code":"\nmeta_info <- readxl::read_xlsx(\"./InputData/Zeybel-2022/OmicsDataSet-Zeybel et al. - 2022.xlsx\", sheet = 2)\nmeta_clin <- readxl::read_xlsx(\"./InputData/Zeybel-2022/OmicsDataSet-Zeybel et al. - 2022.xlsx\", sheet = 3)\n\ntaxa_gut <- readxl::read_xlsx(\"./InputData/Zeybel-2022/OmicsDataSet-Zeybel et al. - 2022.xlsx\", sheet = 4)\ntaxa_ora <- readxl::read_xlsx(\"./InputData/Zeybel-2022/OmicsDataSet-Zeybel et al. - 2022.xlsx\", sheet = 5)\n\nmetabolites_fecal <- readxl::read_xlsx(\"./InputData/Zeybel-2022/OmicsDataSet-Zeybel et al. - 2022.xlsx\", sheet = 6)\n\nprotein_plasma <- readxl::read_xlsx(\"./InputData/Zeybel-2022/OmicsDataSet-Zeybel et al. - 2022.xlsx\", sheet = 7)"},{"path":"ZeybelDataset.html","id":"longitudinal-data","chapter":"2 Zeybel Dataset","heading":"2.2.2 Longitudinal Data","text":"22位患者在治疗前后的时间序列样本metadata\nPatients’ Phenotypic information (sheet 8)\nClinical Physical variables (sheet 9)\nmetadataPatients’ Phenotypic information (sheet 8)Patients’ Phenotypic information (sheet 8)Clinical Physical variables (sheet 9)Clinical Physical variables (sheet 9)taxa fecal samples\nMetaphlan2 profile Gut microbiota (sheet 10)\nMetaphlan2 profile Oral microbiota (sheet 11)\ntaxa fecal samplesMetaphlan2 profile Gut microbiota (sheet 10)Metaphlan2 profile Gut microbiota (sheet 10)Metaphlan2 profile Oral microbiota (sheet 11)Metaphlan2 profile Oral microbiota (sheet 11)metabolites fecal samples\nMetabolomics Patients’ plasma samples (sheet 12)\nmetabolites fecal samplesMetabolomics Patients’ plasma samples (sheet 12)proteomics host plasma\nInflammatory Proteomics Patients’ plasma samples (sheet 13)\nproteomics host plasmaInflammatory Proteomics Patients’ plasma samples (sheet 13)","code":"\nlong_meta_info <- readxl::read_xlsx(\"./InputData/Zeybel-2022/OmicsDataSet-Zeybel et al. - 2022.xlsx\", sheet = 8)\nlong_meta_clin <- readxl::read_xlsx(\"./InputData/Zeybel-2022/OmicsDataSet-Zeybel et al. - 2022.xlsx\", sheet = 9)\n\nlong_taxa_gut <- readxl::read_xlsx(\"./InputData/Zeybel-2022/OmicsDataSet-Zeybel et al. - 2022.xlsx\", sheet = 10)\nlong_taxa_ora <- readxl::read_xlsx(\"./InputData/Zeybel-2022/OmicsDataSet-Zeybel et al. - 2022.xlsx\", sheet = 11)\n\nlong_metabolites_fecal <- readxl::read_xlsx(\"./InputData/Zeybel-2022/OmicsDataSet-Zeybel et al. - 2022.xlsx\", sheet = 12)\n\nlong_protein_plasma <- readxl::read_xlsx(\"./InputData/Zeybel-2022/OmicsDataSet-Zeybel et al. - 2022.xlsx\", sheet = 13)"},{"path":"ZeybelDataset.html","id":"cross-section-data-1","chapter":"2 Zeybel Dataset","heading":"2.3 Cross-section Data","text":"56位患者的横截面也即是基线时期的数据metadataphyloseq-class objectSummarizedExperiment: metabolitesSummarizedExperiment: proteomicsoutput","code":"\nmetadata <- meta_info %>%\n  dplyr::select(-`Patient ID`) %>%\n  # dplyr::rename(`Patient ID` = `Patient ID...2`) %>%\n  dplyr::inner_join(meta_clin,\n                    by = \"PatientID\") %>%\n  dplyr::select(-c(\"Stage\", \"Metabolomics\", \"Proteomics\",\n                   \"GutMetagenomics\", \"OralMetagenomics\")) %>%\n  dplyr::select(PatientID, Gender, Age, everything())\n\nhead(metadata)\n#> # A tibble: 6 × 47\n#>   PatientID Gender   Age LiverFatClass AlcoholConsumption\n#>   <chr>     <chr>  <dbl> <chr>         <chr>             \n#> 1 P101001   Male      52 Severe        No                \n#> 2 P101003   Female    31 None          No                \n#> 3 P101004   Male      43 Moderate      Yes               \n#> 4 P101007   Female    61 Severe        No                \n#> 5 P101009   Male      51 Moderate      No                \n#> 6 P101010   Male      27 Mild          Yes               \n#> # ℹ 42 more variables: Smoker <chr>, Liver_fat <dbl>,\n#> #   Sodium <dbl>, Potassium <dbl>, Creatinine <dbl>,\n#> #   Urea_BUN <dbl>, Uric_acid <dbl>, ALT <dbl>, AST <dbl>,\n#> #   GGT <dbl>, Alkaline_phosphatase <dbl>,\n#> #   Total_Bilirubin <dbl>, Albumin <dbl>,\n#> #   Creatine_Kinase <dbl>, Total_cholesterol <dbl>,\n#> #   High_Density_Lipoprotein <dbl>, …\nimport_metaphlan_taxa <- function(data_metaphlan2,\n                                  taxa_level = NULL) {\n\n  taxa_rank <- c(\"Kingdom\", \"Phylum\", \"Class\",\n                 \"Order\", \"Family\", \"Genus\",\n                 \"Species\", \"Strain\")\n\n  # rename 1st column into \"ID\"\n  colnames(data_metaphlan2)[which(colnames(data_metaphlan2) == \"ID\" |\n                                    colnames(data_metaphlan2) == \"clade_name\")] <- \"ID\"\n\n  # remove the \"NCBI_tax_id\" column\n  if (any(colnames(data_metaphlan2) %in% \"NCBI_tax_id\")) {\n    data_metaphlan2 <- data_metaphlan2 %>%\n      dplyr::select(-NCBI_tax_id)\n  }\n\n  # remove sample names with \"metaphlan_bugs_list\" suffix\n  colnames(data_metaphlan2) <- gsub(\"_metaphlan_bugs_list$\", \"\",\n                                    colnames(data_metaphlan2))\n\n  if (is.null(taxa_level)) {\n    taxa_level <- \"Species\"\n  }\n  ind_number <- match(taxa_level, taxa_rank)\n\n  # remove k__Archaea & k__Viruses & k__Eukaryota & Others which are not bacteria\n  if (length(grep(\"k__Bacteria\", data_metaphlan2$ID)) > 0) {\n    taxa_bacteria <- data_metaphlan2 %>%\n      dplyr::slice(grep(\"k__Bacteria\", ID)) %>%\n      tibble::column_to_rownames(\"ID\")\n  } else {\n    stop(\"There are no bacteria identified in this profile\")\n  }\n\n  # dividing by 100 to normalize the sum into 1\n  taxa_bac_per <- (taxa_bacteria / 100)  %>%\n    tibble::rownames_to_column(\"ID\")\n\n  taxa <- taxa_bac_per %>%\n    dplyr::group_by(ID) %>%\n    dplyr::mutate(Number=length(unlist(strsplit(ID, \"|\", fixed = TRUE)))) %>%\n    dplyr::select(ID, Number) %>%\n    dplyr::filter(Number == ind_number)\n\n  abundance_table <- taxa_bac_per %>%\n    dplyr::filter(ID%in%taxa$ID)\n\n  taxa_table <- lapply(abundance_table$ID, strsplit, split = \"|\", fixed = TRUE)\n  taxa_table <- lapply(taxa_table, unlist)\n  taxa_table <- do.call(rbind, taxa_table)\n  taxa_table <- data.frame(taxa_table)\n  names(taxa_table) <- taxa_rank[1:ind_number]\n  rownames(taxa_table) <- taxa_table[, ind_number]\n\n  abundance_table_res <- abundance_table %>%\n    tibble::column_to_rownames(\"ID\")\n  rownames(abundance_table_res) <- rownames(taxa_table)\n  abundance_table_res <- abundance_table_res[match(rownames(taxa_table),\n                                                   row.names(abundance_table_res)), ,\n                                             drop = FALSE]\n\n  res <- list(tax_tab=taxa_table,\n              abu_tab=abundance_table_res)\n\n  return(res)\n}\n\nget_metaphlan_phyloseq <- function(otu_tab,\n                                   sam_tab,\n                                   tax_tab = NULL) {\n\n  sid <- intersect(sam_tab$PatientID, colnames(otu_tab))\n\n  sam_tab <- sam_tab[sam_tab$PatientID %in% sid, ] %>%\n    tibble::column_to_rownames(\"PatientID\")\n  otu_tab <- otu_tab %>%\n    dplyr::select(all_of(rownames(sam_tab)))\n\n\n  if (!is.null(tax_tab)) {\n    tax_tab <- phyloseq::tax_table(as(tax_tab, \"matrix\"))\n  }\n\n  if (!is.null(sam_tab)) {\n    sam_tab <- phyloseq::sample_data(sam_tab %>% data.frame())\n  }\n\n  asv_tab <- phyloseq::otu_table(as(otu_tab, \"matrix\"),\n                                 taxa_are_rows = TRUE)\n\n  ps <- phyloseq::phyloseq(asv_tab, tax_tab, sam_tab)\n\n  return(ps)\n}\n\n\ntaxa_gut_list <- import_metaphlan_taxa(data_metaphlan2 = taxa_gut)\ntaxa_ora_list <- import_metaphlan_taxa(data_metaphlan2 = taxa_ora)\n\nps_gut <- get_metaphlan_phyloseq(otu_tab = taxa_gut_list$abu_tab,\n                                 sam_tab = metadata,\n                                 tax_tab = taxa_ora_list$tax_tab)\nps_gut\n#> phyloseq-class experiment-level object\n#> otu_table()   OTU Table:         [ 547 taxa and 42 samples ]\n#> sample_data() Sample Data:       [ 42 samples by 46 sample variables ]\n#> tax_table()   Taxonomy Table:    [ 547 taxa by 7 taxonomic ranks ]\n\nps_ora <- get_metaphlan_phyloseq(otu_tab = taxa_ora_list$abu_tab,\n                                 sam_tab = metadata,\n                                 tax_tab = taxa_ora_list$tax_tab)\nps_ora\n#> phyloseq-class experiment-level object\n#> otu_table()   OTU Table:         [ 547 taxa and 41 samples ]\n#> sample_data() Sample Data:       [ 41 samples by 46 sample variables ]\n#> tax_table()   Taxonomy Table:    [ 547 taxa by 7 taxonomic ranks ]\nmetabolites_fecal$metabolitesID <- paste0(\"Chem_\", metabolites_fecal$CHEMICALID)\n\n# Row->metabolites; Col->Samples\nmetabolites_fecal_assay <- metabolites_fecal %>%\n  dplyr::select(c(\"metabolitesID\", c(starts_with(\"P10\")))) %>%\n  tibble::column_to_rownames(\"metabolitesID\")\n\nmetabolites_fecal_rowData <- metabolites_fecal %>%\n  dplyr::select(-c(starts_with(\"P10\"))) %>%\n  dplyr::select(metabolitesID, everything())\n\nmetabolites_fecal_colData <- metadata  %>%\n  dplyr::filter(PatientID %in% colnames(metabolites_fecal_assay)) %>%\n  dplyr::arrange(PatientID)\n\nmetabolites_fecal_assay <- metabolites_fecal_assay %>%\n  dplyr::select(all_of(metabolites_fecal_colData$PatientID))\n\n\nse_metabolite <- SummarizedExperiment(\n                     assays = metabolites_fecal_assay,\n                     rowData = metabolites_fecal_rowData,\n                     colData = metabolites_fecal_colData,\n                     checkDimnames = TRUE)\n\nse_metabolite\n#> class: SummarizedExperiment \n#> dim: 1032 55 \n#> metadata(0):\n#> assays(1): ''\n#> rownames(1032): Chem_100002945 Chem_100002356 ...\n#>   Chem_100015836 Chem_826\n#> rowData names(13): metabolitesID BIOCHEMICAL ... KEGG\n#>   SampleIDHMDBID\n#> colnames(55): P101001 P101003 ... P101095 P101096\n#> colData names(47): PatientID Gender ...\n#>   Right_leg_fat_free_mass Right_leg_total_body_water\nprotein_plasma_new <- protein_plasma %>%\n  dplyr::rename(ProteinID=SampleName)\nprotein_plasma_new$ProteinID <- gsub(\"-\", \"_\", protein_plasma_new$ProteinID)\n\n# Row->proteins; Col->Samples\nprotein_plasma_assay <- protein_plasma_new %>%\n  dplyr::select(c(\"ProteinID\", c(starts_with(\"P10\")))) %>%\n  tibble::column_to_rownames(\"ProteinID\")\n\nprotein_plasma_rowData <- protein_plasma_new %>%\n  dplyr::select(-c(starts_with(\"P10\"))) %>%\n  dplyr::select(ProteinID, everything())\n\nprotein_plasma_colData <- metadata %>%\n  dplyr::filter(PatientID %in% colnames(protein_plasma_assay)) %>%\n  dplyr::arrange(PatientID)\n\nprotein_plasma_assay <- protein_plasma_assay %>%\n  dplyr::select(all_of(protein_plasma_colData$PatientID))\n\nse_protein <- SummarizedExperiment(\n                     assays = protein_plasma_assay,\n                     rowData = protein_plasma_rowData,\n                     colData = protein_plasma_colData,\n                     checkDimnames = TRUE)\n\nse_protein\n#> class: SummarizedExperiment \n#> dim: 72 54 \n#> metadata(0):\n#> assays(1): ''\n#> rownames(72): IL8 VEGFA ... TNFB CSF_1\n#> rowData names(3): ProteinID LOD prop\n#> colnames(54): P101001 P101003 ... P101095 P101096\n#> colData names(47): PatientID Gender ...\n#>   Right_leg_fat_free_mass Right_leg_total_body_water\nif (!dir.exists(\"./InputData/result/\")) {\n  dir.create(\"./InputData/result/\", recursive = TRUE)\n}\n\nsaveRDS(ps_gut, \"./InputData/result/Zeybel_2022_gut_MGS_ps.RDS\", compress = TRUE)\nsaveRDS(ps_ora, \"./InputData/result/Zeybel_2022_oral_MGS_ps.RDS\", compress = TRUE)\nsaveRDS(se_metabolite, \"./InputData/result/Zeybel_2022_fecal_metabolite_se.RDS\", compress = TRUE)\nsaveRDS(se_protein, \"./InputData/result/Zeybel_2022_plasma_protein_se.RDS\", compress = TRUE)"},{"path":"ZeybelDataset.html","id":"longitudinal-data-1","chapter":"2 Zeybel Dataset","heading":"2.4 longitudinal data","text":"metadataphyloseq-class objectSummarizedExperiment: metabolitesSummarizedExperiment: proteomics","code":"\n# after\nmetadata_after <- long_meta_info %>%\n  dplyr::inner_join(long_meta_clin,\n                    by = \"PatientID\") %>%\n  dplyr::select(PatientID, Gender, Age, everything())\n\n\n# before\nmetadata_before <- metadata %>%\n  dplyr::filter(PatientID %in% metadata_after$PatientID) %>%\n  dplyr::mutate(Stage = \"Before\")\n\n# cbind\nlong_metadata <- rbind(metadata_before, metadata_after) %>%\n  dplyr::mutate(SampleID = paste(PatientID, Stage, sep = \"_\")) %>%\n  dplyr::select(SampleID, PatientID, Gender, Age, Stage,\n                LiverFatClass,\n                Weight, Body_mass_index,\n                Hip_circumference,\n                Waist_circumference, everything()) %>%\n  dplyr::arrange(PatientID, desc(Stage))\n\nhead(long_metadata)\n#> # A tibble: 6 × 49\n#>   SampleID PatientID Gender   Age Stage LiverFatClass Weight\n#>   <chr>    <chr>     <chr>  <dbl> <chr> <chr>          <dbl>\n#> 1 P101001… P101001   Male      52 Befo… Severe          83  \n#> 2 P101001… P101001   Male      52 After Severe          82.8\n#> 3 P101004… P101004   Male      43 Befo… Moderate        88  \n#> 4 P101004… P101004   Male      43 After Moderate        88.6\n#> 5 P101007… P101007   Female    61 Befo… Severe          95  \n#> 6 P101007… P101007   Female    61 After Moderate        96.7\n#> # ℹ 42 more variables: Body_mass_index <dbl>,\n#> #   Hip_circumference <dbl>, Waist_circumference <dbl>,\n#> #   AlcoholConsumption <chr>, Smoker <chr>,\n#> #   Liver_fat <dbl>, Sodium <dbl>, Potassium <dbl>,\n#> #   Creatinine <dbl>, Urea_BUN <dbl>, Uric_acid <dbl>,\n#> #   ALT <dbl>, AST <dbl>, GGT <dbl>,\n#> #   Alkaline_phosphatase <dbl>, Total_Bilirubin <dbl>, …\nget_long_taxa <- function(x, y) {\n\n  # x = long_taxa_gut\n  # y = taxa_gut_list\n\n  dat <- x\n  otu_tab <- y$abu_tab\n  tax_tab <- y$tax_tab\n\n  dat$TaxaID <- paste0(\"s__\", dat$TaxaID)\n  dat <- dat %>%\n    tibble::column_to_rownames(\"TaxaID\")\n  dat_cln <- dat[, !is.na(colSums(dat))]\n  sid <- intersect(colnames(dat_cln), colnames(otu_tab))\n  # before\n  dat_before <- otu_tab %>%\n    dplyr::select(all_of(sid))\n  dat_after <- dat_cln %>%\n    dplyr::select(all_of(sid))\n\n  colnames(dat_before) <- paste0(colnames(dat_before), \"_Before\")\n  colnames(dat_after) <- paste0(colnames(dat_after), \"_After\")\n\n  mdat <- dat_before %>%\n    tibble::rownames_to_column(\"TaxaID\") %>%\n    dplyr::inner_join(dat_after %>%\n                        tibble::rownames_to_column(\"TaxaID\"),\n                      by = \"TaxaID\") %>%\n    tibble::column_to_rownames(\"TaxaID\")\n\n  tax_tab_mdat <- tax_tab[rownames(tax_tab)%in%rownames(mdat), , ]\n\n\n  res <- list(abu_tab = mdat,\n              tax_tab = tax_tab_mdat)\n\n  return(res)\n}\n\n\nget_metaphlan_phyloseq2 <- function(\n    otu_tab,\n    sam_tab,\n    tax_tab = NULL) {\n\n  sid <- intersect(sam_tab$SampleID, colnames(otu_tab))\n\n  sam_tab <- sam_tab[sam_tab$SampleID %in% sid, ] %>%\n    tibble::column_to_rownames(\"SampleID\")\n  otu_tab <- otu_tab %>%\n    dplyr::select(all_of(rownames(sam_tab)))\n\n\n  if (!is.null(tax_tab)) {\n    tax_tab <- phyloseq::tax_table(as(tax_tab, \"matrix\"))\n  }\n\n  if (!is.null(sam_tab)) {\n    sam_tab <- phyloseq::sample_data(sam_tab %>% data.frame())\n  }\n\n  asv_tab <- phyloseq::otu_table(as(otu_tab, \"matrix\"),\n                                 taxa_are_rows = TRUE)\n\n  ps <- phyloseq::phyloseq(asv_tab, tax_tab, sam_tab)\n\n  return(ps)\n}\n\nlong_taxa_gut_list <- get_long_taxa(x = long_taxa_gut, y = taxa_gut_list)\nlong_taxa_ora_list <- get_long_taxa(x = long_taxa_ora, y = taxa_ora_list)\n\nlong_ps_gut <- get_metaphlan_phyloseq2(\n                      otu_tab = long_taxa_gut_list$abu_tab,\n                      sam_tab = long_metadata,\n                      tax_tab = long_taxa_gut_list$tax_tab)\nlong_ps_gut\n#> phyloseq-class experiment-level object\n#> otu_table()   OTU Table:         [ 547 taxa and 34 samples ]\n#> sample_data() Sample Data:       [ 34 samples by 48 sample variables ]\n#> tax_table()   Taxonomy Table:    [ 547 taxa by 7 taxonomic ranks ]\n\nlong_ps_ora <- get_metaphlan_phyloseq2(\n                      otu_tab = long_taxa_ora_list$abu_tab,\n                      sam_tab = long_metadata,\n                      tax_tab = long_taxa_ora_list$tax_tab)\nlong_ps_ora\n#> phyloseq-class experiment-level object\n#> otu_table()   OTU Table:         [ 547 taxa and 36 samples ]\n#> sample_data() Sample Data:       [ 36 samples by 48 sample variables ]\n#> tax_table()   Taxonomy Table:    [ 547 taxa by 7 taxonomic ranks ]\nmetabolites_ID <- intersect(metabolites_fecal$BIOCHEMICAL, long_metabolites_fecal$MetaboliteID)\nlong_metabolites_fecal_rowData <- metabolites_fecal_rowData %>%\n  dplyr::filter(BIOCHEMICAL %in% metabolites_ID)\n\n# Row->metabolites; Col->Samples\nlong_metabolites_fecal_assay_after <- long_metabolites_fecal %>%\n  dplyr::inner_join(long_metabolites_fecal_rowData %>%\n                      dplyr::select(metabolitesID, BIOCHEMICAL),\n                    by = c(MetaboliteID = \"BIOCHEMICAL\")) %>%\n  dplyr::select(-MetaboliteID) %>%\n  dplyr::select(c(\"metabolitesID\", c(starts_with(\"P10\")))) %>%\n  tibble::column_to_rownames(\"metabolitesID\")\n\nmeta_sid <- intersect(colnames(long_metabolites_fecal_assay_after),\n                 colnames(metabolites_fecal_assay))\nlong_metabolites_fecal_assay_after <- long_metabolites_fecal_assay_after %>%\n  dplyr::select(all_of(meta_sid))\n\nlong_metabolites_fecal_assay_before <-\n  metabolites_fecal_assay[rownames(metabolites_fecal_assay) %in% rownames(long_metabolites_fecal_assay_after),\n                          colnames(metabolites_fecal_assay) %in% colnames(long_metabolites_fecal_assay_after)]\n\ncolnames(long_metabolites_fecal_assay_before) <- paste0(colnames(long_metabolites_fecal_assay_before), \"_Before\")\ncolnames(long_metabolites_fecal_assay_after) <- paste0(colnames(long_metabolites_fecal_assay_after), \"_After\")\n\nlong_metabolites_fecal_assay <- long_metabolites_fecal_assay_before %>%\n  tibble::rownames_to_column(\"TempRowNames\") %>%\n  dplyr::inner_join(long_metabolites_fecal_assay_after %>%\n                      tibble::rownames_to_column(\"TempRowNames\"),\n                    by = \"TempRowNames\") %>%\n  tibble::column_to_rownames(\"TempRowNames\")\n\nlong_metabolites_fecal_colData <- long_metadata  %>%\n  dplyr::filter(SampleID %in% colnames(long_metabolites_fecal_assay)) %>%\n  dplyr::arrange(SampleID)\n\n\nlong_metabolites_fecal_assay <- long_metabolites_fecal_assay %>%\n  dplyr::select(all_of(long_metabolites_fecal_colData$SampleID))\n\n\nlong_se_metabolite <- SummarizedExperiment(\n                     assays = long_metabolites_fecal_assay,\n                     rowData = long_metabolites_fecal_rowData,\n                     colData = long_metabolites_fecal_colData,\n                     checkDimnames = TRUE)\n\nlong_se_metabolite\n#> class: SummarizedExperiment \n#> dim: 929 42 \n#> metadata(0):\n#> assays(1): ''\n#> rownames(929): Chem_100002945 Chem_100002356 ...\n#>   Chem_100015836 Chem_826\n#> rowData names(13): metabolitesID BIOCHEMICAL ... KEGG\n#>   SampleIDHMDBID\n#> colnames(42): P101001_After P101001_Before ...\n#>   P101077_After P101077_Before\n#> colData names(49): SampleID PatientID ...\n#>   Right_leg_fat_free_mass Right_leg_total_body_water\nlong_protein_plasma$ProteinID <- gsub(\"-\", \"_\", long_protein_plasma$ProteinID)\nproteins_ID <- intersect(protein_plasma_new$ProteinID, long_protein_plasma$ProteinID)\n\n# Row->proteins; Col->Samples\nlong_protein_plasma_assay_after <- long_protein_plasma %>%\n  dplyr::filter(ProteinID %in% proteins_ID) %>%\n  dplyr::select(c(ProteinID, c(starts_with(\"P10\")))) %>%\n  tibble::column_to_rownames(\"ProteinID\")\n\npron_id <- intersect(colnames(long_protein_plasma_assay_after),\n                     colnames(protein_plasma_assay))\nlong_protein_plasma_assay_before <- protein_plasma_assay %>%\n  dplyr::select(all_of(pron_id))\nlong_protein_plasma_assay_after <- long_protein_plasma_assay_after %>%\n  dplyr::select(all_of(pron_id))\n\ncolnames(long_protein_plasma_assay_before) <- paste0(colnames(long_protein_plasma_assay_before), \"_Before\")\ncolnames(long_protein_plasma_assay_after) <- paste0(colnames(long_protein_plasma_assay_after), \"_After\")\n\nlong_protein_plasma_assay <- long_protein_plasma_assay_before %>%\n  tibble::rownames_to_column(\"TempRowNames\") %>%\n  dplyr::inner_join(long_protein_plasma_assay_after %>%\n                      tibble::rownames_to_column(\"TempRowNames\"),\n                    by = \"TempRowNames\") %>%\n  tibble::column_to_rownames(\"TempRowNames\")\n\nlong_protein_plasma_rowData <- protein_plasma_rowData %>%\n  dplyr::rename(`Protein ID` = ProteinID)\n\nlong_protein_plasma_colData <- long_metadata  %>%\n  dplyr::filter(SampleID %in% colnames(long_protein_plasma_assay)) %>%\n  dplyr::arrange(SampleID)\n\nlong_protein_plasma_assay <- long_protein_plasma_assay %>%\n  dplyr::select(all_of(long_protein_plasma_colData$SampleID))\n\nlong_se_protein <- SummarizedExperiment(\n                     assays = long_protein_plasma_assay,\n                     rowData = long_protein_plasma_rowData,\n                     colData = long_protein_plasma_colData,\n                     checkDimnames = TRUE)\n\nlong_se_protein\n#> class: SummarizedExperiment \n#> dim: 72 42 \n#> metadata(0):\n#> assays(1): ''\n#> rownames(72): IL8 VEGFA ... TNFB CSF_1\n#> rowData names(3): Protein ID LOD prop\n#> colnames(42): P101001_After P101001_Before ...\n#>   P101077_After P101077_Before\n#> colData names(49): SampleID PatientID ...\n#>   Right_leg_fat_free_mass Right_leg_total_body_water"},{"path":"ZeybelDataset.html","id":"保存数据","chapter":"2 Zeybel Dataset","heading":"2.5 保存数据","text":"","code":"\nif (!dir.exists(\"./InputData/result/\")) {\n  dir.create(\"./InputData/result/\", recursive = TRUE)\n}\n\nsaveRDS(long_ps_gut, \"./InputData/result/Zeybel_2022_gut_MGS_ps_Paired.RDS\", compress = TRUE)\nsaveRDS(long_ps_ora, \"./InputData/result/Zeybel_2022_oral_MGS_ps_Paired.RDS\", compress = TRUE)\nsaveRDS(long_se_metabolite, \"./InputData/result/Zeybel_2022_fecal_metabolite_se_Paired.RDS\", compress = TRUE)\nsaveRDS(long_se_protein, \"./InputData/result/Zeybel_2022_plasma_protein_se_Paired.RDS\", compress = TRUE)"},{"path":"ZeybelDataset.html","id":"session-info","chapter":"2 Zeybel Dataset","heading":"2.6 Session info","text":"","code":"\ndevtools::session_info()\n#> ─ Session info ───────────────────────────────────────────\n#>  setting  value\n#>  version  R version 4.1.3 (2022-03-10)\n#>  os       macOS Big Sur/Monterey 10.16\n#>  system   x86_64, darwin17.0\n#>  ui       X11\n#>  language (EN)\n#>  collate  en_US.UTF-8\n#>  ctype    en_US.UTF-8\n#>  tz       Asia/Shanghai\n#>  date     2024-02-06\n#>  pandoc   3.1.1 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/ (via rmarkdown)\n#> \n#> ─ Packages ───────────────────────────────────────────────\n#>  package              * version   date (UTC) lib source\n#>  ade4                   1.7-22    2023-02-06 [1] CRAN (R 4.1.2)\n#>  ape                    5.7-1     2023-03-13 [1] CRAN (R 4.1.2)\n#>  Biobase              * 2.54.0    2021-10-26 [2] Bioconductor\n#>  BiocGenerics         * 0.40.0    2021-10-26 [2] Bioconductor\n#>  biomformat             1.22.0    2021-10-26 [2] Bioconductor\n#>  Biostrings             2.62.0    2021-10-26 [2] Bioconductor\n#>  bitops                 1.0-7     2021-04-24 [2] CRAN (R 4.1.0)\n#>  bookdown               0.34      2023-05-09 [2] CRAN (R 4.1.2)\n#>  bslib                  0.6.0     2023-11-21 [1] CRAN (R 4.1.3)\n#>  cachem                 1.0.8     2023-05-01 [2] CRAN (R 4.1.2)\n#>  callr                  3.7.3     2022-11-02 [2] CRAN (R 4.1.2)\n#>  cellranger             1.1.0     2016-07-27 [2] CRAN (R 4.1.0)\n#>  cli                    3.6.1     2023-03-23 [2] CRAN (R 4.1.2)\n#>  cluster                2.1.4     2022-08-22 [2] CRAN (R 4.1.2)\n#>  codetools              0.2-19    2023-02-01 [2] CRAN (R 4.1.2)\n#>  colorspace             2.1-0     2023-01-23 [2] CRAN (R 4.1.2)\n#>  crayon                 1.5.2     2022-09-29 [2] CRAN (R 4.1.2)\n#>  data.table             1.14.8    2023-02-17 [2] CRAN (R 4.1.2)\n#>  DBI                    1.1.3     2022-06-18 [2] CRAN (R 4.1.2)\n#>  DelayedArray           0.20.0    2021-10-26 [2] Bioconductor\n#>  devtools               2.4.5     2022-10-11 [2] CRAN (R 4.1.2)\n#>  digest                 0.6.33    2023-07-07 [1] CRAN (R 4.1.3)\n#>  downlit                0.4.3     2023-06-29 [2] CRAN (R 4.1.3)\n#>  dplyr                * 1.1.4     2023-11-17 [1] CRAN (R 4.1.3)\n#>  ellipsis               0.3.2     2021-04-29 [2] CRAN (R 4.1.0)\n#>  evaluate               0.21      2023-05-05 [2] CRAN (R 4.1.2)\n#>  fansi                  1.0.4     2023-01-22 [2] CRAN (R 4.1.2)\n#>  fastmap                1.1.1     2023-02-24 [2] CRAN (R 4.1.2)\n#>  foreach                1.5.2     2022-02-02 [2] CRAN (R 4.1.2)\n#>  fs                     1.6.2     2023-04-25 [2] CRAN (R 4.1.2)\n#>  generics               0.1.3     2022-07-05 [2] CRAN (R 4.1.2)\n#>  GenomeInfoDb         * 1.30.1    2022-01-30 [2] Bioconductor\n#>  GenomeInfoDbData       1.2.7     2022-03-09 [2] Bioconductor\n#>  GenomicRanges        * 1.46.1    2021-11-18 [2] Bioconductor\n#>  ggplot2                3.4.4     2023-10-12 [1] CRAN (R 4.1.3)\n#>  glue                   1.6.2     2022-02-24 [2] CRAN (R 4.1.2)\n#>  gtable                 0.3.3     2023-03-21 [2] CRAN (R 4.1.2)\n#>  htmltools              0.5.7     2023-11-03 [1] CRAN (R 4.1.3)\n#>  htmlwidgets            1.6.2     2023-03-17 [2] CRAN (R 4.1.2)\n#>  httpuv                 1.6.11    2023-05-11 [2] CRAN (R 4.1.3)\n#>  igraph                 1.5.0     2023-06-16 [1] CRAN (R 4.1.3)\n#>  IRanges              * 2.28.0    2021-10-26 [2] Bioconductor\n#>  iterators              1.0.14    2022-02-05 [2] CRAN (R 4.1.2)\n#>  jquerylib              0.1.4     2021-04-26 [2] CRAN (R 4.1.0)\n#>  jsonlite               1.8.7     2023-06-29 [2] CRAN (R 4.1.3)\n#>  knitr                  1.43      2023-05-25 [2] CRAN (R 4.1.3)\n#>  later                  1.3.1     2023-05-02 [2] CRAN (R 4.1.2)\n#>  lattice                0.21-8    2023-04-05 [2] CRAN (R 4.1.2)\n#>  lifecycle              1.0.3     2022-10-07 [2] CRAN (R 4.1.2)\n#>  magrittr               2.0.3     2022-03-30 [2] CRAN (R 4.1.2)\n#>  MASS                   7.3-60    2023-05-04 [1] CRAN (R 4.1.2)\n#>  Matrix                 1.6-5     2024-01-11 [1] CRAN (R 4.1.3)\n#>  MatrixGenerics       * 1.6.0     2021-10-26 [2] Bioconductor\n#>  matrixStats          * 1.1.0     2023-11-07 [1] CRAN (R 4.1.3)\n#>  memoise                2.0.1     2021-11-26 [2] CRAN (R 4.1.0)\n#>  mgcv                   1.8-42    2023-03-02 [2] CRAN (R 4.1.2)\n#>  mime                   0.12      2021-09-28 [2] CRAN (R 4.1.0)\n#>  miniUI                 0.1.1.1   2018-05-18 [2] CRAN (R 4.1.0)\n#>  multtest               2.50.0    2021-10-26 [2] Bioconductor\n#>  munsell                0.5.0     2018-06-12 [2] CRAN (R 4.1.0)\n#>  nlme                   3.1-162   2023-01-31 [1] CRAN (R 4.1.2)\n#>  permute                0.9-7     2022-01-27 [2] CRAN (R 4.1.2)\n#>  phyloseq             * 1.38.0    2021-10-26 [2] Bioconductor\n#>  pillar                 1.9.0     2023-03-22 [2] CRAN (R 4.1.2)\n#>  pkgbuild               1.4.2     2023-06-26 [2] CRAN (R 4.1.3)\n#>  pkgconfig              2.0.3     2019-09-22 [2] CRAN (R 4.1.0)\n#>  pkgload                1.3.2.1   2023-07-08 [2] CRAN (R 4.1.3)\n#>  plyr                   1.8.8     2022-11-11 [1] CRAN (R 4.1.2)\n#>  prettyunits            1.1.1     2020-01-24 [2] CRAN (R 4.1.0)\n#>  processx               3.8.2     2023-06-30 [2] CRAN (R 4.1.3)\n#>  profvis                0.3.8     2023-05-02 [2] CRAN (R 4.1.2)\n#>  promises               1.2.0.1   2021-02-11 [2] CRAN (R 4.1.0)\n#>  ps                     1.7.5     2023-04-18 [2] CRAN (R 4.1.2)\n#>  purrr                  1.0.1     2023-01-10 [1] CRAN (R 4.1.2)\n#>  R6                     2.5.1     2021-08-19 [2] CRAN (R 4.1.0)\n#>  Rcpp                   1.0.11    2023-07-06 [1] CRAN (R 4.1.3)\n#>  RCurl                  1.98-1.12 2023-03-27 [2] CRAN (R 4.1.2)\n#>  readxl                 1.4.3     2023-07-06 [2] CRAN (R 4.1.3)\n#>  remotes                2.4.2     2021-11-30 [2] CRAN (R 4.1.0)\n#>  reshape2               1.4.4     2020-04-09 [2] CRAN (R 4.1.0)\n#>  rhdf5                  2.38.1    2022-03-10 [2] Bioconductor\n#>  rhdf5filters           1.6.0     2021-10-26 [2] Bioconductor\n#>  Rhdf5lib               1.16.0    2021-10-26 [2] Bioconductor\n#>  rlang                  1.1.1     2023-04-28 [1] CRAN (R 4.1.2)\n#>  rmarkdown              2.23      2023-07-01 [2] CRAN (R 4.1.3)\n#>  rstudioapi             0.15.0    2023-07-07 [2] CRAN (R 4.1.3)\n#>  S4Vectors            * 0.32.4    2022-03-29 [2] Bioconductor\n#>  sass                   0.4.6     2023-05-03 [2] CRAN (R 4.1.2)\n#>  scales                 1.2.1     2022-08-20 [1] CRAN (R 4.1.2)\n#>  sessioninfo            1.2.2     2021-12-06 [2] CRAN (R 4.1.0)\n#>  shiny                  1.7.4.1   2023-07-06 [2] CRAN (R 4.1.3)\n#>  stringi                1.7.12    2023-01-11 [2] CRAN (R 4.1.2)\n#>  stringr                1.5.1     2023-11-14 [1] CRAN (R 4.1.3)\n#>  SummarizedExperiment * 1.24.0    2021-10-26 [2] Bioconductor\n#>  survival               3.5-5     2023-03-12 [2] CRAN (R 4.1.2)\n#>  tibble               * 3.2.1     2023-03-20 [1] CRAN (R 4.1.2)\n#>  tidyselect             1.2.0     2022-10-10 [2] CRAN (R 4.1.2)\n#>  urlchecker             1.0.1     2021-11-30 [2] CRAN (R 4.1.0)\n#>  usethis                2.2.2     2023-07-06 [2] CRAN (R 4.1.3)\n#>  utf8                   1.2.3     2023-01-31 [2] CRAN (R 4.1.2)\n#>  vctrs                  0.6.5     2023-12-01 [1] CRAN (R 4.1.3)\n#>  vegan                  2.6-4     2022-10-11 [1] CRAN (R 4.1.2)\n#>  withr                  2.5.0     2022-03-03 [2] CRAN (R 4.1.2)\n#>  xfun                   0.40      2023-08-09 [1] CRAN (R 4.1.3)\n#>  xml2                   1.3.5     2023-07-06 [2] CRAN (R 4.1.3)\n#>  xtable                 1.8-4     2019-04-21 [2] CRAN (R 4.1.0)\n#>  XVector                0.34.0    2021-10-26 [2] Bioconductor\n#>  yaml                   2.3.7     2023-01-23 [2] CRAN (R 4.1.2)\n#>  zlibbioc               1.40.0    2021-10-26 [2] Bioconductor\n#> \n#>  [1] /Users/zouhua/Library/R/x86_64/4.1/library\n#>  [2] /Library/Frameworks/R.framework/Versions/4.1/Resources/library\n#> \n#> ──────────────────────────────────────────────────────────"},{"path":"ZeybelDataset.html","id":"reference","chapter":"2 Zeybel Dataset","heading":"2.7 Reference","text":"Multiomics Analysis Reveals Impact Microbiota Host Metabolism Hepatic SteatosisMultiomics Analysis Reveals Impact Microbiota Host Metabolism Hepatic SteatosisBasic storage, access, manipulation phylogenetic sequencing data phyloseqBasic storage, access, manipulation phylogenetic sequencing data phyloseqPractical: Organizing data SummarizedExperimentPractical: Organizing data SummarizedExperiment","code":""},{"path":"GEEandMLM.html","id":"GEEandMLM","chapter":"3 GEE and MLM","heading":"3 GEE and MLM","text":"Tutorial Generalized Estimating Equations Mixed Linear Models针对某个科学问题，通常会在一段时间内对多个同一研究对象进行多次或重复测量，这类数据一般称为纵向数据。纵向数据具有两个特点，一是研究对象重复；二是观察值可能存在缺失值。上述两个因素导致在探索结果和观测指标相关性分析时，一般线性（linear regression model）或广义线性模型（generalized regression model）以及重复测量方差分析（repeated ANOVA）均不适用。因此，广义估计方程(generalized estimating equations，GEE) 和混合线性模型(mixed linear model，MLM) 被广泛应用于纵向数据的统计分析。广义估计方程(generalized estimating equations，GEE)： 假定每个研究对象的重复观察值间存在某种类型的作业相关矩阵（应变量的各次重复测量值两两之间相关性的大小），应用准似然函数原理，可以得到回归系数及其方差的一致性估计广义估计方程(generalized estimating equations，GEE)： 假定每个研究对象的重复观察值间存在某种类型的作业相关矩阵（应变量的各次重复测量值两两之间相关性的大小），应用准似然函数原理，可以得到回归系数及其方差的一致性估计混合线性模型(mixed linear model，MLM)：它是一类对误差进行精细分解成对固定效应和随机效应等误差的广义线性模型的方法，相比广义线性模型而言，它能处理纵向数据（如时间序列数据，时间一般作为随机因素）。混合线性模型(mixed linear model，MLM)：它是一类对误差进行精细分解成对固定效应和随机效应等误差的广义线性模型的方法，相比广义线性模型而言，它能处理纵向数据（如时间序列数据，时间一般作为随机因素）。上述两种方法适合解析因变量和自变量的相关性","code":""},{"path":"GEEandMLM.html","id":"原理","chapter":"3 GEE and MLM","heading":"3.1 原理","text":"基本概念自变量（independent variable）：又称独立变量、解释变量（explanatory variable）、外生变量，是可由研究者选择、控制、研究，且能独立变化而影响或引起其他变量变化的条件或因素（变数、变量、变项），因此自变量被看作是因变量的原因。自变量（independent variable）：又称独立变量、解释变量（explanatory variable）、外生变量，是可由研究者选择、控制、研究，且能独立变化而影响或引起其他变量变化的条件或因素（变数、变量、变项），因此自变量被看作是因变量的原因。因变量（dependent variable）：又称应变量、被解释变量、内生变量、反应变量、响应变量（response variable）、依变量、果变量，亦即要研究的目标变量，其取值可被观测且随自变量的变化而变化。因变量（dependent variable）：又称应变量、被解释变量、内生变量、反应变量、响应变量（response variable）、依变量、果变量，亦即要研究的目标变量，其取值可被观测且随自变量的变化而变化。控制变量（controlled variable）：又称额外变量（extraneous variable）、无关变量，是除了实验因素（自变量）以外，所有可能影响实验变化和结果并需要进行控制的潜在条件或因素（变数、变量、变项）控制变量（controlled variable）：又称额外变量（extraneous variable）、无关变量，是除了实验因素（自变量）以外，所有可能影响实验变化和结果并需要进行控制的潜在条件或因素（变数、变量、变项）协变量（covariate）：在实验的设计中，协变量是一个独立变量(解释变量)，不为实验者所操纵，但仍影响响应。同时，它指与因变量有线性相关并在探讨自变量与因变量关系时通过统计技术加以控制 的变量。常用的协变量包括因变量的前测分数、人口统计学指标以及与因变量明显不同的个人特征等。协变量应该属于控制变量的一种。有些控制变量可以通过实验操作加以控制(如照明、室温等)，也称为无关变量；而另一些控制变量由于受实验设计等因素的限制，只能借助统计技术来加以控制，即成了统计分析中的协变量，因而属于统计概念。协变量（covariate）：在实验的设计中，协变量是一个独立变量(解释变量)，不为实验者所操纵，但仍影响响应。同时，它指与因变量有线性相关并在探讨自变量与因变量关系时通过统计技术加以控制 的变量。常用的协变量包括因变量的前测分数、人口统计学指标以及与因变量明显不同的个人特征等。协变量应该属于控制变量的一种。有些控制变量可以通过实验操作加以控制(如照明、室温等)，也称为无关变量；而另一些控制变量由于受实验设计等因素的限制，只能借助统计技术来加以控制，即成了统计分析中的协变量，因而属于统计概念。假定因变量y，自变量X，作为固定变量，而Z则是随机变量（协变量）。广义估计方程(generalized estimating equations，GEE)\n建立结果变量y与协变量Z之间（每个协变量内含有对应的自变量X）的函数关系\n建立y的方差与平均值之间的函数关系\n对y构建一个P*P维作业相关矩阵（自变量X），用以表示因变量的各次重复测量值（自变量）之间的相关性大小\n求参数\\(\\beta\\)的估计值及其协方差矩阵\n广义估计方程(generalized estimating equations，GEE)建立结果变量y与协变量Z之间（每个协变量内含有对应的自变量X）的函数关系建立结果变量y与协变量Z之间（每个协变量内含有对应的自变量X）的函数关系建立y的方差与平均值之间的函数关系建立y的方差与平均值之间的函数关系对y构建一个P*P维作业相关矩阵（自变量X），用以表示因变量的各次重复测量值（自变量）之间的相关性大小对y构建一个P*P维作业相关矩阵（自变量X），用以表示因变量的各次重复测量值（自变量）之间的相关性大小求参数\\(\\beta\\)的估计值及其协方差矩阵求参数\\(\\beta\\)的估计值及其协方差矩阵混合线性模型(mixed linear model，MLM)：构建包含固定因子和随机因子的线性混合模型混合线性模型(mixed linear model，MLM)：构建包含固定因子和随机因子的线性混合模型\\[y = X\\beta + Z\\mu + \\epsilon \\]\\(\\beta\\) 是固定效应值；\\(\\beta\\) 是固定效应值；\\(\\mu\\) 是随机效应值；\\(\\mu\\) 是随机效应值；\\(\\epsilon\\) 是随机误差向量（拟合值和真实值的误差）；\\(\\epsilon\\) 是随机误差向量（拟合值和真实值的误差）；回归系数的95% 置信区间计算：\\[CI_{0.95}^{\\beta_{}} = [\\beta_{} - 1.96 * SE(\\beta_{}),\\space \\beta_{} + 1.96 * SE(\\beta_{})]\\]为各个变量之间存在不同的单位也即是量纲可能不同，所以对数据做归一化和标准化处理是必须的。","code":""},{"path":"GEEandMLM.html","id":"加载r包-1","chapter":"3 GEE and MLM","heading":"3.2 加载R包","text":"","code":"\nknitr::opts_chunk$set(message = FALSE, warning = FALSE)\nlibrary(tidyverse)\nlibrary(data.table)\n\n# rm(list = ls())\noptions(stringsAsFactors = F)\noptions(future.globals.maxSize = 1000 * 1024^2)"},{"path":"GEEandMLM.html","id":"导入数据","chapter":"3 GEE and MLM","heading":"3.3 导入数据","text":"可以点击此处下载数据data_dropout.csv本案例数据来源于一个肾脏病的研究。研究对200个肾病患者进行随访，每年化验一次肾小球滤过率（GFR，评价肾脏功能的指标，会逐年下降）。主要分析目的是探索基线的尿蛋白定量对GFR年下降率（斜率）的影响（尿蛋白量越大，对肾功能危害越大），混杂因素包括基线年龄和性别。patient: 患者ID编号；patient: 患者ID编号；visit：化验次序编号visit：化验次序编号time：化验时间（单位年），第一次化验定为0，后面依次推延；time：化验时间（单位年），第一次化验定为0，后面依次推延；GFR：肾小球滤过率，单位是ml/min/1.73^2，作为响应变量；GFR：肾小球滤过率，单位是ml/min/1.73^2，作为响应变量；age：基线年龄，单位岁；age：基线年龄，单位岁；gender：性别，0=男，1=女；gender：性别，0=男，1=女；micro：基线是否有微量蛋白尿，0=正常蛋白组，1=有；micro：基线是否有微量蛋白尿，0=正常蛋白组，1=有；macro：基线是否有大量蛋白尿，0=正常蛋白组，1=有；macro：基线是否有大量蛋白尿，0=正常蛋白组，1=有；","code":"\ndataset <- data.table::fread(\"./InputData/TherapyData/data_dropout.csv\")\n\ndataset <- dataset |>\n  dplyr::select(-all_of(c(\"line\", \"normo\")))\n\nhead(dataset)\n#>    patient visit     time      GFR      age gender micro\n#> 1:       1     1 0.000000 34.82791 78.55559      1     1\n#> 2:       1     2 1.119435 16.82267 78.55559      1     1\n#> 3:       1     3 2.243480 31.60634 78.55559      1     1\n#> 4:       1     4 3.028584 42.46687 78.55559      1     1\n#> 5:       1     5 3.821319 39.07992 78.55559      1     1\n#> 6:       1     6 4.740926 30.38522 78.55559      1     1\n#>    macro\n#> 1:     0\n#> 2:     0\n#> 3:     0\n#> 4:     0\n#> 5:     0\n#> 6:     0"},{"path":"GEEandMLM.html","id":"研究问题","chapter":"3 GEE and MLM","heading":"3.4 研究问题","text":"患者GFR是否受到基线年龄、性别、尿蛋白情况以及化验时间影响。另外根据专业医学知识，假设尿蛋白不仅影响GFR的下降率，也影响基线GFR，也即是time和尿蛋白micro和macro存在交互影响（此地排除age，gender对GFR下降率的影响）。预测变量还需要加上一个时间x尿蛋白的交互项（交互项是指不同的尿蛋白等级会有不同的GFR下降斜率和下降曲线）","code":""},{"path":"GEEandMLM.html","id":"数据特点","chapter":"3 GEE and MLM","heading":"3.5 数据特点","text":"","code":"\nsummary(dataset) \n#>     patient           visit            time      \n#>  Min.   :  1.00   Min.   :1.000   Min.   :0.000  \n#>  1st Qu.: 52.00   1st Qu.:2.000   1st Qu.:1.164  \n#>  Median : 99.50   Median :4.000   Median :2.986  \n#>  Mean   : 99.98   Mean   :4.183   Mean   :3.161  \n#>  3rd Qu.:149.00   3rd Qu.:6.000   3rd Qu.:5.013  \n#>  Max.   :200.00   Max.   :8.000   Max.   :8.185  \n#>       GFR               age            gender     \n#>  Min.   : -5.966   Min.   :20.00   Min.   :0.000  \n#>  1st Qu.: 30.793   1st Qu.:48.89   1st Qu.:0.000  \n#>  Median : 46.164   Median :60.63   Median :0.000  \n#>  Mean   : 46.518   Mean   :59.36   Mean   :0.307  \n#>  3rd Qu.: 60.888   3rd Qu.:69.65   3rd Qu.:1.000  \n#>  Max.   :109.874   Max.   :90.00   Max.   :1.000  \n#>      micro            macro       \n#>  Min.   :0.0000   Min.   :0.0000  \n#>  1st Qu.:0.0000   1st Qu.:0.0000  \n#>  Median :0.0000   Median :0.0000  \n#>  Mean   :0.3019   Mean   :0.2431  \n#>  3rd Qu.:1.0000   3rd Qu.:0.0000  \n#>  Max.   :1.0000   Max.   :1.0000\ndataset %>%\n  group_by(patient) %>%\n    summarise(\n      count = n(),\n      mean = mean(GFR, na.rm=TRUE),\n      sd = sd(GFR, na.rm=TRUE)\n    )\n#> # A tibble: 200 × 4\n#>    patient count  mean    sd\n#>      <int> <int> <dbl> <dbl>\n#>  1       1     8  30.9  8.11\n#>  2       2     8  76.2 12.9 \n#>  3       3     8  39.8 14.2 \n#>  4       4     4  17.2 17.8 \n#>  5       5     8  73.7  6.58\n#>  6       6     6  25.2 10.5 \n#>  7       7     8  37.3  5.37\n#>  8       8     8  35.2  6.44\n#>  9       9     4  27.0 14.3 \n#> 10      10     8  45.3  7.22\n#> # ℹ 190 more rows\nggplot(data = dataset, aes(x = time, y = GFR, group = patient, color = patient)) +\n  geom_line(alpha = .3) + \n  labs(title = \"GFR Levels of Patient across the therapeutic times\") +\n  theme(legend.position = \"none\")\nrando <- sample(unique(dataset$patient), 10)\nindplot <- subset(dataset, patient %in% rando)\nggplot(indplot, aes(x = time, y = GFR)) + \n  geom_line(color = \"tomato\") + \n  facet_wrap( ~ patient) + \n  labs(x = \"time\", y=\"GFR Levels\", title=\"Individual GFR Levels\\nfor a Random Sample of Patients\") + \n  theme(axis.text.x=element_blank(), axis.ticks.x=element_blank())"},{"path":"GEEandMLM.html","id":"广义估计方程generalized-estimating-equationsgee","chapter":"3 GEE and MLM","heading":"3.6 广义估计方程(generalized estimating equations，GEE)","text":"自变量（independent variable）：age，gender，micro，macro，time自变量（independent variable）：age，gender，micro，macro，time因变量（dependent variable）：GFR因变量（dependent variable）：GFR协变量（covariate）：patient协变量（covariate）：patientGEE通过协变量patient考虑到他们内部观测值的相关性后再对总体效应进行推断，如何确定分组需要考虑到组群变量。除此之外，确定组内相关关系，还需要考虑到组内观测之间的相关性是相互独立还是相互依赖等各种情况。GFR ~ age + gender + micro + macro + time + micro:time + macro:time是因变量和自变量的线性关系方程式，其中micro:time是交互式影响自变量GFR ~ age + gender + micro + macro + time + micro:time + macro:time是因变量和自变量的线性关系方程式，其中micro:time是交互式影响自变量id = patient表示每个patients是一个内在cluster的标识，用于剔除内在相关关系id = patient表示每个patients是一个内在cluster的标识，用于剔除内在相关关系std.err = \"san.se\"计算评估系数的标准误差，san.se适合cluster数目小于等于30的数据集std.err = \"san.se\"计算评估系数的标准误差，san.se适合cluster数目小于等于30的数据集corstr = \"exchangeable\"是构造自变量作业相关矩阵参数\nexchangeable correlation：假设一个cluster里的不同观察是等相关的，并且是时间不依赖的\nautoregressive correlation：假设一个cluster里的不同观察是等相关的，假设一个cluster内的观察是时间依赖的\nunstructured correlation：general correlation structures discuss. imposes structure correlation matrix.\nuserdefined correlation：根据自变量自身特点构造作业相关矩阵\ncorstr = \"exchangeable\"是构造自变量作业相关矩阵参数exchangeable correlation：假设一个cluster里的不同观察是等相关的，并且是时间不依赖的exchangeable correlation：假设一个cluster里的不同观察是等相关的，并且是时间不依赖的autoregressive correlation：假设一个cluster里的不同观察是等相关的，假设一个cluster内的观察是时间依赖的autoregressive correlation：假设一个cluster里的不同观察是等相关的，假设一个cluster内的观察是时间依赖的unstructured correlation：general correlation structures discuss. imposes structure correlation matrix.unstructured correlation：general correlation structures discuss. imposes structure correlation matrix.userdefined correlation：根据自变量自身特点构造作业相关矩阵userdefined correlation：根据自变量自身特点构造作业相关矩阵family = \"gaussian\"是连接函数，链接因变量和自变量（很多中文教程说是协变量）线性关系的函数family = \"gaussian\"是连接函数，链接因变量和自变量（很多中文教程说是协变量）线性关系的函数提取结果Estimate：\\(\\beta\\)相关系数，其中_Intercept_是截距估计值。提供了截距和预测变量的估计系数。Estimate：\\(\\beta\\)相关系数，其中_Intercept_是截距估计值。提供了截距和预测变量的估计系数。Std.err：\\(\\beta\\)相关系的标准误差。给出了与系数估计相关的标准误差。这些是参数估计的不确定性的度量。Std.err：\\(\\beta\\)相关系的标准误差。给出了与系数估计相关的标准误差。这些是参数估计的不确定性的度量。Wald：\\(\\beta\\)相关系的wald检验统计量（检验约束条件是否成立的方法之一：F检验、似然比检验（LR）、沃尔德检验（Wald）和拉格朗日乘子检验（LM））Wald：\\(\\beta\\)相关系的wald检验统计量（检验约束条件是否成立的方法之一：F检验、似然比检验（LR）、沃尔德检验（Wald）和拉格朗日乘子检验（LM））Pr(>|W|)：\\(\\beta\\)相关系的wald检验统计量对应pvalue。提供了与Wald检验相关的p值。它指示系数是否具有统计显著性。Pr(>|W|)：\\(\\beta\\)相关系的wald检验统计量对应pvalue。提供了与Wald检验相关的p值。它指示系数是否具有统计显著性。Estimate_95CI：\\(\\beta\\)置信区间提供可以合理确信真实总体参数位于其中的范围。Estimate 和 Std.err 值用于计算置信区间。例如，micro 变量的比值几率的95%置信区间可能是 [-23.75, -16.72]。该区间表示可以有95%的信心，真实的GFR比值几率位于-23.75和-16.72之间。Estimate_95CI：\\(\\beta\\)置信区间提供可以合理确信真实总体参数位于其中的范围。Estimate 和 Std.err 值用于计算置信区间。例如，micro 变量的比值几率的95%置信区间可能是 [-23.75, -16.72]。该区间表示可以有95%的信心，真实的GFR比值几率位于-23.75和-16.72之间。OddRatio：风险值，一般用于逻辑回归，可以通过对系数估计进行指数化来计算比值几率。比值几率表示单位预测变量变化时响应变量的几率的乘性变化。在本例中，不适合。OddRatio：风险值，一般用于逻辑回归，可以通过对系数估计进行指数化来计算比值几率。比值几率表示单位预测变量变化时响应变量的几率的乘性变化。在本例中，不适合。在校正年龄和性别下，基线的GFR在micro - 正常蛋白组（micro->1; 正常蛋白组->0）估计值：-20.23 (-23.75, -16.72)；基线的GFR在micro - 正常蛋白组（micro->1; 正常蛋白组->0）估计值：-20.23 (-23.75, -16.72)；平均GFR年下降率（斜率）\ntime（正常蛋白组）：-1.63 (-2.36, -0.9)\nmicro - 正常蛋白组：-1.56 (-2.58, -0.54)\nmacro - 正常蛋白组：-1.06 (-2.43, 0.31)\n平均GFR年下降率（斜率）time（正常蛋白组）：-1.63 (-2.36, -0.9)time（正常蛋白组）：-1.63 (-2.36, -0.9)micro - 正常蛋白组：-1.56 (-2.58, -0.54)micro - 正常蛋白组：-1.56 (-2.58, -0.54)macro - 正常蛋白组：-1.06 (-2.43, 0.31)macro - 正常蛋白组：-1.06 (-2.43, 0.31)","code":"\nlibrary(geepack)\n\ngee_fit <- geeglm(GFR ~ age + gender + micro + macro + time + micro:time + macro:time, \n              id = patient, \n              data = dataset, \n              std.err = \"san.se\",\n              corstr = \"exchangeable\",\n              family = \"gaussian\")\n\ngee_fit\n#> \n#> Call:\n#> geeglm(formula = GFR ~ age + gender + micro + macro + time + \n#>     micro:time + macro:time, family = \"gaussian\", data = dataset, \n#>     id = patient, corstr = \"exchangeable\", std.err = \"san.se\")\n#> \n#> Coefficients:\n#> (Intercept)         age      gender       micro       macro \n#>  81.3842922  -0.2561117  -2.9853967 -20.2334224 -28.7164247 \n#>        time  micro:time  macro:time \n#>  -1.6304554  -1.5581604  -1.0560061 \n#> \n#> Degrees of Freedom: 1378 Total (i.e. Null);  1370 Residual\n#> \n#> Scale Link:                   identity\n#> Estimated Scale Parameters:  [1] 249.9992\n#> \n#> Correlation:  Structure = exchangeable    Link = identity \n#> Estimated Correlation Parameters:\n#>     alpha \n#> 0.6922801 \n#> \n#> Number of clusters:   200   Maximum cluster size: 8\ngee_cc <- coef(summary(gee_fit)) |>\n  as.data.frame() |>\n  dplyr::mutate(lower_95CI = round(Estimate - 1.96 * Std.err, 2),\n                upper_95CI = round(Estimate + 1.96 * Std.err, 2)) |>\n  dplyr::mutate(Estimate_95CI = paste0(round(Estimate, 2), \" (\", lower_95CI, \", \", upper_95CI, \")\")) |>\n  dplyr::select(-all_of(c(\"lower_95CI\", \"upper_95CI\"))) |>\n  dplyr::mutate(OddRatio = round(exp(Estimate), 2)) |>\n  dplyr::arrange(`Pr(>|W|)`)\n\nDT::datatable(gee_cc)"},{"path":"GEEandMLM.html","id":"python实现方式","chapter":"3 GEE and MLM","heading":"3.6.1 python实现方式","text":"python调用statsmodels包的gee函数读取数据GEE实现","code":"\nlibrary(reticulate)\n\n# myenvs <- conda_list()\n# \n# envname <- myenvs$name[2]\n# use_condaenv(envname, required = TRUE)\n# # or\nuse_condaenv(\"base\", required = TRUE)import pandas as pd\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smfdataset = pd.read_csv(\"./InputData/TherapyData/data_dropout.csv\")\n\ndataset = dataset.drop(columns = ['line', 'normo'])\n\ndataset.head()\n#>    patient  visit      time        GFR        age  gender  micro  macro\n#> 0        1      1  0.000000  34.827908  78.555588       1      1      0\n#> 1        1      2  1.119435  16.822665  78.555588       1      1      0\n#> 2        1      3  2.243480  31.606338  78.555588       1      1      0\n#> 3        1      4  3.028584  42.466875  78.555588       1      1      0\n#> 4        1      5  3.821319  39.079925  78.555588       1      1      0fam = sm.families.Gaussian()\nind = sm.cov_struct.Exchangeable()\nmod = smf.gee(formula = \"GFR ~ age + gender + micro + macro + time + micro:time + macro:time\", \n              groups = \"patient\", \n              data = dataset, \n              cov_struct = ind,\n              family = fam) \n\nres = mod.fit()\n\nprint(res.summary())\n#>                                GEE Regression Results                              \n#> ===================================================================================\n#> Dep. Variable:                         GFR   No. Observations:                 1378\n#> Model:                                 GEE   No. clusters:                      200\n#> Method:                        Generalized   Min. cluster size:                   1\n#>                       Estimating Equations   Max. cluster size:                   8\n#> Family:                           Gaussian   Mean cluster size:                 6.9\n#> Dependence structure:         Exchangeable   Num. iterations:                     9\n#> Date:                     Tue, 06 Feb 2024   Scale:                         251.425\n#> Covariance type:                    robust   Time:                         13:51:20\n#> ==============================================================================\n#>                  coef    std err          z      P>|z|      [0.025      0.975]\n#> ------------------------------------------------------------------------------\n#> Intercept     81.3824      3.808     21.370      0.000      73.918      88.847\n#> age           -0.2561      0.058     -4.394      0.000      -0.370      -0.142\n#> gender        -2.9871      1.955     -1.528      0.126      -6.818       0.844\n#> micro        -20.2349      1.793    -11.287      0.000     -23.749     -16.721\n#> macro        -28.7160      2.109    -13.618      0.000     -32.849     -24.583\n#> time          -1.6304      0.373     -4.375      0.000      -2.361      -0.900\n#> micro:time    -1.5570      0.521     -2.989      0.003      -2.578      -0.536\n#> macro:time    -1.0533      0.699     -1.508      0.132      -2.423       0.316\n#> ==============================================================================\n#> Skew:                          0.2756   Kurtosis:                       0.4008\n#> Centered skew:                -0.1196   Centered kurtosis:              0.7311\n#> =============================================================================="},{"path":"GEEandMLM.html","id":"混合线性模型mixed-linear-modelmlm","chapter":"3 GEE and MLM","heading":"3.7 混合线性模型(mixed linear model，MLM)","text":"自变量（independent variable）：age，gender，micro，macro，time自变量（independent variable）：age，gender，micro，macro，time因变量（dependent variable）：GFR因变量（dependent variable）：GFR协变量（covariate）：patient协变量（covariate）：patient线性混合效应(LME)模型可以被认为是具有附加成分的回归模型，这些成分可以解释个体(重复测量环境)或群体(多层次/分层环境)之间截距和/或斜率参数的变化。区分混合线性模型中的随机效应和固定效应是一个重要的概念。固定效应是具有特定水平的变量，而随机效应捕捉了由于分组或聚类引起的变异性。比如下方正在探究尿蛋白对来自不同患者的GFR的影响。拥有的变量（例如年龄、性别、尿蛋白等）和患者的变量（patient）。想要了解尿蛋白如何影响患者的G FR。固定效应：具有特定的水平或值需要进行研究的主要变量，如尿蛋白等固定效应：具有特定的水平或值需要进行研究的主要变量，如尿蛋白等随机效应：患者随机效应：患者分层结构：尿蛋白嵌套在患者内分层结构：尿蛋白嵌套在患者内模型方程：GFR = 尿蛋白 + 患者 + 误差模型方程：GFR = 尿蛋白 + 患者 + 误差解释：解释固定效应，以了解尿蛋白的变化如何与GFR的变化相关联。患者的随机效应捕捉了在患者之间的GFR变异性，这不能由固定效应解释解释：解释固定效应，以了解尿蛋白的变化如何与GFR的变化相关联。患者的随机效应捕捉了在患者之间的GFR变异性，这不能由固定效应解释构建模型: 通过(1|patient)确定随机因子GFR dependent variable want model.GFR dependent variable want model.age, gender, time, micro, macro, micro:time, macro:time independent variables (fixed effects).age, gender, time, micro, macro, micro:time, macro:time independent variables (fixed effects).(1|patient) specifies random intercept term grouping variable patient. accounts fact measurements nested within patients, allowing correlations among measurements within patient.(1|patient) specifies random intercept term grouping variable patient. accounts fact measurements nested within patients, allowing correlations among measurements within patient.提取结果提取结果Value：\\(\\beta\\)相关系数，其中_Intercept_是截距估计值。提供了截距和预测变量的估计系数。Value：\\(\\beta\\)相关系数，其中_Intercept_是截距估计值。提供了截距和预测变量的估计系数。Std.Error：\\(\\beta\\)相关系的标准误差。给出了与系数估计相关的标准误差。这些是参数估计的不确定性的度量。Std.Error：\\(\\beta\\)相关系的标准误差。给出了与系数估计相关的标准误差。这些是参数估计的不确定性的度量。t-value：\\(\\beta\\)相关系的t检验统计量t-value：\\(\\beta\\)相关系的t检验统计量p-value：\\(\\beta\\)相关系的wald检验统计量对应pvalue。提供了与Wald检验相关的p值。它指示系数是否具有统计显著性。p-value：\\(\\beta\\)相关系的wald检验统计量对应pvalue。提供了与Wald检验相关的p值。它指示系数是否具有统计显著性。Estimate_95CI：\\(\\beta\\)置信区间提供可以合理确信真实总体参数位于其中的范围。Estimate 和 Std.err 值用于计算置信区间。例如，micro 变量的比值几率的95%置信区间可能是 [-25.04, -15.44]。该区间表示可以有95%的信心，真实的GFR比值几率位于-25.04和-15.44之间。Estimate_95CI：\\(\\beta\\)置信区间提供可以合理确信真实总体参数位于其中的范围。Estimate 和 Std.err 值用于计算置信区间。例如，micro 变量的比值几率的95%置信区间可能是 [-25.04, -15.44]。该区间表示可以有95%的信心，真实的GFR比值几率位于-25.04和-15.44之间。OddRatio：风险值，一般用于逻辑回归，可以通过对系数估计进行指数化来计算比值几率。比值几率表示单位预测变量变化时响应变量的几率的乘性变化。在本例中，不适合。OddRatio：风险值，一般用于逻辑回归，可以通过对系数估计进行指数化来计算比值几率。比值几率表示单位预测变量变化时响应变量的几率的乘性变化。在本例中，不适合。综上：GEE和MLM的结果较为接近","code":"\n# 第一种方法\n# library(lmerTest)\n# mlm_fit <- lmerTest::lmer(GFR ~ age + gender + time + micro + macro +\n#                   micro:time + macro:time +\n#                   (1|patient),\n#                 data = dataset)\n\n# 第二种方法\nlibrary(nlme)\nmlm_fit <- nlme::lme(GFR ~ age + gender + micro + macro + time + micro:time + macro:time,\n               random = ~ 1 | patient,\n               method = \"ML\",\n               data = dataset,\n               control = lmeControl(opt = \"optim\"))\n\nmlm_fit\n#> Linear mixed-effects model fit by maximum likelihood\n#>   Data: dataset \n#>   Log-likelihood: -5241.861\n#>   Fixed: GFR ~ age + gender + micro + macro + time + micro:time + macro:time \n#> (Intercept)         age      gender       micro       macro \n#>   81.376306   -0.255944   -2.992563  -20.239506  -28.714687 \n#>        time  micro:time  macro:time \n#>   -1.630229   -1.553320   -1.044673 \n#> \n#> Random effects:\n#>  Formula: ~1 | patient\n#>         (Intercept) Residual\n#> StdDev:    13.01882 8.923263\n#> \n#> Number of Observations: 1378\n#> Number of Groups: 200\nsummary(mlm_fit)\n#> Linear mixed-effects model fit by maximum likelihood\n#>   Data: dataset \n#>        AIC      BIC    logLik\n#>   10503.72 10556.01 -5241.861\n#> \n#> Random effects:\n#>  Formula: ~1 | patient\n#>         (Intercept) Residual\n#> StdDev:    13.01882 8.923263\n#> \n#> Fixed effects:  GFR ~ age + gender + micro + macro + time + micro:time + macro:time \n#>                 Value Std.Error   DF    t-value p-value\n#> (Intercept)  81.37631  4.055920 1175  20.063588  0.0000\n#> age          -0.25594  0.064048  195  -3.996128  0.0001\n#> gender       -2.99256  2.089156  195  -1.432427  0.1536\n#> micro       -20.23951  2.447454  195  -8.269617  0.0000\n#> macro       -28.71469  2.477851  195 -11.588543  0.0000\n#> time         -1.63023  0.157739 1175 -10.334948  0.0000\n#> micro:time   -1.55332  0.261773 1175  -5.933838  0.0000\n#> macro:time   -1.04467  0.294051 1175  -3.552688  0.0004\n#>  Correlation: \n#>            (Intr) age    gender micro  macro  time  \n#> age        -0.907                                   \n#> gender     -0.017 -0.137                            \n#> micro      -0.184 -0.081 -0.003                     \n#> macro      -0.255  0.015 -0.105  0.425              \n#> time       -0.133  0.000  0.000  0.221  0.218       \n#> micro:time  0.079  0.000  0.005 -0.331 -0.132 -0.603\n#> macro:time  0.062  0.011 -0.003 -0.119 -0.318 -0.536\n#>            micr:tm\n#> age               \n#> gender            \n#> micro             \n#> macro             \n#> time              \n#> micro:time        \n#> macro:time  0.323 \n#> \n#> Standardized Within-Group Residuals:\n#>         Min          Q1         Med          Q3         Max \n#> -3.53422430 -0.56401638  0.02003666  0.56703881  3.80980366 \n#> \n#> Number of Observations: 1378\n#> Number of Groups: 200\n\n# mlm_cc <- coef(summary(mlm_fit)) |>\n#   as.data.frame() |>\n#   dplyr::mutate(lower_95CI = round(Estimate - 1.96 * `Std. Error`, 2),\n#                 upper_95CI = round(Estimate + 1.96 * `Std. Error`, 2)) |>\n#   dplyr::mutate(Estimate_95CI = paste0(round(Estimate, 2), \" (\", lower_95CI, \", \", upper_95CI, \")\")) |>\n#   dplyr::select(-all_of(c(\"lower_95CI\", \"upper_95CI\"))) |>\n#   dplyr::mutate(OddRatio = round(exp(Estimate), 2)) |>\n#   dplyr::arrange(`Pr(>|t|)`)\n\nmlm_cc <- coef(summary(mlm_fit)) |>\n  as.data.frame() |>\n  dplyr::mutate(lower_95CI = round(Value - 1.96 * Std.Error, 2),\n                upper_95CI = round(Value + 1.96 * Std.Error, 2)) |>\n  dplyr::mutate(Estimate_95CI = paste0(round(Value, 2), \" (\", lower_95CI, \", \", upper_95CI, \")\")) |>\n  dplyr::select(-all_of(c(\"lower_95CI\", \"upper_95CI\"))) |>\n  dplyr::mutate(OddRatio = round(exp(Value), 2)) |>\n  dplyr::arrange(`p-value`)\n\nDT::datatable(mlm_cc)"},{"path":"GEEandMLM.html","id":"python实现方式-1","chapter":"3 GEE and MLM","heading":"3.7.1 python实现方式","text":"python调用statsmodels包的gee函数读取数据MLM实现","code":"import pandas as pd\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smfdataset = pd.read_csv(\"./InputData/TherapyData/data_dropout.csv\")\n\ndataset = dataset.drop(columns = ['line', 'normo'])\n\ndataset.head()\n#>    patient  visit      time        GFR        age  gender  micro  macro\n#> 0        1      1  0.000000  34.827908  78.555588       1      1      0\n#> 1        1      2  1.119435  16.822665  78.555588       1      1      0\n#> 2        1      3  2.243480  31.606338  78.555588       1      1      0\n#> 3        1      4  3.028584  42.466875  78.555588       1      1      0\n#> 4        1      5  3.821319  39.079925  78.555588       1      1      0mod_lme = smf.mixedlm(formula = \"GFR ~ age + gender + micro + macro + time + micro:time + macro:time\", \n              groups = dataset[\"patient\"], \n              data = dataset) \n\nmodf_lme = mod_lme.fit()\nprint(modf_lme.summary())\n#>           Mixed Linear Model Regression Results\n#> =========================================================\n#> Model:             MixedLM Dependent Variable: GFR       \n#> No. Observations:  1378    Method:             REML      \n#> No. Groups:        200     Scale:              79.8207   \n#> Min. group size:   1       Log-Likelihood:     -5239.7899\n#> Max. group size:   8       Converged:          Yes       \n#> Mean group size:   6.9                                   \n#> ---------------------------------------------------------\n#>             Coef.  Std.Err.    z    P>|z|  [0.025  0.975]\n#> ---------------------------------------------------------\n#> Intercept   81.380    4.096  19.868 0.000  73.352  89.408\n#> age         -0.256    0.065  -3.957 0.000  -0.383  -0.129\n#> gender      -2.989    2.110  -1.417 0.157  -7.125   1.147\n#> micro      -20.237    2.469  -8.196 0.000 -25.076 -15.397\n#> macro      -28.715    2.500 -11.488 0.000 -33.615 -23.816\n#> time        -1.630    0.157 -10.353 0.000  -1.939  -1.322\n#> micro:time  -1.556    0.262  -5.947 0.000  -2.068  -1.043\n#> macro:time  -1.050    0.295  -3.564 0.000  -1.627  -0.472\n#> Group Var  174.243    2.318                              \n#> ========================================================="},{"path":"GEEandMLM.html","id":"systemic-information","chapter":"3 GEE and MLM","heading":"3.8 Systemic information","text":"","code":"\ndevtools::session_info()\n#> ─ Session info ───────────────────────────────────────────\n#>  setting  value\n#>  version  R version 4.1.3 (2022-03-10)\n#>  os       macOS Big Sur/Monterey 10.16\n#>  system   x86_64, darwin17.0\n#>  ui       X11\n#>  language (EN)\n#>  collate  en_US.UTF-8\n#>  ctype    en_US.UTF-8\n#>  tz       Asia/Shanghai\n#>  date     2024-02-06\n#>  pandoc   3.1.1 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/ (via rmarkdown)\n#> \n#> ─ Packages ───────────────────────────────────────────────\n#>  package     * version date (UTC) lib source\n#>  backports     1.4.1   2021-12-13 [2] CRAN (R 4.1.0)\n#>  bookdown      0.34    2023-05-09 [2] CRAN (R 4.1.2)\n#>  broom         1.0.5   2023-06-09 [2] CRAN (R 4.1.3)\n#>  bslib         0.6.0   2023-11-21 [1] CRAN (R 4.1.3)\n#>  cachem        1.0.8   2023-05-01 [2] CRAN (R 4.1.2)\n#>  callr         3.7.3   2022-11-02 [2] CRAN (R 4.1.2)\n#>  cli           3.6.1   2023-03-23 [2] CRAN (R 4.1.2)\n#>  colorspace    2.1-0   2023-01-23 [2] CRAN (R 4.1.2)\n#>  crayon        1.5.2   2022-09-29 [2] CRAN (R 4.1.2)\n#>  crosstalk     1.2.0   2021-11-04 [2] CRAN (R 4.1.0)\n#>  data.table  * 1.14.8  2023-02-17 [2] CRAN (R 4.1.2)\n#>  devtools      2.4.5   2022-10-11 [2] CRAN (R 4.1.2)\n#>  digest        0.6.33  2023-07-07 [1] CRAN (R 4.1.3)\n#>  downlit       0.4.3   2023-06-29 [2] CRAN (R 4.1.3)\n#>  dplyr       * 1.1.4   2023-11-17 [1] CRAN (R 4.1.3)\n#>  DT            0.31    2023-12-09 [1] CRAN (R 4.1.3)\n#>  ellipsis      0.3.2   2021-04-29 [2] CRAN (R 4.1.0)\n#>  evaluate      0.21    2023-05-05 [2] CRAN (R 4.1.2)\n#>  fansi         1.0.4   2023-01-22 [2] CRAN (R 4.1.2)\n#>  farver        2.1.1   2022-07-06 [2] CRAN (R 4.1.2)\n#>  fastmap       1.1.1   2023-02-24 [2] CRAN (R 4.1.2)\n#>  forcats     * 1.0.0   2023-01-29 [1] CRAN (R 4.1.2)\n#>  fs            1.6.2   2023-04-25 [2] CRAN (R 4.1.2)\n#>  geepack     * 1.3.9   2022-08-16 [1] CRAN (R 4.1.2)\n#>  generics      0.1.3   2022-07-05 [2] CRAN (R 4.1.2)\n#>  ggplot2     * 3.4.4   2023-10-12 [1] CRAN (R 4.1.3)\n#>  glue          1.6.2   2022-02-24 [2] CRAN (R 4.1.2)\n#>  gtable        0.3.3   2023-03-21 [2] CRAN (R 4.1.2)\n#>  here          1.0.1   2020-12-13 [2] CRAN (R 4.1.0)\n#>  highr         0.10    2022-12-22 [2] CRAN (R 4.1.2)\n#>  hms           1.1.3   2023-03-21 [2] CRAN (R 4.1.2)\n#>  htmltools     0.5.7   2023-11-03 [1] CRAN (R 4.1.3)\n#>  htmlwidgets   1.6.2   2023-03-17 [2] CRAN (R 4.1.2)\n#>  httpuv        1.6.11  2023-05-11 [2] CRAN (R 4.1.3)\n#>  jquerylib     0.1.4   2021-04-26 [2] CRAN (R 4.1.0)\n#>  jsonlite      1.8.7   2023-06-29 [2] CRAN (R 4.1.3)\n#>  knitr         1.43    2023-05-25 [2] CRAN (R 4.1.3)\n#>  labeling      0.4.2   2020-10-20 [2] CRAN (R 4.1.0)\n#>  later         1.3.1   2023-05-02 [2] CRAN (R 4.1.2)\n#>  lattice       0.21-8  2023-04-05 [2] CRAN (R 4.1.2)\n#>  lifecycle     1.0.3   2022-10-07 [2] CRAN (R 4.1.2)\n#>  lubridate   * 1.9.2   2023-02-10 [2] CRAN (R 4.1.2)\n#>  magrittr      2.0.3   2022-03-30 [2] CRAN (R 4.1.2)\n#>  MASS          7.3-60  2023-05-04 [1] CRAN (R 4.1.2)\n#>  Matrix        1.6-5   2024-01-11 [1] CRAN (R 4.1.3)\n#>  memoise       2.0.1   2021-11-26 [2] CRAN (R 4.1.0)\n#>  mime          0.12    2021-09-28 [2] CRAN (R 4.1.0)\n#>  miniUI        0.1.1.1 2018-05-18 [2] CRAN (R 4.1.0)\n#>  munsell       0.5.0   2018-06-12 [2] CRAN (R 4.1.0)\n#>  nlme        * 3.1-162 2023-01-31 [1] CRAN (R 4.1.2)\n#>  pillar        1.9.0   2023-03-22 [2] CRAN (R 4.1.2)\n#>  pkgbuild      1.4.2   2023-06-26 [2] CRAN (R 4.1.3)\n#>  pkgconfig     2.0.3   2019-09-22 [2] CRAN (R 4.1.0)\n#>  pkgload       1.3.2.1 2023-07-08 [2] CRAN (R 4.1.3)\n#>  png           0.1-8   2022-11-29 [2] CRAN (R 4.1.2)\n#>  prettyunits   1.1.1   2020-01-24 [2] CRAN (R 4.1.0)\n#>  processx      3.8.2   2023-06-30 [2] CRAN (R 4.1.3)\n#>  profvis       0.3.8   2023-05-02 [2] CRAN (R 4.1.2)\n#>  promises      1.2.0.1 2021-02-11 [2] CRAN (R 4.1.0)\n#>  ps            1.7.5   2023-04-18 [2] CRAN (R 4.1.2)\n#>  purrr       * 1.0.1   2023-01-10 [1] CRAN (R 4.1.2)\n#>  R6            2.5.1   2021-08-19 [2] CRAN (R 4.1.0)\n#>  Rcpp          1.0.11  2023-07-06 [1] CRAN (R 4.1.3)\n#>  readr       * 2.1.4   2023-02-10 [1] CRAN (R 4.1.2)\n#>  remotes       2.4.2   2021-11-30 [2] CRAN (R 4.1.0)\n#>  reticulate  * 1.30    2023-06-09 [2] CRAN (R 4.1.3)\n#>  rlang         1.1.1   2023-04-28 [1] CRAN (R 4.1.2)\n#>  rmarkdown     2.23    2023-07-01 [2] CRAN (R 4.1.3)\n#>  rprojroot     2.0.3   2022-04-02 [2] CRAN (R 4.1.2)\n#>  rstudioapi    0.15.0  2023-07-07 [2] CRAN (R 4.1.3)\n#>  sass          0.4.6   2023-05-03 [2] CRAN (R 4.1.2)\n#>  scales        1.2.1   2022-08-20 [1] CRAN (R 4.1.2)\n#>  sessioninfo   1.2.2   2021-12-06 [2] CRAN (R 4.1.0)\n#>  shiny         1.7.4.1 2023-07-06 [2] CRAN (R 4.1.3)\n#>  stringi       1.7.12  2023-01-11 [2] CRAN (R 4.1.2)\n#>  stringr     * 1.5.1   2023-11-14 [1] CRAN (R 4.1.3)\n#>  tibble      * 3.2.1   2023-03-20 [1] CRAN (R 4.1.2)\n#>  tidyr       * 1.3.0   2023-01-24 [1] CRAN (R 4.1.2)\n#>  tidyselect    1.2.0   2022-10-10 [2] CRAN (R 4.1.2)\n#>  tidyverse   * 2.0.0   2023-02-22 [1] CRAN (R 4.1.2)\n#>  timechange    0.2.0   2023-01-11 [2] CRAN (R 4.1.2)\n#>  tzdb          0.4.0   2023-05-12 [2] CRAN (R 4.1.3)\n#>  urlchecker    1.0.1   2021-11-30 [2] CRAN (R 4.1.0)\n#>  usethis       2.2.2   2023-07-06 [2] CRAN (R 4.1.3)\n#>  utf8          1.2.3   2023-01-31 [2] CRAN (R 4.1.2)\n#>  vctrs         0.6.5   2023-12-01 [1] CRAN (R 4.1.3)\n#>  withr         2.5.0   2022-03-03 [2] CRAN (R 4.1.2)\n#>  xfun          0.40    2023-08-09 [1] CRAN (R 4.1.3)\n#>  xml2          1.3.5   2023-07-06 [2] CRAN (R 4.1.3)\n#>  xtable        1.8-4   2019-04-21 [2] CRAN (R 4.1.0)\n#>  yaml          2.3.7   2023-01-23 [2] CRAN (R 4.1.2)\n#> \n#>  [1] /Users/zouhua/Library/R/x86_64/4.1/library\n#>  [2] /Library/Frameworks/R.framework/Versions/4.1/Resources/library\n#> \n#> ─ Python configuration ───────────────────────────────────\n#>  python:         /Users/zouhua/opt/anaconda3/bin/python\n#>  libpython:      /Users/zouhua/opt/anaconda3/lib/libpython3.9.dylib\n#>  pythonhome:     /Users/zouhua/opt/anaconda3:/Users/zouhua/opt/anaconda3\n#>  version:        3.9.16 | packaged by conda-forge | (main, Feb  1 2023, 21:42:20)  [Clang 14.0.6 ]\n#>  numpy:          /Users/zouhua/opt/anaconda3/lib/python3.9/site-packages/numpy\n#>  numpy_version:  1.23.3\n#>  \n#>  NOTE: Python version was forced by use_python function\n#> \n#> ──────────────────────────────────────────────────────────"},{"path":"GEEandMLM.html","id":"reference-1","chapter":"3 GEE and MLM","heading":"3.9 Reference","text":"线性混合效应模型入门之二 - 实例操作及结果解读（R、Python、SPSS实现）线性混合效应模型入门之二 - 实例操作及结果解读（R、Python、SPSS实现）混合线性模型介绍–Wiki混合线性模型介绍–Wiki广义估计方程中工作相关矩阵的选择及R语言代码广义估计方程中工作相关矩阵的选择及R语言代码在Rstudio 中使用python在Rstudio 中使用pythonAn Introduction Linear Mixed Effects Models Social SciencesAn Introduction Linear Mixed Effects Models Social Sciences","code":""},{"path":"HypothesisTestingMethods.html","id":"HypothesisTestingMethods","chapter":"4 Hypothesis Testing Methods","heading":"4 Hypothesis Testing Methods","text":"显著性检验方法也即是假设检验方法。一般假设检验方法使用需要根据三个条件判断：数据分组数目也即是处理组数目，以2为阈值；数据分组数目也即是处理组数目，以2为阈值；数据的分布是否符合正态分布，符合则选择参数检验方法，否则选择非参数检验方法；数据的分布是否符合正态分布，符合则选择参数检验方法，否则选择非参数检验方法；数据是否是配对数据。数据是否是配对数据。\nFigure 4.1: Hypothesis Testing Methods\n","code":""},{"path":"HypothesisTestingMethods.html","id":"输入数据-1","chapter":"4 Hypothesis Testing Methods","heading":"4.1 输入数据","text":"对数据OmicsDataSet-Zeybel et al. - 2022.xlsx处理后生成的输入文件，详细情况可参考Data Set具体章节。本次使用配对的血清蛋白质组学数据作为案例数据。每组样本的数目 (配对分组：Mild， Moderate， Severe)准备数据","code":"\nsaveRDS(long_se_protein, \"./InputData/result/Zeybel_2022_plasma_protein_se_Paired.RDS\", compress = TRUE)\nknitr::opts_chunk$set(message = FALSE, warning = FALSE)\n\nlibrary(tidyverse)\nlibrary(SummarizedExperiment)\nlibrary(ggpubr)\n\n\nlong_se_protein <- readRDS(\"./InputData/result/Zeybel_2022_plasma_protein_se_Paired.RDS\")\n\nlong_se_protein\n#> class: SummarizedExperiment \n#> dim: 72 42 \n#> metadata(0):\n#> assays(1): ''\n#> rownames(72): IL8 VEGFA ... TNFB CSF_1\n#> rowData names(3): Protein ID LOD prop\n#> colnames(42): P101001_After P101001_Before ...\n#>   P101077_After P101077_Before\n#> colData names(49): SampleID PatientID ...\n#>   Right_leg_fat_free_mass Right_leg_total_body_water\nwith(colData(long_se_protein) %>% data.frame(), table(Stage, LiverFatClass))\n#>         LiverFatClass\n#> Stage    Mild Moderate None Severe\n#>   After     5        7    2      7\n#>   Before    6        7    0      8\nprofile <- assay(long_se_protein) %>%\n  as.data.frame()\nmetadata <- colData(long_se_protein) %>%\n  as.data.frame()\n\n# 两组不配对数据\nmetadata_2_unpaired <- metadata %>%\n  dplyr::filter(Stage == \"Before\") %>%\n  dplyr::filter(LiverFatClass %in% c(\"Mild\", \"Moderate\"))\nprofile_2_unpaired <- profile[, pmatch(rownames(metadata_2_unpaired), colnames(profile)), F]\nmerge_2_unpaired <- metadata_2_unpaired %>%\n  dplyr::select(SampleID, LiverFatClass) %>%\n  dplyr::inner_join(profile_2_unpaired %>% \n                      t() %>%\n                      as.data.frame() %>%\n                      tibble::rownames_to_column(\"SampleID\"),\n                    by = \"SampleID\")\n\n\n# 两组配对数据\nmetadata_2_paired <- metadata %>%\n  dplyr::filter(LiverFatClass == \"Moderate\")\nprofile_2_paired <- profile[, pmatch(rownames(metadata_2_paired), colnames(profile)), F]\nmerge_2_paired <- metadata_2_paired %>%\n  dplyr::select(SampleID, PatientID, Stage) %>%\n  dplyr::inner_join(profile_2_paired %>% \n                      t() %>%\n                      as.data.frame() %>%\n                      tibble::rownames_to_column(\"SampleID\"),\n                    by = \"SampleID\") %>%\n  dplyr::filter(!SampleID %in% c(\"P101052_After\", \"P101052_Before\"))\n\n# 三组数据\nmetadata_3_unpaired <- metadata %>%\n  dplyr::filter(Stage == \"Before\") %>%\n  dplyr::filter(LiverFatClass %in% c(\"Mild\", \"Moderate\", \"Severe\"))\nprofile_3_unpaired <- profile[, pmatch(rownames(metadata_3_unpaired), colnames(profile)), F]\nmerge_3_unpaired <- metadata_3_unpaired %>%\n  dplyr::select(SampleID, LiverFatClass) %>%\n  dplyr::inner_join(profile_3_unpaired %>% \n                      t() %>%\n                      as.data.frame() %>%\n                      tibble::rownames_to_column(\"SampleID\"),\n                    by = \"SampleID\")"},{"path":"HypothesisTestingMethods.html","id":"正态性评估","chapter":"4 Hypothesis Testing Methods","heading":"4.2 正态性评估","text":"可视化探索: density plot 密度图提供了一个关于分布是否呈钟形(正态分布)的直观判断可视化探索: histogram 如果直方图大致呈“钟形”，则假定数据为正态分布可视化探索: Q-Q plot Q-Q图描绘了给定样本与正态分布之间的相关性正态检验: shapiro.test提供单变量的正态分性检验方法（Shapiro-Wilk test）p-value test greater α = 0.05, data assumed normally distributed.正态检验: ks.test提供单变量的正态分性检验方法（Kolmogorov-Smirnov test）p-value test greater α = 0.05, data assumed normally distributed.结果：第二次检验的p值小于0.05，说明IL8数据不是正态分布。","code":"\nggdensity(merge_2_unpaired$IL8, \n          main = \"Density plot of IL8\",\n          xlab = \"IL8\")\ngghistogram(merge_2_unpaired$IL8, \n          main = \"Density plot of IL8\",\n          xlab = \"IL8\")\nggqqplot(merge_2_unpaired$IL8, \n          main = \"Density plot of IL8\",\n          xlab = \"IL8\")\nshapiro.test(merge_2_unpaired$IL8)\n#> \n#>  Shapiro-Wilk normality test\n#> \n#> data:  merge_2_unpaired$IL8\n#> W = 0.93269, p-value = 0.3694\nks.test(merge_2_unpaired$IL8,\n        \"pnorm\")\n#> \n#>  One-sample Kolmogorov-Smirnov test\n#> \n#> data:  merge_2_unpaired$IL8\n#> D = 0.99996, p-value = 2.22e-16\n#> alternative hypothesis: two-sided"},{"path":"HypothesisTestingMethods.html","id":"非正态数据转换方法","chapter":"4 Hypothesis Testing Methods","heading":"4.3 非正态数据转换方法","text":"如果给定的数据集不是正态分布，通常可以执行以下转换之一，使其更符合正态分布:Log Transformation: 将\\(x\\)做\\(log(x)\\)转换Log Transformation: 将\\(x\\)做\\(log(x)\\)转换Square Root Transformation: 将\\(x\\)做\\(\\sqrt{x}\\)开平方根转换Square Root Transformation: 将\\(x\\)做\\(\\sqrt{x}\\)开平方根转换Cube Root Transformation: 将\\(x\\)做\\(x^{1/3}\\)开立方根转换Cube Root Transformation: 将\\(x\\)做\\(x^{1/3}\\)开立方根转换","code":""},{"path":"HypothesisTestingMethods.html","id":"paired-students-t-test","chapter":"4 Hypothesis Testing Methods","heading":"4.4 Paired student’s t-test","text":"配对T检验适合两组数据且它们是正态分布和配对，计算t统计量。R基础函数t.testrstatix提供的t_test()p-value = 0.899比alpha = 0.05要大，接受零假设。IL8在前后没有显著差异。另外也可以计算Effect size效应值 (平均值和方差的比值)。\\(d = \\frac{mean_{D}}{SD_{D}}\\)可视化","code":"\nt.test(IL8 ~ Stage, data = merge_2_paired, paired = TRUE, alternative = \"two.sided\")\n#> \n#>  Paired t-test\n#> \n#> data:  IL8 by Stage\n#> t = 0.13325, df = 5, p-value = 0.8992\n#> alternative hypothesis: true difference in means is not equal to 0\n#> 95 percent confidence interval:\n#>  -0.566393  0.628323\n#> sample estimates:\n#> mean of the differences \n#>                0.030965\nlibrary(rstatix)\n\nstat.test <- merge_2_paired  %>% \n  t_test(IL8 ~ Stage, paired = TRUE, detailed = TRUE) %>%\n  add_significance()\n\nstat.test\n#> # A tibble: 1 × 14\n#>   estimate .y.   group1 group2    n1    n2 statistic     p\n#>      <dbl> <chr> <chr>  <chr>  <int> <int>     <dbl> <dbl>\n#> 1   0.0310 IL8   After  Before     6     6     0.133 0.899\n#> # ℹ 6 more variables: df <dbl>, conf.low <dbl>,\n#> #   conf.high <dbl>, method <chr>, alternative <chr>,\n#> #   p.signif <chr>\nmerge_2_paired %>% cohens_d(IL8 ~ Stage, paired = TRUE)\n#> # A tibble: 1 × 7\n#>   .y.   group1 group2 effsize    n1    n2 magnitude \n#> * <chr> <chr>  <chr>    <dbl> <int> <int> <ord>     \n#> 1 IL8   After  Before  0.0544     6     6 negligible\nstat_label <- stat.test %>% add_xy_position(x = \"Stage\")\n\nggpaired(merge_2_paired, \n         x = \"Stage\", \n         y = \"IL8\", \n         order = c(\"Before\", \"After\"),\n         ylab = \"IL8\", \n         xlab = \"Stage\",\n         fill = \"Stage\") + \n  stat_pvalue_manual(stat_label, tip.length = 0) +\n  labs(subtitle = get_test_label(stat_label, detailed = TRUE))"},{"path":"HypothesisTestingMethods.html","id":"students-t-test","chapter":"4 Hypothesis Testing Methods","heading":"4.5 Student’s t-test","text":"T检验适合两组数据且它们是正态分布，计算t统计量。可视化","code":"\nt.test(IL8 ~ LiverFatClass, data = merge_2_unpaired, paired = FALSE, alternative = \"two.sided\")\n#> \n#>  Welch Two Sample t-test\n#> \n#> data:  IL8 by LiverFatClass\n#> t = -0.32904, df = 6.193, p-value = 0.753\n#> alternative hypothesis: true difference in means between group Mild and group Moderate is not equal to 0\n#> 95 percent confidence interval:\n#>  -1.0116344  0.7702116\n#> sample estimates:\n#>     mean in group Mild mean in group Moderate \n#>               4.716680               4.837391\n\nstat.test <- merge_2_unpaired  %>% \n  t_test(IL8 ~ LiverFatClass, paired = FALSE, detailed = TRUE) %>%\n  add_significance()\n# stat.test\n\nmerge_2_unpaired %>% cohens_d(IL8 ~ LiverFatClass, paired = FALSE)\n#> # A tibble: 1 × 7\n#>   .y.   group1 group2   effsize    n1    n2 magnitude \n#> * <chr> <chr>  <chr>      <dbl> <int> <int> <ord>     \n#> 1 IL8   Mild   Moderate  -0.188     6     7 negligible\nstat_label <- stat.test %>% add_xy_position(x = \"LiverFatClass\")\n\nggboxplot(merge_2_unpaired, \n         x = \"LiverFatClass\", \n         y = \"IL8\", \n         order = c(\"Mild\", \"Moderate\"),\n         ylab = \"IL8\", \n         xlab = \"LiverFatClass\",\n         fill = \"LiverFatClass\") + \n  stat_pvalue_manual(stat_label, tip.length = 0) +\n  labs(subtitle = get_test_label(stat_label, detailed = TRUE))"},{"path":"HypothesisTestingMethods.html","id":"wilcoxon-signed-rank-t-test","chapter":"4 Hypothesis Testing Methods","heading":"4.6 Wilcoxon signed rank t-test","text":"配对Wilcoxon检验适合两组数据且它们是配对，对数据分布没有正态分布要求。R基础函数wilcox.testrstatix提供的wilcox_test()","code":"\nwilcox.test(IL8 ~ Stage, data = merge_2_paired, paired = TRUE, alternative = \"two.sided\")\n#> \n#>  Wilcoxon signed rank exact test\n#> \n#> data:  IL8 by Stage\n#> V = 12, p-value = 0.8438\n#> alternative hypothesis: true location shift is not equal to 0\nlibrary(rstatix)\n\nstat.test <- merge_2_paired  %>% \n  wilcox_test(IL8 ~ Stage, paired = TRUE, detailed = TRUE) %>%\n  add_significance()\n\nstat.test\n#> # A tibble: 1 × 13\n#>   estimate .y.   group1 group2    n1    n2 statistic     p\n#>      <dbl> <chr> <chr>  <chr>  <int> <int>     <dbl> <dbl>\n#> 1   0.0401 IL8   After  Before     6     6        12 0.844\n#> # ℹ 5 more variables: conf.low <dbl>, conf.high <dbl>,\n#> #   method <chr>, alternative <chr>, p.signif <chr>"},{"path":"HypothesisTestingMethods.html","id":"mann-whitney-u-test","chapter":"4 Hypothesis Testing Methods","heading":"4.7 Mann-Whitney U test","text":"Mann-Whitney U test (sometimes called Wilcoxon rank-sum test) used compare differences two independent samples sample distributions normally distributed sample sizes small (n <30).可视化","code":"\nwilcox.test(IL8 ~ LiverFatClass, data = merge_2_unpaired, paired = FALSE, alternative = \"two.sided\")\n#> \n#>  Wilcoxon rank sum exact test\n#> \n#> data:  IL8 by LiverFatClass\n#> W = 13, p-value = 0.2949\n#> alternative hypothesis: true location shift is not equal to 0\nggplot(merge_2_unpaired, aes(x = LiverFatClass, y = IL8)) + \n  geom_boxplot(width=0.3) +\n  stat_summary(fun = mean, geom = \"point\", col = \"black\") +  \n  stat_summary(fun = mean, geom = \"text\", col = \"black\", size = 3, \n               vjust = 3, aes(label = paste(\"Mean:\", round(after_stat(y), digits = 2)))) +\n  xlab(\"LiverFatClass\") +\n  ylab(\"IL8\") +\n  theme_bw()"},{"path":"HypothesisTestingMethods.html","id":"repeated-measures-one-way-anova","chapter":"4 Hypothesis Testing Methods","heading":"4.8 Repeated measures One-way ANOVA","text":"重复测量单因素方差分析需要满足以下假设：1.在设计的任何block中都没有显著的异常值 (rstatix::identify_outliers()可查看离群点)2.数据服从正态分布 (rstatix::shapiro_test()可查看检验结果)3.方差齐性: 组间差异的方差应该相等 (rstatix::anova_test()可查看检验结果)4.处理水平大于2输入数据基本统计特征可视化假设评估：离群点假设评估：正态分布统计检验：ANOVA整体评估变量在所有处理水平的显著性结果：p-value=2.01e-08，表明个人的score在不同时间点是统计学显著差异的。p-value=2.01e-08，表明个人的score在不同时间点是统计学显著差异的。ges: 广义效应大小(由受试者内部因素引起的可变性量)。ges: 广义效应大小(由受试者内部因素引起的可变性量)。统计检验：后置检验评估具体组间两两差异结果并做了检验结果校正结果：任意两组间的pvalue均小于显著性水平alpha = 0.05。可视化：加上显著性标记","code":"\ndata(\"selfesteem\", package = \"datarium\")\n\nselfesteem <- selfesteem %>%\n  gather(key = \"time\", value = \"score\", t1, t2, t3) %>%\n  convert_as_factor(id, time)\n\nhead(selfesteem, 3)\n#> # A tibble: 3 × 3\n#>   id    time  score\n#>   <fct> <fct> <dbl>\n#> 1 1     t1     4.01\n#> 2 2     t1     2.56\n#> 3 3     t1     3.24\nselfesteem %>%\n  group_by(time) %>%\n  get_summary_stats(score, type = \"mean_sd\")\n#> # A tibble: 3 × 5\n#>   time  variable     n  mean    sd\n#>   <fct> <fct>    <dbl> <dbl> <dbl>\n#> 1 t1    score       10  3.14 0.552\n#> 2 t2    score       10  4.93 0.863\n#> 3 t3    score       10  7.64 1.14\nggboxplot(selfesteem, x = \"time\", y = \"score\", add = \"point\")\nselfesteem %>%\n  group_by(time) %>%\n  identify_outliers(score)\n#> # A tibble: 2 × 5\n#>   time  id    score is.outlier is.extreme\n#>   <fct> <fct> <dbl> <lgl>      <lgl>     \n#> 1 t1    6      2.05 TRUE       FALSE     \n#> 2 t2    2      6.91 TRUE       FALSE\nselfesteem %>%\n  group_by(time) %>%\n  shapiro_test(score)\n#> # A tibble: 3 × 4\n#>   time  variable statistic     p\n#>   <fct> <chr>        <dbl> <dbl>\n#> 1 t1    score        0.967 0.859\n#> 2 t2    score        0.876 0.117\n#> 3 t3    score        0.923 0.380\n\n# ggqqplot(selfesteem, \"score\", facet.by = \"time\")\nres.aov <- anova_test(data = selfesteem, dv = score, wid = id, within = time)\nget_anova_table(res.aov)\n#> ANOVA Table (type III tests)\n#> \n#>   Effect DFn DFd      F        p p<.05   ges\n#> 1   time   2  18 55.469 2.01e-08     * 0.829\npwc <- selfesteem %>%\n  pairwise_t_test(\n    score ~ time, paired = TRUE,\n    p.adjust.method = \"bonferroni\"\n    )\npwc\n#> # A tibble: 3 × 10\n#>   .y.   group1 group2    n1    n2 statistic    df          p\n#> * <chr> <chr>  <chr>  <int> <int>     <dbl> <dbl>      <dbl>\n#> 1 score t1     t2        10    10     -4.97     9    7.72e-4\n#> 2 score t1     t3        10    10    -13.2      9    3.34e-7\n#> 3 score t2     t3        10    10     -4.87     9    8.86e-4\n#> # ℹ 2 more variables: p.adj <dbl>, p.adj.signif <chr>\npwc_label <- pwc %>% add_xy_position(x = \"time\")\n\nggboxplot(selfesteem, x = \"time\", y = \"score\", add = \"point\") + \n  stat_pvalue_manual(pwc_label) +\n  labs(\n    subtitle = get_test_label(res.aov, detailed = TRUE),\n    caption = get_pwc_label(pwc_label))"},{"path":"HypothesisTestingMethods.html","id":"one-way-anova","chapter":"4 Hypothesis Testing Methods","heading":"4.9 One-way ANOVA","text":"单因素方差分析需要满足以下假设：1.数据服从正态分布 (rstatix::shapiro_test()可查看检验结果)2.方差齐性: 组间差异的方差应该相等 (rstatix::anova_test()可查看检验结果)3.处理水平大于2数据探索检验：评估植物的平均weight是否在三组处理间是显著差异的结果：由于p值小于0.05的显著性水平，可以得出模型中标注“*”的组之间存在显著性差异。后置检验：组均值之间的多重两两比较 Tukey HSD (Tukey Honest Significant Differences)后置检验2: 采用multcomp::glht方法The function glht() [multcomp package] can used multiple comparison processes ANOVA. General linear hypothesis tests abbreviated glht.后置检验3: T-test pairs可视化：加上假设检验的结果","code":"\nggboxplot(PlantGrowth, x = \"group\", y = \"weight\",\n          color = \"group\", palette = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n          order = c(\"ctrl\", \"trt1\", \"trt2\"),\n          ylab = \"Weight\", xlab = \"Treatment\")\nres.aov <- aov(weight ~ group, data = PlantGrowth)\n\nsummary(res.aov)\n#>             Df Sum Sq Mean Sq F value Pr(>F)  \n#> group        2  3.766  1.8832   4.846 0.0159 *\n#> Residuals   27 10.492  0.3886                 \n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nTukeyHSD(res.aov)\n#>   Tukey multiple comparisons of means\n#>     95% family-wise confidence level\n#> \n#> Fit: aov(formula = weight ~ group, data = PlantGrowth)\n#> \n#> $group\n#>             diff        lwr       upr     p adj\n#> trt1-ctrl -0.371 -1.0622161 0.3202161 0.3908711\n#> trt2-ctrl  0.494 -0.1972161 1.1852161 0.1979960\n#> trt2-trt1  0.865  0.1737839 1.5562161 0.0120064\nlibrary(multcomp)\n\nsummary(glht(res.aov, linfct = mcp(group = \"Tukey\")))\n#> \n#>   Simultaneous Tests for General Linear Hypotheses\n#> \n#> Multiple Comparisons of Means: Tukey Contrasts\n#> \n#> \n#> Fit: aov(formula = weight ~ group, data = PlantGrowth)\n#> \n#> Linear Hypotheses:\n#>                  Estimate Std. Error t value Pr(>|t|)  \n#> trt1 - ctrl == 0  -0.3710     0.2788  -1.331    0.391  \n#> trt2 - ctrl == 0   0.4940     0.2788   1.772    0.198  \n#> trt2 - trt1 == 0   0.8650     0.2788   3.103    0.012 *\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> (Adjusted p values reported -- single-step method)\npairwise.t.test(PlantGrowth$weight, \n                PlantGrowth$group,\n                p.adjust.method = \"BH\")\n#> \n#>  Pairwise comparisons using t tests with pooled SD \n#> \n#> data:  PlantGrowth$weight and PlantGrowth$group \n#> \n#>      ctrl  trt1 \n#> trt1 0.194 -    \n#> trt2 0.132 0.013\n#> \n#> P value adjustment method: BH\npwc_label2 <- PlantGrowth %>%\n  pairwise_t_test(\n    weight ~ group,\n    p.adjust.method = \"BH\"\n    ) %>% add_xy_position(x = \"group\")\n\nggboxplot(PlantGrowth, x = \"group\", y = \"weight\", add = \"point\") + \n  stat_pvalue_manual(pwc_label2) +\n  labs(\n    #subtitle = get_test_label(res.aov, detailed = TRUE),\n    caption = get_pwc_label(pwc_label2))"},{"path":"HypothesisTestingMethods.html","id":"friedman-test","chapter":"4 Hypothesis Testing Methods","heading":"4.10 Friedman test","text":"Friedman test，是一种非参数检验的方法，用于评估三个或更多成对组的分布之间是否存在统计学上的显著差异。当不满足单向重复测量ANOVA检验的正态性假设或因变量在有序量表上测量时，建议使用该方法。输入数据统计检验：friedman test整体评估变量在所有处理水平的显著性统计检验：后置检验评估具体组间两两差异结果并做了检验结果校正可视化：加上假设检验的结果","code":"\ndata(\"selfesteem\", package = \"datarium\")\n\nselfesteem <- selfesteem %>%\n  gather(key = \"time\", value = \"score\", t1, t2, t3) %>%\n  convert_as_factor(id, time)\n\nhead(selfesteem, 3)\n#> # A tibble: 3 × 3\n#>   id    time  score\n#>   <fct> <fct> <dbl>\n#> 1 1     t1     4.01\n#> 2 2     t1     2.56\n#> 3 3     t1     3.24\nres.fried <- selfesteem %>% friedman_test(score ~ time | id)\n\nres.fried\n#> # A tibble: 1 × 6\n#>   .y.       n statistic    df        p method       \n#> * <chr> <int>     <dbl> <dbl>    <dbl> <chr>        \n#> 1 score    10      18.2     2 0.000112 Friedman test\n\n# selfesteem %>% friedman_effsize(score ~ time | id)\npwc <- selfesteem %>%\n  wilcox_test(\n    score ~ time, paired = TRUE,\n    p.adjust.method = \"bonferroni\"\n    )\npwc\n#> # A tibble: 3 × 9\n#>   .y.   group1 group2    n1    n2 statistic     p p.adj\n#> * <chr> <chr>  <chr>  <int> <int>     <dbl> <dbl> <dbl>\n#> 1 score t1     t2        10    10         0 0.002 0.006\n#> 2 score t1     t3        10    10         0 0.002 0.006\n#> 3 score t2     t3        10    10         1 0.004 0.012\n#> # ℹ 1 more variable: p.adj.signif <chr>\npwc_label <- pwc %>% add_xy_position(x = \"time\")\n\nggboxplot(selfesteem, x = \"time\", y = \"score\", add = \"point\") + \n  stat_pvalue_manual(pwc_label, hide.ns = TRUE) +\n  labs(\n    subtitle = get_test_label(res.fried, detailed = TRUE),\n    caption = get_pwc_label(pwc_label))"},{"path":"HypothesisTestingMethods.html","id":"kruskal-wallis-test","chapter":"4 Hypothesis Testing Methods","heading":"4.11 Kruskal-Wallis test","text":"Kruskal-Wallis检验是单向方差分析检验的非参数替代检验。在有两个以上的组进行比较的情况下，它扩展了两样本Wilcoxon检验。当不满足单因素方差分析的假设时，建议使用。数据探索检验：评估植物的平均weight是否在三组处理间是显著差异的结果：由于p值小于0.05的显著性水平，可以得出模型中标注“*”的组之间存在显著性差异。后置检验：组均值之间的多重两两比较 Dunn’s test后置检验2: 采用wilcox_test方法可视化：加上假设检验的结果","code":"\nPlantGrowth %>% \n  group_by(group) %>%\n  get_summary_stats(weight, type = \"common\")\n#> # A tibble: 3 × 11\n#>   group variable     n   min   max median   iqr  mean    sd\n#>   <fct> <fct>    <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl>\n#> 1 ctrl  weight      10  4.17  6.11   5.16 0.743  5.03 0.583\n#> 2 trt1  weight      10  3.59  6.03   4.55 0.662  4.66 0.794\n#> 3 trt2  weight      10  4.92  6.31   5.44 0.467  5.53 0.443\n#> # ℹ 2 more variables: se <dbl>, ci <dbl>\nres.kruskal <- PlantGrowth %>% kruskal_test(weight ~ group)\n\nres.kruskal\n#> # A tibble: 1 × 6\n#>   .y.        n statistic    df      p method        \n#> * <chr>  <int>     <dbl> <int>  <dbl> <chr>         \n#> 1 weight    30      7.99     2 0.0184 Kruskal-Wallis\n\n# Effect size\n# PlantGrowth %>% kruskal_effsize(weight ~ group)\npwc <- PlantGrowth %>% \n  dunn_test(weight ~ group, p.adjust.method = \"bonferroni\") \npwc\n#> # A tibble: 3 × 9\n#>   .y.    group1 group2    n1    n2 statistic       p  p.adj\n#> * <chr>  <chr>  <chr>  <int> <int>     <dbl>   <dbl>  <dbl>\n#> 1 weight ctrl   trt1      10    10     -1.12 0.264   0.791 \n#> 2 weight ctrl   trt2      10    10      1.69 0.0912  0.273 \n#> 3 weight trt1   trt2      10    10      2.81 0.00500 0.0150\n#> # ℹ 1 more variable: p.adj.signif <chr>\npwc2 <- PlantGrowth %>% \n  wilcox_test(weight ~ group, p.adjust.method = \"bonferroni\")\npwc2\n#> # A tibble: 3 × 9\n#>   .y.    group1 group2    n1    n2 statistic     p p.adj\n#> * <chr>  <chr>  <chr>  <int> <int>     <dbl> <dbl> <dbl>\n#> 1 weight ctrl   trt1      10    10      67.5 0.199 0.597\n#> 2 weight ctrl   trt2      10    10      25   0.063 0.189\n#> 3 weight trt1   trt2      10    10      16   0.009 0.027\n#> # ℹ 1 more variable: p.adj.signif <chr>\npwc_label2 <- pwc %>% add_xy_position(x = \"group\")\n\nggboxplot(PlantGrowth, x = \"group\", y = \"weight\", add = \"point\") + \n  stat_pvalue_manual(pwc_label2, hide.ns = TRUE) +\n  labs(\n    subtitle = get_test_label(res.kruskal, detailed = TRUE),\n    caption = get_pwc_label(pwc_label2))"},{"path":"HypothesisTestingMethods.html","id":"blocked-wilcoxon-rank-sum-test","chapter":"4 Hypothesis Testing Methods","heading":"4.12 Blocked Wilcoxon rank-sum test","text":"Two-sided Wilcoxon tests blocked ‘study’是Wilcoxon检验是在考虑不同研究来源（study）的影响下进行的差异检验。这不同于单纯地在每个研究内部分别进行Wilcoxon检验，因为它试图控制或调整来自不同研究的潜在影响，从而提供更准确和可靠的整体分析结果。formula: formula form y ~ x | block y numeric variable, x factor block optional factor stratification.","code":"\n# 安装并加载coin包\nlibrary(coin)\n\n# 示例数据，确保group和study列均为因子类型\ndata <- data.frame(\n  variable = rnorm(100),\n  group = factor(rep(c(\"A\", \"B\"), 50)),\n  study = factor(rep(c(\"Study1\", \"Study2\"), each = 50))\n)\n\n# 使用wilcox_test进行分组Wilcoxon检验\nresult <- coin::wilcox_test(variable ~ group | study, data = data)\nprint(result)\n#> \n#>  Asymptotic Wilcoxon-Mann-Whitney Test\n#> \n#> data:  variable by\n#>   group (A, B) \n#>   stratified by study\n#> Z = 1.0497, p-value = 0.2939\n#> alternative hypothesis: true mu is not equal to 0"},{"path":"HypothesisTestingMethods.html","id":"总结","chapter":"4 Hypothesis Testing Methods","heading":"4.13 总结","text":"1.两组使用t-test或wilcox-test，前者适合正态分布数据后者为非参数检验方法。2.三组及以上使用ANOVA, friedman或KW检验，前者适合正态分布数据后者为非参数检验方法。3.三组数据的初步检验结果需要做后置检验才能解析出具体组间差异。4.在假设检验前，可以对数据进行探索，如正态性评估以及箱线图组间分布评估。","code":""},{"path":"HypothesisTestingMethods.html","id":"systemic-information-1","chapter":"4 Hypothesis Testing Methods","heading":"4.14 Systemic information","text":"","code":"\ndevtools::session_info()\n#> ─ Session info ───────────────────────────────────────────\n#>  setting  value\n#>  version  R version 4.1.3 (2022-03-10)\n#>  os       macOS Big Sur/Monterey 10.16\n#>  system   x86_64, darwin17.0\n#>  ui       X11\n#>  language (EN)\n#>  collate  en_US.UTF-8\n#>  ctype    en_US.UTF-8\n#>  tz       Asia/Shanghai\n#>  date     2024-02-06\n#>  pandoc   3.1.1 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/ (via rmarkdown)\n#> \n#> ─ Packages ───────────────────────────────────────────────\n#>  package              * version   date (UTC) lib source\n#>  abind                  1.4-5     2016-07-21 [2] CRAN (R 4.1.0)\n#>  backports              1.4.1     2021-12-13 [2] CRAN (R 4.1.0)\n#>  Biobase              * 2.54.0    2021-10-26 [2] Bioconductor\n#>  BiocGenerics         * 0.40.0    2021-10-26 [2] Bioconductor\n#>  bitops                 1.0-7     2021-04-24 [2] CRAN (R 4.1.0)\n#>  bookdown               0.34      2023-05-09 [2] CRAN (R 4.1.2)\n#>  broom                  1.0.5     2023-06-09 [2] CRAN (R 4.1.3)\n#>  bslib                  0.6.0     2023-11-21 [1] CRAN (R 4.1.3)\n#>  cachem                 1.0.8     2023-05-01 [2] CRAN (R 4.1.2)\n#>  callr                  3.7.3     2022-11-02 [2] CRAN (R 4.1.2)\n#>  car                    3.1-2     2023-03-30 [2] CRAN (R 4.1.2)\n#>  carData                3.0-5     2022-01-06 [2] CRAN (R 4.1.2)\n#>  cli                    3.6.1     2023-03-23 [2] CRAN (R 4.1.2)\n#>  codetools              0.2-19    2023-02-01 [2] CRAN (R 4.1.2)\n#>  coin                 * 1.4-2     2021-10-08 [1] CRAN (R 4.1.0)\n#>  colorspace             2.1-0     2023-01-23 [2] CRAN (R 4.1.2)\n#>  crayon                 1.5.2     2022-09-29 [2] CRAN (R 4.1.2)\n#>  DelayedArray           0.20.0    2021-10-26 [2] Bioconductor\n#>  devtools               2.4.5     2022-10-11 [2] CRAN (R 4.1.2)\n#>  digest                 0.6.33    2023-07-07 [1] CRAN (R 4.1.3)\n#>  downlit                0.4.3     2023-06-29 [2] CRAN (R 4.1.3)\n#>  dplyr                * 1.1.4     2023-11-17 [1] CRAN (R 4.1.3)\n#>  ellipsis               0.3.2     2021-04-29 [2] CRAN (R 4.1.0)\n#>  evaluate               0.21      2023-05-05 [2] CRAN (R 4.1.2)\n#>  fansi                  1.0.4     2023-01-22 [2] CRAN (R 4.1.2)\n#>  farver                 2.1.1     2022-07-06 [2] CRAN (R 4.1.2)\n#>  fastmap                1.1.1     2023-02-24 [2] CRAN (R 4.1.2)\n#>  forcats              * 1.0.0     2023-01-29 [1] CRAN (R 4.1.2)\n#>  fs                     1.6.2     2023-04-25 [2] CRAN (R 4.1.2)\n#>  generics               0.1.3     2022-07-05 [2] CRAN (R 4.1.2)\n#>  GenomeInfoDb         * 1.30.1    2022-01-30 [2] Bioconductor\n#>  GenomeInfoDbData       1.2.7     2022-03-09 [2] Bioconductor\n#>  GenomicRanges        * 1.46.1    2021-11-18 [2] Bioconductor\n#>  ggplot2              * 3.4.4     2023-10-12 [1] CRAN (R 4.1.3)\n#>  ggpubr               * 0.6.0     2023-02-10 [1] CRAN (R 4.1.2)\n#>  ggsignif               0.6.4     2022-10-13 [2] CRAN (R 4.1.2)\n#>  glue                   1.6.2     2022-02-24 [2] CRAN (R 4.1.2)\n#>  gtable                 0.3.3     2023-03-21 [2] CRAN (R 4.1.2)\n#>  highr                  0.10      2022-12-22 [2] CRAN (R 4.1.2)\n#>  hms                    1.1.3     2023-03-21 [2] CRAN (R 4.1.2)\n#>  htmltools              0.5.7     2023-11-03 [1] CRAN (R 4.1.3)\n#>  htmlwidgets            1.6.2     2023-03-17 [2] CRAN (R 4.1.2)\n#>  httpuv                 1.6.11    2023-05-11 [2] CRAN (R 4.1.3)\n#>  IRanges              * 2.28.0    2021-10-26 [2] Bioconductor\n#>  jquerylib              0.1.4     2021-04-26 [2] CRAN (R 4.1.0)\n#>  jsonlite               1.8.7     2023-06-29 [2] CRAN (R 4.1.3)\n#>  knitr                  1.43      2023-05-25 [2] CRAN (R 4.1.3)\n#>  labeling               0.4.2     2020-10-20 [2] CRAN (R 4.1.0)\n#>  later                  1.3.1     2023-05-02 [2] CRAN (R 4.1.2)\n#>  lattice                0.21-8    2023-04-05 [2] CRAN (R 4.1.2)\n#>  libcoin                1.0-9     2021-09-27 [2] CRAN (R 4.1.0)\n#>  lifecycle              1.0.3     2022-10-07 [2] CRAN (R 4.1.2)\n#>  lubridate            * 1.9.2     2023-02-10 [2] CRAN (R 4.1.2)\n#>  magrittr               2.0.3     2022-03-30 [2] CRAN (R 4.1.2)\n#>  MASS                 * 7.3-60    2023-05-04 [1] CRAN (R 4.1.2)\n#>  Matrix                 1.6-5     2024-01-11 [1] CRAN (R 4.1.3)\n#>  MatrixGenerics       * 1.6.0     2021-10-26 [2] Bioconductor\n#>  matrixStats          * 1.1.0     2023-11-07 [1] CRAN (R 4.1.3)\n#>  memoise                2.0.1     2021-11-26 [2] CRAN (R 4.1.0)\n#>  mime                   0.12      2021-09-28 [2] CRAN (R 4.1.0)\n#>  miniUI                 0.1.1.1   2018-05-18 [2] CRAN (R 4.1.0)\n#>  modeltools             0.2-23    2020-03-05 [2] CRAN (R 4.1.0)\n#>  multcomp             * 1.4-25    2023-06-20 [2] CRAN (R 4.1.3)\n#>  munsell                0.5.0     2018-06-12 [2] CRAN (R 4.1.0)\n#>  mvtnorm              * 1.2-2     2023-06-08 [2] CRAN (R 4.1.3)\n#>  pillar                 1.9.0     2023-03-22 [2] CRAN (R 4.1.2)\n#>  pkgbuild               1.4.2     2023-06-26 [2] CRAN (R 4.1.3)\n#>  pkgconfig              2.0.3     2019-09-22 [2] CRAN (R 4.1.0)\n#>  pkgload                1.3.2.1   2023-07-08 [2] CRAN (R 4.1.3)\n#>  prettyunits            1.1.1     2020-01-24 [2] CRAN (R 4.1.0)\n#>  processx               3.8.2     2023-06-30 [2] CRAN (R 4.1.3)\n#>  profvis                0.3.8     2023-05-02 [2] CRAN (R 4.1.2)\n#>  promises               1.2.0.1   2021-02-11 [2] CRAN (R 4.1.0)\n#>  ps                     1.7.5     2023-04-18 [2] CRAN (R 4.1.2)\n#>  purrr                * 1.0.1     2023-01-10 [1] CRAN (R 4.1.2)\n#>  R6                     2.5.1     2021-08-19 [2] CRAN (R 4.1.0)\n#>  Rcpp                   1.0.11    2023-07-06 [1] CRAN (R 4.1.3)\n#>  RCurl                  1.98-1.12 2023-03-27 [2] CRAN (R 4.1.2)\n#>  readr                * 2.1.4     2023-02-10 [1] CRAN (R 4.1.2)\n#>  remotes                2.4.2     2021-11-30 [2] CRAN (R 4.1.0)\n#>  rlang                  1.1.1     2023-04-28 [1] CRAN (R 4.1.2)\n#>  rmarkdown              2.23      2023-07-01 [2] CRAN (R 4.1.3)\n#>  rstatix              * 0.7.2     2023-02-01 [2] CRAN (R 4.1.2)\n#>  rstudioapi             0.15.0    2023-07-07 [2] CRAN (R 4.1.3)\n#>  S4Vectors            * 0.32.4    2022-03-29 [2] Bioconductor\n#>  sandwich               3.0-2     2022-06-15 [2] CRAN (R 4.1.2)\n#>  sass                   0.4.6     2023-05-03 [2] CRAN (R 4.1.2)\n#>  scales                 1.2.1     2022-08-20 [1] CRAN (R 4.1.2)\n#>  sessioninfo            1.2.2     2021-12-06 [2] CRAN (R 4.1.0)\n#>  shiny                  1.7.4.1   2023-07-06 [2] CRAN (R 4.1.3)\n#>  stringi                1.7.12    2023-01-11 [2] CRAN (R 4.1.2)\n#>  stringr              * 1.5.1     2023-11-14 [1] CRAN (R 4.1.3)\n#>  SummarizedExperiment * 1.24.0    2021-10-26 [2] Bioconductor\n#>  survival             * 3.5-5     2023-03-12 [2] CRAN (R 4.1.2)\n#>  TH.data              * 1.1-2     2023-04-17 [2] CRAN (R 4.1.2)\n#>  tibble               * 3.2.1     2023-03-20 [1] CRAN (R 4.1.2)\n#>  tidyr                * 1.3.0     2023-01-24 [1] CRAN (R 4.1.2)\n#>  tidyselect             1.2.0     2022-10-10 [2] CRAN (R 4.1.2)\n#>  tidyverse            * 2.0.0     2023-02-22 [1] CRAN (R 4.1.2)\n#>  timechange             0.2.0     2023-01-11 [2] CRAN (R 4.1.2)\n#>  tzdb                   0.4.0     2023-05-12 [2] CRAN (R 4.1.3)\n#>  urlchecker             1.0.1     2021-11-30 [2] CRAN (R 4.1.0)\n#>  usethis                2.2.2     2023-07-06 [2] CRAN (R 4.1.3)\n#>  utf8                   1.2.3     2023-01-31 [2] CRAN (R 4.1.2)\n#>  vctrs                  0.6.5     2023-12-01 [1] CRAN (R 4.1.3)\n#>  withr                  2.5.0     2022-03-03 [2] CRAN (R 4.1.2)\n#>  xfun                   0.40      2023-08-09 [1] CRAN (R 4.1.3)\n#>  xml2                   1.3.5     2023-07-06 [2] CRAN (R 4.1.3)\n#>  xtable                 1.8-4     2019-04-21 [2] CRAN (R 4.1.0)\n#>  XVector                0.34.0    2021-10-26 [2] Bioconductor\n#>  yaml                   2.3.7     2023-01-23 [2] CRAN (R 4.1.2)\n#>  zlibbioc               1.40.0    2021-10-26 [2] Bioconductor\n#>  zoo                    1.8-12    2023-04-13 [2] CRAN (R 4.1.2)\n#> \n#>  [1] /Users/zouhua/Library/R/x86_64/4.1/library\n#>  [2] /Library/Frameworks/R.framework/Versions/4.1/Resources/library\n#> \n#> ──────────────────────────────────────────────────────────"},{"path":"HypothesisTestingMethods.html","id":"reference-2","chapter":"4 Hypothesis Testing Methods","heading":"4.15 Reference","text":"data-science--beginners","code":""},{"path":"BatchEffectCorrection.html","id":"BatchEffectCorrection","chapter":"5 Batch Effect Correction","heading":"5 Batch Effect Correction","text":"批次效应是除处理其他因素带来的影响实验结果的效应，比如在研究对照组和实验组时候，提取样本DNA时间不同、送测仪器不同等均可能引入批次效应。批次效应不能够消除，只可以降低，使得它对所研究的生物学问题有较小的影响。\n评估批次效应可以通过PCA或PCoA等降纬可视化技术观察样本的聚集情况是否与非研究问题存在视觉上的相关性，也可以通过一些统计方法如PERMANOVA等计算表达谱整体水平和因素之间的关系。","code":""},{"path":"BatchEffectCorrection.html","id":"mmuphin","chapter":"5 Batch Effect Correction","heading":"5.1 MMUPHin","text":"通常在做多个研究或多个平台的数据整合需要考虑到消除不同研究或平台数据差异，在微生物领域又因为微生物相对丰度数据是稀疏的，所以常在转录组领域使用的校正方法如sva::ComBat和limma::removeBatchEffect等均不适用。“MMUPHin”（Meta-analysis via Mixed Models Utilizing Public Health Information）是一个哈佛大学Huttenhover实验室开发的用于微生物组数据的统计分析包，特别是在研究与公共健康相关的多个研究的数据时使用。它在处理批次效应（batch effects）时的原理是基于混合模型（mixed models）。在微生物组学研究中，批次效应是一个常见的问题。它指的是由于样本处理和测序过程中的技术变异而导致的非生物学差异，这些差异可能会干扰真实的生物学信号。例如，不同的实验室使用不同的样本处理方法或测序平台，可能导致数据之间的系统性差异。MMUPHin处理批次效应的原理：混合模型：MMUPHin使用混合模型来纳入批次效应。在这种模型中，批次效应被视为随机效应，它们与研究中的固定效应（例如治疗组与对照组）分开处理。混合模型：MMUPHin使用混合模型来纳入批次效应。在这种模型中，批次效应被视为随机效应，它们与研究中的固定效应（例如治疗组与对照组）分开处理。元分析方法：MMUPHin利用元分析的技术，允许来自不同研究的数据共同分析。元分析是一种统计方法，它综合并分析多个研究的结果，以获得更广泛、更全面的结论。元分析方法：MMUPHin利用元分析的技术，允许来自不同研究的数据共同分析。元分析是一种统计方法，它综合并分析多个研究的结果，以获得更广泛、更全面的结论。数据整合：通过混合模型和元分析方法，MMUPHin能够在考虑批次效应的同时，整合多个研究的数据，提高分析的统计能力和结论的泛化性。数据整合：通过混合模型和元分析方法，MMUPHin能够在考虑批次效应的同时，整合多个研究的数据，提高分析的统计能力和结论的泛化性。校正批次效应：通过在模型中包括批次效应作为一个变量，MMUPHin可以校正这些非生物学差异，从而使研究结果更加可靠和准确。校正批次效应：通过在模型中包括批次效应作为一个变量，MMUPHin可以校正这些非生物学差异，从而使研究结果更加可靠和准确。","code":""},{"path":"BatchEffectCorrection.html","id":"加载依赖包和数据","chapter":"5 Batch Effect Correction","heading":"5.1.1 加载依赖包和数据","text":"数据来源是 curatedMetagenomicData R包","code":"\nknitr::opts_chunk$set(message = FALSE, warning = FALSE)\n\nlibrary(tidyverse)\n\n# if (!requireNamespace(\"BiocManager\", quietly = TRUE))\n#     install.packages(\"BiocManager\")\n# BiocManager::install(\"MMUPHin\")\n\nlibrary(MMUPHin)\nlibrary(ggplot2)\nlibrary(phyloseq)\n\ndata(\"CRC_abd\", \"CRC_meta\")\nCRC_abd[1:5, 1, drop = FALSE]\n#>                                 FengQ_2015.metaphlan_bugs_list.stool:SID31004\n#> s__Faecalibacterium_prausnitzii                                    0.11110668\n#> s__Streptococcus_salivarius                                        0.09660736\n#> s__Ruminococcus_sp_5_1_39BFAA                                      0.09115385\n#> s__Subdoligranulum_unclassified                                    0.05806767\n#> s__Bacteroides_stercoris                                           0.05685503\n# CRC_meta[1, 1:5]"},{"path":"BatchEffectCorrection.html","id":"数据探索","chapter":"5 Batch Effect Correction","heading":"5.1.2 数据探索","text":"使用MicrobiomeAnalysis::run_ord和MicrobiomeAnalysis::plot_ord可视化数据，选择PCoA的方法。安装MicrobiomeAnalysis包结果：能明显看到样本以studyID分散开来，研究之间的批次效应要远远大于control和CRC的生物学效应，接下来我们通过PERMANOVA做统计分析进一步评估显著性。结果：PERMANOVA的Pr(>F) < 0.05表明study_condition和studyID均与整体肠道微生物结构有显著差异，也说明studyID的批次效应(对肠道结构解释9.1%的变异)对后续study_condition的差异研究等具有非常大的影响，因此需要做批次校正。","code":"\nif (!requireNamespace(c(\"remotes\", \"devtools\"), quietly=TRUE)) {\n  install.packages(c(\"devtools\", \"remotes\"))\n}\nremotes::install_github(\"HuaZou/MicrobiomeAnalysis\")\n# run_ord需要phyloseq object\nrownames(CRC_meta) <- make.names(rownames(CRC_meta))\ncolnames(CRC_abd) <- make.names(colnames(CRC_abd))\nrownames(CRC_abd) <- make.names(rownames(CRC_abd))\ntax_tab <- data.frame(Species = rownames(CRC_abd))\nrownames(tax_tab) <- tax_tab$Species\n\nCRC_phy <- phyloseq::phyloseq(\n  sample_data(CRC_meta),\n  otu_table(CRC_abd, taxa_are_rows = TRUE),\n  tax_table(as.matrix(tax_tab))\n)\n\n# 选择两个研究\nCRC_phy_new <- CRC_phy\nphyloseq::sample_data(CRC_phy_new) <- phyloseq::sample_data(\n  CRC_phy@sam_data %>%\n    data.frame() %>%\n    dplyr::filter(studyID %in% c(\"FengQ_2015.metaphlan_bugs_list.stool\",\n                                 \"VogtmannE_2016.metaphlan_bugs_list.stool\"))) \n# 运行\nord_result <- MicrobiomeAnalysis::run_ord(\n  object = CRC_phy_new,\n  variable = \"study_condition\",\n  method = \"PCoA\")\nMicrobiomeAnalysis::plot_ord(\n  reslist = ord_result,\n  variable = \"study_condition\",\n  variable_color = c(\"red\", \"blue\"),\n  var_shape = \"studyID\",\n  ellipse_type = \"none\")\nMicrobiomeAnalysis::run_PERMANOVA(\n  CRC_phy_new,\n  variables = c(\"study_condition\", \"studyID\"),\n  mode = \"one\",\n  method = \"bray\")\n#>                 SumsOfSample Df SumsOfSqs   MeanSqs\n#> study_condition          211  1 0.6756486 0.6756486\n#> studyID                  211  1 5.6815343 5.6815343\n#>                   F.Model         R2 Pr(>F) AdjustedPvalue\n#> study_condition  2.295539 0.01086411  0.004          0.004\n#> studyID         21.013183 0.09135643  0.001          0.002"},{"path":"BatchEffectCorrection.html","id":"批次效应校正","chapter":"5 Batch Effect Correction","heading":"5.1.3 批次效应校正","text":"需要明确的一点是批次效应只能降低，不能完全消除，并且在做批次效应过程中可能会降低或提高所研究的生物学意义，这是因为使用线性模型校正所带来的结果。MMUPHin处理批次效应的原理：混合模型：MMUPHin使用混合模型来纳入批次效应。在这种模型中，批次效应被视为随机效应，它们与研究中的固定效应（例如治疗组与对照组）分开处理。混合模型可以参考GEE MLM，它提供了常用的两种混合模型GEE和MLM。MMUPHin采用的是Zero-inflated empirical Bayes adjustment batch effect compositional feature abundance data。查看校正后的结果结果：相比校正前，studyID带来的效应明显降低。进一步通过PERMANOVA结果分析。结果：相比校正前，studyID的解释肠道结构总体变异度从9.1%降低到了1.7%。与此同时，study_condition的总体变异则几乎没有太大变化。","code":"\nfit_adjust_batch <- adjust_batch(\n  feature_abd = CRC_abd,\n  batch = \"studyID\",\n  covariates = \"study_condition\",\n  data = CRC_meta,\n  control = list(verbose = FALSE))\n\nCRC_abd_adj <- fit_adjust_batch$feature_abd_adj\n\nCRC_abd_adj[1:5, 1, drop = FALSE]\n#>                                 FengQ_2015.metaphlan_bugs_list.stool.SID31004\n#> s__Faecalibacterium_prausnitzii                                    0.10120482\n#> s__Streptococcus_salivarius                                        0.06044265\n#> s__Ruminococcus_sp_5_1_39BFAA                                      0.02374596\n#> s__Subdoligranulum_unclassified                                    0.03265566\n#> s__Bacteroides_stercoris                                           0.31510103\n# run_ord需要phyloseq object\nrownames(CRC_meta) <- make.names(rownames(CRC_meta))\ncolnames(CRC_abd_adj) <- make.names(colnames(CRC_abd_adj))\nrownames(CRC_abd_adj) <- make.names(rownames(CRC_abd_adj))\ntax_tab_adj <- data.frame(Species = rownames(CRC_abd_adj))\nrownames(tax_tab_adj) <- tax_tab_adj$Species\n\nCRC_phy_adj <- phyloseq::phyloseq(\n  sample_data(CRC_meta),\n  otu_table(CRC_abd_adj, taxa_are_rows = TRUE),\n  tax_table(as.matrix(tax_tab_adj))\n)\n\n# 选择两个研究\nCRC_phy_adj_new <- CRC_phy_adj\nphyloseq::sample_data(CRC_phy_adj_new) <- phyloseq::sample_data(\n  CRC_phy_adj@sam_data %>%\n    data.frame() %>%\n    dplyr::filter(studyID %in% c(\"FengQ_2015.metaphlan_bugs_list.stool\",\n                                 \"VogtmannE_2016.metaphlan_bugs_list.stool\"))) \n# 运行\nord_result <- MicrobiomeAnalysis::run_ord(\n  object = CRC_phy_adj_new,\n  variable = \"study_condition\",\n  method = \"PCoA\")\nMicrobiomeAnalysis::plot_ord(\n  reslist = ord_result,\n  variable = \"study_condition\",\n  variable_color = c(\"red\", \"blue\"),\n  var_shape = \"studyID\",\n  ellipse_type = \"none\")\nMicrobiomeAnalysis::run_PERMANOVA(\n  CRC_phy_adj_new,\n  variables = c(\"study_condition\", \"studyID\"),\n  mode = \"one\",\n  method = \"bray\")\n#>                 SumsOfSample Df SumsOfSqs   MeanSqs\n#> study_condition          211  1 0.7256598 0.7256598\n#> studyID                  211  1 1.0133205 1.0133205\n#>                  F.Model         R2 Pr(>F) AdjustedPvalue\n#> study_condition 2.511293 0.01187309  0.002          0.002\n#> studyID         3.523584 0.01657973  0.001          0.002"},{"path":"BatchEffectCorrection.html","id":"荟萃分析","chapter":"5 Batch Effect Correction","heading":"5.1.4 荟萃分析","text":"荟萃分析的目的是汇总各个研究的共同结果进而获得一个共有的效果，先前也有很多工具提供类似的研究，例如meta包。MMUPHin也提供了lm_meta函数用于分析。先用Maaslin2计算不同研究在control和CRC之间的差异物种；先用Maaslin2计算不同研究在control和CRC之间的差异物种；再使用混合模型汇总所有的结果。再使用混合模型汇总所有的结果。因为采用了线性回归方式，所以可以加入一些协变量如年龄、性别和BMI等人口统计变量作为校正因素。coef表示EffectSize也即是在Control和CRC组间的区别。","code":"\nif(!dir.exists(\"./InputData/MMUPHin_lm_meta\")) {\n  dir.create(\"./InputData/MMUPHin_lm_meta\", recursive = TRUE)\n}\n\nfit_lm_meta <- lm_meta(\n  feature_abd = CRC_abd_adj,\n  batch = \"studyID\",\n  exposure = \"study_condition\",\n  covariates = c(\"gender\", \"age\", \"BMI\"),\n  data = CRC_meta,\n  control = list(verbose = FALSE, \n                 output = \"./InputData/MMUPHin_lm_meta\"))\n\nfit_lm_meta$meta_fits %>% \n  filter(qval.fdr < 0.05) %>% \n  arrange(coef) %>% \n  mutate(feature = factor(feature, levels = feature)) %>% \n  ggplot(aes(y = coef, x = feature)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() +\n  theme_bw()"},{"path":"BatchEffectCorrection.html","id":"总结-1","chapter":"5 Batch Effect Correction","heading":"5.1.5 总结","text":"MMUPHin提供了可以校正多个数据来源的批次效应函数MMUPHin提供了可以校正多个数据来源的批次效应函数MMUPHin在做荟萃分析的时提供了工具MMUPHin在做荟萃分析的时提供了工具","code":""},{"path":"BatchEffectCorrection.html","id":"systemic-information-2","chapter":"5 Batch Effect Correction","heading":"5.2 Systemic information","text":"","code":"\ndevtools::session_info()\n#> ─ Session info ───────────────────────────────────────────\n#>  setting  value\n#>  version  R version 4.1.3 (2022-03-10)\n#>  os       macOS Big Sur/Monterey 10.16\n#>  system   x86_64, darwin17.0\n#>  ui       X11\n#>  language (EN)\n#>  collate  en_US.UTF-8\n#>  ctype    en_US.UTF-8\n#>  tz       Asia/Shanghai\n#>  date     2024-02-06\n#>  pandoc   3.1.1 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/ (via rmarkdown)\n#> \n#> ─ Packages ───────────────────────────────────────────────\n#>  package                  * version    date (UTC) lib source\n#>  ade4                       1.7-22     2023-02-06 [1] CRAN (R 4.1.2)\n#>  ANCOMBC                    2.4.0      2023-10-26 [1] Bioconductor\n#>  annotate                   1.72.0     2021-10-26 [2] Bioconductor\n#>  AnnotationDbi              1.60.2     2023-03-10 [2] Bioconductor\n#>  ape                        5.7-1      2023-03-13 [1] CRAN (R 4.1.2)\n#>  backports                  1.4.1      2021-12-13 [2] CRAN (R 4.1.0)\n#>  base64enc                  0.1-3      2015-07-28 [2] CRAN (R 4.1.0)\n#>  beachmat                   2.10.0     2021-10-26 [2] Bioconductor\n#>  beeswarm                   0.4.0      2021-06-01 [2] CRAN (R 4.1.0)\n#>  biglm                      0.9-2.1    2020-11-27 [2] CRAN (R 4.1.0)\n#>  Biobase                    2.54.0     2021-10-26 [2] Bioconductor\n#>  BiocGenerics               0.40.0     2021-10-26 [2] Bioconductor\n#>  BiocNeighbors              1.12.0     2021-10-26 [2] Bioconductor\n#>  BiocParallel               1.28.3     2021-12-09 [2] Bioconductor\n#>  BiocSingular               1.10.0     2021-10-26 [2] Bioconductor\n#>  biomformat                 1.22.0     2021-10-26 [2] Bioconductor\n#>  Biostrings                 2.62.0     2021-10-26 [2] Bioconductor\n#>  bit                        4.0.5      2022-11-15 [2] CRAN (R 4.1.2)\n#>  bit64                      4.0.5      2020-08-30 [2] CRAN (R 4.1.0)\n#>  bitops                     1.0-7      2021-04-24 [2] CRAN (R 4.1.0)\n#>  blob                       1.2.4      2023-03-17 [2] CRAN (R 4.1.2)\n#>  bluster                    1.4.0      2021-10-26 [2] Bioconductor\n#>  bookdown                   0.34       2023-05-09 [2] CRAN (R 4.1.2)\n#>  boot                       1.3-28.1   2022-11-22 [2] CRAN (R 4.1.2)\n#>  bslib                      0.6.0      2023-11-21 [1] CRAN (R 4.1.3)\n#>  cachem                     1.0.8      2023-05-01 [2] CRAN (R 4.1.2)\n#>  callr                      3.7.3      2022-11-02 [2] CRAN (R 4.1.2)\n#>  caTools                    1.18.2     2021-03-28 [2] CRAN (R 4.1.0)\n#>  cellranger                 1.1.0      2016-07-27 [2] CRAN (R 4.1.0)\n#>  checkmate                  2.2.0      2023-04-27 [2] CRAN (R 4.1.2)\n#>  class                      7.3-22     2023-05-03 [2] CRAN (R 4.1.2)\n#>  cli                        3.6.1      2023-03-23 [2] CRAN (R 4.1.2)\n#>  cluster                    2.1.4      2022-08-22 [2] CRAN (R 4.1.2)\n#>  codetools                  0.2-19     2023-02-01 [2] CRAN (R 4.1.2)\n#>  colorspace                 2.1-0      2023-01-23 [2] CRAN (R 4.1.2)\n#>  cowplot                    1.1.2      2023-12-15 [1] CRAN (R 4.1.3)\n#>  crayon                     1.5.2      2022-09-29 [2] CRAN (R 4.1.2)\n#>  CVXR                       1.0-12     2024-02-02 [1] CRAN (R 4.1.3)\n#>  data.table                 1.14.8     2023-02-17 [2] CRAN (R 4.1.2)\n#>  DBI                        1.1.3      2022-06-18 [2] CRAN (R 4.1.2)\n#>  DECIPHER                   2.22.0     2021-10-26 [2] Bioconductor\n#>  decontam                   1.14.0     2021-10-26 [2] Bioconductor\n#>  DelayedArray               0.20.0     2021-10-26 [2] Bioconductor\n#>  DelayedMatrixStats         1.16.0     2021-10-26 [2] Bioconductor\n#>  DEoptimR                   1.0-14     2023-06-09 [2] CRAN (R 4.1.3)\n#>  DescTools                  0.99.49    2023-05-17 [2] CRAN (R 4.1.3)\n#>  DESeq2                     1.34.0     2021-10-26 [2] Bioconductor\n#>  devtools                   2.4.5      2022-10-11 [2] CRAN (R 4.1.2)\n#>  digest                     0.6.33     2023-07-07 [1] CRAN (R 4.1.3)\n#>  DirichletMultinomial       1.36.0     2021-10-26 [2] Bioconductor\n#>  doParallel                 1.0.17     2022-02-07 [2] CRAN (R 4.1.2)\n#>  doRNG                      1.8.6      2023-01-16 [2] CRAN (R 4.1.2)\n#>  downlit                    0.4.3      2023-06-29 [2] CRAN (R 4.1.3)\n#>  dplyr                    * 1.1.4      2023-11-17 [1] CRAN (R 4.1.3)\n#>  e1071                      1.7-13     2023-02-01 [2] CRAN (R 4.1.2)\n#>  ellipsis                   0.3.2      2021-04-29 [2] CRAN (R 4.1.0)\n#>  energy                     1.7-11     2022-12-22 [1] CRAN (R 4.1.2)\n#>  evaluate                   0.21       2023-05-05 [2] CRAN (R 4.1.2)\n#>  Exact                      3.2        2022-09-25 [2] CRAN (R 4.1.2)\n#>  expm                       0.999-7    2023-01-09 [2] CRAN (R 4.1.2)\n#>  fansi                      1.0.4      2023-01-22 [2] CRAN (R 4.1.2)\n#>  farver                     2.1.1      2022-07-06 [2] CRAN (R 4.1.2)\n#>  fastmap                    1.1.1      2023-02-24 [2] CRAN (R 4.1.2)\n#>  forcats                  * 1.0.0      2023-01-29 [1] CRAN (R 4.1.2)\n#>  foreach                    1.5.2      2022-02-02 [2] CRAN (R 4.1.2)\n#>  foreign                    0.8-84     2022-12-06 [2] CRAN (R 4.1.2)\n#>  Formula                    1.2-5      2023-02-24 [2] CRAN (R 4.1.2)\n#>  fs                         1.6.2      2023-04-25 [2] CRAN (R 4.1.2)\n#>  genefilter                 1.76.0     2021-10-26 [2] Bioconductor\n#>  geneplotter                1.72.0     2021-10-26 [2] Bioconductor\n#>  generics                   0.1.3      2022-07-05 [2] CRAN (R 4.1.2)\n#>  GenomeInfoDb               1.30.1     2022-01-30 [2] Bioconductor\n#>  GenomeInfoDbData           1.2.7      2022-03-09 [2] Bioconductor\n#>  GenomicRanges              1.46.1     2021-11-18 [2] Bioconductor\n#>  getopt                     1.20.3     2019-03-22 [2] CRAN (R 4.1.0)\n#>  ggbeeswarm                 0.7.2      2023-04-29 [1] CRAN (R 4.1.2)\n#>  ggplot2                  * 3.4.4      2023-10-12 [1] CRAN (R 4.1.3)\n#>  ggrepel                    0.9.3      2023-02-03 [1] CRAN (R 4.1.2)\n#>  gld                        2.6.6      2022-10-23 [2] CRAN (R 4.1.2)\n#>  glmnet                     4.1-7      2023-03-23 [2] CRAN (R 4.1.2)\n#>  glue                       1.6.2      2022-02-24 [2] CRAN (R 4.1.2)\n#>  gmp                        0.7-1      2023-02-07 [2] CRAN (R 4.1.2)\n#>  gplots                     3.1.3      2022-04-25 [2] CRAN (R 4.1.2)\n#>  gridExtra                  2.3        2017-09-09 [2] CRAN (R 4.1.0)\n#>  gsl                        2.1-8      2023-01-24 [2] CRAN (R 4.1.2)\n#>  gtable                     0.3.3      2023-03-21 [2] CRAN (R 4.1.2)\n#>  gtools                     3.9.4      2022-11-27 [2] CRAN (R 4.1.2)\n#>  hash                       2.2.6.2    2022-03-22 [2] CRAN (R 4.1.2)\n#>  highr                      0.10       2022-12-22 [2] CRAN (R 4.1.2)\n#>  Hmisc                      5.1-0      2023-05-08 [1] CRAN (R 4.1.2)\n#>  hms                        1.1.3      2023-03-21 [2] CRAN (R 4.1.2)\n#>  htmlTable                  2.4.1      2022-07-07 [2] CRAN (R 4.1.2)\n#>  htmltools                  0.5.7      2023-11-03 [1] CRAN (R 4.1.3)\n#>  htmlwidgets                1.6.2      2023-03-17 [2] CRAN (R 4.1.2)\n#>  httpuv                     1.6.11     2023-05-11 [2] CRAN (R 4.1.3)\n#>  httr                       1.4.6      2023-05-08 [2] CRAN (R 4.1.2)\n#>  igraph                     1.5.0      2023-06-16 [1] CRAN (R 4.1.3)\n#>  IRanges                    2.28.0     2021-10-26 [2] Bioconductor\n#>  irlba                      2.3.5.1    2022-10-03 [2] CRAN (R 4.1.2)\n#>  iterators                  1.0.14     2022-02-05 [2] CRAN (R 4.1.2)\n#>  jquerylib                  0.1.4      2021-04-26 [2] CRAN (R 4.1.0)\n#>  jsonlite                   1.8.7      2023-06-29 [2] CRAN (R 4.1.3)\n#>  KEGGREST                   1.34.0     2021-10-26 [2] Bioconductor\n#>  KernSmooth                 2.23-22    2023-07-10 [2] CRAN (R 4.1.3)\n#>  knitr                      1.43       2023-05-25 [2] CRAN (R 4.1.3)\n#>  labeling                   0.4.2      2020-10-20 [2] CRAN (R 4.1.0)\n#>  later                      1.3.1      2023-05-02 [2] CRAN (R 4.1.2)\n#>  lattice                    0.21-8     2023-04-05 [2] CRAN (R 4.1.2)\n#>  lazyeval                   0.2.2      2019-03-15 [2] CRAN (R 4.1.0)\n#>  lifecycle                  1.0.3      2022-10-07 [2] CRAN (R 4.1.2)\n#>  limma                      3.50.3     2022-04-07 [2] Bioconductor\n#>  lme4                       1.1-34     2023-07-04 [1] CRAN (R 4.1.3)\n#>  lmerTest                   3.1-3      2020-10-23 [1] CRAN (R 4.1.0)\n#>  lmom                       2.9        2022-05-29 [2] CRAN (R 4.1.2)\n#>  locfit                     1.5-9.8    2023-06-11 [2] CRAN (R 4.1.3)\n#>  logging                    0.10-108   2019-07-14 [2] CRAN (R 4.1.0)\n#>  lpsymphony                 1.22.0     2021-10-26 [2] Bioconductor (R 4.1.1)\n#>  lubridate                * 1.9.2      2023-02-10 [2] CRAN (R 4.1.2)\n#>  Maaslin2                   1.8.0      2021-10-26 [2] Bioconductor\n#>  magrittr                   2.0.3      2022-03-30 [2] CRAN (R 4.1.2)\n#>  MASS                       7.3-60     2023-05-04 [1] CRAN (R 4.1.2)\n#>  mathjaxr                   1.6-0      2022-02-28 [2] CRAN (R 4.1.2)\n#>  Matrix                     1.6-5      2024-01-11 [1] CRAN (R 4.1.3)\n#>  MatrixGenerics             1.6.0      2021-10-26 [2] Bioconductor\n#>  matrixStats                1.1.0      2023-11-07 [1] CRAN (R 4.1.3)\n#>  memoise                    2.0.1      2021-11-26 [2] CRAN (R 4.1.0)\n#>  metadat                    1.2-0      2022-04-06 [2] CRAN (R 4.1.2)\n#>  metafor                    4.2-0      2023-05-08 [2] CRAN (R 4.1.2)\n#>  metagenomeSeq              1.36.0     2021-10-26 [2] Bioconductor\n#>  mgcv                       1.8-42     2023-03-02 [2] CRAN (R 4.1.2)\n#>  mia                        1.10.0     2023-10-24 [1] Bioconductor\n#>  MicrobiomeAnalysis         1.0.3      2023-12-02 [1] Bioconductor\n#>  mime                       0.12       2021-09-28 [2] CRAN (R 4.1.0)\n#>  miniUI                     0.1.1.1    2018-05-18 [2] CRAN (R 4.1.0)\n#>  minqa                      1.2.5      2022-10-19 [2] CRAN (R 4.1.2)\n#>  MMUPHin                  * 1.8.2      2022-04-03 [1] Bioconductor\n#>  multcomp                   1.4-25     2023-06-20 [2] CRAN (R 4.1.3)\n#>  MultiAssayExperiment       1.20.0     2021-10-26 [2] Bioconductor\n#>  multtest                   2.50.0     2021-10-26 [2] Bioconductor\n#>  munsell                    0.5.0      2018-06-12 [2] CRAN (R 4.1.0)\n#>  mvtnorm                    1.2-2      2023-06-08 [2] CRAN (R 4.1.3)\n#>  nlme                       3.1-162    2023-01-31 [1] CRAN (R 4.1.2)\n#>  nloptr                     2.0.3      2022-05-26 [2] CRAN (R 4.1.2)\n#>  nnet                       7.3-19     2023-05-03 [2] CRAN (R 4.1.2)\n#>  numDeriv                   2016.8-1.1 2019-06-06 [2] CRAN (R 4.1.0)\n#>  optparse                   1.7.3      2022-07-20 [2] CRAN (R 4.1.2)\n#>  pbapply                    1.7-2      2023-06-27 [2] CRAN (R 4.1.3)\n#>  pcaPP                      2.0-3      2022-10-24 [2] CRAN (R 4.1.2)\n#>  permute                    0.9-7      2022-01-27 [2] CRAN (R 4.1.2)\n#>  phyloseq                 * 1.38.0     2021-10-26 [2] Bioconductor\n#>  pillar                     1.9.0      2023-03-22 [2] CRAN (R 4.1.2)\n#>  pkgbuild                   1.4.2      2023-06-26 [2] CRAN (R 4.1.3)\n#>  pkgconfig                  2.0.3      2019-09-22 [2] CRAN (R 4.1.0)\n#>  pkgload                    1.3.2.1    2023-07-08 [2] CRAN (R 4.1.3)\n#>  plyr                       1.8.8      2022-11-11 [1] CRAN (R 4.1.2)\n#>  png                        0.1-8      2022-11-29 [2] CRAN (R 4.1.2)\n#>  prettyunits                1.1.1      2020-01-24 [2] CRAN (R 4.1.0)\n#>  processx                   3.8.2      2023-06-30 [2] CRAN (R 4.1.3)\n#>  profvis                    0.3.8      2023-05-02 [2] CRAN (R 4.1.2)\n#>  promises                   1.2.0.1    2021-02-11 [2] CRAN (R 4.1.0)\n#>  proxy                      0.4-27     2022-06-09 [2] CRAN (R 4.1.2)\n#>  ps                         1.7.5      2023-04-18 [2] CRAN (R 4.1.2)\n#>  purrr                    * 1.0.1      2023-01-10 [1] CRAN (R 4.1.2)\n#>  R6                         2.5.1      2021-08-19 [2] CRAN (R 4.1.0)\n#>  ragg                       1.2.5      2023-01-12 [2] CRAN (R 4.1.2)\n#>  rbibutils                  2.2.13     2023-01-13 [2] CRAN (R 4.1.2)\n#>  RColorBrewer               1.1-3      2022-04-03 [1] CRAN (R 4.1.2)\n#>  Rcpp                       1.0.11     2023-07-06 [1] CRAN (R 4.1.3)\n#>  RCurl                      1.98-1.12  2023-03-27 [2] CRAN (R 4.1.2)\n#>  Rdpack                     2.4        2022-07-20 [2] CRAN (R 4.1.2)\n#>  readr                    * 2.1.4      2023-02-10 [1] CRAN (R 4.1.2)\n#>  readxl                     1.4.3      2023-07-06 [2] CRAN (R 4.1.3)\n#>  remotes                    2.4.2      2021-11-30 [2] CRAN (R 4.1.0)\n#>  reshape2                   1.4.4      2020-04-09 [2] CRAN (R 4.1.0)\n#>  rhdf5                      2.38.1     2022-03-10 [2] Bioconductor\n#>  rhdf5filters               1.6.0      2021-10-26 [2] Bioconductor\n#>  Rhdf5lib                   1.16.0     2021-10-26 [2] Bioconductor\n#>  rlang                      1.1.1      2023-04-28 [1] CRAN (R 4.1.2)\n#>  rmarkdown                  2.23       2023-07-01 [2] CRAN (R 4.1.3)\n#>  Rmpfr                      0.9-2      2023-04-22 [2] CRAN (R 4.1.2)\n#>  rngtools                   1.5.2      2021-09-20 [2] CRAN (R 4.1.0)\n#>  robustbase                 0.99-0     2023-06-16 [2] CRAN (R 4.1.3)\n#>  rootSolve                  1.8.2.3    2021-09-29 [2] CRAN (R 4.1.0)\n#>  rpart                      4.1.19     2022-10-21 [2] CRAN (R 4.1.2)\n#>  RSQLite                    2.3.1      2023-04-03 [2] CRAN (R 4.1.2)\n#>  rstudioapi                 0.15.0     2023-07-07 [2] CRAN (R 4.1.3)\n#>  rsvd                       1.0.5      2021-04-16 [2] CRAN (R 4.1.0)\n#>  S4Vectors                  0.32.4     2022-03-29 [2] Bioconductor\n#>  sandwich                   3.0-2      2022-06-15 [2] CRAN (R 4.1.2)\n#>  sass                       0.4.6      2023-05-03 [2] CRAN (R 4.1.2)\n#>  ScaledMatrix               1.2.0      2021-10-26 [2] Bioconductor\n#>  scales                     1.2.1      2022-08-20 [1] CRAN (R 4.1.2)\n#>  scater                     1.22.0     2021-10-26 [2] Bioconductor\n#>  scuttle                    1.4.0      2021-10-26 [2] Bioconductor\n#>  sessioninfo                1.2.2      2021-12-06 [2] CRAN (R 4.1.0)\n#>  shape                      1.4.6      2021-05-19 [2] CRAN (R 4.1.0)\n#>  shiny                      1.7.4.1    2023-07-06 [2] CRAN (R 4.1.3)\n#>  SingleCellExperiment       1.16.0     2021-10-26 [2] Bioconductor\n#>  sparseMatrixStats          1.6.0      2021-10-26 [2] Bioconductor\n#>  stringi                    1.7.12     2023-01-11 [2] CRAN (R 4.1.2)\n#>  stringr                  * 1.5.1      2023-11-14 [1] CRAN (R 4.1.3)\n#>  SummarizedExperiment       1.24.0     2021-10-26 [2] Bioconductor\n#>  survival                   3.5-5      2023-03-12 [2] CRAN (R 4.1.2)\n#>  systemfonts                1.0.4      2022-02-11 [2] CRAN (R 4.1.2)\n#>  textshaping                0.3.6      2021-10-13 [2] CRAN (R 4.1.0)\n#>  TH.data                    1.1-2      2023-04-17 [2] CRAN (R 4.1.2)\n#>  tibble                   * 3.2.1      2023-03-20 [1] CRAN (R 4.1.2)\n#>  tidyr                    * 1.3.0      2023-01-24 [1] CRAN (R 4.1.2)\n#>  tidyselect                 1.2.0      2022-10-10 [2] CRAN (R 4.1.2)\n#>  tidytree                   0.4.2      2022-12-18 [2] CRAN (R 4.1.2)\n#>  tidyverse                * 2.0.0      2023-02-22 [1] CRAN (R 4.1.2)\n#>  timechange                 0.2.0      2023-01-11 [2] CRAN (R 4.1.2)\n#>  treeio                     1.18.1     2021-11-14 [2] Bioconductor\n#>  TreeSummarizedExperiment   2.2.0      2021-10-26 [2] Bioconductor\n#>  tzdb                       0.4.0      2023-05-12 [2] CRAN (R 4.1.3)\n#>  urlchecker                 1.0.1      2021-11-30 [2] CRAN (R 4.1.0)\n#>  usethis                    2.2.2      2023-07-06 [2] CRAN (R 4.1.3)\n#>  utf8                       1.2.3      2023-01-31 [2] CRAN (R 4.1.2)\n#>  vctrs                      0.6.5      2023-12-01 [1] CRAN (R 4.1.3)\n#>  vegan                      2.6-4      2022-10-11 [1] CRAN (R 4.1.2)\n#>  vipor                      0.4.5      2017-03-22 [2] CRAN (R 4.1.0)\n#>  viridis                    0.6.3      2023-05-03 [2] CRAN (R 4.1.2)\n#>  viridisLite                0.4.2      2023-05-02 [2] CRAN (R 4.1.2)\n#>  withr                      2.5.0      2022-03-03 [2] CRAN (R 4.1.2)\n#>  Wrench                     1.12.0     2021-10-26 [2] Bioconductor\n#>  xfun                       0.40       2023-08-09 [1] CRAN (R 4.1.3)\n#>  XML                        3.99-0.14  2023-03-19 [2] CRAN (R 4.1.2)\n#>  xml2                       1.3.5      2023-07-06 [2] CRAN (R 4.1.3)\n#>  xtable                     1.8-4      2019-04-21 [2] CRAN (R 4.1.0)\n#>  XVector                    0.34.0     2021-10-26 [2] Bioconductor\n#>  yaml                       2.3.7      2023-01-23 [2] CRAN (R 4.1.2)\n#>  yulab.utils                0.0.6      2022-12-20 [2] CRAN (R 4.1.2)\n#>  zlibbioc                   1.40.0     2021-10-26 [2] Bioconductor\n#>  zoo                        1.8-12     2023-04-13 [2] CRAN (R 4.1.2)\n#> \n#>  [1] /Users/zouhua/Library/R/x86_64/4.1/library\n#>  [2] /Library/Frameworks/R.framework/Versions/4.1/Resources/library\n#> \n#> ──────────────────────────────────────────────────────────"},{"path":"BatchEffectCorrection.html","id":"reference-3","chapter":"5 Batch Effect Correction","heading":"5.3 Reference","text":"MMUPHinMMUPHinDoing Meta-Analysis R: Hands-GuideDoing Meta-Analysis R: Hands-Guide","code":""},{"path":"LinearModelonMicrobialCommunity.html","id":"LinearModelonMicrobialCommunity","chapter":"6 Linear Model on Microbial Community","heading":"6 Linear Model on Microbial Community","text":"在微生物研究中，通常会使用基于距离矩阵的置换检验（如PERMANOVA）判断环境因素和微生物群落结构的相关性关系。本文使用另一套分析方法计算环境因素对微生物群落差异和微生物相对丰度差异的贡献，它使用到的是：相关性分析：计算环境因素和各个物种相对丰度的相关性大小；相关性分析：计算环境因素和各个物种相对丰度的相关性大小；多元线性回归分析：计算主要的环境因素对各个物种相对丰度的贡献（\\(R^2\\)）；多元线性回归分析：计算主要的环境因素对各个物种相对丰度的贡献（\\(R^2\\)）；拆分线性回归的总体贡献：计算每一个环境因素对各个物种相对丰度的重要程度（类似方差解分析）。拆分线性回归的总体贡献：计算每一个环境因素对各个物种相对丰度的重要程度（类似方差解分析）。本文为了确定影响微生物（肠道和口腔）群落差异和微生物相对丰度差异的人体特征变量。声明：本文参考了小白鱼的《仿一篇文献的相关性分析和线性模型评估影响群落组成的重要环境变量》。","code":""},{"path":"LinearModelonMicrobialCommunity.html","id":"加载r包-2","chapter":"6 Linear Model on Microbial Community","heading":"6.1 加载R包","text":"","code":"\nknitr::opts_chunk$set(message = FALSE, warning = FALSE)\nlibrary(tidyverse)\nlibrary(phyloseq)\n\nlibrary(caret)\nlibrary(leaps)\nlibrary(relaimpo)\n\n# rm(list = ls())\noptions(stringsAsFactors = F)\noptions(future.globals.maxSize = 1000 * 1024^2)"},{"path":"LinearModelonMicrobialCommunity.html","id":"导入数据-1","chapter":"6 Linear Model on Microbial Community","heading":"6.2 导入数据","text":"对数据OmicsDataSet-Zeybel et al. - 2022.xlsx处理后生成的，可参考数据生成和预处理章节。ps_gut：来自宿主肠道微生物组 (见Zeybel Dataset章节)ps_gut：来自宿主肠道微生物组 (见Zeybel Dataset章节)ps_oral：来自宿主肠道微生物组 (见Zeybel Dataset章节)ps_oral：来自宿主肠道微生物组 (见Zeybel Dataset章节)","code":"\nsaveRDS(ps_gut, \"./InputData/result/Zeybel_2022_gut_MGS_ps.RDS\", compress = TRUE)\nsaveRDS(ps_ora, \"./InputData/result/Zeybel_2022_oral_MGS_ps.RDS\", compress = TRUE)\nps_gut <- readRDS(\"./InputData/result/Zeybel_2022_gut_MGS_ps.RDS\")\nps_oral <- readRDS(\"./InputData/result/Zeybel_2022_oral_MGS_ps.RDS\")"},{"path":"LinearModelonMicrobialCommunity.html","id":"数据准备","chapter":"6 Linear Model on Microbial Community","heading":"6.3 数据准备","text":"人体特征指标：如Liver_fat, Creatinine, Body_mass_index等人体特征指标：如Liver_fat, Creatinine, Body_mass_index等门水平微生物表达谱：phylum levels门水平微生物表达谱：phylum levels","code":"\nmeta_gut <- ps_gut@sam_data %>%\n  data.frame() %>%\n  na.omit() %>%\n  dplyr::select(6:14)\n\nmeta_oral <- ps_oral@sam_data %>%\n  data.frame() %>%\n  na.omit() %>%\n  dplyr::select(6:14)\n\nsid <- intersect(rownames(meta_gut), rownames(meta_oral))\n\n# remotes::install_github(\"HuaZou/MicrobiomeAnalysis\")\nprof_gut <- MicrobiomeAnalysis::aggregate_taxa(\n  x = ps_gut,\n  level = \"Phylum\")\nprof_gut <- MicrobiomeAnalysis::trim_prevalence(\n  object = prof_gut,\n  cutoff = 0.1,\n  trim = \"feature\")\nprof_gut <- prof_gut@otu_table %>%\n  data.frame()\nprof_gut_final <- prof_gut[, pmatch(sid, colnames(prof_gut))]\n\nprof_oral <- MicrobiomeAnalysis::aggregate_taxa(\n  x = ps_oral,\n  level = \"Phylum\")\nprof_oral <- MicrobiomeAnalysis::trim_prevalence(\n  object = prof_oral,\n  cutoff = 0.1,\n  trim = \"feature\")\nprof_oral <- prof_oral@otu_table %>%\n  data.frame()\nprof_oral_final <- prof_oral[, pmatch(sid, colnames(prof_oral))]\n\nmeta_final <- meta_oral[pmatch(sid, rownames(meta_oral)), ,]\n\nrm(ps_gut, ps_oral, meta_gut, meta_oral, sid, prof_gut, prof_oral)"},{"path":"LinearModelonMicrobialCommunity.html","id":"相关性分析","chapter":"6 Linear Model on Microbial Community","heading":"6.4 相关性分析","text":"人体特征和物种相关性分析，分别计算每个人体特征和各个物种丰度的相关系数（采用spearman相关系数）。","code":"\nrun_cor <- function(\n    data_sam,\n    data_otu,\n    columns  = NULL,\n    method = c(\"spearman\", \"pearson\", \"kendall\"),\n    p_adjust = c(\"none\", \"fdr\", \"bonferroni\", \"holm\",\n                 \"hochberg\", \"hommel\", \"BH\", \"BY\")) {\n\n  # data_sam = meta_final\n  # data_otu = prof_gut_final\n  # columns = NULL\n  # method = \"spearman\"\n  # p_adjust = \"BH\"\n\n  if (is.null(method)) {\n    method <- \"spearman\"\n  } else {\n    method <- match.arg(\n      method,\n      c(\"spearman\", \"pearson\", \"kendall\")\n    )\n  }\n  # p_adjust\n  p_adjust <- match.arg(p_adjust,\n                        c(\"none\", \"fdr\", \"bonferroni\", \"holm\",\n                          \"hochberg\", \"hommel\", \"BH\", \"BY\")\n  )\n\n  interset_sampleid <- dplyr::intersect(\n      colnames(data_otu), rownames(data_sam))\n\n  data_otu_interset <- data_otu %>% \n    as.data.frame() %>%\n    dplyr::select(dplyr::all_of(interset_sampleid))\n  data_sam_interset <- data_sam %>% \n    as.data.frame()\n\n  data_sam_interset_final <- data_sam_interset[pmatch(interset_sampleid, \n                                                      rownames(data_sam_interset)), , F]\n\n  if (!all(colnames(data_otu_interset) == rownames(data_sam_interset_final))) {\n    stop(\"The order of SampleID is wrong, please check your inputdata\")\n  }\n\n  sam_tab <- data_sam_interset_final %>%\n      as.data.frame() %>%\n      tibble::rownames_to_column(\"TempRowNames\")\n  otu_tab_t <- data_otu_interset %>%\n      as.data.frame() %>%\n      base::t() %>%\n      as.data.frame()\n\n  # columns for test\n  if (!is.null(columns)) {\n    sam_tab <- sam_tab %>%\n      tibble::column_to_rownames(\"TempRowNames\") %>%\n      dplyr::select(dplyr::all_of(columns))\n  } else {\n    sam_tab <- sam_tab %>%\n      tibble::column_to_rownames(\"TempRowNames\")    \n  }\n\n  if (!all(rownames(otu_tab_t) == rownames(sam_tab))) {\n    stop(\"The order of SampleID is wrong, please check your input\")\n  }\n\n  # calculate the association between individual taxa and factors\n  res <- data.frame()\n  for (i in 1:ncol(sam_tab)) {\n    # whether all the elements are numeric\n    if (!is.numeric(sam_tab[, i])) {\n      stop(\"Please check your input, values in \", colnames(sam_tab)[i],\" are not numeric\")\n    }\n    for (j in 1:ncol(otu_tab_t)) {\n      mdat <- data.frame(x=sam_tab[, i],\n                         y=otu_tab_t[, j]) %>%\n        na.omit()\n      fit <- stats::cor.test(mdat$x, mdat$y, method = method)\n      temp <- data.frame(Phenotype=colnames(sam_tab)[i],\n                         FeatureID=colnames(otu_tab_t)[j],\n                         Statistic=fit$statistic,\n                         Rho=fit$estimate,\n                         Pvalue=fit$p.value)\n      res <- rbind(res, temp)\n    }\n  }\n\n  res$AdjustedPvalue <- p.adjust(as.numeric(res$Pvalue), method = p_adjust)\n  rownames(res) <- NULL\n\n  return(res)\n}\n\ngut_corres <- run_cor(\n  data_sam = meta_final,\n  data_otu = prof_gut_final,\n  p_adjust = \"BH\")\n\noral_corres <- run_cor(\n  data_sam = meta_final,\n  data_otu = prof_oral_final,\n  p_adjust = \"BH\")\n\nhead(gut_corres[, 1:3], 2)\n#>   Phenotype         FeatureID Statistic\n#> 1 Liver_fat p__Actinobacteria      7914\n#> 2 Liver_fat  p__Bacteroidetes      4858"},{"path":"LinearModelonMicrobialCommunity.html","id":"线性回归分析","chapter":"6 Linear Model on Microbial Community","heading":"6.5 线性回归分析","text":"人体特征指标对各个物种的贡献度可通过多元线性回归分析，即物种作为Y响应变量，人体特征作为X变量，通过回归的\\(R^2\\)解析总解释度。人体指标可能存在共线性的情况，可以在线性回归计算时候选择前向或后向回归方式筛选重要的变量。两种方法对结果影响较大，可能会得到大相径庭的结果。","code":""},{"path":"LinearModelonMicrobialCommunity.html","id":"选择变量分析思路","chapter":"6 Linear Model on Microbial Community","heading":"6.5.1 选择变量分析思路","text":"通过前向选择变量的分析思路通过前向逐步回归，在所有人体特征变量筛选重要的变量，尽可能减少人体特征共线性以获取简约模型，又同时尽可能保证模型的总解释率不要损失很多；通过前向逐步回归，在所有人体特征变量筛选重要的变量，尽可能减少人体特征共线性以获取简约模型，又同时尽可能保证模型的总解释率不要损失很多；使用选择的人体特征变量，分别拟合与每个物种丰度的多元线性回归，以期通过人体特征变量来解释物种丰度组成的差异；使用选择的人体特征变量，分别拟合与每个物种丰度的多元线性回归，以期通过人体特征变量来解释物种丰度组成的差异；对于在第（2）步中获得的最优模型，提取它们的总解释率（即线性模型的R2或校正后的R2）等信息；对于在第（2）步中获得的最优模型，提取它们的总解释率（即线性模型的R2或校正后的R2）等信息；对于在第（2）步中获得的最优模型，通过类似方差分解分析的方法，评估主要的人体特征对于物种丰度总方差的贡献，实现定量分析主要的人体特征相对重要性的目的。对于在第（2）步中获得的最优模型，通过类似方差分解分析的方法，评估主要的人体特征对于物种丰度总方差的贡献，实现定量分析主要的人体特征相对重要性的目的。通过后向选择变量的分析思路使用所有人体特征变量，分别拟合与每个物种丰度的多元线性回归，以期通过人体特征变量来解释物种丰度组成的差异；使用所有人体特征变量，分别拟合与每个物种丰度的多元线性回归，以期通过人体特征变量来解释物种丰度组成的差异；通过后向逐步回归，在构建好的每个线性模型中筛选重要的变量，尽可能减少人体特征变量共线性以获取简约模型，又同时尽可能保证模型的总解释率不要损失很多；通过后向逐步回归，在构建好的每个线性模型中筛选重要的变量，尽可能减少人体特征变量共线性以获取简约模型，又同时尽可能保证模型的总解释率不要损失很多；对于在第（2）步中获得的最优模型，提取它们的总解释率（即线性模型的R2或校正后的R2）等信息；对于在第（2）步中获得的最优模型，提取它们的总解释率（即线性模型的R2或校正后的R2）等信息；对于在第（2）步中获得的最优模型，通过类似方差分解分析的方法，评估主要的人体特征对于物种丰度总方差的贡献，实现定量分析主要的人体特征相对重要性的目的。对于在第（2）步中获得的最优模型，通过类似方差分解分析的方法，评估主要的人体特征对于物种丰度总方差的贡献，实现定量分析主要的人体特征相对重要性的目的。","code":""},{"path":"LinearModelonMicrobialCommunity.html","id":"函数","chapter":"6 Linear Model on Microbial Community","heading":"6.5.2 函数","text":"method参数控制筛选变量的方向：“leapForward”: 前向逐步回归 (forward selection)“leapForward”: 前向逐步回归 (forward selection)“leapBackward”: 后向逐步回归 (backward selection)“leapBackward”: 后向逐步回归 (backward selection)“leapSeq”: 逐步回归 (stepwise selection)“leapSeq”: 逐步回归 (stepwise selection)","code":"\nrun_lm <- function(\n    data_sam,\n    data_otu,\n    columns  = NULL,\n    method = c(\"leapForward\", \"leapBackward\", \"leapSeq\")) {\n\n  # data_sam = meta_final\n  # data_otu = prof_gut_final\n  # columns = NULL\n  # method = \"leapForward\"\n\n  if (is.null(method)) {\n    method <- \"leapForward\"\n  } else {\n    method <- match.arg(\n      method,\n      c(\"leapForward\", \"leapBackward\", \"leapSeq\")\n    )\n  }\n\n  interset_sampleid <- dplyr::intersect(\n      colnames(data_otu), rownames(data_sam))\n\n  data_otu_interset <- data_otu %>% \n    as.data.frame() %>%\n    dplyr::select(dplyr::all_of(interset_sampleid))\n  data_sam_interset <- data_sam %>% \n    as.data.frame()\n\n  data_sam_interset_final <- data_sam_interset[pmatch(interset_sampleid, \n                                                      rownames(data_sam_interset)), , F]\n\n  if (!all(colnames(data_otu_interset) == rownames(data_sam_interset_final))) {\n    stop(\"The order of SampleID is wrong, please check your inputdata\")\n  }\n\n  sam_tab <- data_sam_interset_final %>%\n      as.data.frame() %>%\n      tibble::rownames_to_column(\"TempRowNames\")\n  otu_tab_t <- data_otu_interset %>%\n      as.data.frame() %>%\n      base::t() %>%\n      as.data.frame()\n\n  # columns for test\n  if (!is.null(columns)) {\n    sam_tab <- sam_tab %>%\n      tibble::column_to_rownames(\"TempRowNames\") %>%\n      dplyr::select(dplyr::all_of(columns))\n  } else {\n    sam_tab <- sam_tab %>%\n      tibble::column_to_rownames(\"TempRowNames\")    \n  }\n\n  if (!all(rownames(otu_tab_t) == rownames(sam_tab))) {\n    stop(\"The order of SampleID is wrong, please check your input\")\n  }\n  \n  LM_func <- function(dat, feature_name) {\n    \n    feature <- feature_name\n    colnames(dat)[1] <- \"Taxa\"\n    \n    set.seed(123)\n    \n    # 变量选择\n    train.control <- trainControl(method = \"cv\", number = 3)\n    step.model <- train(Taxa ~., data = dat,\n                        method = method, \n                        tuneGrid = data.frame(nvmax = 1:5),\n                        trControl = train.control)\n    \n    model.coef <- coef(step.model$finalModel, as.numeric(step.model$bestTune)) %>%\n      as.data.frame()\n    final_index <- rownames(model.coef)[-1]\n    \n    # 基于上述选择的变量，使用 lm()拟合变量与各物种丰度的多元线性回归，获取最优模型\n    if (length(final_index) < 1) {\n      result_model <- data.frame(FeatureID = feature,\n                                 R2 = NA,\n                                 AdjustedR2 = NA,\n                                 Pvalue = NA)\n      result_import <- data.frame(TempID = colnames(dat)[-1],\n                                 Value = NA) %>%\n        tibble::column_to_rownames(\"TempID\") %>%\n        setNames(feature)\n    } else {\n      dat_new <- dat %>%\n        dplyr::select(dplyr::all_of(c(\"Taxa\", final_index)))\n      lm_fit <- lm(Taxa ~., data = dat_new)\n      lm_stat <- summary(lm_fit)\n      R2 <- lm_stat$r.squared \n      adjR2 <- lm_stat$adj.r.squared \n      fvalue <- lm_stat$fstatistic \n      Pvalue <- pf(fvalue[1], fvalue[2], fvalue[3])\n      \n      result_model <- data.frame(FeatureID = feature,\n                                 R2 = R2,\n                                 AdjustedR2 = adjR2,\n                                 Pvalue = Pvalue)\n      \n      # 多元线性回归（已通过变量选择后的最优模型）中各环境变量的相对重要性\n      error <- tryCatch(\n        expr = {\n          crf <- relaimpo::calc.relimp(lm_fit, rela = FALSE)\n        },\n        error = function(e){\n          message('calc.relimp Caught an error!')\n          print(e)\n        }\n      )\n      \n      if (length(error) > 1) {\n        result_import <- data.frame(TempID = colnames(dat)[-1],\n                                     Value = NA) %>%\n            tibble::column_to_rownames(\"TempID\") %>%\n            setNames(feature)  \n      } else {\n        temp_import <- crf@lmg %>%\n          as.data.frame() %>%\n          setNames(feature)\n        temp_import_NA <- data.frame(TempID = c(setdiff(colnames(dat)[-1], final_index)),\n                                     Value = NA) %>%\n          tibble::column_to_rownames(\"TempID\") %>%\n          setNames(feature)\n        \n        result_import <- rbind(temp_import, temp_import_NA)        \n      }\n    }\n    \n    res <- list(model = result_model,\n                import = result_import)\n    \n    return(res)\n  }  \n  \n\n  res_model <- data.frame()\n  res_import <- data.frame(matrix(NA, nrow = ncol(sam_tab), ncol = 0))\n  \n  for (i in 1:ncol(otu_tab_t)) {\n    \n    mdat <- cbind(otu_tab_t[, i, ], sam_tab)\n    featureID <- colnames(otu_tab_t)[i]\n    \n    temp_list <- LM_func(dat = mdat, feature_name = featureID)\n    \n    res_model <- rbind(res_model, temp_list$model)\n    res_import <- cbind(res_import, temp_list$import)\n  }\n  \n  res <- list(model = res_model,\n              import = res_import)\n  \n  return(res)\n}\n\ngut_LM <- run_lm(\n  data_sam = meta_final,\n  data_otu = prof_gut_final,\n  method = \"leapBackward\")\n#> <simpleError in solve.default(covg[diese, diese], matrix(covg[diese, andere],     length(diese), p + 1 - length(diese))): 'a' is 0-diml>\n#> <simpleError in solve.default(covg[diese, diese], matrix(covg[diese, andere],     length(diese), p + 1 - length(diese))): 'a' is 0-diml>\n#> <simpleError in solve.default(covg[diese, diese], matrix(covg[diese, andere],     length(diese), p + 1 - length(diese))): 'a' is 0-diml>\n#> <simpleError in solve.default(covg[diese, diese], matrix(covg[diese, andere],     length(diese), p + 1 - length(diese))): 'a' is 0-diml>\n#> <simpleError in solve.default(covg[diese, diese], matrix(covg[diese, andere],     length(diese), p + 1 - length(diese))): 'a' is 0-diml>\n\noral_LM <- run_lm(\n  data_sam = meta_final,\n  data_otu = prof_oral_final,\n  method = \"leapBackward\")\n#> <simpleError in solve.default(covg[diese, diese], matrix(covg[diese, andere],     length(diese), p + 1 - length(diese))): 'a' is 0-diml>\n#> <simpleError in solve.default(covg[diese, diese], matrix(covg[diese, andere],     length(diese), p + 1 - length(diese))): 'a' is 0-diml>\n#> <simpleError in solve.default(covg[diese, diese], matrix(covg[diese, andere],     length(diese), p + 1 - length(diese))): 'a' is 0-diml>\n#> <simpleError in solve.default(covg[diese, diese], matrix(covg[diese, andere],     length(diese), p + 1 - length(diese))): 'a' is 0-diml>\n\nhead(oral_LM$model[, 1:3], 2)\n#>                FeatureID        R2 AdjustedR2\n#> value  p__Actinobacteria 0.2355881  0.2109297\n#> value1  p__Bacteroidetes 0.3249810  0.2285498"},{"path":"LinearModelonMicrobialCommunity.html","id":"可视化","chapter":"6 Linear Model on Microbial Community","heading":"6.6 可视化","text":"热图的颜色表示相关系数大小；热图的颜色表示相关系数大小；柱状图表示人体特征变量对物种丰度差异的变异度解释；柱状图表示人体特征变量对物种丰度差异的变异度解释；热图的圆圈大小表示人体特征变量对物种的贡献程度大小。热图的圆圈大小表示人体特征变量对物种的贡献程度大小。结果：基于相关性和最优多元回归模型的人体特征指标差异对微生物群落差异和微生物门相对丰度差异的贡献。热图表示了人体特征指标和微生物的Spearman相关系数，柱形图表示了人体指标对解释微生物变异的总贡献（通过多元线性回归获得），圆圈大小表示人体指标的重要性（通过多元线性回归和方差分解分析获得）。A图是肠道微生物和人体特征变量的结果；B图是口腔微生物和人体特征变量的结果；A图是肠道微生物和人体特征变量的结果；B图是口腔微生物和人体特征变量的结果；肠道微生物和口腔微生物与人体特征变量相关性差异较大，人体特征变量对口腔微生物相对丰度差异共享度较大，Liver fat和Sodium对口腔的Bacterodies, Firmicutes和Proteobacteria物种差异和相对丰度差异有较大贡献，而肠道仅Urea_BUN对Actinobacteria物种差异和相对丰度有较大贡献；肠道微生物和口腔微生物与人体特征变量相关性差异较大，人体特征变量对口腔微生物相对丰度差异共享度较大，Liver fat和Sodium对口腔的Bacterodies, Firmicutes和Proteobacteria物种差异和相对丰度差异有较大贡献，而肠道仅Urea_BUN对Actinobacteria物种差异和相对丰度有较大贡献；人体特征变量对微生物群落解释度差异在肠道和口腔也存在较大差异。在口腔解释度最高的是Proteobacteria，而在肠道则是Actinobacteria；人体特征变量对微生物群落解释度差异在肠道和口腔也存在较大差异。在口腔解释度最高的是Proteobacteria，而在肠道则是Actinobacteria；相比PERMANOVA分析（各个微生物对整体人体特征变量的总变异度，也即单个微生物对人体变量总体的扰动程度），该组合方法不仅计算了各个微生物对核心人体特征变量（前后向逐步回归筛选）的解释度，而且也计算了这些核心变量对该微生物的重要程度（\\(R^2\\)分解成重要性打分）。相比PERMANOVA分析（各个微生物对整体人体特征变量的总变异度，也即单个微生物对人体变量总体的扰动程度），该组合方法不仅计算了各个微生物对核心人体特征变量（前后向逐步回归筛选）的解释度，而且也计算了这些核心变量对该微生物的重要程度（\\(R^2\\)分解成重要性打分）。","code":"\nget_LM_plot <- function(datCor, datLM)  {\n  \n  dat_cor <- datCor\n  dat_cor[which(dat_cor$Pvalue < 0.001), \"siglabel\"] <- \"***\"\n  dat_cor[which(dat_cor$Pvalue < 0.01 & dat_cor$Pvalue > 0.001), \"siglabel\"] <- \"**\"\n  dat_cor[which(dat_cor$Pvalue < 0.05 & dat_cor$Pvalue > 0.01), \"siglabel\"] <- \"*\"\n  \n  dat_LM <- datLM\n  dat_LM_R2 <- dat_LM$model\n  dat_LM_import <- dat_LM$import\n  \n  dat_LM_R2[which(dat_LM_R2$Pvalue < 0.001), \"siglabel\"] <- \"***\"\n  dat_LM_R2[which(dat_LM_R2$Pvalue < 0.01 & dat_LM_R2$Pvalue > 0.001), \"siglabel\"] <- \"**\"\n  dat_LM_R2[which(dat_LM_R2$Pvalue < 0.05 & dat_LM_R2$Pvalue > 0.01), \"siglabel\"] <- \"*\"\n  \n  dat_LM_import_final <- dat_LM_import %>%\n    tibble::rownames_to_column(\"Phenotype\") %>%\n    tidyr::gather(key = \"FeatureID\", value = \"importance\", -Phenotype)\n  \n  p1 <- ggplot() +\n    geom_tile(data = dat_cor, aes(x = FeatureID, y = Phenotype, fill = Rho)) +\n    scale_fill_gradientn(colors = c(\"#2D6DB1\", \"white\", \"#DC1623\"), limit = c(-1, 1)) +\n    scale_x_discrete(expand = c(0, 0)) +\n    scale_y_discrete(expand = c(0, 0)) +\n    geom_text(data = dat_cor, aes(x = FeatureID, y = Phenotype, label = siglabel), size = 3) +\n    geom_point(data = dat_LM_import_final, aes(x = FeatureID, y = Phenotype, size = importance * 100), shape = 1) +\n    scale_size_continuous(range = c(0, 5)) +\n    labs(y = \"\", x = \"\", fill = \"Correlation\", size = \"Importance (%)\") +  \n    guides(fill = guide_legend(order = 1), \n           size = guide_legend(order = 2)) +\n    theme_bw() +\n    theme(panel.grid = element_blank(), \n          panel.background = element_rect(color = \"black\"), \n          legend.key = element_blank(), \n          axis.text.x = element_text(color = \"black\", angle = 45, hjust = 1, vjust = 1), \n          axis.text.y = element_text(color = \"black\"), \n          axis.ticks = element_line(color = \"black\"))\n  \n  \n  p2 <- ggplot() +\n    geom_col(data = dat_LM_R2, aes(x = FeatureID, y = R2 * 100), fill = \"#4882B2\", width = 0.6) +\n    scale_y_continuous(expand = c(0, 0), limits = c(0, 100)) +\n    labs(y = \"Explained variation (%)\", x = \"\") +\n    theme(panel.grid = element_blank(),\n          panel.background = element_blank(),\n          axis.text.x = element_text(color = \"black\", angle = 45, hjust = 1, vjust = 1),\n          axis.text.y = element_text(color = \"black\"),\n          axis.line = element_line(color = \"black\"),\n          axis.ticks = element_line(color = \"black\"))\n  \n  \n  pl <- cowplot::plot_grid(p2, p1, ncol = 2, align = \"h\", rel_widths = c(0.7, 1))\n  \n  return(pl)  \n}\n\ncowplot::plot_grid(\n  get_LM_plot(datCor = gut_corres, datLM = gut_LM),\n  get_LM_plot(datCor = oral_corres, datLM = oral_LM),\n  ncol = 1, align = \"hv\", labels = LETTERS[1:2])"},{"path":"LinearModelonMicrobialCommunity.html","id":"systemic-information-3","chapter":"6 Linear Model on Microbial Community","heading":"6.7 Systemic information","text":"","code":"\ndevtools::session_info()\n#> ─ Session info ───────────────────────────────────────────\n#>  setting  value\n#>  version  R version 4.1.3 (2022-03-10)\n#>  os       macOS Big Sur/Monterey 10.16\n#>  system   x86_64, darwin17.0\n#>  ui       X11\n#>  language (EN)\n#>  collate  en_US.UTF-8\n#>  ctype    en_US.UTF-8\n#>  tz       Asia/Shanghai\n#>  date     2024-02-06\n#>  pandoc   3.1.1 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/ (via rmarkdown)\n#> \n#> ─ Packages ───────────────────────────────────────────────\n#>  package                  * version    date (UTC) lib source\n#>  ade4                       1.7-22     2023-02-06 [1] CRAN (R 4.1.2)\n#>  ANCOMBC                    2.4.0      2023-10-26 [1] Bioconductor\n#>  annotate                   1.72.0     2021-10-26 [2] Bioconductor\n#>  AnnotationDbi              1.60.2     2023-03-10 [2] Bioconductor\n#>  ape                        5.7-1      2023-03-13 [1] CRAN (R 4.1.2)\n#>  backports                  1.4.1      2021-12-13 [2] CRAN (R 4.1.0)\n#>  base64enc                  0.1-3      2015-07-28 [2] CRAN (R 4.1.0)\n#>  beachmat                   2.10.0     2021-10-26 [2] Bioconductor\n#>  beeswarm                   0.4.0      2021-06-01 [2] CRAN (R 4.1.0)\n#>  Biobase                    2.54.0     2021-10-26 [2] Bioconductor\n#>  BiocGenerics               0.40.0     2021-10-26 [2] Bioconductor\n#>  BiocNeighbors              1.12.0     2021-10-26 [2] Bioconductor\n#>  BiocParallel               1.28.3     2021-12-09 [2] Bioconductor\n#>  BiocSingular               1.10.0     2021-10-26 [2] Bioconductor\n#>  biomformat                 1.22.0     2021-10-26 [2] Bioconductor\n#>  Biostrings                 2.62.0     2021-10-26 [2] Bioconductor\n#>  bit                        4.0.5      2022-11-15 [2] CRAN (R 4.1.2)\n#>  bit64                      4.0.5      2020-08-30 [2] CRAN (R 4.1.0)\n#>  bitops                     1.0-7      2021-04-24 [2] CRAN (R 4.1.0)\n#>  blob                       1.2.4      2023-03-17 [2] CRAN (R 4.1.2)\n#>  bluster                    1.4.0      2021-10-26 [2] Bioconductor\n#>  bookdown                   0.34       2023-05-09 [2] CRAN (R 4.1.2)\n#>  boot                     * 1.3-28.1   2022-11-22 [2] CRAN (R 4.1.2)\n#>  bslib                      0.6.0      2023-11-21 [1] CRAN (R 4.1.3)\n#>  cachem                     1.0.8      2023-05-01 [2] CRAN (R 4.1.2)\n#>  callr                      3.7.3      2022-11-02 [2] CRAN (R 4.1.2)\n#>  caret                    * 6.0-94     2023-03-21 [2] CRAN (R 4.1.2)\n#>  caTools                    1.18.2     2021-03-28 [2] CRAN (R 4.1.0)\n#>  cellranger                 1.1.0      2016-07-27 [2] CRAN (R 4.1.0)\n#>  checkmate                  2.2.0      2023-04-27 [2] CRAN (R 4.1.2)\n#>  class                      7.3-22     2023-05-03 [2] CRAN (R 4.1.2)\n#>  cli                        3.6.1      2023-03-23 [2] CRAN (R 4.1.2)\n#>  cluster                    2.1.4      2022-08-22 [2] CRAN (R 4.1.2)\n#>  codetools                  0.2-19     2023-02-01 [2] CRAN (R 4.1.2)\n#>  colorspace                 2.1-0      2023-01-23 [2] CRAN (R 4.1.2)\n#>  corpcor                    1.6.10     2021-09-16 [2] CRAN (R 4.1.0)\n#>  cowplot                    1.1.2      2023-12-15 [1] CRAN (R 4.1.3)\n#>  crayon                     1.5.2      2022-09-29 [2] CRAN (R 4.1.2)\n#>  CVXR                       1.0-12     2024-02-02 [1] CRAN (R 4.1.3)\n#>  data.table                 1.14.8     2023-02-17 [2] CRAN (R 4.1.2)\n#>  DBI                        1.1.3      2022-06-18 [2] CRAN (R 4.1.2)\n#>  DECIPHER                   2.22.0     2021-10-26 [2] Bioconductor\n#>  decontam                   1.14.0     2021-10-26 [2] Bioconductor\n#>  DelayedArray               0.20.0     2021-10-26 [2] Bioconductor\n#>  DelayedMatrixStats         1.16.0     2021-10-26 [2] Bioconductor\n#>  DescTools                  0.99.49    2023-05-17 [2] CRAN (R 4.1.3)\n#>  DESeq2                     1.34.0     2021-10-26 [2] Bioconductor\n#>  devtools                   2.4.5      2022-10-11 [2] CRAN (R 4.1.2)\n#>  digest                     0.6.33     2023-07-07 [1] CRAN (R 4.1.3)\n#>  DirichletMultinomial       1.36.0     2021-10-26 [2] Bioconductor\n#>  doParallel                 1.0.17     2022-02-07 [2] CRAN (R 4.1.2)\n#>  doRNG                      1.8.6      2023-01-16 [2] CRAN (R 4.1.2)\n#>  downlit                    0.4.3      2023-06-29 [2] CRAN (R 4.1.3)\n#>  dplyr                    * 1.1.4      2023-11-17 [1] CRAN (R 4.1.3)\n#>  e1071                      1.7-13     2023-02-01 [2] CRAN (R 4.1.2)\n#>  ellipsis                   0.3.2      2021-04-29 [2] CRAN (R 4.1.0)\n#>  energy                     1.7-11     2022-12-22 [1] CRAN (R 4.1.2)\n#>  evaluate                   0.21       2023-05-05 [2] CRAN (R 4.1.2)\n#>  Exact                      3.2        2022-09-25 [2] CRAN (R 4.1.2)\n#>  expm                       0.999-7    2023-01-09 [2] CRAN (R 4.1.2)\n#>  fansi                      1.0.4      2023-01-22 [2] CRAN (R 4.1.2)\n#>  farver                     2.1.1      2022-07-06 [2] CRAN (R 4.1.2)\n#>  fastmap                    1.1.1      2023-02-24 [2] CRAN (R 4.1.2)\n#>  forcats                  * 1.0.0      2023-01-29 [1] CRAN (R 4.1.2)\n#>  foreach                    1.5.2      2022-02-02 [2] CRAN (R 4.1.2)\n#>  foreign                    0.8-84     2022-12-06 [2] CRAN (R 4.1.2)\n#>  Formula                    1.2-5      2023-02-24 [2] CRAN (R 4.1.2)\n#>  fs                         1.6.2      2023-04-25 [2] CRAN (R 4.1.2)\n#>  future                     1.33.0     2023-07-01 [2] CRAN (R 4.1.3)\n#>  future.apply               1.11.0     2023-05-21 [2] CRAN (R 4.1.3)\n#>  genefilter                 1.76.0     2021-10-26 [2] Bioconductor\n#>  geneplotter                1.72.0     2021-10-26 [2] Bioconductor\n#>  generics                   0.1.3      2022-07-05 [2] CRAN (R 4.1.2)\n#>  GenomeInfoDb               1.30.1     2022-01-30 [2] Bioconductor\n#>  GenomeInfoDbData           1.2.7      2022-03-09 [2] Bioconductor\n#>  GenomicRanges              1.46.1     2021-11-18 [2] Bioconductor\n#>  ggbeeswarm                 0.7.2      2023-04-29 [1] CRAN (R 4.1.2)\n#>  ggplot2                  * 3.4.4      2023-10-12 [1] CRAN (R 4.1.3)\n#>  ggrepel                    0.9.3      2023-02-03 [1] CRAN (R 4.1.2)\n#>  gld                        2.6.6      2022-10-23 [2] CRAN (R 4.1.2)\n#>  glmnet                     4.1-7      2023-03-23 [2] CRAN (R 4.1.2)\n#>  globals                    0.16.2     2022-11-21 [2] CRAN (R 4.1.2)\n#>  glue                       1.6.2      2022-02-24 [2] CRAN (R 4.1.2)\n#>  gmp                        0.7-1      2023-02-07 [2] CRAN (R 4.1.2)\n#>  gower                      1.0.1      2022-12-22 [2] CRAN (R 4.1.2)\n#>  gplots                     3.1.3      2022-04-25 [2] CRAN (R 4.1.2)\n#>  gridExtra                  2.3        2017-09-09 [2] CRAN (R 4.1.0)\n#>  gsl                        2.1-8      2023-01-24 [2] CRAN (R 4.1.2)\n#>  gtable                     0.3.3      2023-03-21 [2] CRAN (R 4.1.2)\n#>  gtools                     3.9.4      2022-11-27 [2] CRAN (R 4.1.2)\n#>  hardhat                    1.3.0      2023-03-30 [2] CRAN (R 4.1.2)\n#>  highr                      0.10       2022-12-22 [2] CRAN (R 4.1.2)\n#>  Hmisc                      5.1-0      2023-05-08 [1] CRAN (R 4.1.2)\n#>  hms                        1.1.3      2023-03-21 [2] CRAN (R 4.1.2)\n#>  htmlTable                  2.4.1      2022-07-07 [2] CRAN (R 4.1.2)\n#>  htmltools                  0.5.7      2023-11-03 [1] CRAN (R 4.1.3)\n#>  htmlwidgets                1.6.2      2023-03-17 [2] CRAN (R 4.1.2)\n#>  httpuv                     1.6.11     2023-05-11 [2] CRAN (R 4.1.3)\n#>  httr                       1.4.6      2023-05-08 [2] CRAN (R 4.1.2)\n#>  igraph                     1.5.0      2023-06-16 [1] CRAN (R 4.1.3)\n#>  ipred                      0.9-14     2023-03-09 [2] CRAN (R 4.1.2)\n#>  IRanges                    2.28.0     2021-10-26 [2] Bioconductor\n#>  irlba                      2.3.5.1    2022-10-03 [2] CRAN (R 4.1.2)\n#>  iterators                  1.0.14     2022-02-05 [2] CRAN (R 4.1.2)\n#>  jquerylib                  0.1.4      2021-04-26 [2] CRAN (R 4.1.0)\n#>  jsonlite                   1.8.7      2023-06-29 [2] CRAN (R 4.1.3)\n#>  KEGGREST                   1.34.0     2021-10-26 [2] Bioconductor\n#>  KernSmooth                 2.23-22    2023-07-10 [2] CRAN (R 4.1.3)\n#>  knitr                      1.43       2023-05-25 [2] CRAN (R 4.1.3)\n#>  labeling                   0.4.2      2020-10-20 [2] CRAN (R 4.1.0)\n#>  later                      1.3.1      2023-05-02 [2] CRAN (R 4.1.2)\n#>  lattice                  * 0.21-8     2023-04-05 [2] CRAN (R 4.1.2)\n#>  lava                       1.7.2.1    2023-02-27 [2] CRAN (R 4.1.2)\n#>  lazyeval                   0.2.2      2019-03-15 [2] CRAN (R 4.1.0)\n#>  leaps                    * 3.1        2020-01-16 [2] CRAN (R 4.1.0)\n#>  lifecycle                  1.0.3      2022-10-07 [2] CRAN (R 4.1.2)\n#>  limma                      3.50.3     2022-04-07 [2] Bioconductor\n#>  listenv                    0.9.0      2022-12-16 [2] CRAN (R 4.1.2)\n#>  lme4                       1.1-34     2023-07-04 [1] CRAN (R 4.1.3)\n#>  lmerTest                   3.1-3      2020-10-23 [1] CRAN (R 4.1.0)\n#>  lmom                       2.9        2022-05-29 [2] CRAN (R 4.1.2)\n#>  locfit                     1.5-9.8    2023-06-11 [2] CRAN (R 4.1.3)\n#>  lubridate                * 1.9.2      2023-02-10 [2] CRAN (R 4.1.2)\n#>  magrittr                   2.0.3      2022-03-30 [2] CRAN (R 4.1.2)\n#>  MASS                     * 7.3-60     2023-05-04 [1] CRAN (R 4.1.2)\n#>  Matrix                   * 1.6-5      2024-01-11 [1] CRAN (R 4.1.3)\n#>  MatrixGenerics             1.6.0      2021-10-26 [2] Bioconductor\n#>  matrixStats                1.1.0      2023-11-07 [1] CRAN (R 4.1.3)\n#>  memoise                    2.0.1      2021-11-26 [2] CRAN (R 4.1.0)\n#>  metagenomeSeq              1.36.0     2021-10-26 [2] Bioconductor\n#>  mgcv                       1.8-42     2023-03-02 [2] CRAN (R 4.1.2)\n#>  mia                        1.10.0     2023-10-24 [1] Bioconductor\n#>  MicrobiomeAnalysis         1.0.3      2023-12-02 [1] Bioconductor\n#>  mime                       0.12       2021-09-28 [2] CRAN (R 4.1.0)\n#>  miniUI                     0.1.1.1    2018-05-18 [2] CRAN (R 4.1.0)\n#>  minqa                      1.2.5      2022-10-19 [2] CRAN (R 4.1.2)\n#>  mitools                  * 2.4        2019-04-26 [2] CRAN (R 4.1.0)\n#>  ModelMetrics               1.2.2.2    2020-03-17 [2] CRAN (R 4.1.0)\n#>  multcomp                   1.4-25     2023-06-20 [2] CRAN (R 4.1.3)\n#>  MultiAssayExperiment       1.20.0     2021-10-26 [2] Bioconductor\n#>  multtest                   2.50.0     2021-10-26 [2] Bioconductor\n#>  munsell                    0.5.0      2018-06-12 [2] CRAN (R 4.1.0)\n#>  mvtnorm                    1.2-2      2023-06-08 [2] CRAN (R 4.1.3)\n#>  nlme                       3.1-162    2023-01-31 [1] CRAN (R 4.1.2)\n#>  nloptr                     2.0.3      2022-05-26 [2] CRAN (R 4.1.2)\n#>  nnet                       7.3-19     2023-05-03 [2] CRAN (R 4.1.2)\n#>  numDeriv                   2016.8-1.1 2019-06-06 [2] CRAN (R 4.1.0)\n#>  parallelly                 1.36.0     2023-05-26 [2] CRAN (R 4.1.3)\n#>  permute                    0.9-7      2022-01-27 [2] CRAN (R 4.1.2)\n#>  phyloseq                 * 1.38.0     2021-10-26 [2] Bioconductor\n#>  pillar                     1.9.0      2023-03-22 [2] CRAN (R 4.1.2)\n#>  pkgbuild                   1.4.2      2023-06-26 [2] CRAN (R 4.1.3)\n#>  pkgconfig                  2.0.3      2019-09-22 [2] CRAN (R 4.1.0)\n#>  pkgload                    1.3.2.1    2023-07-08 [2] CRAN (R 4.1.3)\n#>  plyr                       1.8.8      2022-11-11 [1] CRAN (R 4.1.2)\n#>  png                        0.1-8      2022-11-29 [2] CRAN (R 4.1.2)\n#>  prettyunits                1.1.1      2020-01-24 [2] CRAN (R 4.1.0)\n#>  pROC                       1.18.4     2023-07-06 [2] CRAN (R 4.1.3)\n#>  processx                   3.8.2      2023-06-30 [2] CRAN (R 4.1.3)\n#>  prodlim                    2023.03.31 2023-04-02 [2] CRAN (R 4.1.2)\n#>  profvis                    0.3.8      2023-05-02 [2] CRAN (R 4.1.2)\n#>  promises                   1.2.0.1    2021-02-11 [2] CRAN (R 4.1.0)\n#>  proxy                      0.4-27     2022-06-09 [2] CRAN (R 4.1.2)\n#>  ps                         1.7.5      2023-04-18 [2] CRAN (R 4.1.2)\n#>  purrr                    * 1.0.1      2023-01-10 [1] CRAN (R 4.1.2)\n#>  R6                         2.5.1      2021-08-19 [2] CRAN (R 4.1.0)\n#>  rbibutils                  2.2.13     2023-01-13 [2] CRAN (R 4.1.2)\n#>  RColorBrewer               1.1-3      2022-04-03 [1] CRAN (R 4.1.2)\n#>  Rcpp                       1.0.11     2023-07-06 [1] CRAN (R 4.1.3)\n#>  RCurl                      1.98-1.12  2023-03-27 [2] CRAN (R 4.1.2)\n#>  Rdpack                     2.4        2022-07-20 [2] CRAN (R 4.1.2)\n#>  readr                    * 2.1.4      2023-02-10 [1] CRAN (R 4.1.2)\n#>  readxl                     1.4.3      2023-07-06 [2] CRAN (R 4.1.3)\n#>  recipes                    1.0.6      2023-04-25 [2] CRAN (R 4.1.2)\n#>  relaimpo                 * 2.2-7      2023-10-04 [1] CRAN (R 4.1.3)\n#>  remotes                    2.4.2      2021-11-30 [2] CRAN (R 4.1.0)\n#>  reshape2                   1.4.4      2020-04-09 [2] CRAN (R 4.1.0)\n#>  rhdf5                      2.38.1     2022-03-10 [2] Bioconductor\n#>  rhdf5filters               1.6.0      2021-10-26 [2] Bioconductor\n#>  Rhdf5lib                   1.16.0     2021-10-26 [2] Bioconductor\n#>  rlang                      1.1.1      2023-04-28 [1] CRAN (R 4.1.2)\n#>  rmarkdown                  2.23       2023-07-01 [2] CRAN (R 4.1.3)\n#>  Rmpfr                      0.9-2      2023-04-22 [2] CRAN (R 4.1.2)\n#>  rngtools                   1.5.2      2021-09-20 [2] CRAN (R 4.1.0)\n#>  rootSolve                  1.8.2.3    2021-09-29 [2] CRAN (R 4.1.0)\n#>  rpart                      4.1.19     2022-10-21 [2] CRAN (R 4.1.2)\n#>  RSQLite                    2.3.1      2023-04-03 [2] CRAN (R 4.1.2)\n#>  rstudioapi                 0.15.0     2023-07-07 [2] CRAN (R 4.1.3)\n#>  rsvd                       1.0.5      2021-04-16 [2] CRAN (R 4.1.0)\n#>  S4Vectors                  0.32.4     2022-03-29 [2] Bioconductor\n#>  sandwich                   3.0-2      2022-06-15 [2] CRAN (R 4.1.2)\n#>  sass                       0.4.6      2023-05-03 [2] CRAN (R 4.1.2)\n#>  ScaledMatrix               1.2.0      2021-10-26 [2] Bioconductor\n#>  scales                     1.2.1      2022-08-20 [1] CRAN (R 4.1.2)\n#>  scater                     1.22.0     2021-10-26 [2] Bioconductor\n#>  scuttle                    1.4.0      2021-10-26 [2] Bioconductor\n#>  sessioninfo                1.2.2      2021-12-06 [2] CRAN (R 4.1.0)\n#>  shape                      1.4.6      2021-05-19 [2] CRAN (R 4.1.0)\n#>  shiny                      1.7.4.1    2023-07-06 [2] CRAN (R 4.1.3)\n#>  SingleCellExperiment       1.16.0     2021-10-26 [2] Bioconductor\n#>  sparseMatrixStats          1.6.0      2021-10-26 [2] Bioconductor\n#>  stringi                    1.7.12     2023-01-11 [2] CRAN (R 4.1.2)\n#>  stringr                  * 1.5.1      2023-11-14 [1] CRAN (R 4.1.3)\n#>  SummarizedExperiment       1.24.0     2021-10-26 [2] Bioconductor\n#>  survey                   * 4.2-1      2023-05-03 [2] CRAN (R 4.1.2)\n#>  survival                 * 3.5-5      2023-03-12 [2] CRAN (R 4.1.2)\n#>  TH.data                    1.1-2      2023-04-17 [2] CRAN (R 4.1.2)\n#>  tibble                   * 3.2.1      2023-03-20 [1] CRAN (R 4.1.2)\n#>  tidyr                    * 1.3.0      2023-01-24 [1] CRAN (R 4.1.2)\n#>  tidyselect                 1.2.0      2022-10-10 [2] CRAN (R 4.1.2)\n#>  tidytree                   0.4.2      2022-12-18 [2] CRAN (R 4.1.2)\n#>  tidyverse                * 2.0.0      2023-02-22 [1] CRAN (R 4.1.2)\n#>  timechange                 0.2.0      2023-01-11 [2] CRAN (R 4.1.2)\n#>  timeDate                   4022.108   2023-01-07 [2] CRAN (R 4.1.2)\n#>  treeio                     1.18.1     2021-11-14 [2] Bioconductor\n#>  TreeSummarizedExperiment   2.2.0      2021-10-26 [2] Bioconductor\n#>  tzdb                       0.4.0      2023-05-12 [2] CRAN (R 4.1.3)\n#>  urlchecker                 1.0.1      2021-11-30 [2] CRAN (R 4.1.0)\n#>  usethis                    2.2.2      2023-07-06 [2] CRAN (R 4.1.3)\n#>  utf8                       1.2.3      2023-01-31 [2] CRAN (R 4.1.2)\n#>  vctrs                      0.6.5      2023-12-01 [1] CRAN (R 4.1.3)\n#>  vegan                      2.6-4      2022-10-11 [1] CRAN (R 4.1.2)\n#>  vipor                      0.4.5      2017-03-22 [2] CRAN (R 4.1.0)\n#>  viridis                    0.6.3      2023-05-03 [2] CRAN (R 4.1.2)\n#>  viridisLite                0.4.2      2023-05-02 [2] CRAN (R 4.1.2)\n#>  withr                      2.5.0      2022-03-03 [2] CRAN (R 4.1.2)\n#>  Wrench                     1.12.0     2021-10-26 [2] Bioconductor\n#>  xfun                       0.40       2023-08-09 [1] CRAN (R 4.1.3)\n#>  XML                        3.99-0.14  2023-03-19 [2] CRAN (R 4.1.2)\n#>  xml2                       1.3.5      2023-07-06 [2] CRAN (R 4.1.3)\n#>  xtable                     1.8-4      2019-04-21 [2] CRAN (R 4.1.0)\n#>  XVector                    0.34.0     2021-10-26 [2] Bioconductor\n#>  yaml                       2.3.7      2023-01-23 [2] CRAN (R 4.1.2)\n#>  yulab.utils                0.0.6      2022-12-20 [2] CRAN (R 4.1.2)\n#>  zlibbioc                   1.40.0     2021-10-26 [2] Bioconductor\n#>  zoo                        1.8-12     2023-04-13 [2] CRAN (R 4.1.2)\n#> \n#>  [1] /Users/zouhua/Library/R/x86_64/4.1/library\n#>  [2] /Library/Frameworks/R.framework/Versions/4.1/Resources/library\n#> \n#> ──────────────────────────────────────────────────────────"},{"path":"LinearModelonMicrobialCommunity.html","id":"reference-4","chapter":"6 Linear Model on Microbial Community","heading":"6.8 Reference","text":"Balance community assembly processes mediates species coexistence agricultural soil microbiomes across eastern ChinaBalance community assembly processes mediates species coexistence agricultural soil microbiomes across eastern China仿一篇文献的相关性分析和线性模型评估影响群落组成的重要环境变量仿一篇文献的相关性分析和线性模型评估影响群落组成的重要环境变量Stepwise Regression Essentials RStepwise Regression Essentials R","code":""},{"path":"PermutationTest.html","id":"PermutationTest","chapter":"7 Permutation Test","heading":"7 Permutation Test","text":"置换检验属于一种非参数检验，最初真正认识置换检验是从PERMANOVA分析开始的，PERMANOVA的原理是：第一步，获取原始统计量。先计算组间距离的平方和和组内距离的平方和的差值（类似F分布统计量）；第一步，获取原始统计量。先计算组间距离的平方和和组内距离的平方和的差值（类似F分布统计量）；第二步，随机抽取样本组成分组再计算上述类似F分布统计量，重复该过程1000次；第二步，随机抽取样本组成分组再计算上述类似F分布统计量，重复该过程1000次；第三步。上述1000次得到的数值组成统计量分布，观察原始统计量落在分布的两端（显著性水平=0.05），是则显著差异，否则接受原假设。第三步。上述1000次得到的数值组成统计量分布，观察原始统计量落在分布的两端（显著性水平=0.05），是则显著差异，否则接受原假设。从上述步骤能看出第二步是利用了置换检验的思想，通过随机事件得到的结果判断原始结果是否是随机发生的。置换检验方法通常会用在小样本组间比较，一般对样本总体分布情况无要求，特别适用于总体分布未知的小样本数据，即使样本数据小到无法使用比如说t检验，但如通过比较简单假设检验的统计量则要考虑数据分布（比如评估两组数据的差异，先通过T检验获得原始T统计量，随后再通过置换检验抽取样本再获取T统计量，最后再评估原始T统计量在T统计量分布的区域）。","code":""},{"path":"PermutationTest.html","id":"加载r包-3","chapter":"7 Permutation Test","heading":"7.1 加载R包","text":"","code":"\nknitr::opts_chunk$set(message = FALSE, warning = FALSE)\nlibrary(tidyverse)\nlibrary(multcomp)\nlibrary(lmPerm)\n\n# rm(list = ls())\noptions(stringsAsFactors = F)\noptions(future.globals.maxSize = 1000 * 1024^2)"},{"path":"PermutationTest.html","id":"小样本数据案例","chapter":"7 Permutation Test","heading":"7.2 小样本数据案例","text":"现有两组数据，一组是对照组，一组是实验组，它们的样本量分别是3和5，通过以下数据是否能够证实实验处理可以改善结果？对照组：73，75，78对照组：73，75，78实验组：68，69，80，76，82实验组：68，69，80，76，82解题思路：T检验或Wilcox检验一般要求任意一组样本量均大于等于5较为合适，且两组样本量相差较小（非平衡数据）。该问题样本量较小，普通的假设检验不适合，可以采用置换检验（两组平均值的差值作为统计量）。具体步骤：第一步，零假设是实验组和对照组没有任何差别；第一步，零假设是实验组和对照组没有任何差别；第二步，获取原始统计量。先计算两组平均值的差值作为统计量，\\(M_{0} = 0.333\\)；第二步，获取原始统计量。先计算两组平均值的差值作为统计量，\\(M_{0} = 0.333\\)；第三步，对照组和实验组混合后随机抽取样本组成A和B再计算两组平均值的差值，重复该过程1000次，上述1000次得到的数值组成统计量分布\\(M_{1000}\\)；第三步，对照组和实验组混合后随机抽取样本组成A和B再计算两组平均值的差值，重复该过程1000次，上述1000次得到的数值组成统计量分布\\(M_{1000}\\)；第四步，计算\\(M_{1000}\\)大于\\(M_{0} = 0.333\\)的个数\\(n\\)，概率\\(P=n/1000\\)。若\\(P < 0.05\\)则说明实验处理有助于提升结果，否则接受零假设。第四步，计算\\(M_{1000}\\)大于\\(M_{0} = 0.333\\)的个数\\(n\\)，概率\\(P=n/1000\\)。若\\(P < 0.05\\)则说明实验处理有助于提升结果，否则接受零假设。结果：Pvalue > 0.05，说明实验处理对结果没有显著提升。除了自己撰写脚本外，还可以通过R包内置的函数实现两组置换检验。","code":"\ncontrol <- c(73, 75, 78)\ntreatment <- c(68, 69, 80, 76, 82)\n\npermute_fun <- function(x1, x2, times = 1000) {\n  \n  # x1 = control\n  # x2 = treatment\n  # times = 1000\n  \n  M0 <- mean(x1) - mean(x2)\n  x <- c(x1, x2)\n  \n  M_distri <- c()\n  for (i in 1:times ) {\n    x1_new <- sample(x, length(x1))\n    x2_new <- sample(x, length(x2))\n    \n    M_temp <- mean(x1_new) - mean(x2_new)\n    M_distri <- c(M_distri, M_temp)\n  }\n  \n  dat <- data.frame(Time = 1:times,\n                    Value = M_distri)\n  p_value <- length(M_distri[M_distri > M0]) / length(M_distri)\n  p_label <- paste0(\"Pvalue = \", p_value, \" (M1000 > M0)\")\n  \n  pl <- ggplot(dat, aes(x = Value)) + \n    geom_histogram(aes(y=..density..), binwidth=.5, \n                   color = \"black\", fill = \"white\") +\n    geom_density(alpha=.2, fill=\"#FF6666\") +\n    scale_x_continuous(expand = c(0, 0)) +\n    scale_y_continuous(expand = c(0, 0)) +\n    labs(title = \"Distribution of M statistics\",\n         x = \"Mean(group1) - Mean(group2)\") +\n    geom_vline(xintercept = M0, color = \"red\", linetype = \"dashed\", linewidth = 1) +  \n    annotate(\"text\", label = p_label, x = 4, y = 0.14, size = 4) +\n    theme_bw()\n  \n  return(pl)\n}\n\npermute_fun(x1 = control, x2 = treatment)\nEnvStats::twoSamplePermutationTestLocation(\n  x = control,\n  y = treatment,\n  fcn = 'mean',\n  alternative = 'greater',\n  mu1.minus.mu2 = 0,\n  paired = FALSE,\n  exact = FALSE,\n  n.permutations = 1000,\n  seed = 123)\n#> \n#> Results of Hypothesis Test\n#> --------------------------\n#> \n#> Null Hypothesis:                 mu.x-mu.y = 0\n#> \n#> Alternative Hypothesis:          True mu.x-mu.y is greater than 0\n#> \n#> Test Name:                       Two-Sample Permutation Test\n#>                                  Based on Differences in Means\n#>                                  (Based on Sampling\n#>                                  Permutation Distribution\n#>                                  1000 Times)\n#> \n#> Estimated Parameter(s):          mean of x = 75.33333\n#>                                  mean of y = 75.00000\n#> \n#> Data:                            x = control  \n#>                                  y = treatment\n#> \n#> Sample Sizes:                    nx = 3\n#>                                  ny = 5\n#> \n#> Test Statistic:                  mean.x - mean.y = 0.3333333\n#> \n#> P-value:                         0.497"},{"path":"PermutationTest.html","id":"线性回归案例","chapter":"7 Permutation Test","heading":"7.3 线性回归案例","text":"线性回归要求残差项服从正态分布，但在实际中残差项会存在离群点或偏差，无法达到完美的正态分布情况。因此使用基于置换检验的线性回归方法会有助于找到显著差异的贡献项。普通线性回归结果揭示dose对weight没有显著性贡献 (公式中变量的顺序非常重要，公式中后面变量的效果会根据公式前面变量的效果进行调整)残差情况置换检验代替传统线性回归方法结果：dose对weight变量有显著贡献","code":"\ndata(litter)\nmod1 <- aov(weight ~ number + gesttime + dose, data = litter)\nsummary(mod1)\n#>             Df Sum Sq Mean Sq F value  Pr(>F)   \n#> number       1   69.8   69.77   4.367 0.04038 * \n#> gesttime     1  143.7  143.70   8.994 0.00378 **\n#> dose         3  122.8   40.93   2.562 0.06196 . \n#> Residuals   68 1086.4   15.98                   \n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nqqnorm(resid(mod1), main = \"Normal Q-Q Plot\")\nqqline(resid(mod1), col = \"red\")\nset.seed(123)\nmod2 <- lmPerm::aovp(weight ~ number + gesttime + dose, data = litter)\n#> [1] \"Settings:  unique SS : numeric variables centered\"\nsummary(mod2)\n#> Component 1 :\n#>             Df R Sum Sq R Mean Sq Iter Pr(Prob)   \n#> number       1    64.85    64.849 1957  0.04905 * \n#> gesttime     1   153.99   153.986 5000  0.00220 **\n#> dose         3   122.80    40.934 2171  0.04422 * \n#> Residuals   68  1086.42    15.977                 \n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"PermutationTest.html","id":"总结-2","chapter":"7 Permutation Test","heading":"7.4 总结","text":"置换检验思想不仅仅可以用于参数未知和分布未知的小样本数据，也可以用于大样本数据（计算代价较高）；置换检验思想不仅仅可以用于参数未知和分布未知的小样本数据，也可以用于大样本数据（计算代价较高）；置换检验也适合组间样本量不平衡的数据。置换检验也适合组间样本量不平衡的数据。","code":""},{"path":"PermutationTest.html","id":"systemic-information-4","chapter":"7 Permutation Test","heading":"7.5 Systemic information","text":"","code":"\ndevtools::session_info()\n#> ─ Session info ───────────────────────────────────────────\n#>  setting  value\n#>  version  R version 4.1.3 (2022-03-10)\n#>  os       macOS Big Sur/Monterey 10.16\n#>  system   x86_64, darwin17.0\n#>  ui       X11\n#>  language (EN)\n#>  collate  en_US.UTF-8\n#>  ctype    en_US.UTF-8\n#>  tz       Asia/Shanghai\n#>  date     2024-02-06\n#>  pandoc   3.1.1 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/ (via rmarkdown)\n#> \n#> ─ Packages ───────────────────────────────────────────────\n#>  package     * version date (UTC) lib source\n#>  bookdown      0.34    2023-05-09 [2] CRAN (R 4.1.2)\n#>  bslib         0.6.0   2023-11-21 [1] CRAN (R 4.1.3)\n#>  cachem        1.0.8   2023-05-01 [2] CRAN (R 4.1.2)\n#>  callr         3.7.3   2022-11-02 [2] CRAN (R 4.1.2)\n#>  cli           3.6.1   2023-03-23 [2] CRAN (R 4.1.2)\n#>  codetools     0.2-19  2023-02-01 [2] CRAN (R 4.1.2)\n#>  colorspace    2.1-0   2023-01-23 [2] CRAN (R 4.1.2)\n#>  crayon        1.5.2   2022-09-29 [2] CRAN (R 4.1.2)\n#>  devtools      2.4.5   2022-10-11 [2] CRAN (R 4.1.2)\n#>  digest        0.6.33  2023-07-07 [1] CRAN (R 4.1.3)\n#>  downlit       0.4.3   2023-06-29 [2] CRAN (R 4.1.3)\n#>  dplyr       * 1.1.4   2023-11-17 [1] CRAN (R 4.1.3)\n#>  ellipsis      0.3.2   2021-04-29 [2] CRAN (R 4.1.0)\n#>  EnvStats      2.8.1   2023-08-22 [1] CRAN (R 4.1.3)\n#>  evaluate      0.21    2023-05-05 [2] CRAN (R 4.1.2)\n#>  fansi         1.0.4   2023-01-22 [2] CRAN (R 4.1.2)\n#>  farver        2.1.1   2022-07-06 [2] CRAN (R 4.1.2)\n#>  fastmap       1.1.1   2023-02-24 [2] CRAN (R 4.1.2)\n#>  forcats     * 1.0.0   2023-01-29 [1] CRAN (R 4.1.2)\n#>  fs            1.6.2   2023-04-25 [2] CRAN (R 4.1.2)\n#>  generics      0.1.3   2022-07-05 [2] CRAN (R 4.1.2)\n#>  ggplot2     * 3.4.4   2023-10-12 [1] CRAN (R 4.1.3)\n#>  glue          1.6.2   2022-02-24 [2] CRAN (R 4.1.2)\n#>  gtable        0.3.3   2023-03-21 [2] CRAN (R 4.1.2)\n#>  highr         0.10    2022-12-22 [2] CRAN (R 4.1.2)\n#>  hms           1.1.3   2023-03-21 [2] CRAN (R 4.1.2)\n#>  htmltools     0.5.7   2023-11-03 [1] CRAN (R 4.1.3)\n#>  htmlwidgets   1.6.2   2023-03-17 [2] CRAN (R 4.1.2)\n#>  httpuv        1.6.11  2023-05-11 [2] CRAN (R 4.1.3)\n#>  jquerylib     0.1.4   2021-04-26 [2] CRAN (R 4.1.0)\n#>  jsonlite      1.8.7   2023-06-29 [2] CRAN (R 4.1.3)\n#>  knitr         1.43    2023-05-25 [2] CRAN (R 4.1.3)\n#>  labeling      0.4.2   2020-10-20 [2] CRAN (R 4.1.0)\n#>  later         1.3.1   2023-05-02 [2] CRAN (R 4.1.2)\n#>  lattice       0.21-8  2023-04-05 [2] CRAN (R 4.1.2)\n#>  lifecycle     1.0.3   2022-10-07 [2] CRAN (R 4.1.2)\n#>  lmPerm      * 2.1.0   2016-08-02 [1] CRAN (R 4.1.0)\n#>  lubridate   * 1.9.2   2023-02-10 [2] CRAN (R 4.1.2)\n#>  magrittr      2.0.3   2022-03-30 [2] CRAN (R 4.1.2)\n#>  MASS        * 7.3-60  2023-05-04 [1] CRAN (R 4.1.2)\n#>  Matrix        1.6-5   2024-01-11 [1] CRAN (R 4.1.3)\n#>  memoise       2.0.1   2021-11-26 [2] CRAN (R 4.1.0)\n#>  mime          0.12    2021-09-28 [2] CRAN (R 4.1.0)\n#>  miniUI        0.1.1.1 2018-05-18 [2] CRAN (R 4.1.0)\n#>  multcomp    * 1.4-25  2023-06-20 [2] CRAN (R 4.1.3)\n#>  munsell       0.5.0   2018-06-12 [2] CRAN (R 4.1.0)\n#>  mvtnorm     * 1.2-2   2023-06-08 [2] CRAN (R 4.1.3)\n#>  pillar        1.9.0   2023-03-22 [2] CRAN (R 4.1.2)\n#>  pkgbuild      1.4.2   2023-06-26 [2] CRAN (R 4.1.3)\n#>  pkgconfig     2.0.3   2019-09-22 [2] CRAN (R 4.1.0)\n#>  pkgload       1.3.2.1 2023-07-08 [2] CRAN (R 4.1.3)\n#>  prettyunits   1.1.1   2020-01-24 [2] CRAN (R 4.1.0)\n#>  processx      3.8.2   2023-06-30 [2] CRAN (R 4.1.3)\n#>  profvis       0.3.8   2023-05-02 [2] CRAN (R 4.1.2)\n#>  promises      1.2.0.1 2021-02-11 [2] CRAN (R 4.1.0)\n#>  ps            1.7.5   2023-04-18 [2] CRAN (R 4.1.2)\n#>  purrr       * 1.0.1   2023-01-10 [1] CRAN (R 4.1.2)\n#>  R6            2.5.1   2021-08-19 [2] CRAN (R 4.1.0)\n#>  Rcpp          1.0.11  2023-07-06 [1] CRAN (R 4.1.3)\n#>  readr       * 2.1.4   2023-02-10 [1] CRAN (R 4.1.2)\n#>  remotes       2.4.2   2021-11-30 [2] CRAN (R 4.1.0)\n#>  rlang         1.1.1   2023-04-28 [1] CRAN (R 4.1.2)\n#>  rmarkdown     2.23    2023-07-01 [2] CRAN (R 4.1.3)\n#>  rstudioapi    0.15.0  2023-07-07 [2] CRAN (R 4.1.3)\n#>  sandwich      3.0-2   2022-06-15 [2] CRAN (R 4.1.2)\n#>  sass          0.4.6   2023-05-03 [2] CRAN (R 4.1.2)\n#>  scales        1.2.1   2022-08-20 [1] CRAN (R 4.1.2)\n#>  sessioninfo   1.2.2   2021-12-06 [2] CRAN (R 4.1.0)\n#>  shiny         1.7.4.1 2023-07-06 [2] CRAN (R 4.1.3)\n#>  stringi       1.7.12  2023-01-11 [2] CRAN (R 4.1.2)\n#>  stringr     * 1.5.1   2023-11-14 [1] CRAN (R 4.1.3)\n#>  survival    * 3.5-5   2023-03-12 [2] CRAN (R 4.1.2)\n#>  TH.data     * 1.1-2   2023-04-17 [2] CRAN (R 4.1.2)\n#>  tibble      * 3.2.1   2023-03-20 [1] CRAN (R 4.1.2)\n#>  tidyr       * 1.3.0   2023-01-24 [1] CRAN (R 4.1.2)\n#>  tidyselect    1.2.0   2022-10-10 [2] CRAN (R 4.1.2)\n#>  tidyverse   * 2.0.0   2023-02-22 [1] CRAN (R 4.1.2)\n#>  timechange    0.2.0   2023-01-11 [2] CRAN (R 4.1.2)\n#>  tzdb          0.4.0   2023-05-12 [2] CRAN (R 4.1.3)\n#>  urlchecker    1.0.1   2021-11-30 [2] CRAN (R 4.1.0)\n#>  usethis       2.2.2   2023-07-06 [2] CRAN (R 4.1.3)\n#>  utf8          1.2.3   2023-01-31 [2] CRAN (R 4.1.2)\n#>  vctrs         0.6.5   2023-12-01 [1] CRAN (R 4.1.3)\n#>  withr         2.5.0   2022-03-03 [2] CRAN (R 4.1.2)\n#>  xfun          0.40    2023-08-09 [1] CRAN (R 4.1.3)\n#>  xml2          1.3.5   2023-07-06 [2] CRAN (R 4.1.3)\n#>  xtable        1.8-4   2019-04-21 [2] CRAN (R 4.1.0)\n#>  yaml          2.3.7   2023-01-23 [2] CRAN (R 4.1.2)\n#>  zoo           1.8-12  2023-04-13 [2] CRAN (R 4.1.2)\n#> \n#>  [1] /Users/zouhua/Library/R/x86_64/4.1/library\n#>  [2] /Library/Frameworks/R.framework/Versions/4.1/Resources/library\n#> \n#> ──────────────────────────────────────────────────────────"},{"path":"PermutationTest.html","id":"reference-5","chapter":"7 Permutation Test","heading":"7.6 Reference","text":"Fisher, R. ., 1935. Design Experiments. Oliver & Boyd, Edinburgh.Fisher, R. ., 1935. Design Experiments. Oliver & Boyd, Edinburgh.Two-Sample Permutation Test Difference MeansTwo-Sample Permutation Test Difference Means","code":""},{"path":"SurvivalAnalysis.html","id":"SurvivalAnalysis","chapter":"8 Survival Analysis","heading":"8 Survival Analysis","text":"","code":""},{"path":"SurvivalAnalysis.html","id":"介绍-1","chapter":"8 Survival Analysis","heading":"8.1 介绍","text":"生存分析的目的是分析某个时间点的“生存概率”是多少。基于这样的研究目的，需要提供生存数据，它是一种由不同的开始时间和结束时间组成的事件-时间的数据，比如在癌症研究领域，研究手术到死亡的过程、治疗到疾病进展等等。在开展生存分析前，需要了解什么是删失（censored）。对于确定的事件，由于其他原因导致其出现无法记录、无法观察等等，这些都可以称为删失。“删失（censored）数据指在观察或试验中,由于人力或其他原因未能观察到所感兴趣的事件发生，因而得到的数据。”\nFigure 4.1: Censored survival data\n图表示10个参与者，在事件为发生前有7位患者出现了删失情况。忽略删失样本会导致生存概率结果出现偏差。生存分析是一种可以适当考虑被删失患者的方法。","code":""},{"path":"SurvivalAnalysis.html","id":"组成","chapter":"8 Survival Analysis","heading":"8.2 组成","text":"生存数据是有事件状态和对应时间组成，事件状态可以分成发生和删失。事件时间：\\(T_i\\)事件时间：\\(T_i\\)删失时间：\\(C_i\\)删失时间：\\(C_i\\)事件状态：如果观察到事件则是1；否则是删失0。事件时间要小于删失时间。事件状态：如果观察到事件则是1；否则是删失0。事件时间要小于删失时间。通过密度分布图可以观察到事件发生和删失状态在时间上的区别，如果不考虑删失则会导致评估结果偏高。\nFigure 8.1: distribution follow-times\n某个对象在某个时间点的生存概率公式为：\\(S(t) = Pr(T > t) = 1- F(t)\\)\\(S(t)\\)是生存函数\\(S(t)\\)是生存函数\\(F(t) = 1- Pr(T > t)\\)是累积分布函数\\(F(t) = 1- Pr(T > t)\\)是累积分布函数","code":""},{"path":"SurvivalAnalysis.html","id":"案例","chapter":"8 Survival Analysis","heading":"8.3 案例","text":"","code":""},{"path":"SurvivalAnalysis.html","id":"加载r包-4","chapter":"8 Survival Analysis","heading":"8.3.1 加载R包","text":"","code":"\nknitr::opts_chunk$set(message = FALSE, warning = FALSE)\nlibrary(tidyverse)\nlibrary(survival)\nlibrary(survminer)\nlibrary(gtsummary)\n\n# rm(list = ls())\noptions(stringsAsFactors = F)\noptions(future.globals.maxSize = 1000 * 1024^2)\n\n# group & color\nsex_grp <- c(\"Male\", \"Female\")\nsex_col <- c(\"#F28880\", \"#60C4D3\")"},{"path":"SurvivalAnalysis.html","id":"导入数据-2","chapter":"8 Survival Analysis","heading":"8.3.2 导入数据","text":"肺癌数据: 本次研究目的—-不同性别以及患者的生存状态是否存在差异生存时间（time）: 观察到的生存时间 (days)生存时间（time）: 观察到的生存时间 (days)生存状态（status）: 死亡(2->1)和删失(1->0)生存状态（status）: 死亡(2->1)和删失(1->0)性别（sex）: 1=Male, 2=Female性别（sex）: 1=Male, 2=Female肿瘤活动状态（ph.ecog）：0=ECOG0，1=ECOG1，2=ECOG2肿瘤活动状态（ph.ecog）：0=ECOG0，1=ECOG1，2=ECOG2","code":"\ndat <- \n  lung %>% \n  mutate(status = recode(status, `1` = 0, `2` = 1),\n         sex = recode(sex, `1` = \"Male\", `2` = \"Female\")) %>%\n  filter(!ph.ecog %in% c(NA, 3)) %>%\n  mutate(ph.ecog = recode(ph.ecog, `0` = \"ECOG0\", `1` = \"ECOG1\", `2` = \"ECOG2\"),\n         sex = factor(sex, levels = sex_grp))\n\nhead(dat[, c(\"time\", \"status\", \"sex\", \"ph.ecog\")])\n#>   time status  sex ph.ecog\n#> 1  306      1 Male   ECOG1\n#> 2  455      1 Male   ECOG0\n#> 3 1010      0 Male   ECOG0\n#> 4  210      1 Male   ECOG1\n#> 5  883      1 Male   ECOG0\n#> 6 1022      0 Male   ECOG1"},{"path":"SurvivalAnalysis.html","id":"生存对象","chapter":"8 Survival Analysis","heading":"8.3.3 生存对象","text":"通过Surv()生成生存对象，在使用survfit()生成生存曲线Kaplan-Meier plot的准备数据。","code":"\nsur_fit <- survival::survfit(survival::Surv(time, status) ~ sex, data = dat)\n\nsur_fit\n#> Call: survfit(formula = survival::Surv(time, status) ~ sex, data = dat)\n#> \n#>              n events median 0.95LCL 0.95UCL\n#> sex=Male   136    110    283     218     320\n#> sex=Female  90     53    426     348     550"},{"path":"SurvivalAnalysis.html","id":"组间生存时间差异比较","chapter":"8 Survival Analysis","heading":"8.3.4 组间生存时间差异比较","text":"问题：在肺癌患者不同的性别分组中，生存概率是否存在差异性呢？通常采用Log-rank检验推断两生存曲线整体间（整个观察期间）是否有差异，若生存曲线出现交叉情况，由于不满足成比例假设，则Log-rank检验不适用。从图上的logRank p = 0.0018来看，女性在肺癌中生存周期更长。结合男性可能抽烟的额外因素考虑，该结果也符合预期。","code":"\nsurvminer::ggsurvplot(\n    fit = sur_fit,\n    pval = TRUE,\n    xlab = \"Days\",\n    ylab = \"Overall survival probability\",\n    legend.title = \"Sex\",\n    legend.labs = sex_grp,\n    palette = sex_col,\n    break.x.by = 100, \n    surv.median.line = \"hv\",\n    risk.table = TRUE,\n    risk.table.y.text = FALSE)"},{"path":"SurvivalAnalysis.html","id":"中位生存期","chapter":"8 Survival Analysis","heading":"8.3.5 中位生存期","text":"中位生存期(Median Survival Time)，又称为半数生存期， 即当累积生存率为0.5时所对应的生存时间，表示有且只有50%的个体可以活过这个时间。女性的中位生存期（426天）要远远高于男性的（283天）","code":"\nsur_fit %>%\n  tbl_survfit(\n    probs = 0.5,\n    label_header = \"**Median survival (95% CI)**\"\n  ) "},{"path":"SurvivalAnalysis.html","id":"n年生存概率","chapter":"8 Survival Analysis","heading":"8.3.6 N年生存概率","text":"选择1到3年生存概率，评估男女性间的差异","code":"\nsur_fit %>%\n  tbl_survfit(\n    times = c(365, 730),\n    label_header = \"**{time} Days survival (95% CI)**\"\n  )"},{"path":"SurvivalAnalysis.html","id":"cox回归模型","chapter":"8 Survival Analysis","heading":"8.3.7 Cox回归模型","text":"logRank test是定性变量是否和生存相关，定量变量之间的风险比例值需要用到Cox回归模型。单变量Cox回归仅评估该变量和生存的关系，多变量Cox回归可以校正其他因素影响后再评估单个变量的风险比例值。以Male作为Reference，Female的风险比例值HR为0.6且对应的p<0.05，HR小于1，说明在肺癌患者中，Female的死亡风险要显著低于Male。","code":"\nbroom::tidy(survival::coxph(Surv(time, status) ~ sex, data = dat)) %>% # conf.int = TRUE, exponentiate = TRUE\n            dplyr::select(-statistic) %>%\n            dplyr::mutate(`Hazard ratios` = exp(estimate),\n                          HR_conf.low = exp(estimate) - 1.95*std.error,\n                          HR_conf.high = exp(estimate) + 1.95*std.error,\n                          HR = round(`Hazard ratios`, 2),\n                          HR_conf.low = round(HR_conf.low, 2),\n                          HR_conf.high = round(HR_conf.high, 2),\n                          p.value = signif(p.value, 2)) %>%\n            dplyr::select(term, HR, HR_conf.low, HR_conf.high, p.value) %>%\n  rbind(as_tibble(data.frame(term = \"RefMale\", \n                  HR = NA,\n                  HR_conf.low = NA, \n                  HR_conf.high = NA, \n                  p.value = NA)))\n#> # A tibble: 2 × 5\n#>   term         HR HR_conf.low HR_conf.high p.value\n#>   <chr>     <dbl>       <dbl>        <dbl>   <dbl>\n#> 1 sexFemale   0.6        0.27         0.92   0.002\n#> 2 RefMale    NA         NA           NA     NA"},{"path":"SurvivalAnalysis.html","id":"其他生存分析","chapter":"8 Survival Analysis","heading":"8.3.8 其他生存分析","text":"探究不同性别分组的ECOG是否与生存状态相关函数：1.获取生存分析结果；2.可视化生存曲线准备数据和获取生存结果画图结果：不同性别分组内的ECOG组（ECOG0和ECOG1）与生存状态没有显著差异。","code":"\nget_cox_res <- function(\n    input, groups, \n    group_names, RefGroup) {\n  \n  input_dat <- input %>%\n    dplyr::select(all_of(groups)) %>%\n    stats::setNames(c(\"TIME\", \"STATUS\", \"GROUP\")) %>%\n    dplyr::filter(GROUP %in% group_names) %>%\n    dplyr::mutate(GROUP = factor(as.character(GROUP), levels = group_names))\n      \n  ## Group: log rank-test\n  fit <- survfit(Surv(TIME, STATUS) ~ GROUP, data = input_dat)\n  logrank <- surv_pvalue(fit = fit, data = input_dat)      \n      \n  ## Group: Hazard ratios: Low as reference\n  HR <- broom::tidy(survival::coxph(survival::Surv(TIME, STATUS) ~ GROUP, data = input_dat)) %>%\n        dplyr::select(-statistic) %>%\n        dplyr::mutate(`Hazard ratios` = exp(estimate),\n                      HR_conf.low = exp(estimate) - 1.95*std.error,\n                      HR_conf.high = exp(estimate) + 1.95*std.error,\n                      HR = signif(`Hazard ratios`, 2),\n                      HR_conf.low = signif(HR_conf.low, 2),\n                      HR_conf.high = signif(HR_conf.high, 2),\n                      cox_pval = signif(p.value, 2),\n                      HR_95 = paste0(HR, \" (\", HR_conf.low, \" - \", HR_conf.high, \")\")) %>%\n        dplyr::select(term, HR_95, cox_pval) %>%\n        rbind(data.frame(term = paste0(\"Ref\", RefGroup),\n                         HR_95 = NA,\n                         cox_pval = NA)) \n      \n  ## Group: Combination\n  res <- logrank %>%\n        dplyr::select(pval) %>%\n        dplyr::rename(logRank_pval = pval) %>%\n        rbind(data.frame(logRank_pval = rep(NA, (length(group_names) - 1) ))) %>%\n        cbind(HR) %>%\n        dplyr::select(term, logRank_pval, HR_95, cox_pval) %>%\n        dplyr::rename(logRank_pval = logRank_pval,\n                      HR_95 = HR_95,\n                      cox_pval = cox_pval)           \n      \n  return(res)\n}\n\n# survival plot\nget_plot <- function(\n    input, groups, group_names,\n    feaID, TypeTime, NegGroup, PosGroup) {\n      \n  input_dat <- input %>%\n        dplyr::select(all_of(groups)) %>%\n        stats::setNames(c(\"TIME\", \"STATUS\", \"GROUP\")) %>%\n        dplyr::filter(GROUP %in% group_names) %>%\n        dplyr::mutate(GROUP = factor(as.character(GROUP), levels = group_names))\n      \n  # survival model\n  fit <- survminer::surv_fit(Surv(TIME, STATUS) ~ GROUP, data = input_dat)\n  logrank <- surv_pvalue(fit = fit, data = input_dat)\n  pval_label <- paste(logrank$method, signif(logrank$pval, 3), sep = \": p=\")\n      \n  # median survival time\n  med_time <- fit %>% \n    gtsummary::tbl_survfit(\n    probs = 0.5,\n      label_header = \"**Median survival (95% CI)**\"\n    ) %>%\n    as.tibble() %>%\n    dplyr::slice(-1) %>%\n    stats::setNames(c(\"Group\", \"Time\")) %>%\n    dplyr::group_by(Group) %>%\n    dplyr::mutate(Median_temp = unlist(strsplit(Time, \"\\\\s+\\\\(\"))[1]) %>%\n    dplyr::mutate(Median = ifelse(Median_temp == \"-\", \"undef.\", Median_temp),\n                  Median_label = paste0(Group, \" (\", Median, \" Days)\")) %>%\n    dplyr::ungroup() \n      \n    # cox model HR\n    cox_type <- rbind(NegGroup, PosGroup) %>%\n        dplyr::filter(!is.na(HR_95)) %>%\n        dplyr::mutate(term = gsub(\"GROUP\", \"\", term)) %>%\n        dplyr::rename(Group = term) %>%\n        dplyr::mutate(HR_95 = gsub(\"\\\\s+-\\\\s+\", \";\", HR_95),\n                      HR_95 = gsub(\"\\\\s+\", \"\", HR_95),\n                      cox_label = paste0(\"cox p=\", cox_pval, \", HR=\", HR_95),\n                      logRank_pval = signif(logRank_pval, 3))\n      \n    # merge labels \n    sur_labels <- med_time %>%\n       dplyr::left_join(cox_type %>% \n                          dplyr::select(Group, cox_label), \n                        by = \"Group\")\n    sur_labels$cox_label[is.na(sur_labels$cox_label)] <- \"Reference\"\n    sur_labels$final_label <- paste(sur_labels$Median_label, sur_labels$cox_label,\n                                     sep = \"   \")\n     \n    # finale pvalue label\n    pval_label_final <- paste0(pval_label, \"\\n\", \n                                \"(Male: p=\", cox_type$logRank_pval[1],\n                                \"; \",\n                                \"Female: p=\", cox_type$logRank_pval[2],\n                                \")\")\n     \n    ggsurv <- ggsurvplot(\n        fit,\n        pval = pval_label_final,\n        pval.size = 4, \n        pval.coord = c(0, 0.05),\n        xlab = \"Overall Survival Time (Days)\", \n        surv.scale = \"percent\",\n        break.time.by = 100, \n        risk.table.y.text.col = T, \n        risk.table = T,\n        risk.table.title = \"\",\n        risk.table.fontsize = 4,\n        risk.table.height = 0.3,\n        risk.table.y.text = FALSE, \n        ncensor.plot = FALSE,\n        surv.median.line = \"hv\",\n        palette = c(\"#803C08\", \"#F1A340\", \n                    \"#2C0a4B\", \"#998EC3\"),\n        legend = c(0.7, 0.89),\n        legend.labs = sur_labels$final_label,\n        legend.title = \"\",\n        font.legend = c(10, \"plain\"),\n        tables.theme = theme_cleantable(),\n        ggtheme = theme_classic() + theme(\n             axis.title = element_text(size = 10, face = \"bold\"),\n             axis.text = element_text(size = 9),\n             legend.background = element_rect(fill = \"transparent\", color = NA),\n             legend.box.background = element_rect(fill = \"transparent\", color = NA)\n           )        \n      )      \n      \n  return(ggsurv)\n}\ndat_new <- dat %>%\n  dplyr::select(time, status, sex, ph.ecog) %>%\n  dplyr::mutate(MixedGroup = paste(sex, ph.ecog, sep = \"_\")) %>%\n  dplyr::mutate(MixedGroup = factor(MixedGroup, \n            levels = c(\"Male_ECOG0\", \"Male_ECOG1\", \"Male_ECOG2\", \n                       \"Female_ECOG0\", \"Female_ECOG1\", \"Female_ECOG2\")),\n            sex = factor(sex, levels = sex_grp))\n\nMaleGroup <- get_cox_res(\n      input = dat_new, \n      groups = c(\"time\", \"status\", \"MixedGroup\"), \n      group_names = c(\"Male_ECOG0\", \"Male_ECOG1\"), \n      RefGroup = \"Male_ECOG0\") \nFemaleGroup <- get_cox_res(\n      input = dat_new, \n      groups = c(\"time\", \"status\", \"MixedGroup\"), \n      group_names = c(\"Female_ECOG0\", \"Female_ECOG1\"), \n      RefGroup = \"Female_ECOG0\") \nggsurpl <- get_plot(\n        input = dat_new, \n        groups = c(\"time\", \"status\", \"MixedGroup\"), \n        group_names = c(\"Male_ECOG0\", \"Male_ECOG1\",\n                        \"Female_ECOG0\", \"Female_ECOG1\"), \n        feaID = \"ECOG\",\n        NegGroup = MaleGroup,\n        PosGroup = FemaleGroup)\nggsurpl"},{"path":"SurvivalAnalysis.html","id":"总结-3","chapter":"8 Survival Analysis","heading":"8.4 总结","text":"生存数据很常见，是时间到事件的数据；生存数据很常见，是时间到事件的数据；需要生存分析技术来解释删失的数据；需要生存分析技术来解释删失的数据；survival R包提供了生存分析工具，包括Surv和surfit函数survival R包提供了生存分析工具，包括Surv和surfit函数survminer R包提供了ggsurvplot函数允许基于ggplot2定制Kaplan-Meier图survminer R包提供了ggsurvplot函数允许基于ggplot2定制Kaplan-Meier图组间比较可采用log-rank检验，采用survival::survdiff组间比较可采用log-rank检验，采用survival::survdiff单或多变量Cox回归分析可以使用survival::Cox进行单或多变量Cox回归分析可以使用survival::Cox进行","code":""},{"path":"SurvivalAnalysis.html","id":"systemic-information-5","chapter":"8 Survival Analysis","heading":"8.5 Systemic information","text":"","code":"\ndevtools::session_info()\n#> ─ Session info ───────────────────────────────────────────\n#>  setting  value\n#>  version  R version 4.1.3 (2022-03-10)\n#>  os       macOS Big Sur/Monterey 10.16\n#>  system   x86_64, darwin17.0\n#>  ui       X11\n#>  language (EN)\n#>  collate  en_US.UTF-8\n#>  ctype    en_US.UTF-8\n#>  tz       Asia/Shanghai\n#>  date     2024-02-06\n#>  pandoc   3.1.1 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/ (via rmarkdown)\n#> \n#> ─ Packages ───────────────────────────────────────────────\n#>  package       * version date (UTC) lib source\n#>  abind           1.4-5   2016-07-21 [2] CRAN (R 4.1.0)\n#>  backports       1.4.1   2021-12-13 [2] CRAN (R 4.1.0)\n#>  bookdown        0.34    2023-05-09 [2] CRAN (R 4.1.2)\n#>  broom           1.0.5   2023-06-09 [2] CRAN (R 4.1.3)\n#>  broom.helpers   1.13.0  2023-03-28 [2] CRAN (R 4.1.2)\n#>  bslib           0.6.0   2023-11-21 [1] CRAN (R 4.1.3)\n#>  cachem          1.0.8   2023-05-01 [2] CRAN (R 4.1.2)\n#>  callr           3.7.3   2022-11-02 [2] CRAN (R 4.1.2)\n#>  car             3.1-2   2023-03-30 [2] CRAN (R 4.1.2)\n#>  carData         3.0-5   2022-01-06 [2] CRAN (R 4.1.2)\n#>  cli             3.6.1   2023-03-23 [2] CRAN (R 4.1.2)\n#>  colorspace      2.1-0   2023-01-23 [2] CRAN (R 4.1.2)\n#>  commonmark      1.9.0   2023-03-17 [2] CRAN (R 4.1.2)\n#>  crayon          1.5.2   2022-09-29 [2] CRAN (R 4.1.2)\n#>  data.table      1.14.8  2023-02-17 [2] CRAN (R 4.1.2)\n#>  devtools        2.4.5   2022-10-11 [2] CRAN (R 4.1.2)\n#>  digest          0.6.33  2023-07-07 [1] CRAN (R 4.1.3)\n#>  downlit         0.4.3   2023-06-29 [2] CRAN (R 4.1.3)\n#>  dplyr         * 1.1.4   2023-11-17 [1] CRAN (R 4.1.3)\n#>  ellipsis        0.3.2   2021-04-29 [2] CRAN (R 4.1.0)\n#>  evaluate        0.21    2023-05-05 [2] CRAN (R 4.1.2)\n#>  fansi           1.0.4   2023-01-22 [2] CRAN (R 4.1.2)\n#>  farver          2.1.1   2022-07-06 [2] CRAN (R 4.1.2)\n#>  fastmap         1.1.1   2023-02-24 [2] CRAN (R 4.1.2)\n#>  forcats       * 1.0.0   2023-01-29 [1] CRAN (R 4.1.2)\n#>  fs              1.6.2   2023-04-25 [2] CRAN (R 4.1.2)\n#>  generics        0.1.3   2022-07-05 [2] CRAN (R 4.1.2)\n#>  ggplot2       * 3.4.4   2023-10-12 [1] CRAN (R 4.1.3)\n#>  ggpubr        * 0.6.0   2023-02-10 [1] CRAN (R 4.1.2)\n#>  ggsignif        0.6.4   2022-10-13 [2] CRAN (R 4.1.2)\n#>  ggtext          0.1.2   2022-09-16 [2] CRAN (R 4.1.2)\n#>  glue            1.6.2   2022-02-24 [2] CRAN (R 4.1.2)\n#>  gridExtra       2.3     2017-09-09 [2] CRAN (R 4.1.0)\n#>  gridtext        0.1.5   2022-09-16 [2] CRAN (R 4.1.2)\n#>  gt              0.9.0   2023-03-31 [2] CRAN (R 4.1.2)\n#>  gtable          0.3.3   2023-03-21 [2] CRAN (R 4.1.2)\n#>  gtsummary     * 1.7.1   2023-04-27 [2] CRAN (R 4.1.2)\n#>  highr           0.10    2022-12-22 [2] CRAN (R 4.1.2)\n#>  hms             1.1.3   2023-03-21 [2] CRAN (R 4.1.2)\n#>  htmltools       0.5.7   2023-11-03 [1] CRAN (R 4.1.3)\n#>  htmlwidgets     1.6.2   2023-03-17 [2] CRAN (R 4.1.2)\n#>  httpuv          1.6.11  2023-05-11 [2] CRAN (R 4.1.3)\n#>  jquerylib       0.1.4   2021-04-26 [2] CRAN (R 4.1.0)\n#>  jsonlite        1.8.7   2023-06-29 [2] CRAN (R 4.1.3)\n#>  km.ci           0.5-6   2022-04-06 [2] CRAN (R 4.1.2)\n#>  KMsurv          0.1-5   2012-12-03 [2] CRAN (R 4.1.0)\n#>  knitr           1.43    2023-05-25 [2] CRAN (R 4.1.3)\n#>  labeling        0.4.2   2020-10-20 [2] CRAN (R 4.1.0)\n#>  later           1.3.1   2023-05-02 [2] CRAN (R 4.1.2)\n#>  lattice         0.21-8  2023-04-05 [2] CRAN (R 4.1.2)\n#>  lifecycle       1.0.3   2022-10-07 [2] CRAN (R 4.1.2)\n#>  lubridate     * 1.9.2   2023-02-10 [2] CRAN (R 4.1.2)\n#>  magrittr        2.0.3   2022-03-30 [2] CRAN (R 4.1.2)\n#>  markdown        1.7     2023-05-16 [2] CRAN (R 4.1.3)\n#>  Matrix          1.6-5   2024-01-11 [1] CRAN (R 4.1.3)\n#>  memoise         2.0.1   2021-11-26 [2] CRAN (R 4.1.0)\n#>  mime            0.12    2021-09-28 [2] CRAN (R 4.1.0)\n#>  miniUI          0.1.1.1 2018-05-18 [2] CRAN (R 4.1.0)\n#>  munsell         0.5.0   2018-06-12 [2] CRAN (R 4.1.0)\n#>  pillar          1.9.0   2023-03-22 [2] CRAN (R 4.1.2)\n#>  pkgbuild        1.4.2   2023-06-26 [2] CRAN (R 4.1.3)\n#>  pkgconfig       2.0.3   2019-09-22 [2] CRAN (R 4.1.0)\n#>  pkgload         1.3.2.1 2023-07-08 [2] CRAN (R 4.1.3)\n#>  prettyunits     1.1.1   2020-01-24 [2] CRAN (R 4.1.0)\n#>  processx        3.8.2   2023-06-30 [2] CRAN (R 4.1.3)\n#>  profvis         0.3.8   2023-05-02 [2] CRAN (R 4.1.2)\n#>  promises        1.2.0.1 2021-02-11 [2] CRAN (R 4.1.0)\n#>  ps              1.7.5   2023-04-18 [2] CRAN (R 4.1.2)\n#>  purrr         * 1.0.1   2023-01-10 [1] CRAN (R 4.1.2)\n#>  R6              2.5.1   2021-08-19 [2] CRAN (R 4.1.0)\n#>  Rcpp            1.0.11  2023-07-06 [1] CRAN (R 4.1.3)\n#>  readr         * 2.1.4   2023-02-10 [1] CRAN (R 4.1.2)\n#>  remotes         2.4.2   2021-11-30 [2] CRAN (R 4.1.0)\n#>  rlang           1.1.1   2023-04-28 [1] CRAN (R 4.1.2)\n#>  rmarkdown       2.23    2023-07-01 [2] CRAN (R 4.1.3)\n#>  rstatix         0.7.2   2023-02-01 [2] CRAN (R 4.1.2)\n#>  rstudioapi      0.15.0  2023-07-07 [2] CRAN (R 4.1.3)\n#>  sass            0.4.6   2023-05-03 [2] CRAN (R 4.1.2)\n#>  scales          1.2.1   2022-08-20 [1] CRAN (R 4.1.2)\n#>  sessioninfo     1.2.2   2021-12-06 [2] CRAN (R 4.1.0)\n#>  shiny           1.7.4.1 2023-07-06 [2] CRAN (R 4.1.3)\n#>  stringi         1.7.12  2023-01-11 [2] CRAN (R 4.1.2)\n#>  stringr       * 1.5.1   2023-11-14 [1] CRAN (R 4.1.3)\n#>  survival      * 3.5-5   2023-03-12 [2] CRAN (R 4.1.2)\n#>  survminer     * 0.4.9   2021-03-09 [2] CRAN (R 4.1.0)\n#>  survMisc        0.5.6   2022-04-07 [2] CRAN (R 4.1.2)\n#>  tibble        * 3.2.1   2023-03-20 [1] CRAN (R 4.1.2)\n#>  tidyr         * 1.3.0   2023-01-24 [1] CRAN (R 4.1.2)\n#>  tidyselect      1.2.0   2022-10-10 [2] CRAN (R 4.1.2)\n#>  tidyverse     * 2.0.0   2023-02-22 [1] CRAN (R 4.1.2)\n#>  timechange      0.2.0   2023-01-11 [2] CRAN (R 4.1.2)\n#>  tzdb            0.4.0   2023-05-12 [2] CRAN (R 4.1.3)\n#>  urlchecker      1.0.1   2021-11-30 [2] CRAN (R 4.1.0)\n#>  usethis         2.2.2   2023-07-06 [2] CRAN (R 4.1.3)\n#>  utf8            1.2.3   2023-01-31 [2] CRAN (R 4.1.2)\n#>  vctrs           0.6.5   2023-12-01 [1] CRAN (R 4.1.3)\n#>  withr           2.5.0   2022-03-03 [2] CRAN (R 4.1.2)\n#>  xfun            0.40    2023-08-09 [1] CRAN (R 4.1.3)\n#>  xml2            1.3.5   2023-07-06 [2] CRAN (R 4.1.3)\n#>  xtable          1.8-4   2019-04-21 [2] CRAN (R 4.1.0)\n#>  yaml            2.3.7   2023-01-23 [2] CRAN (R 4.1.2)\n#>  zoo             1.8-12  2023-04-13 [2] CRAN (R 4.1.2)\n#> \n#>  [1] /Users/zouhua/Library/R/x86_64/4.1/library\n#>  [2] /Library/Frameworks/R.framework/Versions/4.1/Resources/library\n#> \n#> ──────────────────────────────────────────────────────────"},{"path":"SurvivalAnalysis.html","id":"reference-6","chapter":"8 Survival Analysis","heading":"8.6 Reference","text":"Survival Analysis R","code":""},{"path":"dataprocessing.html","id":"dataprocessing","chapter":"9 Data Processing","heading":"9 Data Processing","text":"代谢组数据一般是搜库后的质谱峰度谱数据，用峰强intensity表示。Raw intensity通常不直接用于假设检验或线性回归等统计方法，需要对其做数据预处理。本次应用到的数据是Zeybel 2022年发布的文章_Multiomics Analysis Reveals Impact Microbiota Host Metabolism Hepatic Steatosis_的粪便代谢组学质谱数据。55份粪便代谢组，1032个代谢物","code":""},{"path":"dataprocessing.html","id":"处理流程","chapter":"9 Data Processing","heading":"9.1 处理流程","text":"数据检查：1.核查所有代谢物intensity value是数值型；2.缺失值的比例数据检查：1.核查所有代谢物intensity value是数值型；2.缺失值的比例补充缺失值补充缺失值数据过滤（针对代谢物或样本）数据过滤（针对代谢物或样本）数据标准化（针对代谢物或样本）数据标准化（针对代谢物或样本）","code":""},{"path":"dataprocessing.html","id":"加载r包-5","chapter":"9 Data Processing","heading":"9.2 加载R包","text":"","code":"\nknitr::opts_chunk$set(message = FALSE, warning = FALSE)\nlibrary(tidyverse)\nlibrary(SummarizedExperiment)\n\n# rm(list = ls())\noptions(stringsAsFactors = F)\noptions(future.globals.maxSize = 1000 * 1024^2)"},{"path":"dataprocessing.html","id":"导入数据-3","chapter":"9 Data Processing","heading":"9.3 导入数据","text":"对数据OmicsDataSet-Zeybel et al. - 2022.xlsx处理后生成的输入文件，详细情况可参考Data Set具体章节。","code":"\nsaveRDS(se_metabolite, \"./InputData/result/Zeybel_2022_fecal_metabolite_se.RDS\", compress = TRUE)\ndata_meta <- readRDS(\"./InputData/result/Zeybel_2022_fecal_metabolite_se.RDS\")\n\ndata_meta\n#> class: SummarizedExperiment \n#> dim: 1032 55 \n#> metadata(0):\n#> assays(1): ''\n#> rownames(1032): Chem_100002945 Chem_100002356 ...\n#>   Chem_100015836 Chem_826\n#> rowData names(13): metabolitesID BIOCHEMICAL ... KEGG\n#>   SampleIDHMDBID\n#> colnames(55): P101001 P101003 ... P101095 P101096\n#> colData names(47): PatientID Gender ...\n#>   Right_leg_fat_free_mass Right_leg_total_body_water\n# colData(data_meta)\n# assay(data_meta)\n# rowData(data_meta)"},{"path":"dataprocessing.html","id":"构建qc样本","chapter":"9 Data Processing","heading":"9.4 构建QC样本","text":"该数据集不存在QC样本，这导致不能做QC的变化范围的数据过滤，因此构建新的QC样本。以上述随机抽取6个样本作为QC样本。QC样本一般是送测样本混合后再分成N份样本（迈维非靶或广靶均是这样做）再测，它可以评估每次质谱的效果或做代谢物过滤。","code":"\nmeta_tab <- colData(data_meta) |>\n  as.data.frame()\nfeature_tab <- rowData(data_meta) \nassay_tab <- assay(data_meta) |>\n  as.data.frame()\n\nrand_sample <- sample(colnames(assay_tab), 6)\nQC_assay <- assay_tab[, rand_sample]\ncolnames(QC_assay) <- paste0(\"QC\", 1:6)\nassay_tab_new <- cbind(assay_tab, QC_assay)\n\nQC_meta <- data.frame(matrix(NA, nrow = 6, ncol = ncol(meta_tab))) \ncolnames(QC_meta) <- colnames(meta_tab)\nrownames(QC_meta) <- colnames(QC_assay)\nQC_meta$LiverFatClass <- \"QC\"\nQC_meta$PatientID <- rownames(QC_meta)\nmeta_tab_new <- rbind(meta_tab, QC_meta)\n\ndata_meta_new <- SummarizedExperiment(\n  assays = assay_tab_new,\n  rowData = feature_tab,\n  colData = meta_tab_new,\n  checkDimnames = TRUE)\n\ndata_meta_new\n#> class: SummarizedExperiment \n#> dim: 1032 61 \n#> metadata(0):\n#> assays(1): ''\n#> rownames(1032): Chem_100002945 Chem_100002356 ...\n#>   Chem_100015836 Chem_826\n#> rowData names(13): metabolitesID BIOCHEMICAL ... KEGG\n#>   SampleIDHMDBID\n#> colnames(61): P101001 P101003 ... QC5 QC6\n#> colData names(47): PatientID Gender ...\n#>   Right_leg_fat_free_mass Right_leg_total_body_water"},{"path":"dataprocessing.html","id":"数据过滤","chapter":"9 Data Processing","heading":"9.5 数据过滤","text":"结果：12.5%的缺失值存在，下面进行缺失值补充。","code":"\nCheckData <- function(object) {\n  \n  # object = data_meta_new\n  \n  # features are in rows and Samples in columns\n  DataAssay <- SummarizedExperiment::assay(object)\n  \n  # numeric & missing values\n  int_mat <- DataAssay\n  rowNms <- rownames(int_mat)\n  colNms <- colnames(int_mat)\n  naNms <- sum(is.na(int_mat))\n  for (i in 1:ncol(int_mat)) {\n    if (class(int_mat[, i]) == \"integer64\") {\n      int_mat[, i] <- as.double(int_mat[, i])\n    }\n  }\n  \n  num_mat <- apply(int_mat, 2, as.numeric)\n  if (sum(is.na(num_mat)) > naNms) {\n    num_mat <- apply(int_mat, 2, function(x) as.numeric(gsub(\",\",  \"\", x)))\n    if (sum(is.na(num_mat)) > naNms) {\n      message(\"<font color=\\\"red\\\">Non-numeric values were found and replaced by NA.<\/font>\")\n    } else {\n      message(\"All data values are numeric.\")\n    }\n  } else {\n    message(\"All data values are numeric.\")\n  }\n  \n  int_mat <- num_mat\n  rownames(int_mat) <- rowNms\n  colnames(int_mat) <- colNms\n  varCol <- apply(int_mat, 2, var, na.rm = T)\n  constCol <- (varCol == 0 | is.na(varCol))\n  constNum <- sum(constCol, na.rm = T)\n  if (constNum > 0) {\n    print(paste(\"<font color=\\\"red\\\">\", constNum, \n      \"features with a constant or single value across samples were found and deleted.<\/font>\"))\n    int_mat <- int_mat[, !constCol, drop = FALSE]\n  }\n  \n  totalCount <- nrow(int_mat) * ncol(int_mat)\n  naCount <- sum(is.na(int_mat))\n  naPercent <- round(100 * naCount/totalCount, 1)\n\n  print(paste(\"A total of \", naCount, \" (\", naPercent, \n    \"%) missing values were detected.\", sep = \"\"))  \n\n  DataMeta <- colData(object) |>\n    as.data.frame()\n  DataFeature <- rowData(object)\n  \n  res <- SummarizedExperiment(\n    assays = int_mat,\n    rowData = DataFeature,\n    colData = DataMeta,\n    checkDimnames = TRUE)\n  \n  return(object)\n}\n\nse_check <- CheckData(object = data_meta_new)\n#> [1] \"A total of 7839 (12.5%) missing values were detected.\"\nse_check\n#> class: SummarizedExperiment \n#> dim: 1032 61 \n#> metadata(0):\n#> assays(1): ''\n#> rownames(1032): Chem_100002945 Chem_100002356 ...\n#>   Chem_100015836 Chem_826\n#> rowData names(13): metabolitesID BIOCHEMICAL ... KEGG\n#>   SampleIDHMDBID\n#> colnames(61): P101001 P101003 ... QC5 QC6\n#> colData names(47): PatientID Gender ...\n#>   Right_leg_fat_free_mass Right_leg_total_body_water"},{"path":"dataprocessing.html","id":"补缺失值","chapter":"9 Data Processing","heading":"9.6 补缺失值","text":"Missing Value 的产生原因主要有两个：1）一个代谢峰在某些生物样品中存在而在另外一些生物样品中不存在； 2）某些代谢物在生物样品中的浓度低于质谱的检测限。Missing Value 在数据中的表现形式为 NA值。对于大规模代谢组学来说，因为其长时间的数据采集，质谱灵敏度的漂移使MV的问题更加严重。一般来说，对一个代谢组学数据来说， Missing Value 会占到所有数据点的 20%左右 。首先需要对 Missing Value 进行过滤，对于 Missing Value超过一定比例的代谢峰来说，该代谢峰很有可能是一个偶然出现的噪声信号，因此将其从数据中删除。 比如，在代谢组学数据中，一般采用的标准为代谢峰需要在 80%的质量控制（quality control， QC） 样品中出现，否则删除。对于 Missing Value 超过一定比例的生物样品来说，该样品很有可能是在样品制备或者数据采集过程中出现了误差，如该样品稀释比例异常或者进样体积异常，这些样品需要被删除掉。删除掉异常的生物样品和代谢峰之后，剩余的 Missing Value 需要统计学方法进行补齐（MVimputation），不同的 Missing Value补齐方法对数据的结构影响非常大，最好的 Missing Value 补齐方法是那些可以最好的重构出数据原本结构的方法。 Gromski (influence scaling metabolomics data model classification accuracy) 通过使用完整的代谢组学数据构建 Missing Value 数据，然后使用不同的 Missing Value补齐方法对数据进行补齐，然后对不同 Missing Value 补齐方法补齐的数据进行多元统计学分析， 最终发现 K 值临近方法（K-nearest neighbor，KNN）对代谢组学数据的补齐效果最好。缺失值补充方法有很多种，如下“none”: missing values replaced zero.“none”: missing values replaced zero.“LOD”: specific Limit Detection provides user.“LOD”: specific Limit Detection provides user.“half_min”: half minimal values across samples except zero.“half_min”: half minimal values across samples except zero.“median”: median values across samples except zero.“median”: median values across samples except zero.“mean”: mean values across samples except zero.“mean”: mean values across samples except zero.“min”: minimal values across samples except zero.“min”: minimal values across samples except zero.“knn”: k-nearest neighbors samples.“knn”: k-nearest neighbors samples.“rf”: nonparametric missing value imputation using Random Forest.“rf”: nonparametric missing value imputation using Random Forest.“QRILC”: missing values imputation based quantile regression. (default: “none”).“QRILC”: missing values imputation based quantile regression. (default: “none”).一般采用k近邻的方法，它的原理是离该缺失值样本最近的K个样本具有类似的属性，使用它们的平均值填补缺失值是相对可靠的方法，但是也需要注意该方法的阈值适用范围。这里使用MicrobiomeAnalysis提供的impute_abundance函数，先安装此包。结果：代谢物的缺失值在任何组大于50%会被移除，最后移除的代谢物表达矩阵用于缺失值补充。","code":"\nif (!requireNamespace(c(\"remotes\", \"devtools\"), quietly=TRUE)) {\n  install.packages(c(\"devtools\", \"remotes\"))\n}\n\nremotes::install_github(\"HuaZou/MicrobiomeAnalysis\")\n\n# library(MicrobiomeAnalysis)\nlibrary(MicrobiomeAnalysis)\n\nse_impute <- impute_abundance(\n  object = se_check,\n  group = \"LiverFatClass\",\n  method = \"knn\",\n  cutoff = 50,\n  knum = 10)\n\nse_impute\n#> class: SummarizedExperiment \n#> dim: 956 61 \n#> metadata(0):\n#> assays(1): ''\n#> rownames(956): Chem_100002945 Chem_100002356 ...\n#>   Chem_100015836 Chem_826\n#> rowData names(13): metabolitesID BIOCHEMICAL ... KEGG\n#>   SampleIDHMDBID\n#> colnames(61): P101001 P101003 ... QC5 QC6\n#> colData names(47): PatientID Gender ...\n#>   Right_leg_fat_free_mass Right_leg_total_body_water"},{"path":"dataprocessing.html","id":"数据过滤-1","chapter":"9 Data Processing","heading":"9.7 数据过滤","text":"在非靶向代谢组或蛋白质组经常会使用该方法，目的是过滤掉不太可能用于分析的代谢物或蛋白质。过滤会基于QC样本的相对丰度标准方差relative standard deviation (RSD = SD / mean)，可以理解为特征的数据波动范围。 LC-MS或GC-MS对不同样本可能存在不同偏好行，采用QC样本可以得到波动范围，那些具有高RSD的特征可能受到质谱操作的影响较大，因此它们的可靠性相对较低不需要用于后续下游分析。一般情况下，RSD阈值在LC-MS和GC-MS分别是20%和30%（保留波动小于该阈值的代谢物）。在通过QC的RSD过滤完后，还可以通过以下方法过滤噪声（过滤低丰度或高变化的特征）过滤方法\nInterquantile range (IQR)（过滤常数特征，即波动较小的特征，它们可能是常态表达）;\nStandard deviation (SD) （过滤常数特征，即波动较小的特征，它们可能是常态表达）;\nMedian absolute deviation (MAD) （过滤常数特征，即波动较小的特征，它们可能是常态表达）;\nRelative standard deviation (RSD = SD/mean) （过滤低重复性特征，它们可能受到质谱操作影响）;\nNon-parametric relative standard deviation (MAD/median) （过滤低重复性特征，它们可能受到质谱操作影响）;\nMean intensity value （过滤低丰度特征，它们可能是噪声或仪器测量极限值）;\nMedian intensity value （过滤低丰度特征，它们可能是噪声或仪器测量极限值）;\n过滤方法Interquantile range (IQR)（过滤常数特征，即波动较小的特征，它们可能是常态表达）;Interquantile range (IQR)（过滤常数特征，即波动较小的特征，它们可能是常态表达）;Standard deviation (SD) （过滤常数特征，即波动较小的特征，它们可能是常态表达）;Standard deviation (SD) （过滤常数特征，即波动较小的特征，它们可能是常态表达）;Median absolute deviation (MAD) （过滤常数特征，即波动较小的特征，它们可能是常态表达）;Median absolute deviation (MAD) （过滤常数特征，即波动较小的特征，它们可能是常态表达）;Relative standard deviation (RSD = SD/mean) （过滤低重复性特征，它们可能受到质谱操作影响）;Relative standard deviation (RSD = SD/mean) （过滤低重复性特征，它们可能受到质谱操作影响）;Non-parametric relative standard deviation (MAD/median) （过滤低重复性特征，它们可能受到质谱操作影响）;Non-parametric relative standard deviation (MAD/median) （过滤低重复性特征，它们可能受到质谱操作影响）;Mean intensity value （过滤低丰度特征，它们可能是噪声或仪器测量极限值）;Mean intensity value （过滤低丰度特征，它们可能是噪声或仪器测量极限值）;Median intensity value （过滤低丰度特征，它们可能是噪声或仪器测量极限值）;Median intensity value （过滤低丰度特征，它们可能是噪声或仪器测量极限值）;一般过滤的阈值设置\n少于 250 个特征: 5%\n介于 250 到 500 个特征: 10%\n介于 500 到 1000 个特征: 25%\n超过 1000 个特征: 40%\n一般过滤的阈值设置少于 250 个特征: 5%少于 250 个特征: 5%介于 250 到 500 个特征: 10%介于 250 到 500 个特征: 10%介于 500 到 1000 个特征: 25%介于 500 到 1000 个特征: 25%超过 1000 个特征: 40%超过 1000 个特征: 40%结果：过滤掉不符合要求的代谢物以及也过滤掉了QC样本 (25%过滤太多了，这里选择90%)根据QC样本的代谢物RSD过滤代谢物根据QC样本的代谢物RSD过滤代谢物再根据代谢物波动范围过滤不符合的代谢物再根据代谢物波动范围过滤不符合的代谢物","code":"\nFilterFeature <- function(\n    object,\n    group,    \n    qc_label,\n    method = c(\"none\", \"iqr\", \"rsd\", \n               \"nrsd\", \"mean\", \"sd\",\n               \"mad\", \"median\"),\n    rsd_cutoff = 25) {\n  \n  # object = se_impute\n  # group = \"LiverFatClass\"  \n  # qc_label = \"QC\"\n  # method = \"iqr\"\n  # rsd_cutoff = 25  \n  \n  # row->features; col->samples  \n  features_tab <- SummarizedExperiment::assay(object) \n  metadata_tab <- SummarizedExperiment::colData(object) \n  \n  # QC samples\n  colnames(metadata_tab)[which(colnames(metadata_tab) == group)] <- \"TempGroup\"\n  qc_samples <- metadata_tab %>% \n    as.data.frame() %>%\n    dplyr::filter(TempGroup == qc_label)\n  if (dim(qc_samples)[1] == 0) {\n    stop(\"No qc samples have been chosen, please check your input\")\n  }\n  \n  # QC samples' feature table\n  qc_feature <- features_tab[, colnames(features_tab) %in% \n                               rownames(qc_samples)] %>%\n    t()\n  \n  # filter features by QC RSD\n  rsd <- rsd_cutoff / 100\n  sds <- apply(qc_feature, 2, sd, na.rm = T)\n  mns <- apply(qc_feature, 2, mean, na.rm = T)\n  rsd_vals <- abs(sds/mns) %>% na.omit()\n  gd_inx <- rsd_vals < rsd\n  int_mat <- features_tab[gd_inx, ]\n  print(paste(\"Removed \", (dim(qc_feature)[2] - dim(int_mat)[1]), \n  \" features based on QC RSD values. QC samples are excluded from downstream functional analysis.\"))\n  \n  # whether to filter features by percentage according to the number\n  PerformFeatureFilter <- function(datMatrix, \n                                   qc_method = method,\n                                   remain_num = NULL) {\n    \n    dat <- datMatrix\n    feat_num <- ncol(dat)\n    feat_nms <- colnames(dat)\n    nm <- NULL\n    if (qc_method == \"none\" && feat_num < 5000) { # only allow for less than 4000\n      remain <- rep(TRUE, feat_num)\n      nm <- \"No filtering was applied\"\n    } else {\n      if (qc_method == \"rsd\"){\n        sds <- apply(dat, 2, sd, na.rm = T)\n        mns <- apply(dat, 2, mean, na.rm = T)\n        filter_val <- abs(sds/mns)\n        nm <- \"Relative standard deviation\"\n      } else if (qc_method == \"nrsd\" ) {\n        mads <- apply(dat, 2, mad, na.rm = T)\n        meds <- apply(dat, 2, median, na.rm = T)\n        filter_val <- abs(mads/meds)\n        nm <- \"Non-paramatric relative standard deviation\"\n      } else if (qc_method == \"mean\") {\n        filter_val <- apply(dat, 2, mean, na.rm = T)\n        nm <- \"mean\"\n      } else if (qc_method == \"sd\") {\n        filter_val <- apply(dat, 2, sd, na.rm = T)\n        nm <- \"standard deviation\"\n      } else if (qc_method == \"mad\") {\n        filter_val <- apply(dat, 2, mad, na.rm = T)\n        nm <- \"Median absolute deviation\"\n      } else if (qc_method == \"median\") {\n        filter_val <- apply(dat, 2, median, na.rm = T)\n        nm <- \"median\"\n      } else if (qc_method == \"iqr\") { # iqr\n        filter_val <- apply(dat, 2, IQR, na.rm = T)\n        nm <- \"Interquantile Range\"\n      }\n      \n      # get the rank of the filtered variables\n      rk <- rank(-filter_val, ties.method = \"random\")\n      \n      if (is.null(remain_num)) { # apply empirical filtering based on data size\n          if (feat_num < 250) { # reduce 5%\n            remain <- rk < feat_num * 0.95\n            message(\"Further feature filtering based on \", nm)\n          } else if (feat_num < 500) { # reduce 10%\n            remain <- rk < feat_num * 0.9\n            message(\"Further feature filtering based on \", nm)\n          } else if (feat_num < 1000) { # reduce 25%\n            remain <- rk < feat_num * 0.75\n            message(\"Further feature filtering based on \", nm)\n          } else { # reduce 40%, if still over 5000, then only use top 5000\n            remain <- rk < feat_num * 0.6\n            message(\"Further feature filtering based on \", nm)\n          }\n      } else {\n        remain <- rk < remain_num\n      }\n    }\n    \n    res <- datMatrix[, remain]\n    \n    return(res)\n  }  \n  \n  feature_res <- PerformFeatureFilter(t(int_mat))\n  \n  # remove QC samples \n  feature_final <- feature_res[!rownames(feature_res) %in% rownames(qc_samples), ]\n  \n  # save int_mat into se object \n  datarow <- object@elementMetadata %>% \n    as.data.frame() \n  rownames(datarow) <- datarow$metabolitesID\n  res <- import_SE(\n    object = t(feature_final),\n    rowdata = datarow,\n    coldata = object@colData)\n  \n  return(res) \n}\n\nse_filter <- FilterFeature(\n  object = se_impute,\n  group = \"LiverFatClass\",\n  qc_label = \"QC\",\n  method = \"iqr\",\n  rsd_cutoff = 90)\n#> [1] \"Removed  94  features based on QC RSD values. QC samples are excluded from downstream functional analysis.\"\n\nse_filter\n#> class: SummarizedExperiment \n#> dim: 646 55 \n#> metadata(0):\n#> assays(1): ''\n#> rownames(646): Chem_100002945 Chem_100002356 ...\n#>   Chem_1004 Chem_100015836\n#> rowData names(13): metabolitesID BIOCHEMICAL ... KEGG\n#>   SampleIDHMDBID\n#> colnames(55): P101001 P101003 ... P101095 P101096\n#> colData names(47): PatientID Gender ...\n#>   Right_leg_fat_free_mass Right_leg_total_body_water"},{"path":"dataprocessing.html","id":"数据标准化","chapter":"9 Data Processing","heading":"9.8 数据标准化","text":"数据标准化为了三部分：基于单个数值本身的数据转换，目的是将数据进行各种形式的转换从而提高数据的正态分布性，校正奇异值，达到减少分析误差的效果。代谢组学数据大都为偏倚分布，因此数据转换是非常常见的数据处理方式之一，常用的方法为对数变换（log）。经过数据转换之后的数据仍然没有处在同一个标准量度上，对于代谢组学数据来说，不同代谢峰的强度可以相差几个甚至十几个数量级，如此大的差别导致在多元统计分析时，强度大的代谢峰有可能掩盖强度小的代谢峰的贡献。因此，在统计分析前，尤其是多元统计分析，为了将所有代谢峰统一到同一个量度，需要对数据进行中心化和标度化。\nLog transformation (base 10)\nSquare root transformation (square root data values)\nCube root transformation (cube root data values)\n基于单个数值本身的数据转换，目的是将数据进行各种形式的转换从而提高数据的正态分布性，校正奇异值，达到减少分析误差的效果。代谢组学数据大都为偏倚分布，因此数据转换是非常常见的数据处理方式之一，常用的方法为对数变换（log）。经过数据转换之后的数据仍然没有处在同一个标准量度上，对于代谢组学数据来说，不同代谢峰的强度可以相差几个甚至十几个数量级，如此大的差别导致在多元统计分析时，强度大的代谢峰有可能掩盖强度小的代谢峰的贡献。因此，在统计分析前，尤其是多元统计分析，为了将所有代谢峰统一到同一个量度，需要对数据进行中心化和标度化。Log transformation (base 10)Log transformation (base 10)Square root transformation (square root data values)Square root transformation (square root data values)Cube root transformation (cube root data values)Cube root transformation (cube root data values)使用MicrobiomeAnalysis提供的transform_abundances，选择log10p，改变数据的偏态分布。基于样本自身的标准化，目的是去除样本间的系统差异（比如不同测序深度），例如通过均值中心化处理， 代谢峰转变为与自己平均值之间的差值，且所有的变量都以零为中心变化，因此中心化的数据就能直接反应变量的变化情况，有利于观察组间差异和聚类分析。\nSample-specific normalization (.e. weight, volume)\nNormalization sum (relative abundance)\nNormalization median\nNormalization reference sample (PQN)\nNormalization pooled sample group (group PQN)\nNormalization reference feature\nQuantile normalization (suggested > 1000 features)\n基于样本自身的标准化，目的是去除样本间的系统差异（比如不同测序深度），例如通过均值中心化处理， 代谢峰转变为与自己平均值之间的差值，且所有的变量都以零为中心变化，因此中心化的数据就能直接反应变量的变化情况，有利于观察组间差异和聚类分析。Sample-specific normalization (.e. weight, volume)Sample-specific normalization (.e. weight, volume)Normalization sum (relative abundance)Normalization sum (relative abundance)Normalization medianNormalization medianNormalization reference sample (PQN)Normalization reference sample (PQN)Normalization pooled sample group (group PQN)Normalization pooled sample group (group PQN)Normalization reference featureNormalization reference featureQuantile normalization (suggested > 1000 features)Quantile normalization (suggested > 1000 features)基于特征的数据标准化，目的是增加各个变量在不同样品中的可比性\nMean centering (mean-centered )\nAuto scaling (mean-centered divided standard deviation variable)\nPareto scaling (mean-centered divided square root standard deviation variable)\nRange scaling (mean-centered divided range variable)\n基于特征的数据标准化，目的是增加各个变量在不同样品中的可比性Mean centering (mean-centered )Mean centering (mean-centered )Auto scaling (mean-centered divided standard deviation variable)Auto scaling (mean-centered divided standard deviation variable)Pareto scaling (mean-centered divided square root standard deviation variable)Pareto scaling (mean-centered divided square root standard deviation variable)Range scaling (mean-centered divided range variable)Range scaling (mean-centered divided range variable)查看数据状态","code":"\nse_tran <- MicrobiomeAnalysis::transform_abundances(\n  object = se_filter,\n  transform = \"log10p\")\n\nse_tran\n#> class: SummarizedExperiment \n#> dim: 646 55 \n#> metadata(0):\n#> assays(1): ''\n#> rownames(646): Chem_100002945 Chem_100002356 ...\n#>   Chem_1004 Chem_100015836\n#> rowData names(13): metabolitesID BIOCHEMICAL ... KEGG\n#>   SampleIDHMDBID\n#> colnames(55): P101001 P101003 ... P101095 P101096\n#> colData names(47): PatientID Gender ...\n#>   Right_leg_fat_free_mass Right_leg_total_body_water\nNormalizeData <- function(\n    object,\n    rowNorm = c(\"Quantile\", \"GroupPQN\", \"SamplePQN\",\n                \"CompNorm\", \"SumNorm\", \"MedianNorm\",\n                \"SpecNorm\", \"None\"),\n    ref = NULL,\n    SpeWeight = 1) {\n  \n  # object = se_tran\n  # rowNorm = \"SumNorm\"\n  # ref = NULL\n  # SpeWeight = 1\n  \n  # row->features; col->samples \n  features_tab <- SummarizedExperiment::assay(object) \n  metadata_tab <- SummarizedExperiment::colData(object)   \n  \n  # row->samples; col->features \n  feaTab <- t(features_tab)\n  colNames <- colnames(feaTab)\n  rowNames <- rownames(feaTab)\n  \n  #############################################\n  # Sample normalization\n  # perform quantile normalization on the raw data (can be log transformed later by user)\n  QuantileNormalize <- function(data) {\n    return(t(preprocessCore::normalize.quantiles(t(data), copy=FALSE)));\n  }\n  # normalize by a reference sample (probability quotient normalization)\n  # ref should be the name of the reference sample\n  ProbNorm <- function(x, ref_smpl) {\n    return(x/median(as.numeric(x/ref_smpl), na.rm = T))\n  }\n  \n  # normalize by a reference reference (i.e. creatinine)\n  # ref should be the name of the cmpd\n  CompNorm <- function(x, ref) {\n    return(1000 * x/x[ref])\n  }\n  \n  # normalize by sum (relative abundance)\n  SumNorm <- function(x) {\n    #return(1000 * x/sum(x, na.rm = T))\n    return(x/sum(x, na.rm = T))\n  }\n  \n  # normalize by median\n  MedianNorm <- function(x) {\n    return(x/median(x, na.rm = T))\n  }  \n  \n  # row-wise normalization (samples)\n  if (rowNorm == \"Quantile\") {\n    datrowNorm <- QuantileNormalize(feaTab)\n    # this can introduce constant variables if a variable is \n    # at the same rank across all samples (replaced by its average across all)\n    varCol <- apply(datrowNorm, 2, var, na.rm = T)\n    constCol <- (varCol == 0 | is.na(varCol))\n    constNum <- sum(constCol, na.rm = T)\n    if (constNum > 0) {\n      message(paste(\"After quantile normalization\", constNum, \n                    \"features with a constant value were found and deleted.\"))\n      datrowNorm <- datrowNorm[, !constCol, drop = FALSE]\n      colNames <- colnames(datrowNorm)\n      rowNames <- rownames(datrowNorm)\n    }\n    rownm <- \"Quantile Normalization\"\n  } else if (rowNorm == \"GroupPQN\") {\n    grp_inx <- metadata_tab$group == ref\n    ref.smpl <- apply(feaTab[grp_inx, , drop = FALSE], 2, mean)\n    datrowNorm <- t(apply(feaTab, 1, ProbNorm, ref.smpl))\n    rownm <- \"Probabilistic Quotient Normalization by a reference group\"\n  } else if (rowNorm == \"SamplePQN\") {\n    ref.smpl <- feaTab[ref, , drop = FALSE]\n    datrowNorm <- t(apply(feaTab, 1, ProbNorm, ref.smpl))\n    rownm <- \"Probabilistic Quotient Normalization by a reference sample\"\n  } else if (rowNorm == \"CompNorm\") {\n    datrowNorm <- t(apply(t(feaTab), 1, CompNorm, ref))\n    rownm <- \"Normalization by a reference feature\";\n  } else if (rowNorm == \"SumNorm\") {\n    datrowNorm <- t(apply(feaTab, 1, SumNorm))\n    rownm <- \"Normalization to constant sum\"\n  } else if (rowNorm == \"MedianNorm\") {\n    datrowNorm <- t(apply(feaTab, 1, MedianNorm))\n    rownm <- \"Normalization to sample median\"\n  } else if(rowNorm == \"SpecNorm\") {\n    norm.vec <- rep(SpeWeight, nrow(feaTab)) # default all same weight vec to prevent error\n    datrowNorm <- feaTab / norm.vec\n    message(\"No sample specific information were given, all set to 1.0\")\n    rownm <- \"Normalization by sample-specific factor\"\n  } else {\n    # nothing to do\n    rownm <- \"N/A\"\n    datrowNorm <- feaTab\n  }\n  ################################################ \n  \n  # use apply will lose dimension info (i.e. row names and colnames)\n  # row->samples; col->features \n  rownames(datrowNorm) <- rowNames\n  colnames(datrowNorm) <- colNames\n  \n  # if the reference by feature, the feature column should be removed, since it is all 1\n  if(rowNorm == \"CompNorm\" && !is.null(ref)){\n    inx <- match(ref, colnames(datrowNorm))\n    datrowNorm <- datrowNorm[, -inx, drop=FALSE]\n    colNames <- colNames[-inx]\n  }\n\n  DataMeta <- colData(object) |>\n    as.data.frame()\n  DataFeature <- rowData(object)\n  \n  datrowNorm[is.na(datrowNorm)] <- 0\n  \n  se <- SummarizedExperiment(\n    assays = t(datrowNorm),\n    rowData = DataFeature,\n    colData = DataMeta,\n    checkDimnames = TRUE)  \n  \n  # need to do some sanity check, for log there may be Inf values introduced\n  res <- CheckData(se)\n  \n  return(res)\n}\n\nse_norm <- NormalizeData(\n  object = se_tran,\n  rowNorm = \"SumNorm\")\n#> [1] \"A total of 0 (0%) missing values were detected.\"\n\nse_norm\n#> class: SummarizedExperiment \n#> dim: 646 55 \n#> metadata(0):\n#> assays(1): ''\n#> rownames(646): Chem_100002945 Chem_100002356 ...\n#>   Chem_1004 Chem_100015836\n#> rowData names(13): metabolitesID BIOCHEMICAL ... KEGG\n#>   SampleIDHMDBID\n#> colnames(55): P101001 P101003 ... P101095 P101096\n#> colData names(47): PatientID Gender ...\n#>   Right_leg_fat_free_mass Right_leg_total_body_water\nse_scale <- scale_variables(\n  object = se_norm,\n  method = \"zscore\")\n\nse_scale\n#> class: SummarizedExperiment \n#> dim: 646 55 \n#> metadata(0):\n#> assays(1): ''\n#> rownames(646): Chem_100002945 Chem_100002356 ...\n#>   Chem_1004 Chem_100015836\n#> rowData names(13): metabolitesID BIOCHEMICAL ... KEGG\n#>   SampleIDHMDBID\n#> colnames(55): P101001 P101003 ... P101095 P101096\n#> colData names(47): PatientID Gender ...\n#>   Right_leg_fat_free_mass Right_leg_total_body_water\nSummarizedExperiment::assay(se_filter)  %>% data.frame() %>% head()\n#>                   P101001      P101003      P101004\n#> Chem_100002945 51127588.0  42040432.00  34940596.00\n#> Chem_100002356  5105020.5   4006120.25   3885477.00\n#> Chem_100021502   756686.2    983889.19    851026.50\n#> Chem_100008903 94392176.0 117463144.00 115155104.00\n#> Chem_100000657 25632184.0  26952236.00  25106562.00\n#> Chem_100001397   123026.4     86646.23     22810.19\n#>                   P101007     P101009    P101010    P101011\n#> Chem_100002945 58518636.0  51118832.0 83783688.0 29017984.0\n#> Chem_100002356  4285129.5   6665653.5  9057441.0  2802655.2\n#> Chem_100021502   726593.9    232959.5   650261.1   541954.8\n#> Chem_100008903 79582632.0 118408760.0 92508664.0 94076424.0\n#> Chem_100000657 31371314.0  27787270.0 26685844.0 27780988.0\n#> Chem_100001397   375686.5    118662.2   130040.2   258790.7\n#>                   P101012    P101013     P101016\n#> Chem_100002945 51222064.0 77550128.0 30949554.00\n#> Chem_100002356  5996555.0 11367511.0  3874736.75\n#> Chem_100021502   598491.0   438885.6  1625844.75\n#> Chem_100008903 69473744.0 80567352.0 98766592.00\n#> Chem_100000657 30158644.0 27591838.0 21537830.00\n#> Chem_100001397   121117.4   526472.9    51847.78\n#>                    P101017     P101018  P101019\n#> Chem_100002945  26923596.0  56720032.0 27956064\n#> Chem_100002356   2817151.0   8029728.0  3766664\n#> Chem_100021502    566466.9    427850.6   519559\n#> Chem_100008903 129547656.0 118271584.0 37880820\n#> Chem_100000657  34510160.0  24383964.0 25435894\n#> Chem_100001397    309598.5    142944.8   122802\n#>                     P101021     P101022     P101024\n#> Chem_100002945  48723600.00  16282054.0 77028824.00\n#> Chem_100002356   5174967.00   1746182.9  5519105.50\n#> Chem_100021502   1301591.25   1474247.4   970475.75\n#> Chem_100008903 163868720.00 106189520.0 71475920.00\n#> Chem_100000657  33230896.00  28310448.0 24481250.00\n#> Chem_100001397     36066.18    143211.6    41351.85\n#>                    P101025     P101027     P101030\n#> Chem_100002945  32022342.0  22589448.0  38449788.0\n#> Chem_100002356   2557365.0   1882902.6   2860324.2\n#> Chem_100021502    628680.1    635516.6    367246.8\n#> Chem_100008903 147776592.0 127571792.0 128319128.0\n#> Chem_100000657  36634552.0  26803284.0  38250240.0\n#> Chem_100001397    299205.7    338827.8    240744.7\n#>                   P101031    P101038      P101041\n#> Chem_100002945 59134052.0 32038030.0  20833830.00\n#> Chem_100002356  4721201.0  4011627.5   2938779.00\n#> Chem_100021502   512037.9   852000.1    634488.56\n#> Chem_100008903 90447848.0 46622592.0 111919096.00\n#> Chem_100000657 31415658.0 36232668.0  27869314.00\n#> Chem_100001397   748813.9   497035.7     45508.17\n#>                   P101042    P101047     P101050\n#> Chem_100002945 33809080.0 18637508.0  21978476.0\n#> Chem_100002356  3017260.5  1935144.1   2897211.0\n#> Chem_100021502  1680135.8   326005.6    316650.2\n#> Chem_100008903 89762056.0 97617984.0 112900000.0\n#> Chem_100000657 29975144.0 30274784.0  29706444.0\n#> Chem_100001397   141089.5   151984.7    167735.3\n#>                    P101051    P101052     P101054\n#> Chem_100002945 24265162.00 52203780.0  12836384.0\n#> Chem_100002356  2476279.50  5928454.0   1685760.6\n#> Chem_100021502   737202.88   459385.9    346176.6\n#> Chem_100008903 71779912.00 64008512.0 111279888.0\n#> Chem_100000657 28526700.00 19797506.0  22277808.0\n#> Chem_100001397    83878.49   153736.2    131393.6\n#>                   P101056     P101057      P101059\n#> Chem_100002945 18546636.0 32301820.00  22645984.00\n#> Chem_100002356  1650011.0  3419157.75   2196044.25\n#> Chem_100021502   585470.2   417958.47    734586.31\n#> Chem_100008903 68771592.0 77140264.00 113564872.00\n#> Chem_100000657 20182492.0 22884156.00  28125854.00\n#> Chem_100001397   125445.7    36627.55     67012.24\n#>                   P101061    P101062      P101064\n#> Chem_100002945 23683254.0 29027646.0  32629048.00\n#> Chem_100002356  3217499.2  4060367.8   3031529.50\n#> Chem_100021502   337035.7   982299.4   1255148.00\n#> Chem_100008903 96143304.0 98940424.0 108473368.00\n#> Chem_100000657 27426428.0 27010240.0  29414698.00\n#> Chem_100001397   248423.8    35064.2     32855.53\n#>                   P101065    P101067    P101068    P101069\n#> Chem_100002945 22950806.0 33555116.0 44283972.0 52685972.0\n#> Chem_100002356  2467147.2  3567913.2  6525382.0  3984333.5\n#> Chem_100021502   637699.1   284516.1   664800.1   684813.6\n#> Chem_100008903 86418592.0 95236288.0 71289048.0 74526792.0\n#> Chem_100000657 25252692.0 33943364.0 28292364.0 31375248.0\n#> Chem_100001397   137605.2   155844.5   109021.4   178198.0\n#>                     P101071     P101072     P101074\n#> Chem_100002945  32415040.00  34170948.0  22550616.0\n#> Chem_100002356   3001414.50   4679519.0   2529255.5\n#> Chem_100021502    596846.06    316855.0    646136.8\n#> Chem_100008903 115519872.00 127401592.0 108255040.0\n#> Chem_100000657  33193432.00  27121940.0  24320710.0\n#> Chem_100001397     74016.23    404225.1    124975.2\n#>                   P101075    P101076     P101077    P101079\n#> Chem_100002945 22058076.0 24455466.0  25225170.0 15718590.0\n#> Chem_100002356  2583265.5  3515218.2   3272875.0  2449462.5\n#> Chem_100021502   198381.7   255897.7    547243.4   508791.6\n#> Chem_100008903 83989120.0 77315256.0 158257952.0 78587928.0\n#> Chem_100000657 25176120.0 25405452.0  25782852.0 26353500.0\n#> Chem_100001397   177570.7   155756.0    410891.4   292623.9\n#>                    P101080     P101081     P101082\n#> Chem_100002945  29120336.0  65904836.0  22908578.0\n#> Chem_100002356   2695001.5   6474709.5   2110243.8\n#> Chem_100021502   1256550.2    339909.3    596292.2\n#> Chem_100008903 163246832.0 124678488.0 100435064.0\n#> Chem_100000657  25819136.0  34524436.0  27735140.0\n#> Chem_100001397    162495.1    237136.2    154358.6\n#>                   P101084     P101085      P101088\n#> Chem_100002945 29140440.0  20427124.0  29199012.00\n#> Chem_100002356  3648091.2   3253531.8   4154170.75\n#> Chem_100021502   497300.8    309859.3    601515.12\n#> Chem_100008903 86139200.0 103513520.0 101921248.00\n#> Chem_100000657 30228504.0  29317998.0  28259446.00\n#> Chem_100001397   181003.1    126785.3     36267.95\n#>                    P101090     P101094     P101095\n#> Chem_100002945  24042020.0 36910084.00 35662068.00\n#> Chem_100002356   2396959.8  4759584.50  3452283.25\n#> Chem_100021502    794206.0   414972.84  3606340.50\n#> Chem_100008903 107571936.0 85426888.00 53107852.00\n#> Chem_100000657  32471818.0 25804370.00 25684144.00\n#> Chem_100001397    217137.2    75320.37    59115.54\n#>                    P101096\n#> Chem_100002945 66402192.00\n#> Chem_100002356  6374383.00\n#> Chem_100021502  1077637.50\n#> Chem_100008903 80095704.00\n#> Chem_100000657 28136850.00\n#> Chem_100001397    81256.43\nSummarizedExperiment::assay(se_scale) %>% as.data.frame() %>% head()\n#>                   P101001    P101003    P101004     P101007\n#> Chem_100002945  1.0003202  0.8340093  0.4824815  1.16514410\n#> Chem_100002356  0.7698677  0.4528499  0.4722902  0.20487334\n#> Chem_100021502  0.3493679  1.0177030  0.8133573  0.17978061\n#> Chem_100008903 -0.1750138  0.9830758  1.0729215 -0.95957735\n#> Chem_100000657 -0.8755692  0.3320746  0.1405178  0.05966061\n#> Chem_100001397 -0.1384950 -0.4886188 -2.2159878  1.25940891\n#>                   P101009    P101010     P101011    P101012\n#> Chem_100002945  1.2101541 2.51666716 -0.23603447  0.9681736\n#> Chem_100002356  1.5968592 2.40769233 -0.53984618  1.1277217\n#> Chem_100021502 -1.7072851 0.23001842 -0.16887486 -0.1021096\n#> Chem_100008903  0.8551114 0.14676736  0.04917596 -1.2248011\n#> Chem_100000657  0.2436337 0.16307095  0.14091374  0.1443482\n#> Chem_100001397 -0.1126339 0.03397164  0.89961516 -0.1717796\n#>                   P101013    P101016    P101017     P101018\n#> Chem_100002945  2.0188766  0.2942855 -0.8313337  0.97319820\n#> Chem_100002356  2.6944940  0.5645338 -0.8739209  1.61833342\n#> Chem_100021502 -0.6590182  2.0858052 -0.3221498 -0.85175224\n#> Chem_100008903 -0.7100038  0.7289363  0.5094011  0.17118653\n#> Chem_100000657 -0.4044572 -0.6113151  0.4869781 -1.97118260\n#> Chem_100001397  1.7605892 -1.0914366  0.9755675 -0.04186828\n#>                   P101019    P101021    P101022    P101024\n#> Chem_100002945 -0.2712992  0.9955133 -1.5896988  2.2111767\n#> Chem_100002356  0.2276389  0.9004347 -1.6181559  1.1215870\n#> Chem_100021502 -0.2140225  1.4138229  1.7307078  0.9167298\n#> Chem_100008903 -2.8549375  1.7868883  0.5688224 -0.8265065\n#> Chem_100000657 -0.3095136  1.2218079  0.5114391 -0.6834080\n#> Chem_100001397 -0.0599027 -1.7098957  0.1531504 -1.5061848\n#>                   P101025     P101027    P101030\n#> Chem_100002945 -0.5131518 -1.12363191  0.2445829\n#> Chem_100002356 -1.1975338 -1.72629859 -0.6727476\n#> Chem_100021502 -0.1942294 -0.02995268 -1.0063388\n#> Chem_100008903  0.7802989  0.66296793  0.7574122\n#> Chem_100000657  0.5904137 -0.84889311  1.7406139\n#> Chem_100001397  0.8890289  1.14875934  0.7222524\n#>                     P101031    P101038    P101041\n#> Chem_100002945  1.168623874 -0.2262161 -0.9809803\n#> Chem_100002356  0.419680765  0.1279997 -0.3563059\n#> Chem_100021502 -0.473153554  0.5272900  0.1685822\n#> Chem_100008903 -0.573539379 -2.5698105  0.7331244\n#> Chem_100000657  0.009496466  1.3142118  0.3866294\n#> Chem_100001397  2.150497430  1.6629837 -1.3594124\n#>                    P101042    P101047    P101050    P101051\n#> Chem_100002945 -0.20090806 -0.8221882 -0.8428020 -0.8411860\n#> Chem_100002356 -0.65053616 -1.0044608 -0.3867684 -0.9759579\n#> Chem_100021502  1.70722179 -0.8169443 -1.1135464  0.3044130\n#> Chem_100008903 -0.58479970  0.9161006  0.7688378 -1.0618801\n#> Chem_100000657 -0.28533153  2.2064810  0.8421985 -0.1252541\n#> Chem_100001397 -0.02285532  0.3938023  0.3611153 -0.6384336\n#>                   P101052      P101054     P101056\n#> Chem_100002945  0.9926892 -2.296699968 -1.43237721\n#> Chem_100002356  1.0808513 -1.801646341 -1.89570397\n#> Chem_100021502 -0.6001134 -1.014348465 -0.07517259\n#> Chem_100008903 -1.5220028  0.552048340 -1.09542644\n#> Chem_100000657 -2.8081437 -1.475308440 -2.29749895\n#> Chem_100001397  0.1323507 -0.003866928 -0.08340496\n#>                   P101057    P101059     P101061\n#> Chem_100002945  0.1681043 -0.8517417 -0.80214648\n#> Chem_100002356  0.0597999 -1.1313483 -0.25699974\n#> Chem_100021502 -0.5719122  0.3928758 -1.07911803\n#> Chem_100008903 -0.4110574  0.6676180  0.03368079\n#> Chem_100000657 -0.8242837  0.2289504 -0.11809493\n#> Chem_100001397 -1.6273812 -0.8768282  0.82233565\n#>                     P101062     P101064     P101065\n#> Chem_100002945 -0.212424092 -0.29037347 -1.01430996\n#> Chem_100002356  0.380130583 -0.64068901 -1.01468081\n#> Chem_100021502  0.942031935  1.17235520  0.01733636\n#> Chem_100008903  0.246540820  0.02821322 -0.50583950\n#> Chem_100000657  0.009576575 -0.41962877 -1.06217007\n#> Chem_100001397 -1.721577407 -1.92445285 -0.00290000\n#>                     P101067     P101068    P101069\n#> Chem_100002945 -0.003299045  0.46934926  1.1451062\n#> Chem_100002356 -0.062895019  1.21147760  0.2290397\n#> Chem_100021502 -1.427023227  0.01261184  0.2054004\n#> Chem_100008903 -0.090326948 -1.32808732 -0.8518409\n#> Chem_100000657  1.167281224 -0.66958167  0.7051260\n#> Chem_100001397  0.185767205 -0.35772768  0.3721211\n#>                   P101071     P101072     P101074\n#> Chem_100002945 -0.2032196 -0.08576324 -0.59386916\n#> Chem_100002356 -0.5776847  0.48352488 -0.56010297\n#> Chem_100021502 -0.1292284 -1.29807207  0.31345022\n#> Chem_100008903  0.3790460  0.67962371  0.89703195\n#> Chem_100000657  0.6959017 -0.72717873 -0.02654831\n#> Chem_100001397 -0.8295869  1.38520647  0.04111287\n#>                   P101075     P101076    P101077\n#> Chem_100002945 -0.6159217 -0.49414392 -0.9078624\n#> Chem_100002356 -0.4801326  0.15510081 -0.4410953\n#> Chem_100021502 -1.8614934 -1.46259716 -0.3369384\n#> Chem_100008903  0.1071849 -0.35840476  1.2817143\n#> Chem_100000657  0.3067290 -0.01063717 -1.2738198\n#> Chem_100001397  0.5185327  0.29413098  1.3778912\n#>                    P101079    P101080    P101081    P101082\n#> Chem_100002945 -1.39766849 -0.2815374  1.2411439 -0.2174673\n#> Chem_100002356 -0.55203632 -0.6806099  1.0146353 -0.7200718\n#> Chem_100021502 -0.07166915  1.3499028 -1.3252140  0.3605258\n#> Chem_100008903 -0.01517937  1.7767796  0.2037930  1.1324356\n#> Chem_100000657  0.81689897 -0.5145400  0.1341008  1.8329001\n#> Chem_100001397  1.20709278  0.2676124  0.5800063  0.4461643\n#>                    P101084     P101085    P101088\n#> Chem_100002945 -0.46790569 -0.79956923  0.1802240\n#> Chem_100002356 -0.10759663  0.09177914  0.7628154\n#> Chem_100021502 -0.46472994 -1.02787918  0.2536728\n#> Chem_100008903 -0.57912087  0.80980413  0.8781108\n#> Chem_100000657  0.04971752  1.39120715  1.3696377\n#> Chem_100001397  0.33924205  0.07559725 -1.5551143\n#>                   P101090    P101094     P101095    P101096\n#> Chem_100002945 -0.6907198  0.4533621 -0.04305132  1.4483158\n#> Chem_100002356 -0.9084270  0.8247035 -0.30391871  1.1374565\n#> Chem_100021502  0.5441123 -0.6113564  3.12218010  0.8849878\n#> Chem_100008903  0.5074603 -0.1412276 -2.25574976 -0.9769806\n#> Chem_100000657  1.2559215 -0.1213712 -1.27251866 -0.7621895\n#> Chem_100001397  0.6738970 -0.6924755 -1.14889648 -0.7480860"},{"path":"dataprocessing.html","id":"数据分布变化","chapter":"9 Data Processing","heading":"9.9 数据分布变化","text":"函数来自于POMA包以样本为基点的代谢物数据分布情况（组间箱线图）以代谢物为基点的代谢物数据分布情况（组间箱线图）所有以代谢物为基点的数据分布结果：补缺失值没有改变数据分布状态，仍然是偏态分布补缺失值没有改变数据分布状态，仍然是偏态分布log10单个数据转换将偏态分布转成偏向正态分布，而在该基础上的相对丰度则由偏向了正态分布log10单个数据转换将偏态分布转成偏向正态分布，而在该基础上的相对丰度则由偏向了正态分布relative abundance在样本内部归一化其所有的特征，数据分布没有发生任何变化relative abundance在样本内部归一化其所有的特征，数据分布没有发生任何变化Zscore是跨样本针对特征归一化其，数据分布呈现标准正态分布Zscore是跨样本针对特征归一化其，数据分布呈现标准正态分布","code":"\nPOMABoxplots <- function(\n    data,\n    group,\n    feature_type = \"samples\",    \n    jitter = FALSE,\n    feature_name = NULL,\n    show_number = NULL,\n    label_size = 10,\n    legend_position = \"bottom\") {\n  \n  # data = se_impute\n  # group = \"LiverFatClass\"\n  # feature_type = \"samples\"\n  # jitter = FALSE\n  # feature_name = NULL\n  # show_number = 10\n  # label_size = 10\n  # legend_position = \"bottom\"\n  \n  if (missing(data)) {\n    stop(\"data argument is empty!\")\n  }\n  \n  if(!is(data, \"SummarizedExperiment\")){\n    stop(\"data is not a SummarizedExperiment object. \\nSee SummarizedExperiment::SummarizedExperiment\")\n  }\n  \n  if (!(feature_type %in% c(\"samples\", \"features\"))) {\n    stop(\"Incorrect value for group argument!\")\n  }\n  \n  if (!is.null(feature_name)) {\n    if(!any(feature_name %in% rownames(SummarizedExperiment::assay(data)))) {\n      stop(\"None of the specified features found\")\n    }\n    if(!all(feature_name %in% rownames(SummarizedExperiment::assay(data)))){\n      warning(paste0(\"Feature/s \",\n                     paste0(feature_name[!feature_name %in% rownames(SummarizedExperiment::assay(data))], collapse = \", \"),\n                     \" not found\"))\n    }\n  }\n  \n  \n  if(!(legend_position %in% c(\"none\", \"top\", \"bottom\", \"left\", \"right\"))) {\n    stop(\"Incorrect value for legend_position argument!\")\n  }\n  \n  e <- t(SummarizedExperiment::assay(data))\n  target <- SummarizedExperiment::colData(data) %>%\n    as.data.frame() %>% \n    tibble::rownames_to_column(\"ID\") %>%\n    dplyr::select(c(\"ID\", group))\n  colnames(target)[which(colnames(target) == group)] <- \"TempGroup\"\n  data <- cbind(target, e) %>%\n    dplyr::arrange(desc(ID))\n\n  if (feature_type == \"samples\") {\n    if (is.null(show_number)) {\n      plot_data <- data %>%\n        tidyr::pivot_longer(cols = -c(ID, TempGroup)) %>%\n        ggplot2::ggplot(ggplot2::aes(ID, value, color = TempGroup))      \n    } else {\n      selected_samples <- target$ID[1:show_number]\n      plot_data <- data %>%\n        tidyr::pivot_longer(cols = -c(ID, TempGroup)) %>%\n        dplyr::filter(ID %in% selected_samples) %>%\n        ggplot2::ggplot(ggplot2::aes(ID, value, color = TempGroup))       \n    }\n  } else {\n    if(all(is.null(feature_name), is.null(show_number))) {\n      plot_data <- data %>%\n        dplyr::select(-ID) %>%\n        tidyr::pivot_longer(cols = -TempGroup) %>%\n        ggplot2::ggplot(ggplot2::aes(name, value, color = TempGroup))\n      \n    } else if (all(!is.null(feature_name), is.null(show_number))) {\n      plot_data <- data %>%\n        dplyr::select(-ID) %>%\n        tidyr::pivot_longer(cols = -TempGroup) %>%\n        dplyr::filter(name %in% feature_name) %>%\n        ggplot2::ggplot(ggplot2::aes(name, value, color = TempGroup))\n    } else if (all(is.null(feature_name), !is.null(show_number))) {\n      selected_features <- colnames(e)[1:show_number]\n      plot_data <- data %>%\n        dplyr::select(-ID) %>%\n        tidyr::pivot_longer(cols = -TempGroup) %>%\n        dplyr::filter(name %in% selected_features) %>%\n        ggplot2::ggplot(ggplot2::aes(name, value, color = TempGroup))\n    } else if (all(!is.null(feature_name), !is.null(show_number))) {\n      plot_data <- data %>%\n        dplyr::select(-ID) %>%\n        tidyr::pivot_longer(cols = -TempGroup) %>%\n        dplyr::filter(name %in% feature_name) %>%\n        ggplot2::ggplot(ggplot2::aes(name, value, color = TempGroup))\n    }\n  }\n  \n  plot_complete <- plot_data +\n    ggplot2::geom_boxplot() +\n    {if(jitter)ggplot2::geom_jitter(alpha = 0.5, position = ggplot2::position_jitterdodge())} +\n    ggplot2::theme_bw() +\n    ggplot2::labs(x = \"\", \n                  y = \"Value\") +\n    ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, hjust = 1, size = label_size),\n                   legend.title = ggplot2::element_blank(),\n                   legend.position = legend_position) +\n    ggplot2::scale_colour_viridis_d(begin = 0, end = 0.8)\n  \n  return(plot_complete)\n}\n\n\nPOMADensity <- function(\n    data,\n    group,\n    feature_type = \"features\",    \n    feature_name = NULL,\n    show_number = NULL,\n    legend_position = \"bottom\") {\n  \n  # data = se_impute\n  # group = \"LiverFatClass\"\n  # feature_type = \"features\"\n  # feature_name = NULL\n  # show_number = 10\n  # legend_position = \"bottom\"\n\n  if (missing(data)) {\n    stop(\"data argument is empty!\")\n  }\n  \n  if(!is(data, \"SummarizedExperiment\")){\n    stop(\"data is not a SummarizedExperiment object. \\nSee SummarizedExperiment::SummarizedExperiment\")\n  }\n  \n  if (!(feature_type %in% c(\"samples\", \"features\"))) {\n    stop(\"Incorrect value for group argument!\")\n  }\n  \n  if (!is.null(feature_name)) {\n    if(!any(feature_name %in% rownames(SummarizedExperiment::assay(data)))) {\n      stop(\"None of the specified features found\")\n    }\n    if(!all(feature_name %in% rownames(SummarizedExperiment::assay(data)))){\n      warning(paste0(\"Feature/s \",\n                     paste0(feature_name[!feature_name %in% rownames(SummarizedExperiment::assay(data))], collapse = \", \"),\n                     \" not found\"))\n    }\n  }\n  \n  if(!(legend_position %in% c(\"none\", \"top\", \"bottom\", \"left\", \"right\"))) {\n    stop(\"Incorrect value for legend_position argument!\")\n  }\n  \n  e <- t(SummarizedExperiment::assay(data))\n  target <- SummarizedExperiment::colData(data) %>%\n    as.data.frame() %>% \n    tibble::rownames_to_column(\"ID\") %>%\n    dplyr::select(c(\"ID\", group))\n  colnames(target)[which(colnames(target) == group)] <- \"TempGroup\"\n  data <- cbind(target, e)\n  \n  if (feature_type == \"samples\") {\n    if (is.null(show_number)) {\n      plot_data <- data %>%\n        tidyr::pivot_longer(cols = -c(ID, TempGroup)) %>%\n        ggplot2::ggplot(ggplot2::aes(value, fill = TempGroup))      \n    } else {\n      selected_samples <- target$ID[1:show_number]      \n      plot_data <- data %>%\n        tidyr::pivot_longer(cols = -c(ID, TempGroup)) %>%\n        dplyr::filter(ID %in% selected_samples) %>%\n        ggplot2::ggplot(ggplot2::aes(value, fill = TempGroup))       \n    }\n  } else {\n    if(all(is.null(feature_name), is.null(show_number))) {\n      plot_data <- data %>%\n        dplyr::select(-ID) %>%\n        tidyr::pivot_longer(cols = -TempGroup) %>%\n        ggplot2::ggplot(ggplot2::aes(value, fill = TempGroup))\n      \n    } else if (all(!is.null(feature_name), is.null(show_number))) {\n      plot_data <- data %>%\n        dplyr::select(-ID) %>%\n        tidyr::pivot_longer(cols = -TempGroup) %>%\n        dplyr::filter(name %in% feature_name) %>%\n        ggplot2::ggplot(ggplot2::aes(value, fill = TempGroup))\n    } else if (all(is.null(feature_name), !is.null(show_number))) {\n      selected_features <- colnames(e)[1:show_number]      \n      plot_data <- data %>%\n        dplyr::select(-ID) %>%\n        tidyr::pivot_longer(cols = -TempGroup) %>%\n        dplyr::filter(name %in% selected_features) %>%\n        ggplot2::ggplot(ggplot2::aes(value, fill = TempGroup))\n    } else if (all(!is.null(feature_name), !is.null(show_number))) {\n      plot_data <- data %>%\n        dplyr::select(-ID) %>%\n        tidyr::pivot_longer(cols = -TempGroup) %>%\n        dplyr::filter(name %in% feature_name) %>%\n        ggplot2::ggplot(ggplot2::aes(value, fill = TempGroup))\n    }\n  }  \n  \n  plot_complete <- plot_data +\n    ggplot2::geom_density(alpha = 0.4) +\n    ggplot2::theme_bw() +\n    ggplot2::labs(x = \"Value\",\n                  y = \"Density\") +\n    ggplot2::theme(legend.title = ggplot2::element_blank(),\n                   legend.position = legend_position) +\n    ggplot2::scale_fill_viridis_d(begin = 0, end = 0.8)\n  \n  return(plot_complete)\n  \n}\n\n\nget_distribution <- function(\n    datset,\n    Type = c(\"raw\", \"check\", \"filter\", \n             \"impute\", \"norm_relative\", \"norm_log10\",\n             \"norm_scale\")) {\n  \n  # datset = se\n  # Type = \"raw\"\n  \n  dat <- SummarizedExperiment::assay(datset) %>% \n      data.frame() %>%\n      rownames_to_column(\"name\") %>%\n      tidyr::gather(key = \"sample\", value = \"value\", -name)    \n  \n  if (Type == \"raw\") {\n    pl <- ggplot(dat, aes(x = value)) + \n            geom_histogram(color = \"black\", fill = \"white\") +\n            labs(title = \"Distribution of Raw \\n Metabolites Intensity\", \n                 x = \"Raw Intensity\", y = \"Frequency\") +\n            theme_bw()    \n  } else if (Type == \"check\") {\n    pl <- ggplot(dat, aes(x = value)) + \n            geom_histogram(color = \"black\", fill = \"white\") +\n            labs(title = \"Distribution of check \\n Metabolites Intensity\", \n                 x = \"checked Intensity\", y = \"Frequency\") +\n            theme_bw()    \n  } else if (Type == \"filter\") {\n    pl <- ggplot(dat, aes(x = value)) + \n            geom_histogram(color = \"black\", fill = \"white\")+\n            labs(title = \"Distribution of filter\\n Metabolites Intensity\", \n                 x = \"filtered Intensity\", y = \"Frequency\")+\n            theme_bw()    \n  } else if (Type == \"impute\") {\n    pl <- ggplot(dat, aes(x = value)) + \n            geom_histogram(color = \"black\", fill = \"white\")+\n            labs(title = \"Distribution of impute\\n Metabolites Intensity\", \n                 x = \"imputed Intensity\", y = \"Frequency\")+\n            theme_bw()    \n  } else if (Type == \"norm_relative\") {\n    pl <- ggplot(dat, aes(x = value)) + \n            geom_histogram(color = \"black\", fill = \"white\")+\n            labs(title = \"Distribution of norm\\n Metabolites Intensity\", \n                 x = \"norm \\n relative abundance\", y=\"Frequency\")+\n            theme_bw()    \n  } else if (Type == \"norm_log10\") {\n    pl <- ggplot(dat, aes(x = value)) + \n            geom_histogram(color = \"black\", fill = \"white\")+\n            labs(title = \"Distribution of norm\\n Metabolites Intensity\", \n                 x = \"norm \\n log10(Intensity)\", y = \"Frequency\")+\n            theme_bw()    \n  } else if (Type == \"norm_scale\") {\n    pl <- ggplot(dat, aes(x = value)) + \n            geom_histogram(color = \"black\", fill = \"white\")+\n            labs(title = \"Distribution of norm\\n Metabolites Intensity\", \n                 x = \"norm \\n Scale(Intensity)\", y = \"Frequency\")+\n            theme_bw()    \n  }\n  \n  return(pl)\n}\npl_unnor <- POMABoxplots(data = se_impute, group = \"LiverFatClass\", \n                         feature_type = \"samples\", jitter = FALSE, show_number = 10) +\n  ggtitle(\"Not Normalized (imputation)\") +\n  theme(legend.position = \"none\") \n\npl_nor_log <- POMABoxplots(data = se_tran, group = \"LiverFatClass\", \n                          feature_type = \"samples\", jitter = FALSE, show_number = 10) +\n  ggtitle(\"Normalized (log10)\")\n\npl_nor_rb <- POMABoxplots(data = se_norm, group = \"LiverFatClass\", \n                          feature_type = \"samples\", jitter = FALSE, show_number = 10) +\n  ggtitle(\"Normalized (relative abundance)\")\n\npl_nor_zscore <- POMABoxplots(data = se_scale, group = \"LiverFatClass\", \n                          feature_type = \"samples\", jitter = FALSE, show_number = 10) +\n  ggtitle(\"Normalized (Zscore)\")\n\ncowplot::plot_grid(pl_unnor, pl_nor_log, \n                   pl_nor_rb, pl_nor_zscore, \n                   ncol = 1, align = \"v\",\n                   labels = LETTERS[1:4])\npl_unnor <- POMADensity(data = se_impute, group = \"LiverFatClass\", feature_type = \"features\") +\n  ggtitle(\"Not Normalized\") +\n  theme(legend.position = \"none\") # data before normalization\n\npl_nor_log <- POMADensity(data = se_tran, group = \"LiverFatClass\", feature_type = \"features\") +\n  ggtitle(\"Normalized (log10)\") # data after normalization\n\npl_nor_rb <- POMADensity(data = se_norm, group = \"LiverFatClass\", feature_type = \"features\") +\n  ggtitle(\"Normalized (relative abundance)\") # data after normalization\n\npl_nor_zscore <- POMADensity(data = se_scale, group = \"LiverFatClass\", feature_type = \"features\") +\n  ggtitle(\"Normalized (Zscore)\") # data after normalization\n\ncowplot::plot_grid(pl_unnor, pl_nor_log, \n                   pl_nor_rb, pl_nor_zscore, \n                   ncol = 1, align = \"v\",\n                   labels = LETTERS[1:4])\nraw_pl <- get_distribution(datset = data_meta_new, Type = \"raw\")\ncheck_pl <- get_distribution(datset = se_check, Type = \"check\")\nfilter_pl <- get_distribution(datset = se_filter, Type = \"filter\")\nimpute_pl <- get_distribution(datset = se_impute, Type = \"impute\")\nnorm_log10_pl <- get_distribution(datset = se_tran, Type = \"norm_log10\")\nnorm_relative_pl <- get_distribution(datset = se_norm, Type = \"norm_relative\")\nnorm_scale_pl <- get_distribution(datset = se_scale, Type = \"norm_scale\")\n\ncowplot::plot_grid(raw_pl, check_pl, \n                   filter_pl, impute_pl, \n                   norm_log10_pl, norm_relative_pl,\n                   norm_scale_pl,\n                   align = \"hv\", nrow = 2,\n                   labels = LETTERS[1:7])"},{"path":"dataprocessing.html","id":"保存数据-1","chapter":"9 Data Processing","heading":"9.10 保存数据","text":"","code":"\nif (!dir.exists(\"./InputData/result/QC\")) {\n  dir.create(\"./InputData/result/QC\", recursive = TRUE)\n}\n\nsaveRDS(data_meta_new, \"./InputData/result/QC/se_raw.RDS\", compress = TRUE)\nsaveRDS(se_check, \"./InputData/result/QC/se_check.RDS\", compress = TRUE)\nsaveRDS(se_impute, \"./InputData/result/QC/se_impute.RDS\", compress = TRUE)\nsaveRDS(se_filter, \"./InputData/result/QC/se_filter.RDS\", compress = TRUE)\n\nsaveRDS(se_tran, \"./InputData/result/QC/se_tran.RDS\", compress = TRUE)\nsaveRDS(se_norm, \"./InputData/result/QC/se_norm.RDS\", compress = TRUE)\nsaveRDS(se_scale, \"./InputData/result/QC/se_scale.RDS\", compress = TRUE)"},{"path":"dataprocessing.html","id":"总结-4","chapter":"9 Data Processing","heading":"9.11 总结","text":"数据预处理是代谢组分析较为重要的步骤，通常建议使用log+zscore的方法对数据归一化处理，用于后续的统计分析，但看到有关文章在计算Log2FoldChange的时候使用原始intensity值计算。","code":""},{"path":"dataprocessing.html","id":"session-info-1","chapter":"9 Data Processing","heading":"9.12 Session info","text":"","code":"\ndevtools::session_info()\n#> ─ Session info ───────────────────────────────────────────\n#>  setting  value\n#>  version  R version 4.1.3 (2022-03-10)\n#>  os       macOS Big Sur/Monterey 10.16\n#>  system   x86_64, darwin17.0\n#>  ui       X11\n#>  language (EN)\n#>  collate  en_US.UTF-8\n#>  ctype    en_US.UTF-8\n#>  tz       Asia/Shanghai\n#>  date     2024-02-06\n#>  pandoc   3.1.1 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/ (via rmarkdown)\n#> \n#> ─ Packages ───────────────────────────────────────────────\n#>  package                  * version    date (UTC) lib source\n#>  ade4                       1.7-22     2023-02-06 [1] CRAN (R 4.1.2)\n#>  ANCOMBC                    2.4.0      2023-10-26 [1] Bioconductor\n#>  annotate                   1.72.0     2021-10-26 [2] Bioconductor\n#>  AnnotationDbi              1.60.2     2023-03-10 [2] Bioconductor\n#>  ape                        5.7-1      2023-03-13 [1] CRAN (R 4.1.2)\n#>  backports                  1.4.1      2021-12-13 [2] CRAN (R 4.1.0)\n#>  base64enc                  0.1-3      2015-07-28 [2] CRAN (R 4.1.0)\n#>  beachmat                   2.10.0     2021-10-26 [2] Bioconductor\n#>  beeswarm                   0.4.0      2021-06-01 [2] CRAN (R 4.1.0)\n#>  Biobase                  * 2.54.0     2021-10-26 [2] Bioconductor\n#>  BiocGenerics             * 0.40.0     2021-10-26 [2] Bioconductor\n#>  BiocNeighbors              1.12.0     2021-10-26 [2] Bioconductor\n#>  BiocParallel               1.28.3     2021-12-09 [2] Bioconductor\n#>  BiocSingular               1.10.0     2021-10-26 [2] Bioconductor\n#>  biomformat                 1.22.0     2021-10-26 [2] Bioconductor\n#>  Biostrings                 2.62.0     2021-10-26 [2] Bioconductor\n#>  bit                        4.0.5      2022-11-15 [2] CRAN (R 4.1.2)\n#>  bit64                      4.0.5      2020-08-30 [2] CRAN (R 4.1.0)\n#>  bitops                     1.0-7      2021-04-24 [2] CRAN (R 4.1.0)\n#>  blob                       1.2.4      2023-03-17 [2] CRAN (R 4.1.2)\n#>  bluster                    1.4.0      2021-10-26 [2] Bioconductor\n#>  bookdown                   0.34       2023-05-09 [2] CRAN (R 4.1.2)\n#>  boot                       1.3-28.1   2022-11-22 [2] CRAN (R 4.1.2)\n#>  bslib                      0.6.0      2023-11-21 [1] CRAN (R 4.1.3)\n#>  cachem                     1.0.8      2023-05-01 [2] CRAN (R 4.1.2)\n#>  callr                      3.7.3      2022-11-02 [2] CRAN (R 4.1.2)\n#>  caTools                    1.18.2     2021-03-28 [2] CRAN (R 4.1.0)\n#>  cellranger                 1.1.0      2016-07-27 [2] CRAN (R 4.1.0)\n#>  checkmate                  2.2.0      2023-04-27 [2] CRAN (R 4.1.2)\n#>  class                      7.3-22     2023-05-03 [2] CRAN (R 4.1.2)\n#>  cli                        3.6.1      2023-03-23 [2] CRAN (R 4.1.2)\n#>  cluster                    2.1.4      2022-08-22 [2] CRAN (R 4.1.2)\n#>  codetools                  0.2-19     2023-02-01 [2] CRAN (R 4.1.2)\n#>  colorspace                 2.1-0      2023-01-23 [2] CRAN (R 4.1.2)\n#>  cowplot                    1.1.2      2023-12-15 [1] CRAN (R 4.1.3)\n#>  crayon                     1.5.2      2022-09-29 [2] CRAN (R 4.1.2)\n#>  CVXR                       1.0-12     2024-02-02 [1] CRAN (R 4.1.3)\n#>  data.table                 1.14.8     2023-02-17 [2] CRAN (R 4.1.2)\n#>  DBI                        1.1.3      2022-06-18 [2] CRAN (R 4.1.2)\n#>  DECIPHER                   2.22.0     2021-10-26 [2] Bioconductor\n#>  decontam                   1.14.0     2021-10-26 [2] Bioconductor\n#>  DelayedArray               0.20.0     2021-10-26 [2] Bioconductor\n#>  DelayedMatrixStats         1.16.0     2021-10-26 [2] Bioconductor\n#>  DescTools                  0.99.49    2023-05-17 [2] CRAN (R 4.1.3)\n#>  DESeq2                     1.34.0     2021-10-26 [2] Bioconductor\n#>  devtools                   2.4.5      2022-10-11 [2] CRAN (R 4.1.2)\n#>  digest                     0.6.33     2023-07-07 [1] CRAN (R 4.1.3)\n#>  DirichletMultinomial       1.36.0     2021-10-26 [2] Bioconductor\n#>  doParallel                 1.0.17     2022-02-07 [2] CRAN (R 4.1.2)\n#>  doRNG                      1.8.6      2023-01-16 [2] CRAN (R 4.1.2)\n#>  downlit                    0.4.3      2023-06-29 [2] CRAN (R 4.1.3)\n#>  dplyr                    * 1.1.4      2023-11-17 [1] CRAN (R 4.1.3)\n#>  e1071                      1.7-13     2023-02-01 [2] CRAN (R 4.1.2)\n#>  ellipsis                   0.3.2      2021-04-29 [2] CRAN (R 4.1.0)\n#>  energy                     1.7-11     2022-12-22 [1] CRAN (R 4.1.2)\n#>  evaluate                   0.21       2023-05-05 [2] CRAN (R 4.1.2)\n#>  Exact                      3.2        2022-09-25 [2] CRAN (R 4.1.2)\n#>  expm                       0.999-7    2023-01-09 [2] CRAN (R 4.1.2)\n#>  fansi                      1.0.4      2023-01-22 [2] CRAN (R 4.1.2)\n#>  farver                     2.1.1      2022-07-06 [2] CRAN (R 4.1.2)\n#>  fastmap                    1.1.1      2023-02-24 [2] CRAN (R 4.1.2)\n#>  forcats                  * 1.0.0      2023-01-29 [1] CRAN (R 4.1.2)\n#>  foreach                    1.5.2      2022-02-02 [2] CRAN (R 4.1.2)\n#>  foreign                    0.8-84     2022-12-06 [2] CRAN (R 4.1.2)\n#>  Formula                    1.2-5      2023-02-24 [2] CRAN (R 4.1.2)\n#>  fs                         1.6.2      2023-04-25 [2] CRAN (R 4.1.2)\n#>  genefilter                 1.76.0     2021-10-26 [2] Bioconductor\n#>  geneplotter                1.72.0     2021-10-26 [2] Bioconductor\n#>  generics                   0.1.3      2022-07-05 [2] CRAN (R 4.1.2)\n#>  GenomeInfoDb             * 1.30.1     2022-01-30 [2] Bioconductor\n#>  GenomeInfoDbData           1.2.7      2022-03-09 [2] Bioconductor\n#>  GenomicRanges            * 1.46.1     2021-11-18 [2] Bioconductor\n#>  ggbeeswarm                 0.7.2      2023-04-29 [1] CRAN (R 4.1.2)\n#>  ggplot2                  * 3.4.4      2023-10-12 [1] CRAN (R 4.1.3)\n#>  ggrepel                    0.9.3      2023-02-03 [1] CRAN (R 4.1.2)\n#>  gld                        2.6.6      2022-10-23 [2] CRAN (R 4.1.2)\n#>  glmnet                     4.1-7      2023-03-23 [2] CRAN (R 4.1.2)\n#>  glue                       1.6.2      2022-02-24 [2] CRAN (R 4.1.2)\n#>  gmp                        0.7-1      2023-02-07 [2] CRAN (R 4.1.2)\n#>  gplots                     3.1.3      2022-04-25 [2] CRAN (R 4.1.2)\n#>  gridExtra                  2.3        2017-09-09 [2] CRAN (R 4.1.0)\n#>  gsl                        2.1-8      2023-01-24 [2] CRAN (R 4.1.2)\n#>  gtable                     0.3.3      2023-03-21 [2] CRAN (R 4.1.2)\n#>  gtools                     3.9.4      2022-11-27 [2] CRAN (R 4.1.2)\n#>  highr                      0.10       2022-12-22 [2] CRAN (R 4.1.2)\n#>  Hmisc                      5.1-0      2023-05-08 [1] CRAN (R 4.1.2)\n#>  hms                        1.1.3      2023-03-21 [2] CRAN (R 4.1.2)\n#>  htmlTable                  2.4.1      2022-07-07 [2] CRAN (R 4.1.2)\n#>  htmltools                  0.5.7      2023-11-03 [1] CRAN (R 4.1.3)\n#>  htmlwidgets                1.6.2      2023-03-17 [2] CRAN (R 4.1.2)\n#>  httpuv                     1.6.11     2023-05-11 [2] CRAN (R 4.1.3)\n#>  httr                       1.4.6      2023-05-08 [2] CRAN (R 4.1.2)\n#>  igraph                     1.5.0      2023-06-16 [1] CRAN (R 4.1.3)\n#>  impute                     1.68.0     2021-10-26 [2] Bioconductor\n#>  IRanges                  * 2.28.0     2021-10-26 [2] Bioconductor\n#>  irlba                      2.3.5.1    2022-10-03 [2] CRAN (R 4.1.2)\n#>  iterators                  1.0.14     2022-02-05 [2] CRAN (R 4.1.2)\n#>  jquerylib                  0.1.4      2021-04-26 [2] CRAN (R 4.1.0)\n#>  jsonlite                   1.8.7      2023-06-29 [2] CRAN (R 4.1.3)\n#>  KEGGREST                   1.34.0     2021-10-26 [2] Bioconductor\n#>  KernSmooth                 2.23-22    2023-07-10 [2] CRAN (R 4.1.3)\n#>  knitr                      1.43       2023-05-25 [2] CRAN (R 4.1.3)\n#>  labeling                   0.4.2      2020-10-20 [2] CRAN (R 4.1.0)\n#>  later                      1.3.1      2023-05-02 [2] CRAN (R 4.1.2)\n#>  lattice                    0.21-8     2023-04-05 [2] CRAN (R 4.1.2)\n#>  lazyeval                   0.2.2      2019-03-15 [2] CRAN (R 4.1.0)\n#>  lifecycle                  1.0.3      2022-10-07 [2] CRAN (R 4.1.2)\n#>  limma                      3.50.3     2022-04-07 [2] Bioconductor\n#>  lme4                       1.1-34     2023-07-04 [1] CRAN (R 4.1.3)\n#>  lmerTest                   3.1-3      2020-10-23 [1] CRAN (R 4.1.0)\n#>  lmom                       2.9        2022-05-29 [2] CRAN (R 4.1.2)\n#>  locfit                     1.5-9.8    2023-06-11 [2] CRAN (R 4.1.3)\n#>  lubridate                * 1.9.2      2023-02-10 [2] CRAN (R 4.1.2)\n#>  magrittr                   2.0.3      2022-03-30 [2] CRAN (R 4.1.2)\n#>  MASS                       7.3-60     2023-05-04 [1] CRAN (R 4.1.2)\n#>  Matrix                     1.6-5      2024-01-11 [1] CRAN (R 4.1.3)\n#>  MatrixGenerics           * 1.6.0      2021-10-26 [2] Bioconductor\n#>  matrixStats              * 1.1.0      2023-11-07 [1] CRAN (R 4.1.3)\n#>  memoise                    2.0.1      2021-11-26 [2] CRAN (R 4.1.0)\n#>  metagenomeSeq              1.36.0     2021-10-26 [2] Bioconductor\n#>  mgcv                       1.8-42     2023-03-02 [2] CRAN (R 4.1.2)\n#>  mia                        1.10.0     2023-10-24 [1] Bioconductor\n#>  MicrobiomeAnalysis       * 1.0.3      2023-12-02 [1] Bioconductor\n#>  mime                       0.12       2021-09-28 [2] CRAN (R 4.1.0)\n#>  miniUI                     0.1.1.1    2018-05-18 [2] CRAN (R 4.1.0)\n#>  minqa                      1.2.5      2022-10-19 [2] CRAN (R 4.1.2)\n#>  multcomp                   1.4-25     2023-06-20 [2] CRAN (R 4.1.3)\n#>  MultiAssayExperiment       1.20.0     2021-10-26 [2] Bioconductor\n#>  multtest                   2.50.0     2021-10-26 [2] Bioconductor\n#>  munsell                    0.5.0      2018-06-12 [2] CRAN (R 4.1.0)\n#>  mvtnorm                    1.2-2      2023-06-08 [2] CRAN (R 4.1.3)\n#>  nlme                       3.1-162    2023-01-31 [1] CRAN (R 4.1.2)\n#>  nloptr                     2.0.3      2022-05-26 [2] CRAN (R 4.1.2)\n#>  nnet                       7.3-19     2023-05-03 [2] CRAN (R 4.1.2)\n#>  numDeriv                   2016.8-1.1 2019-06-06 [2] CRAN (R 4.1.0)\n#>  permute                    0.9-7      2022-01-27 [2] CRAN (R 4.1.2)\n#>  phyloseq                   1.38.0     2021-10-26 [2] Bioconductor\n#>  pillar                     1.9.0      2023-03-22 [2] CRAN (R 4.1.2)\n#>  pkgbuild                   1.4.2      2023-06-26 [2] CRAN (R 4.1.3)\n#>  pkgconfig                  2.0.3      2019-09-22 [2] CRAN (R 4.1.0)\n#>  pkgload                    1.3.2.1    2023-07-08 [2] CRAN (R 4.1.3)\n#>  plyr                       1.8.8      2022-11-11 [1] CRAN (R 4.1.2)\n#>  png                        0.1-8      2022-11-29 [2] CRAN (R 4.1.2)\n#>  prettyunits                1.1.1      2020-01-24 [2] CRAN (R 4.1.0)\n#>  processx                   3.8.2      2023-06-30 [2] CRAN (R 4.1.3)\n#>  profvis                    0.3.8      2023-05-02 [2] CRAN (R 4.1.2)\n#>  promises                   1.2.0.1    2021-02-11 [2] CRAN (R 4.1.0)\n#>  proxy                      0.4-27     2022-06-09 [2] CRAN (R 4.1.2)\n#>  ps                         1.7.5      2023-04-18 [2] CRAN (R 4.1.2)\n#>  purrr                    * 1.0.1      2023-01-10 [1] CRAN (R 4.1.2)\n#>  R6                         2.5.1      2021-08-19 [2] CRAN (R 4.1.0)\n#>  rbibutils                  2.2.13     2023-01-13 [2] CRAN (R 4.1.2)\n#>  RColorBrewer               1.1-3      2022-04-03 [1] CRAN (R 4.1.2)\n#>  Rcpp                       1.0.11     2023-07-06 [1] CRAN (R 4.1.3)\n#>  RCurl                      1.98-1.12  2023-03-27 [2] CRAN (R 4.1.2)\n#>  Rdpack                     2.4        2022-07-20 [2] CRAN (R 4.1.2)\n#>  readr                    * 2.1.4      2023-02-10 [1] CRAN (R 4.1.2)\n#>  readxl                     1.4.3      2023-07-06 [2] CRAN (R 4.1.3)\n#>  remotes                    2.4.2      2021-11-30 [2] CRAN (R 4.1.0)\n#>  reshape2                   1.4.4      2020-04-09 [2] CRAN (R 4.1.0)\n#>  rhdf5                      2.38.1     2022-03-10 [2] Bioconductor\n#>  rhdf5filters               1.6.0      2021-10-26 [2] Bioconductor\n#>  Rhdf5lib                   1.16.0     2021-10-26 [2] Bioconductor\n#>  rlang                      1.1.1      2023-04-28 [1] CRAN (R 4.1.2)\n#>  rmarkdown                  2.23       2023-07-01 [2] CRAN (R 4.1.3)\n#>  Rmpfr                      0.9-2      2023-04-22 [2] CRAN (R 4.1.2)\n#>  rngtools                   1.5.2      2021-09-20 [2] CRAN (R 4.1.0)\n#>  rootSolve                  1.8.2.3    2021-09-29 [2] CRAN (R 4.1.0)\n#>  rpart                      4.1.19     2022-10-21 [2] CRAN (R 4.1.2)\n#>  RSQLite                    2.3.1      2023-04-03 [2] CRAN (R 4.1.2)\n#>  rstudioapi                 0.15.0     2023-07-07 [2] CRAN (R 4.1.3)\n#>  rsvd                       1.0.5      2021-04-16 [2] CRAN (R 4.1.0)\n#>  S4Vectors                * 0.32.4     2022-03-29 [2] Bioconductor\n#>  sandwich                   3.0-2      2022-06-15 [2] CRAN (R 4.1.2)\n#>  sass                       0.4.6      2023-05-03 [2] CRAN (R 4.1.2)\n#>  ScaledMatrix               1.2.0      2021-10-26 [2] Bioconductor\n#>  scales                     1.2.1      2022-08-20 [1] CRAN (R 4.1.2)\n#>  scater                     1.22.0     2021-10-26 [2] Bioconductor\n#>  scuttle                    1.4.0      2021-10-26 [2] Bioconductor\n#>  sessioninfo                1.2.2      2021-12-06 [2] CRAN (R 4.1.0)\n#>  shape                      1.4.6      2021-05-19 [2] CRAN (R 4.1.0)\n#>  shiny                      1.7.4.1    2023-07-06 [2] CRAN (R 4.1.3)\n#>  SingleCellExperiment       1.16.0     2021-10-26 [2] Bioconductor\n#>  sparseMatrixStats          1.6.0      2021-10-26 [2] Bioconductor\n#>  stringi                    1.7.12     2023-01-11 [2] CRAN (R 4.1.2)\n#>  stringr                  * 1.5.1      2023-11-14 [1] CRAN (R 4.1.3)\n#>  SummarizedExperiment     * 1.24.0     2021-10-26 [2] Bioconductor\n#>  survival                   3.5-5      2023-03-12 [2] CRAN (R 4.1.2)\n#>  TH.data                    1.1-2      2023-04-17 [2] CRAN (R 4.1.2)\n#>  tibble                   * 3.2.1      2023-03-20 [1] CRAN (R 4.1.2)\n#>  tidyr                    * 1.3.0      2023-01-24 [1] CRAN (R 4.1.2)\n#>  tidyselect                 1.2.0      2022-10-10 [2] CRAN (R 4.1.2)\n#>  tidytree                   0.4.2      2022-12-18 [2] CRAN (R 4.1.2)\n#>  tidyverse                * 2.0.0      2023-02-22 [1] CRAN (R 4.1.2)\n#>  timechange                 0.2.0      2023-01-11 [2] CRAN (R 4.1.2)\n#>  treeio                     1.18.1     2021-11-14 [2] Bioconductor\n#>  TreeSummarizedExperiment   2.2.0      2021-10-26 [2] Bioconductor\n#>  tzdb                       0.4.0      2023-05-12 [2] CRAN (R 4.1.3)\n#>  urlchecker                 1.0.1      2021-11-30 [2] CRAN (R 4.1.0)\n#>  usethis                    2.2.2      2023-07-06 [2] CRAN (R 4.1.3)\n#>  utf8                       1.2.3      2023-01-31 [2] CRAN (R 4.1.2)\n#>  vctrs                      0.6.5      2023-12-01 [1] CRAN (R 4.1.3)\n#>  vegan                      2.6-4      2022-10-11 [1] CRAN (R 4.1.2)\n#>  vipor                      0.4.5      2017-03-22 [2] CRAN (R 4.1.0)\n#>  viridis                    0.6.3      2023-05-03 [2] CRAN (R 4.1.2)\n#>  viridisLite                0.4.2      2023-05-02 [2] CRAN (R 4.1.2)\n#>  withr                      2.5.0      2022-03-03 [2] CRAN (R 4.1.2)\n#>  Wrench                     1.12.0     2021-10-26 [2] Bioconductor\n#>  xfun                       0.40       2023-08-09 [1] CRAN (R 4.1.3)\n#>  XML                        3.99-0.14  2023-03-19 [2] CRAN (R 4.1.2)\n#>  xml2                       1.3.5      2023-07-06 [2] CRAN (R 4.1.3)\n#>  xtable                     1.8-4      2019-04-21 [2] CRAN (R 4.1.0)\n#>  XVector                    0.34.0     2021-10-26 [2] Bioconductor\n#>  yaml                       2.3.7      2023-01-23 [2] CRAN (R 4.1.2)\n#>  yulab.utils                0.0.6      2022-12-20 [2] CRAN (R 4.1.2)\n#>  zlibbioc                   1.40.0     2021-10-26 [2] Bioconductor\n#>  zoo                        1.8-12     2023-04-13 [2] CRAN (R 4.1.2)\n#> \n#>  [1] /Users/zouhua/Library/R/x86_64/4.1/library\n#>  [2] /Library/Frameworks/R.framework/Versions/4.1/Resources/library\n#> \n#> ──────────────────────────────────────────────────────────"},{"path":"dataprocessing.html","id":"reference-7","chapter":"9 Data Processing","heading":"9.13 Reference","text":"","code":""},{"path":"DimensionReduction.html","id":"DimensionReduction","chapter":"10 Dimension Reduction","heading":"10 Dimension Reduction","text":"降维分析是为了查看样本的差异或挖掘潜在标志物。方法有以下三种：主成分分析（PCA）主成分分析PCA（Principal Component Analysis）是一种常用的数据分析方法。PCA通过线性变换将原始数据变换为一组各维度线性无关的表示，可用于提取数据的主要特征分量，常用于高维数据的降维。偏最小二乘回归分析法（PLS-DA）偏最小二乘判别分析（PLS-DA）是一种有监督模式识别的多元统计分析方法，将多维数据在压缩前先按需要寻找的差异因素分组。正交偏最小二乘判别分析（OPLS-DA）正交偏最小二乘判别分析（OPLS-DA）结合了正交信号矫正（OSC）和PLS-DA方法，能够将X矩阵信息分解成与Y相关和不相关的两类信息，通过去除不相关的差异来筛选差异变量。","code":""},{"path":"DimensionReduction.html","id":"加载r包-6","chapter":"10 Dimension Reduction","heading":"10.1 加载R包","text":"","code":"\nknitr::opts_chunk$set(message = FALSE, warning = FALSE)\nlibrary(tidyverse)\nlibrary(ropls)\nlibrary(SummarizedExperiment)\nlibrary(MicrobiomeAnalysis)\n\n# rm(list = ls())\noptions(stringsAsFactors = F)\noptions(future.globals.maxSize = 1000 * 1024^2)\n\ngrp_names <- c(\"None\", \"Mild\", \"Moderate\", \"Severe\")\ngrp_colors <- c(\"#7DD06F\", \"#844081\", \"#688EC1\", \"#C17E73\")"},{"path":"DimensionReduction.html","id":"导入数据-4","chapter":"10 Dimension Reduction","heading":"10.2 导入数据","text":"对数据OmicsDataSet-Zeybel et al. - 2022.xlsx处理后生成的，可参考数据预处理章节。","code":"\nsaveRDS(se_scale, \"./InputData/result/QC/se_scale.RDS\", compress = TRUE)\ndata_meta <- readRDS(\"./InputData/result/QC/se_scale.RDS\")"},{"path":"DimensionReduction.html","id":"函数-1","chapter":"10 Dimension Reduction","heading":"10.3 函数","text":"","code":"\nDR_fun <- function(\n    x,\n    group,\n    group_names,\n    group_colors,\n    DRtype = c(\"PCA\", \"PLS\", \"OPLS\"),\n    occ_cutoff = 0.5) {\n  \n  # x = data_meta\n  # group = \"LiverFatClass\"\n  # group_names = grp_names\n  # group_colors = grp_colors\n  # DRtype = \"PLS\" # PCA\n  # occ_cutoff = 0.5\n  \n  # dataseat\n  metadata <- SummarizedExperiment::colData(x) %>%\n      as.data.frame()\n  profile <- SummarizedExperiment::assay(x) %>%\n      as.data.frame()\n\n  colnames(metadata)[which(colnames(metadata) == group)] <- \"CompVar\"\n  phenotype <- metadata %>%\n    dplyr::filter(CompVar %in% group_names) %>%\n    dplyr::mutate(CompVar = as.character(CompVar)) %>%\n    dplyr::mutate(CompVar = factor(CompVar, levels = group_names))\n  \n  sid <- intersect(rownames(phenotype), colnames(profile))\n  phen <- phenotype[pmatch(sid, rownames(phenotype)), , ]\n  prof <- profile %>%\n    dplyr::select(all_of(sid))\n  \n  if (!all(colnames(prof) == rownames(phen))) {\n    stop(\"Wrong Order\")\n  }\n  \n  trim_FeatureOrSample <- function(x, nRow, threshold) {\n  \n    df_occ <- apply(x, nRow, function(x) {\n      length(x[c(which(!is.na(x) & x!=0))]) / length(x)\n    }) %>%\n      data.frame() %>% stats::setNames(\"Occ\") %>%\n      tibble::rownames_to_column(\"type\")\n    if(nRow == 1){\n      rownames(df_occ) <- rownames(x)\n    }else{\n      rownames(df_occ) <- colnames(x)\n    }\n    df_KEEP <- apply(df_occ > threshold, 1, all) %>%\n      data.frame() %>% stats::setNames(\"Status\") %>%\n      dplyr::filter(Status)\n  \n    res <- x %>%\n      tibble::rownames_to_column(\"featureid\") %>%\n      dplyr::filter(featureid %in% rownames(df_KEEP)) %>%\n      tibble::column_to_rownames(\"featureid\")\n    \n    return(res)\n  }\n\n  prof_cln <- trim_FeatureOrSample(prof, 1, occ_cutoff)\n  dataMatrix <- prof_cln %>% t() # row->sampleID; col->features\n  sampleMetadata <- phen %>% # row->sampleID; col->features\n    dplyr::mutate(CompVar = factor(CompVar, levels = group_names)) %>%\n    dplyr::mutate(Color = factor(CompVar, \n                                  levels = group_names,\n                                  labels = group_colors),\n                  Color = as.character(Color))    \n  \n  if (DRtype == \"PCA\") {\n    fit <- opls(dataMatrix)\n    plot(fit,\n         typeVc = \"x-score\",\n         parAsColFcVn = sampleMetadata$CompVar,\n         )\n  } else if (DRtype == \"PLS\") {\n    fit <- opls(dataMatrix, sampleMetadata$CompVar, predI = 2)\n    plot(fit,\n         typeVc = \"x-score\",\n         parAsColFcVn = sampleMetadata$CompVar,\n         )\n  } else if (DRtype == \"OPLS\") {\n    # only for binary classification\n    fit <- opls(dataMatrix, sampleMetadata$CompVar, predI = 1, orthoI = NA)\n    plot(fit,\n         typeVc = \"x-score\",\n         parAsColFcVn = sampleMetadata$CompVar,\n         )\n  }\n\n  return(fit)\n}"},{"path":"DimensionReduction.html","id":"主成分分析pca","chapter":"10 Dimension Reduction","heading":"10.4 主成分分析（PCA）","text":"结果：PCA将原始features重新组合成新的主成分，进而形成了基于主成分的矩阵。每个主成分是由原来features的线性组合而成。左上图: 碎石图展示不同主成分的可解释度，也即是代表全体的features，评估主成分是否足够左上图: 碎石图展示不同主成分的可解释度，也即是代表全体的features，评估主成分是否足够右上图: 离群点图，它展示的各样本在投影平面和投影平面正交的距离，数值较高样本表明它们与其他样本间的差异较大右上图: 离群点图，它展示的各样本在投影平面和投影平面正交的距离，数值较高样本表明它们与其他样本间的差异较大左下图：每个样本的主成分得分（可简单理解为系数，此处只展示第一和第二主成分），该数值表示主成分能解释多少features: 该数值由features矩阵分解得到。各个样本在PC1和PC2轴的排序坐标差异，通过它们可评估样本在组成上的差异。左下图：每个样本的主成分得分（可简单理解为系数，此处只展示第一和第二主成分），该数值表示主成分能解释多少features: 该数值由features矩阵分解得到。各个样本在PC1和PC2轴的排序坐标差异，通过它们可评估样本在组成上的差异。右下图：载荷值: 理解为构成每个主成分的features，可以认为一个主成分是由N个feature线性组合合成，每个features对该主成分的贡献程度作为loading的数值。边缘处的变量表示它们在各样本中的含量差别明显（如在某些样本中具有较大/较小的极端值等），即对排序空间的贡献较大，暗示它们可能为一些重要的代谢物。右下图：载荷值: 理解为构成每个主成分的features，可以认为一个主成分是由N个feature线性组合合成，每个features对该主成分的贡献程度作为loading的数值。边缘处的变量表示它们在各样本中的含量差别明显（如在某些样本中具有较大/较小的极端值等），即对排序空间的贡献较大，暗示它们可能为一些重要的代谢物。","code":"\nPCA_res <- DR_fun(\n    x = data_meta,\n    group = \"LiverFatClass\",\n    group_names = grp_names,\n    group_colors = grp_colors,    \n    DRtype = \"PCA\",\n    occ_cutoff = 0.5)\n#> PCA\n#> 55 samples x 646 variables\n#> standard scaling of predictors\n#>       R2X(cum) pre ort\n#> Total     0.52  10   0"},{"path":"DimensionReduction.html","id":"偏最小二乘回归分析法pls-da","chapter":"10 Dimension Reduction","heading":"10.5 偏最小二乘回归分析法（PLS-DA）","text":"PLS-DA需要提供Y响应变量，它通过投影分别将预测变量（Y响应变量）和观测变量（自变量）投影到一个新空间，来寻找一个线性回归模型。通过建立组学数据与样本类别之间的关系模型，实现对样本类别的预测，为有监督的建模方式。偏最小二乘（PLS）是一种基于预测变量和响应变量之间协方差的潜在变量回归方法，找到不同类别的分割信息最优的线性组合，PLS的每一个成分都赋予一个权值，即对应该成分的分离能力。结果：R2X和R2Y分别表示所建模型对X和Y矩阵的解释率，Q2标示模型的预测能力，它们的值越接近于1表明模型的拟合度越好，训练集的样本越能够被准确划分到其原始归属中。左上图: 展示了2个正交轴的R2Y和Q2Y左上图: 展示了2个正交轴的R2Y和Q2Y右上图: PLS-DA模型的R2Y和Q2Y与随机置换数据后获得的相应值进行比较右上图: PLS-DA模型的R2Y和Q2Y与随机置换数据后获得的相应值进行比较左下图：展示了各样本在投影平面内以及正交投影面的距离，具有高值的样本标注出名称，表明它们与其它样本间的差异较大。颜色代表性别分组。左下图：展示了各样本在投影平面内以及正交投影面的距离，具有高值的样本标注出名称，表明它们与其它样本间的差异较大。颜色代表性别分组。右下图：各样本在PLS-DA轴中的坐标，颜色代表不同分组。我们可以看到，相对于上文的PCA（仅通过方差特征值分解），PLS-DA在区分组间差异时更有效（带监督的偏最小二乘判别分析）。图的下方还提供了R2X、R2Y等值，用于评估模型优度。右下图：各样本在PLS-DA轴中的坐标，颜色代表不同分组。我们可以看到，相对于上文的PCA（仅通过方差特征值分解），PLS-DA在区分组间差异时更有效（带监督的偏最小二乘判别分析）。图的下方还提供了R2X、R2Y等值，用于评估模型优度。此外，还可通过变量投影重要度（Variable Importance Projection，VIP）衡量各代谢物组分含量对样本分类判别的影响强度和解释能力，辅助标志代谢物的筛选。通常以VIP > 1作为筛选标准。","code":"\nPLS_res <- DR_fun(\n    x = data_meta,\n    group = \"LiverFatClass\",\n    group_names = grp_names,\n    group_colors = grp_colors,    \n    DRtype = \"PLS\",\n    occ_cutoff = 0.5)\n#> PLS-DA\n#> 55 samples x 646 variables and 1 response\n#> standard scaling of predictors and response(s)\n#>       R2X(cum) R2Y(cum) Q2(cum) RMSEE pre ort pR2Y pQ2\n#> Total    0.118    0.384  -0.195 0.348   2   0 0.05 0.5\nvip_values <- getVipVn(PLS_res)\n\nvip_select <- vip_values[vip_values > 1]\n\nhead(vip_select)\n#> Chem_100002356 Chem_100009014 Chem_100009009 Chem_100009007 \n#>       1.182314       1.205334       1.900846       1.412153 \n#> Chem_100009160 Chem_100001654 \n#>       1.240287       1.348693"},{"path":"DimensionReduction.html","id":"正交偏最小二乘判别分析opls-da","chapter":"10 Dimension Reduction","heading":"10.6 正交偏最小二乘判别分析（OPLS-DA）","text":"PLS-DA容易出现过拟合（overfitting）问题。所谓过拟合，即通过训练集建立了一个预测模型，它在训练集上表现出色，但通过测试集测试时却表现不佳。过拟合是机器学习中的一个常见问题，主要出现在具有比样本数量更多的变量数量的数据集的分析中。主要是因为PLS-DA是有监督的预测模型且偏向训练数据。相比PLS-DA，叠加了正交分解的OPLS-DA能更好地避免过拟合现象，这是因为它会通过将与X和Y正交的变量删除，避免不差异的变量影响结果。OPLS从给定的自变量数据集中移除正交变量，并把这些正交变量和非正交变量区分开来。然后再对非正交变量做偏最小二乘法获得载荷矩阵也即是在Y情况下的最大方差。None vs Severe结果和PLS-DA一致。左上图: 展示了2个正交轴的R2Y和Q2Y左上图: 展示了2个正交轴的R2Y和Q2Y右上图: PLS-DA模型的R2Y和Q2Y与随机置换数据后获得的相应值进行比较右上图: PLS-DA模型的R2Y和Q2Y与随机置换数据后获得的相应值进行比较左下图：展示了各样本在投影平面内以及正交投影面的距离，具有高值的样本标注出名称，表明它们与其它样本间的差异较大。颜色代表性别分组。左下图：展示了各样本在投影平面内以及正交投影面的距离，具有高值的样本标注出名称，表明它们与其它样本间的差异较大。颜色代表性别分组。右下图：各样本在PLS-DA轴中的坐标，颜色代表不同分组。我们可以看到，相对于上文的PCA（仅通过方差特征值分解），PLS-DA在区分组间差异时更有效（带监督的偏最小二乘判别分析）。图的下方还提供了R2X、R2Y等值，用于评估模型优度。右下图：各样本在PLS-DA轴中的坐标，颜色代表不同分组。我们可以看到，相对于上文的PCA（仅通过方差特征值分解），PLS-DA在区分组间差异时更有效（带监督的偏最小二乘判别分析）。图的下方还提供了R2X、R2Y等值，用于评估模型优度。","code":"\nDR_fun(\n    x = data_meta,\n    group = \"LiverFatClass\",\n    group_names = grp_names[c(1, 4)],\n    group_colors = grp_colors[c(1, 4)],\n    DRtype = \"OPLS\",\n    occ_cutoff = 0.5)\n#> OPLS-DA\n#> 22 samples x 646 variables and 1 response\n#> standard scaling of predictors and response(s)\n#>       R2X(cum) R2Y(cum) Q2(cum)  RMSEE pre ort pR2Y  pQ2\n#> Total    0.247    0.986   0.635 0.0663   1   2 0.95 0.05#> OPLS-DA\n#> 22 samples x 646 variables and 1 response\n#> standard scaling of predictors and response(s)\n#>       R2X(cum) R2Y(cum) Q2(cum)  RMSEE pre ort pR2Y  pQ2\n#> Total    0.247    0.986   0.635 0.0663   1   2 0.95 0.05"},{"path":"DimensionReduction.html","id":"session-info-2","chapter":"10 Dimension Reduction","heading":"10.7 Session info","text":"","code":"\ndevtools::session_info()\n#> ─ Session info ───────────────────────────────────────────\n#>  setting  value\n#>  version  R version 4.1.3 (2022-03-10)\n#>  os       macOS Big Sur/Monterey 10.16\n#>  system   x86_64, darwin17.0\n#>  ui       X11\n#>  language (EN)\n#>  collate  en_US.UTF-8\n#>  ctype    en_US.UTF-8\n#>  tz       Asia/Shanghai\n#>  date     2024-02-06\n#>  pandoc   3.1.1 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/ (via rmarkdown)\n#> \n#> ─ Packages ───────────────────────────────────────────────\n#>  package                  * version    date (UTC) lib source\n#>  ade4                       1.7-22     2023-02-06 [1] CRAN (R 4.1.2)\n#>  ANCOMBC                    2.4.0      2023-10-26 [1] Bioconductor\n#>  annotate                   1.72.0     2021-10-26 [2] Bioconductor\n#>  AnnotationDbi              1.60.2     2023-03-10 [2] Bioconductor\n#>  ape                        5.7-1      2023-03-13 [1] CRAN (R 4.1.2)\n#>  backports                  1.4.1      2021-12-13 [2] CRAN (R 4.1.0)\n#>  base64enc                  0.1-3      2015-07-28 [2] CRAN (R 4.1.0)\n#>  beachmat                   2.10.0     2021-10-26 [2] Bioconductor\n#>  beeswarm                   0.4.0      2021-06-01 [2] CRAN (R 4.1.0)\n#>  Biobase                  * 2.54.0     2021-10-26 [2] Bioconductor\n#>  BiocGenerics             * 0.40.0     2021-10-26 [2] Bioconductor\n#>  BiocNeighbors              1.12.0     2021-10-26 [2] Bioconductor\n#>  BiocParallel               1.28.3     2021-12-09 [2] Bioconductor\n#>  BiocSingular               1.10.0     2021-10-26 [2] Bioconductor\n#>  biomformat                 1.22.0     2021-10-26 [2] Bioconductor\n#>  Biostrings                 2.62.0     2021-10-26 [2] Bioconductor\n#>  bit                        4.0.5      2022-11-15 [2] CRAN (R 4.1.2)\n#>  bit64                      4.0.5      2020-08-30 [2] CRAN (R 4.1.0)\n#>  bitops                     1.0-7      2021-04-24 [2] CRAN (R 4.1.0)\n#>  blob                       1.2.4      2023-03-17 [2] CRAN (R 4.1.2)\n#>  bluster                    1.4.0      2021-10-26 [2] Bioconductor\n#>  bookdown                   0.34       2023-05-09 [2] CRAN (R 4.1.2)\n#>  boot                       1.3-28.1   2022-11-22 [2] CRAN (R 4.1.2)\n#>  bslib                      0.6.0      2023-11-21 [1] CRAN (R 4.1.3)\n#>  cachem                     1.0.8      2023-05-01 [2] CRAN (R 4.1.2)\n#>  callr                      3.7.3      2022-11-02 [2] CRAN (R 4.1.2)\n#>  caTools                    1.18.2     2021-03-28 [2] CRAN (R 4.1.0)\n#>  cellranger                 1.1.0      2016-07-27 [2] CRAN (R 4.1.0)\n#>  checkmate                  2.2.0      2023-04-27 [2] CRAN (R 4.1.2)\n#>  class                      7.3-22     2023-05-03 [2] CRAN (R 4.1.2)\n#>  cli                        3.6.1      2023-03-23 [2] CRAN (R 4.1.2)\n#>  cluster                    2.1.4      2022-08-22 [2] CRAN (R 4.1.2)\n#>  codetools                  0.2-19     2023-02-01 [2] CRAN (R 4.1.2)\n#>  colorspace                 2.1-0      2023-01-23 [2] CRAN (R 4.1.2)\n#>  crayon                     1.5.2      2022-09-29 [2] CRAN (R 4.1.2)\n#>  CVXR                       1.0-12     2024-02-02 [1] CRAN (R 4.1.3)\n#>  data.table                 1.14.8     2023-02-17 [2] CRAN (R 4.1.2)\n#>  DBI                        1.1.3      2022-06-18 [2] CRAN (R 4.1.2)\n#>  DECIPHER                   2.22.0     2021-10-26 [2] Bioconductor\n#>  decontam                   1.14.0     2021-10-26 [2] Bioconductor\n#>  DelayedArray               0.20.0     2021-10-26 [2] Bioconductor\n#>  DelayedMatrixStats         1.16.0     2021-10-26 [2] Bioconductor\n#>  DescTools                  0.99.49    2023-05-17 [2] CRAN (R 4.1.3)\n#>  DESeq2                     1.34.0     2021-10-26 [2] Bioconductor\n#>  devtools                   2.4.5      2022-10-11 [2] CRAN (R 4.1.2)\n#>  digest                     0.6.33     2023-07-07 [1] CRAN (R 4.1.3)\n#>  DirichletMultinomial       1.36.0     2021-10-26 [2] Bioconductor\n#>  doParallel                 1.0.17     2022-02-07 [2] CRAN (R 4.1.2)\n#>  doRNG                      1.8.6      2023-01-16 [2] CRAN (R 4.1.2)\n#>  downlit                    0.4.3      2023-06-29 [2] CRAN (R 4.1.3)\n#>  dplyr                    * 1.1.4      2023-11-17 [1] CRAN (R 4.1.3)\n#>  e1071                      1.7-13     2023-02-01 [2] CRAN (R 4.1.2)\n#>  ellipsis                   0.3.2      2021-04-29 [2] CRAN (R 4.1.0)\n#>  energy                     1.7-11     2022-12-22 [1] CRAN (R 4.1.2)\n#>  evaluate                   0.21       2023-05-05 [2] CRAN (R 4.1.2)\n#>  Exact                      3.2        2022-09-25 [2] CRAN (R 4.1.2)\n#>  expm                       0.999-7    2023-01-09 [2] CRAN (R 4.1.2)\n#>  fansi                      1.0.4      2023-01-22 [2] CRAN (R 4.1.2)\n#>  fastmap                    1.1.1      2023-02-24 [2] CRAN (R 4.1.2)\n#>  forcats                  * 1.0.0      2023-01-29 [1] CRAN (R 4.1.2)\n#>  foreach                    1.5.2      2022-02-02 [2] CRAN (R 4.1.2)\n#>  foreign                    0.8-84     2022-12-06 [2] CRAN (R 4.1.2)\n#>  Formula                    1.2-5      2023-02-24 [2] CRAN (R 4.1.2)\n#>  fs                         1.6.2      2023-04-25 [2] CRAN (R 4.1.2)\n#>  genefilter                 1.76.0     2021-10-26 [2] Bioconductor\n#>  geneplotter                1.72.0     2021-10-26 [2] Bioconductor\n#>  generics                   0.1.3      2022-07-05 [2] CRAN (R 4.1.2)\n#>  GenomeInfoDb             * 1.30.1     2022-01-30 [2] Bioconductor\n#>  GenomeInfoDbData           1.2.7      2022-03-09 [2] Bioconductor\n#>  GenomicRanges            * 1.46.1     2021-11-18 [2] Bioconductor\n#>  ggbeeswarm                 0.7.2      2023-04-29 [1] CRAN (R 4.1.2)\n#>  ggplot2                  * 3.4.4      2023-10-12 [1] CRAN (R 4.1.3)\n#>  ggrepel                    0.9.3      2023-02-03 [1] CRAN (R 4.1.2)\n#>  gld                        2.6.6      2022-10-23 [2] CRAN (R 4.1.2)\n#>  glmnet                     4.1-7      2023-03-23 [2] CRAN (R 4.1.2)\n#>  glue                       1.6.2      2022-02-24 [2] CRAN (R 4.1.2)\n#>  gmp                        0.7-1      2023-02-07 [2] CRAN (R 4.1.2)\n#>  gplots                     3.1.3      2022-04-25 [2] CRAN (R 4.1.2)\n#>  gridExtra                  2.3        2017-09-09 [2] CRAN (R 4.1.0)\n#>  gsl                        2.1-8      2023-01-24 [2] CRAN (R 4.1.2)\n#>  gtable                     0.3.3      2023-03-21 [2] CRAN (R 4.1.2)\n#>  gtools                     3.9.4      2022-11-27 [2] CRAN (R 4.1.2)\n#>  highr                      0.10       2022-12-22 [2] CRAN (R 4.1.2)\n#>  Hmisc                      5.1-0      2023-05-08 [1] CRAN (R 4.1.2)\n#>  hms                        1.1.3      2023-03-21 [2] CRAN (R 4.1.2)\n#>  htmlTable                  2.4.1      2022-07-07 [2] CRAN (R 4.1.2)\n#>  htmltools                  0.5.7      2023-11-03 [1] CRAN (R 4.1.3)\n#>  htmlwidgets                1.6.2      2023-03-17 [2] CRAN (R 4.1.2)\n#>  httpuv                     1.6.11     2023-05-11 [2] CRAN (R 4.1.3)\n#>  httr                       1.4.6      2023-05-08 [2] CRAN (R 4.1.2)\n#>  igraph                     1.5.0      2023-06-16 [1] CRAN (R 4.1.3)\n#>  IRanges                  * 2.28.0     2021-10-26 [2] Bioconductor\n#>  irlba                      2.3.5.1    2022-10-03 [2] CRAN (R 4.1.2)\n#>  iterators                  1.0.14     2022-02-05 [2] CRAN (R 4.1.2)\n#>  jquerylib                  0.1.4      2021-04-26 [2] CRAN (R 4.1.0)\n#>  jsonlite                   1.8.7      2023-06-29 [2] CRAN (R 4.1.3)\n#>  KEGGREST                   1.34.0     2021-10-26 [2] Bioconductor\n#>  KernSmooth                 2.23-22    2023-07-10 [2] CRAN (R 4.1.3)\n#>  knitr                      1.43       2023-05-25 [2] CRAN (R 4.1.3)\n#>  later                      1.3.1      2023-05-02 [2] CRAN (R 4.1.2)\n#>  lattice                    0.21-8     2023-04-05 [2] CRAN (R 4.1.2)\n#>  lazyeval                   0.2.2      2019-03-15 [2] CRAN (R 4.1.0)\n#>  lifecycle                  1.0.3      2022-10-07 [2] CRAN (R 4.1.2)\n#>  limma                      3.50.3     2022-04-07 [2] Bioconductor\n#>  lme4                       1.1-34     2023-07-04 [1] CRAN (R 4.1.3)\n#>  lmerTest                   3.1-3      2020-10-23 [1] CRAN (R 4.1.0)\n#>  lmom                       2.9        2022-05-29 [2] CRAN (R 4.1.2)\n#>  locfit                     1.5-9.8    2023-06-11 [2] CRAN (R 4.1.3)\n#>  lubridate                * 1.9.2      2023-02-10 [2] CRAN (R 4.1.2)\n#>  magrittr                   2.0.3      2022-03-30 [2] CRAN (R 4.1.2)\n#>  MASS                       7.3-60     2023-05-04 [1] CRAN (R 4.1.2)\n#>  Matrix                     1.6-5      2024-01-11 [1] CRAN (R 4.1.3)\n#>  MatrixGenerics           * 1.6.0      2021-10-26 [2] Bioconductor\n#>  matrixStats              * 1.1.0      2023-11-07 [1] CRAN (R 4.1.3)\n#>  memoise                    2.0.1      2021-11-26 [2] CRAN (R 4.1.0)\n#>  metagenomeSeq              1.36.0     2021-10-26 [2] Bioconductor\n#>  mgcv                       1.8-42     2023-03-02 [2] CRAN (R 4.1.2)\n#>  mia                        1.10.0     2023-10-24 [1] Bioconductor\n#>  MicrobiomeAnalysis       * 1.0.3      2023-12-02 [1] Bioconductor\n#>  mime                       0.12       2021-09-28 [2] CRAN (R 4.1.0)\n#>  miniUI                     0.1.1.1    2018-05-18 [2] CRAN (R 4.1.0)\n#>  minqa                      1.2.5      2022-10-19 [2] CRAN (R 4.1.2)\n#>  multcomp                   1.4-25     2023-06-20 [2] CRAN (R 4.1.3)\n#>  MultiAssayExperiment       1.20.0     2021-10-26 [2] Bioconductor\n#>  multtest                   2.50.0     2021-10-26 [2] Bioconductor\n#>  munsell                    0.5.0      2018-06-12 [2] CRAN (R 4.1.0)\n#>  mvtnorm                    1.2-2      2023-06-08 [2] CRAN (R 4.1.3)\n#>  nlme                       3.1-162    2023-01-31 [1] CRAN (R 4.1.2)\n#>  nloptr                     2.0.3      2022-05-26 [2] CRAN (R 4.1.2)\n#>  nnet                       7.3-19     2023-05-03 [2] CRAN (R 4.1.2)\n#>  numDeriv                   2016.8-1.1 2019-06-06 [2] CRAN (R 4.1.0)\n#>  permute                    0.9-7      2022-01-27 [2] CRAN (R 4.1.2)\n#>  phyloseq                   1.38.0     2021-10-26 [2] Bioconductor\n#>  pillar                     1.9.0      2023-03-22 [2] CRAN (R 4.1.2)\n#>  pkgbuild                   1.4.2      2023-06-26 [2] CRAN (R 4.1.3)\n#>  pkgconfig                  2.0.3      2019-09-22 [2] CRAN (R 4.1.0)\n#>  pkgload                    1.3.2.1    2023-07-08 [2] CRAN (R 4.1.3)\n#>  plyr                       1.8.8      2022-11-11 [1] CRAN (R 4.1.2)\n#>  png                        0.1-8      2022-11-29 [2] CRAN (R 4.1.2)\n#>  prettyunits                1.1.1      2020-01-24 [2] CRAN (R 4.1.0)\n#>  processx                   3.8.2      2023-06-30 [2] CRAN (R 4.1.3)\n#>  profvis                    0.3.8      2023-05-02 [2] CRAN (R 4.1.2)\n#>  promises                   1.2.0.1    2021-02-11 [2] CRAN (R 4.1.0)\n#>  proxy                      0.4-27     2022-06-09 [2] CRAN (R 4.1.2)\n#>  ps                         1.7.5      2023-04-18 [2] CRAN (R 4.1.2)\n#>  purrr                    * 1.0.1      2023-01-10 [1] CRAN (R 4.1.2)\n#>  R6                         2.5.1      2021-08-19 [2] CRAN (R 4.1.0)\n#>  rbibutils                  2.2.13     2023-01-13 [2] CRAN (R 4.1.2)\n#>  RColorBrewer               1.1-3      2022-04-03 [1] CRAN (R 4.1.2)\n#>  Rcpp                       1.0.11     2023-07-06 [1] CRAN (R 4.1.3)\n#>  RCurl                      1.98-1.12  2023-03-27 [2] CRAN (R 4.1.2)\n#>  Rdpack                     2.4        2022-07-20 [2] CRAN (R 4.1.2)\n#>  readr                    * 2.1.4      2023-02-10 [1] CRAN (R 4.1.2)\n#>  readxl                     1.4.3      2023-07-06 [2] CRAN (R 4.1.3)\n#>  remotes                    2.4.2      2021-11-30 [2] CRAN (R 4.1.0)\n#>  reshape2                   1.4.4      2020-04-09 [2] CRAN (R 4.1.0)\n#>  rhdf5                      2.38.1     2022-03-10 [2] Bioconductor\n#>  rhdf5filters               1.6.0      2021-10-26 [2] Bioconductor\n#>  Rhdf5lib                   1.16.0     2021-10-26 [2] Bioconductor\n#>  rlang                      1.1.1      2023-04-28 [1] CRAN (R 4.1.2)\n#>  rmarkdown                  2.23       2023-07-01 [2] CRAN (R 4.1.3)\n#>  Rmpfr                      0.9-2      2023-04-22 [2] CRAN (R 4.1.2)\n#>  rngtools                   1.5.2      2021-09-20 [2] CRAN (R 4.1.0)\n#>  rootSolve                  1.8.2.3    2021-09-29 [2] CRAN (R 4.1.0)\n#>  ropls                    * 1.26.4     2022-01-11 [2] Bioconductor\n#>  rpart                      4.1.19     2022-10-21 [2] CRAN (R 4.1.2)\n#>  RSQLite                    2.3.1      2023-04-03 [2] CRAN (R 4.1.2)\n#>  rstudioapi                 0.15.0     2023-07-07 [2] CRAN (R 4.1.3)\n#>  rsvd                       1.0.5      2021-04-16 [2] CRAN (R 4.1.0)\n#>  S4Vectors                * 0.32.4     2022-03-29 [2] Bioconductor\n#>  sandwich                   3.0-2      2022-06-15 [2] CRAN (R 4.1.2)\n#>  sass                       0.4.6      2023-05-03 [2] CRAN (R 4.1.2)\n#>  ScaledMatrix               1.2.0      2021-10-26 [2] Bioconductor\n#>  scales                     1.2.1      2022-08-20 [1] CRAN (R 4.1.2)\n#>  scater                     1.22.0     2021-10-26 [2] Bioconductor\n#>  scuttle                    1.4.0      2021-10-26 [2] Bioconductor\n#>  sessioninfo                1.2.2      2021-12-06 [2] CRAN (R 4.1.0)\n#>  shape                      1.4.6      2021-05-19 [2] CRAN (R 4.1.0)\n#>  shiny                      1.7.4.1    2023-07-06 [2] CRAN (R 4.1.3)\n#>  SingleCellExperiment       1.16.0     2021-10-26 [2] Bioconductor\n#>  sparseMatrixStats          1.6.0      2021-10-26 [2] Bioconductor\n#>  stringi                    1.7.12     2023-01-11 [2] CRAN (R 4.1.2)\n#>  stringr                  * 1.5.1      2023-11-14 [1] CRAN (R 4.1.3)\n#>  SummarizedExperiment     * 1.24.0     2021-10-26 [2] Bioconductor\n#>  survival                   3.5-5      2023-03-12 [2] CRAN (R 4.1.2)\n#>  TH.data                    1.1-2      2023-04-17 [2] CRAN (R 4.1.2)\n#>  tibble                   * 3.2.1      2023-03-20 [1] CRAN (R 4.1.2)\n#>  tidyr                    * 1.3.0      2023-01-24 [1] CRAN (R 4.1.2)\n#>  tidyselect                 1.2.0      2022-10-10 [2] CRAN (R 4.1.2)\n#>  tidytree                   0.4.2      2022-12-18 [2] CRAN (R 4.1.2)\n#>  tidyverse                * 2.0.0      2023-02-22 [1] CRAN (R 4.1.2)\n#>  timechange                 0.2.0      2023-01-11 [2] CRAN (R 4.1.2)\n#>  treeio                     1.18.1     2021-11-14 [2] Bioconductor\n#>  TreeSummarizedExperiment   2.2.0      2021-10-26 [2] Bioconductor\n#>  tzdb                       0.4.0      2023-05-12 [2] CRAN (R 4.1.3)\n#>  urlchecker                 1.0.1      2021-11-30 [2] CRAN (R 4.1.0)\n#>  usethis                    2.2.2      2023-07-06 [2] CRAN (R 4.1.3)\n#>  utf8                       1.2.3      2023-01-31 [2] CRAN (R 4.1.2)\n#>  vctrs                      0.6.5      2023-12-01 [1] CRAN (R 4.1.3)\n#>  vegan                      2.6-4      2022-10-11 [1] CRAN (R 4.1.2)\n#>  vipor                      0.4.5      2017-03-22 [2] CRAN (R 4.1.0)\n#>  viridis                    0.6.3      2023-05-03 [2] CRAN (R 4.1.2)\n#>  viridisLite                0.4.2      2023-05-02 [2] CRAN (R 4.1.2)\n#>  withr                      2.5.0      2022-03-03 [2] CRAN (R 4.1.2)\n#>  Wrench                     1.12.0     2021-10-26 [2] Bioconductor\n#>  xfun                       0.40       2023-08-09 [1] CRAN (R 4.1.3)\n#>  XML                        3.99-0.14  2023-03-19 [2] CRAN (R 4.1.2)\n#>  xml2                       1.3.5      2023-07-06 [2] CRAN (R 4.1.3)\n#>  xtable                     1.8-4      2019-04-21 [2] CRAN (R 4.1.0)\n#>  XVector                    0.34.0     2021-10-26 [2] Bioconductor\n#>  yaml                       2.3.7      2023-01-23 [2] CRAN (R 4.1.2)\n#>  yulab.utils                0.0.6      2022-12-20 [2] CRAN (R 4.1.2)\n#>  zlibbioc                   1.40.0     2021-10-26 [2] Bioconductor\n#>  zoo                        1.8-12     2023-04-13 [2] CRAN (R 4.1.2)\n#> \n#>  [1] /Users/zouhua/Library/R/x86_64/4.1/library\n#>  [2] /Library/Frameworks/R.framework/Versions/4.1/Resources/library\n#> \n#> ──────────────────────────────────────────────────────────"},{"path":"DimensionReduction.html","id":"reference-8","chapter":"10 Dimension Reduction","heading":"10.8 Reference","text":"ropls: PCA, PLS(-DA) OPLS(-DA) multivariate analysis feature selection omics data","code":""},{"path":"DifferetialAnalysis.html","id":"DifferetialAnalysis","chapter":"11 Differetial Analysis","heading":"11 Differetial Analysis","text":"差异分析的目的是为了筛选代谢物标记物，常用的方法有以下几种倍数变化法 (Fold Change)，也有基于log2的Fold change，计算组间倍数变化倍数变化法 (Fold Change)，也有基于log2的Fold change，计算组间倍数变化T检验，计算组间均值的t统计量差别T检验，计算组间均值的t统计量差别PLS-DA或OPLS-DA的VIP(Variable Importance Projection，变量投影重要度)，计算代谢物在投影平面坐标的重要度打分，个人理解有点类似主成分的特征系数PLS-DA或OPLS-DA的VIP(Variable Importance Projection，变量投影重要度)，计算代谢物在投影平面坐标的重要度打分，个人理解有点类似主成分的特征系数","code":""},{"path":"DifferetialAnalysis.html","id":"安装microbiomeanalysis包","chapter":"11 Differetial Analysis","heading":"11.1 安装MicrobiomeAnalysis包","text":"MicrobiomeAnalysis可提供下面分析使用的函数","code":"\nif (!requireNamespace(c(\"remotes\", \"devtools\"), quietly=TRUE)) {\n  install.packages(c(\"devtools\", \"remotes\"))\n}\nremotes::install_github(\"HuaZou/MicrobiomeAnalysis\")"},{"path":"DifferetialAnalysis.html","id":"加载r包-7","chapter":"11 Differetial Analysis","heading":"11.2 加载R包","text":"","code":"\nknitr::opts_chunk$set(message = FALSE, warning = FALSE)\nlibrary(tidyverse)\nlibrary(ropls)\nlibrary(SummarizedExperiment)\nlibrary(MicrobiomeAnalysis)\nlibrary(ggplot2)\nlibrary(ggrepel)\n\n# rm(list = ls())\noptions(stringsAsFactors = F)\noptions(future.globals.maxSize = 1000 * 1024^2)\n\ngrp_names <- c(\"None\", \"Mild\", \"Moderate\", \"Severe\")\ngrp_colors <- c(\"#7DD06F\", \"#844081\", \"#688EC1\", \"#C17E73\")"},{"path":"DifferetialAnalysis.html","id":"导入数据-5","chapter":"11 Differetial Analysis","heading":"11.3 导入数据","text":"对数据OmicsDataSet-Zeybel et al. - 2022.xlsx处理后生成的，可参考数据预处理章节。se_filter.RDS用于计算倍数变化se_filter.RDS用于计算倍数变化se_scale.RDS用于T检验和PLS-DAse_scale.RDS用于T检验和PLS-DA","code":"\nsaveRDS(se_filter, \"./InputData/result/QC/se_filter.RDS\", compress = TRUE)\nsaveRDS(se_scale, \"./InputData/result/QC/se_scale.RDS\", compress = TRUE)\nse_filter <- readRDS(\"./InputData/result/QC/se_filter.RDS\")\nse_scale <- readRDS(\"./InputData/result/QC/se_scale.RDS\")"},{"path":"DifferetialAnalysis.html","id":"平均值和方差-mean---sd","chapter":"11 Differetial Analysis","heading":"11.4 平均值和方差 (mean +/- sd)","text":"根据代谢物的相对定量或绝对定量结果，计算某个代谢物在两组间表达量的平均值和方差这里选择”None”和”Severe”两组计算","code":"\nmeansd_fun <- function(\n    x,\n    group,\n    group_names,\n    occ_cutoff = 0.5) {\n  \n  # x = se_filter\n  # group = \"LiverFatClass\"\n  # group_names = grp_names[c(1, 4)]\n  # occ_cutoff = 0.5\n  \n  # dataseat\n  metadata <- SummarizedExperiment::colData(x) %>%\n      as.data.frame()\n  profile <- SummarizedExperiment::assay(x) %>%\n      as.data.frame()\n  feature <- SummarizedExperiment::rowData(x) %>%\n      as.data.frame() \n\n  colnames(metadata)[which(colnames(metadata) == group)] <- \"CompVar\"\n  phenotype <- metadata %>%\n    dplyr::filter(CompVar %in% group_names) %>%\n    dplyr::mutate(CompVar = as.character(CompVar)) %>%\n    dplyr::mutate(CompVar = factor(CompVar, levels = group_names))\n  \n  sid <- intersect(rownames(phenotype), colnames(profile))\n  phen <- phenotype[pmatch(sid, rownames(phenotype)), , ]\n  prof <- profile %>%\n    dplyr::select(all_of(sid))\n  \n  if (!all(colnames(prof) == rownames(phen))) {\n    stop(\"Wrong Order\")\n  }\n  \n  trim_FeatureOrSample <- function(x, nRow, threshold) {\n  \n    df_occ <- apply(x, nRow, function(x) {\n      length(x[c(which(!is.na(x) & x!=0))]) / length(x)\n    }) %>%\n      data.frame() %>% stats::setNames(\"Occ\") %>%\n      tibble::rownames_to_column(\"type\")\n    if (nRow == 1) {\n      rownames(df_occ) <- rownames(x)\n    } else {\n      rownames(df_occ) <- colnames(x)\n    }\n    df_KEEP <- apply(df_occ > threshold, 1, all) %>%\n      data.frame() %>% stats::setNames(\"Status\") %>%\n      dplyr::filter(Status)\n  \n    res <- x %>%\n      tibble::rownames_to_column(\"featureid\") %>%\n      dplyr::filter(featureid %in% rownames(df_KEEP)) %>%\n      tibble::column_to_rownames(\"featureid\")\n    \n    return(res)\n  }\n\n  prof_cln <- trim_FeatureOrSample(prof, 1, occ_cutoff)\n  mean_res <- apply(prof_cln, 1, function(x1, y1) {\n    dat <- data.frame(value = as.numeric(x1), group = y1)\n    \n    mn <- tapply(dat$value, dat$group, function(x){mean(x, na.rm = TRUE)}) %>%\n      data.frame() %>% stats::setNames(\"value\") %>%\n      tibble::rownames_to_column(\"Group\")\n    mn1 <- with(mn, mn[Group %in% group_names[1], \"value\"])\n    mn2 <- with(mn, mn[Group %in% group_names[2], \"value\"])\n    mn3 <- with(mn, mn[Group %in% group_names[3], \"value\"])\n    mnall <- mean(dat$value, na.rm = TRUE)\n    \n    SD <- tapply(dat$value, dat$group, function(x){sd(x, na.rm = TRUE)}) %>%\n      data.frame() %>% stats::setNames(\"value\") %>%\n      tibble::rownames_to_column(\"Group\")\n    SD1 <- with(SD, SD[Group %in% group_names[1], \"value\"])\n    SD2 <- with(SD, SD[Group %in% group_names[2], \"value\"])\n    SD3 <- with(SD, SD[Group %in% group_names[3], \"value\"])\n    SDall <- sd(dat$value, na.rm = TRUE)\n    \n    mean_sd_all <- paste(round(mnall, 8), round(SDall, 8), sep = \"+/-\")\n    mean_sd_1 <- paste(round(mn1, 8), round(SD1, 8), sep = \"+/-\")\n    mean_sd_2 <- paste(round(mn2, 8), round(SD2, 8), sep = \"+/-\")\n    mean_sd_3 <- paste(round(mn3, 8), round(SD3, 8), sep = \"+/-\")\n    \n    res <- c(mean_sd_all, mean_sd_1, mean_sd_2, mean_sd_3)\n    return(res)\n  }, phen$CompVar) %>%\n    t() %>% as.data.frame() %>%\n    tibble::rownames_to_column(\"Feature\")\n  \n  colnames(mean_res) <- c(\"FeatureID\", \n                        \"Mean+/-SD Abundance(All)\",\n                     paste0(\"Mean Abundance \", group_names)) \n  \n  if (!is.null(feature)) {\n    res <- mean_res %>%\n      dplyr::inner_join(feature %>%\n                          tibble::rownames_to_column(\"FeatureID\"),\n                        by = \"FeatureID\")    \n  } else {\n    res <- mean_res    \n  }  \n\n  return(res)\n}\n\nmeansd_result <- meansd_fun(\n  x = se_filter,\n  group = \"LiverFatClass\",\n  group_names = grp_names[c(1, 4)],\n  occ_cutoff = 0.5)\n\nhead(meansd_result)\n#>        FeatureID            Mean+/-SD Abundance(All)\n#> 1 Chem_100002945 33862956.0909091+/-15764070.6522433\n#> 2 Chem_100002356 3629040.02272727+/-1307163.71272114\n#> 3 Chem_100021502   684442.63282273+/-371654.38934552\n#> 4 Chem_100008903 102839488.727273+/-27950099.0087515\n#> 5 Chem_100000657 27786810.8181818+/-3032359.06117482\n#> 6 Chem_100001397   150438.97897828+/-100797.51178993\n#>               Mean Abundance None\n#> 1     31958567+/-19461108.7209389\n#> 2  3322149.325+/-1301360.05772809\n#> 3  684387.21095+/-465469.48938036\n#> 4   103557801.6+/-25226703.757032\n#> 5     27636924+/-3730876.87127851\n#> 6 128489.89046444+/-63015.4982611\n#>                 Mean Abundance Severe  metabolitesID\n#> 1         35449947+/-12589758.3211378 Chem_100002945\n#> 2 3884782.27083333+/-1311269.55266439 Chem_100002356\n#> 3   684488.81771667+/-293986.70676612 Chem_100021502\n#> 4 102240894.666667+/-31142531.5321634 Chem_100008903\n#> 5       27911716.5+/-2475560.05052023 Chem_100000657\n#> 6   168729.88607315+/-123873.84220169 Chem_100001397\n#>                                   BIOCHEMICAL SUPER.PATHWAY\n#> 1 (14 or 15)-methylpalmitate (a17:0 or i17:0)         Lipid\n#> 2  (16 or 17)-methylstearate (a19:0 or i19:0)         Lipid\n#> 3           (2 or 3)-decenoate (10:1n7 or n8)         Lipid\n#> 4             1,2-dilinoleoyl-GPC (18:2/18:2)         Lipid\n#> 5             1,2-dipalmitoyl-GPC (16:0/16:0)         Lipid\n#> 6                        1,3,7-trimethylurate   Xenobiotics\n#>                SUB.PATHWAY COMPID       PLATFORM CHEMICALID\n#> 1     Fatty Acid, Branched  38768      LC/MS Neg  100002945\n#> 2     Fatty Acid, Branched  38296      LC/MS Neg  100002356\n#> 3  Medium Chain Fatty Acid  63436      LC/MS Neg  100021502\n#> 4 Phosphatidylcholine (PC)  52603 LC/MS Pos Late  100008903\n#> 5 Phosphatidylcholine (PC)  19130 LC/MS Pos Late  100000657\n#> 6      Xanthine Metabolism  34404      LC/MS Neg  100001397\n#>     RI     MASS       PUBCHEM       CAS   KEGG\n#> 1 5695 269.2487 8181;17903417      <NA> C16995\n#> 2 5993 297.2799       3083779 2724-59-6   <NA>\n#> 3 4990 169.1234          <NA>      <NA>   <NA>\n#> 4 2100 782.5694       5288075  998-06-1   <NA>\n#> 5 2450 734.5694        452110   63-89-8 D03585\n#> 6 1985 209.0680         79437 5415-44-1 C16361\n#>   SampleIDHMDBID\n#> 1    HMDB0061859\n#> 2    HMDB0037397\n#> 3           <NA>\n#> 4    HMDB0008138\n#> 5    HMDB0000564\n#> 6    HMDB0002123"},{"path":"DifferetialAnalysis.html","id":"倍数变化法-fold-change","chapter":"11 Differetial Analysis","heading":"11.5 倍数变化法 (Fold Change)","text":"倍数变化法即根据代谢物的相对定量或绝对定量结果，计算某个代谢物在两组间表达量的差异倍数（Fold Change），简称FC值。假设A物质在对照组中定量结果为1，在疾病组中定量结果为3，那么此物质的FC值即为3。由于代谢物定量结果肯定是非负数，那么FC的取值就是(0, +∞)。为筛选到差异更为显著的代谢物，小迈提供给各位老师的结果中默认选择的是FC值≥2或≤0.5的物质，此标准设置的较为严格，若因此筛到的差异代谢物较少，可根据需求将差异倍数标准调整为1.5倍或者1.2倍，这两种阈值在代谢组研究相关文章中也是较为常见的。结果：FoldChange是组间倍数变化FoldChange是组间倍数变化Log2FoldChange是组间倍数变化的log2对数值Log2FoldChange是组间倍数变化的log2对数值","code":"\nfc_result <- MicrobiomeAnalysis::run_metabolomeDA(\n  object_raw = se_filter,\n  variable = \"LiverFatClass\",\n  variable_name = grp_names[c(1, 4)],\n  DA_method = \"fc\",\n  cutoff_prev = 0.5)\n\nhead(fc_result)\n#>        FeatureID                Block FoldChange\n#> 1 Chem_100002945 10_None vs 12_Severe  0.9015124\n#> 2 Chem_100002356 10_None vs 12_Severe  0.8551700\n#> 3 Chem_100021502 10_None vs 12_Severe  0.9998516\n#> 4 Chem_100008903 10_None vs 12_Severe  1.0128804\n#> 5 Chem_100000657 10_None vs 12_Severe  0.9901549\n#> 6 Chem_100001397 10_None vs 12_Severe  0.7615123\n#>   Log2FoldChange Mean Abundance (All) Mean Abundance None\n#> 1  -0.1495807503           33862956.1          31958567.0\n#> 2  -0.2257168212            3629040.0           3322149.3\n#> 3  -0.0002141722             684442.6            684387.2\n#> 4   0.0184638782          102839488.7         103557801.6\n#> 5  -0.0142737971           27786810.8          27636924.0\n#> 6  -0.3930606787             150439.0            128489.9\n#>   Mean Abundance Severe  metabolitesID\n#> 1            35449947.0 Chem_100002945\n#> 2             3884782.3 Chem_100002356\n#> 3              684488.8 Chem_100021502\n#> 4           102240894.7 Chem_100008903\n#> 5            27911716.5 Chem_100000657\n#> 6              168729.9 Chem_100001397\n#>                                   BIOCHEMICAL SUPER.PATHWAY\n#> 1 (14 or 15)-methylpalmitate (a17:0 or i17:0)         Lipid\n#> 2  (16 or 17)-methylstearate (a19:0 or i19:0)         Lipid\n#> 3           (2 or 3)-decenoate (10:1n7 or n8)         Lipid\n#> 4             1,2-dilinoleoyl-GPC (18:2/18:2)         Lipid\n#> 5             1,2-dipalmitoyl-GPC (16:0/16:0)         Lipid\n#> 6                        1,3,7-trimethylurate   Xenobiotics\n#>                SUB.PATHWAY COMPID       PLATFORM CHEMICALID\n#> 1     Fatty Acid, Branched  38768      LC/MS Neg  100002945\n#> 2     Fatty Acid, Branched  38296      LC/MS Neg  100002356\n#> 3  Medium Chain Fatty Acid  63436      LC/MS Neg  100021502\n#> 4 Phosphatidylcholine (PC)  52603 LC/MS Pos Late  100008903\n#> 5 Phosphatidylcholine (PC)  19130 LC/MS Pos Late  100000657\n#> 6      Xanthine Metabolism  34404      LC/MS Neg  100001397\n#>     RI     MASS       PUBCHEM       CAS   KEGG\n#> 1 5695 269.2487 8181;17903417      <NA> C16995\n#> 2 5993 297.2799       3083779 2724-59-6   <NA>\n#> 3 4990 169.1234          <NA>      <NA>   <NA>\n#> 4 2100 782.5694       5288075  998-06-1   <NA>\n#> 5 2450 734.5694        452110   63-89-8 D03585\n#> 6 1985 209.0680         79437 5415-44-1 C16361\n#>   SampleIDHMDBID\n#> 1    HMDB0061859\n#> 2    HMDB0037397\n#> 3           <NA>\n#> 4    HMDB0008138\n#> 5    HMDB0000564\n#> 6    HMDB0002123"},{"path":"DifferetialAnalysis.html","id":"t检验","chapter":"11 Differetial Analysis","heading":"11.6 T检验","text":"T检验，又叫student t 检验（Student’s t test）,是一种常用的假设检验方法，也是差异代谢物筛选中常见的统计策略之一。假设检验首先必须要有假设，我们假设某代谢物在A组和B组的含量没有差异（H0，零假设），然后基于此假设，通过t test计算出统计量t值和其对应的p值，如果P-value<0.05，那么说明小概率事件出现了，我们应该拒绝零假设，即A组和B组的含量不一样，即有显著差异。结果：Pvalue是组间t检验结果Pvalue是组间t检验结果AdjustedPvalue是组间t检验结果pvalue的FDR校正结果，多次假设检验需要做FDR校正AdjustedPvalue是组间t检验结果pvalue的FDR校正结果，多次假设检验需要做FDR校正","code":"\nt_result <- MicrobiomeAnalysis::run_metabolomeDA(\n  object_norm = se_scale,\n  variable = \"LiverFatClass\",\n  variable_name = grp_names[c(1, 4)],\n  DA_method = \"t\")\n\nhead(t_result)\n#>        FeatureID                Block  Statistic    Pvalue\n#> 1 Chem_100002945 10_None vs 12_Severe -0.6037683 0.5558211\n#> 2 Chem_100002356 10_None vs 12_Severe -0.7749522 0.4500496\n#> 3 Chem_100021502 10_None vs 12_Severe -0.3713518 0.7163065\n#> 4 Chem_100008903 10_None vs 12_Severe  0.9263985 0.3653264\n#> 5 Chem_100000657 10_None vs 12_Severe  1.1285338 0.2774432\n#> 6 Chem_100001397 10_None vs 12_Severe -0.2611731 0.7966485\n#>   AdjustedPvalue  metabolitesID\n#> 1      0.8508542 Chem_100002945\n#> 2      0.7999555 Chem_100002356\n#> 3      0.9150357 Chem_100021502\n#> 4      0.7784815 Chem_100008903\n#> 5      0.7084122 Chem_100000657\n#> 6      0.9189909 Chem_100001397\n#>                                   BIOCHEMICAL SUPER.PATHWAY\n#> 1 (14 or 15)-methylpalmitate (a17:0 or i17:0)         Lipid\n#> 2  (16 or 17)-methylstearate (a19:0 or i19:0)         Lipid\n#> 3           (2 or 3)-decenoate (10:1n7 or n8)         Lipid\n#> 4             1,2-dilinoleoyl-GPC (18:2/18:2)         Lipid\n#> 5             1,2-dipalmitoyl-GPC (16:0/16:0)         Lipid\n#> 6                        1,3,7-trimethylurate   Xenobiotics\n#>                SUB.PATHWAY COMPID       PLATFORM CHEMICALID\n#> 1     Fatty Acid, Branched  38768      LC/MS Neg  100002945\n#> 2     Fatty Acid, Branched  38296      LC/MS Neg  100002356\n#> 3  Medium Chain Fatty Acid  63436      LC/MS Neg  100021502\n#> 4 Phosphatidylcholine (PC)  52603 LC/MS Pos Late  100008903\n#> 5 Phosphatidylcholine (PC)  19130 LC/MS Pos Late  100000657\n#> 6      Xanthine Metabolism  34404      LC/MS Neg  100001397\n#>     RI     MASS       PUBCHEM       CAS   KEGG\n#> 1 5695 269.2487 8181;17903417      <NA> C16995\n#> 2 5993 297.2799       3083779 2724-59-6   <NA>\n#> 3 4990 169.1234          <NA>      <NA>   <NA>\n#> 4 2100 782.5694       5288075  998-06-1   <NA>\n#> 5 2450 734.5694        452110   63-89-8 D03585\n#> 6 1985 209.0680         79437 5415-44-1 C16361\n#>   SampleIDHMDBID\n#> 1    HMDB0061859\n#> 2    HMDB0037397\n#> 3           <NA>\n#> 4    HMDB0008138\n#> 5    HMDB0000564\n#> 6    HMDB0002123"},{"path":"DifferetialAnalysis.html","id":"变量投影重要度-vip-正交偏最小二乘判别分析opls-da","chapter":"11 Differetial Analysis","heading":"11.7 变量投影重要度 (VIP) 正交偏最小二乘判别分析（OPLS-DA）","text":"由于代谢组数据具有“高维、高噪音、高变异”的特点，因此一般采用多元统计分析方法，可以在最大程度保留原始信息的基础上将高维复杂的数据进行“简化和降维”，建立可靠的数学模型对研究对象的代谢谱特点进行归纳和总结。常见的多元统计分析方法包括PLS-DA或OPLS-DA。偏最小二乘判别分析（PLS-DA）是一种有监督模式识别的多元统计分析方法，将多维数据在压缩前先按需要寻找的差异因素分组（预先设定Y值来进行目标分类和判别），这样可以找到与用于分组的因素最相关的变量，而减少一些其它因素的影响。PLS-DA常用于区分各组间代谢轮廓的总体差异，筛选组间的差异代谢物。正交偏最小二乘判别分析（OPLS-DA）结合了正交信号矫正（OSC）和PLS-DA方法，能够将X矩阵信息分解成与Y相关和不相关的两类信息，通过去除不相关的差异来筛选差异变量。VIP（Variable important projection）是(O)PLS-DA模型变量的变量权重值，可用于衡量各代谢物积累差异对各组样本分类判别的影响强度和解释能力，VIP≥1为常见的差异代谢物筛选标准。结果：VIP是每个代谢物和投影平面向量的投影重要度VIP是每个代谢物和投影平面向量的投影重要度CorPvalue是每个代谢物和投影平面向量的相关系数CorPvalue是每个代谢物和投影平面向量的相关系数","code":"\nVIP_result <- MicrobiomeAnalysis::run_metabolomeDA(\n  object_norm = se_scale,\n  variable = \"LiverFatClass\",\n  variable_name = grp_names[c(1, 4)],\n  DA_method = \"vip\")\n#> PLS-DA\n#> 22 samples x 646 variables and 1 response\n#> standard scaling of predictors and response(s)\n#>       R2X(cum) R2Y(cum) Q2(cum) RMSEE pre ort pR2Y  pQ2\n#> Total    0.101    0.836   0.555 0.212   1   0  0.2 0.05\n\nhead(VIP_result)\n#>        FeatureID                Block      VIP    CorPvalue\n#> 1 Chem_100015755 10_None vs 12_Severe 2.672936 8.114814e-05\n#> 2 Chem_100001437 10_None vs 12_Severe 2.601041 1.550944e-04\n#> 3 Chem_100009066 10_None vs 12_Severe 2.549095 2.397091e-04\n#> 4       Chem_503 10_None vs 12_Severe 2.541717 2.544812e-04\n#> 5 Chem_100009181 10_None vs 12_Severe 2.469432 4.460156e-04\n#> 6 Chem_100022013 10_None vs 12_Severe 2.455673 4.939068e-04\n#>    metabolitesID\n#> 1 Chem_100015755\n#> 2 Chem_100001437\n#> 3 Chem_100009066\n#> 4       Chem_503\n#> 5 Chem_100009181\n#> 6 Chem_100022013\n#>                                      BIOCHEMICAL\n#> 1 ceramide (d18:1/20:0, d16:1/22:0, d20:1/18:0)*\n#> 2                 cysteine-glutathione disulfide\n#> 3          1-palmitoyl-2-oleoyl-GPI (16:0/18:1)*\n#> 4                                         serine\n#> 5           1-stearoyl-2-oleoyl-GPI (18:0/18:1)*\n#> 6                 tetrahydrocortisol glucuronide\n#>   SUPER.PATHWAY                              SUB.PATHWAY\n#> 1         Lipid                                Ceramides\n#> 2    Amino Acid                   Glutathione Metabolism\n#> 3         Lipid                Phosphatidylinositol (PI)\n#> 4    Amino Acid Glycine, Serine and Threonine Metabolism\n#> 5         Lipid                Phosphatidylinositol (PI)\n#> 6         Lipid                          Corticosteroids\n#>   COMPID        PLATFORM CHEMICALID   RI     MASS  PUBCHEM\n#> 1  57440  LC/MS Pos Late  100015755 3920 594.5820     <NA>\n#> 2  35159 LC/MS Pos Early  100001437 2465 427.0952  3080690\n#> 3  52669  LC/MS Pos Late  100009066 3140 854.5753 71296232\n#> 4   1648 LC/MS Pos Early        503 1239 106.0499     5951\n#> 5  52726  LC/MS Pos Late  100009181 3711 882.6066     <NA>\n#> 6  64411       LC/MS Neg  100022013 4666 541.2654     <NA>\n#>          CAS   KEGG SampleIDHMDBID\n#> 1       <NA>   <NA>           <NA>\n#> 2 13081-14-6 R00900    HMDB0000656\n#> 3       <NA>   <NA>    HMDB0009783\n#> 4    56-45-1 C00065    HMDB0000187\n#> 5       <NA>   <NA>           <NA>\n#> 6       <NA>   <NA>           <NA>"},{"path":"DifferetialAnalysis.html","id":"合并所有结果","chapter":"11 Differetial Analysis","heading":"11.8 合并所有结果","text":"合并上述六个指标，用于后续判断差异代谢物","code":"\nmergedResults <- function(\n    fc_result,\n    vip_result,\n    test_result,\n    group_names,\n    group_labels) {\n  \n  overlap_cols <- intersect(\n    intersect(colnames(fc_result),\n              colnames(vip_result)),\n    colnames(test_result))\n  \n  overlap_cols <- overlap_cols[overlap_cols != \"FeatureID\"]\n  \n  mdat <- fc_result %>%\n    dplyr::mutate(Block2 = paste(group_labels, collapse = \" vs \")) %>%\n    dplyr::mutate(FeatureID = make.names(FeatureID)) %>%\n    dplyr::inner_join(vip_result %>%\n                        # dplyr::select(-Block) %>%\n                        dplyr::select(-dplyr::all_of(overlap_cols)) %>%\n                        dplyr::mutate(FeatureID = make.names(FeatureID)),\n                      by = \"FeatureID\") %>%\n    dplyr::inner_join(test_result %>%\n                        # dplyr::select(-Block) %>%\n                        dplyr::select(-dplyr::all_of(overlap_cols)) %>%                        \n                        dplyr::mutate(FeatureID = make.names(FeatureID)),\n                      by = \"FeatureID\") \n  \n  res <- mdat %>%\n    dplyr::select(FeatureID, Block2, Block,\n                  FoldChange, Log2FoldChange,\n                  VIP, CorPvalue,\n                  Statistic, Pvalue, AdjustedPvalue,\n                  everything()) %>%\n    dplyr::arrange(AdjustedPvalue, Log2FoldChange)\n    \n  return(res)\n}\n\nfinal_result <- mergedResults(\n  fc_result = fc_result,\n  vip_result = VIP_result,\n  test_result = t_result,\n  group_names = grp_names[c(1, 4)],\n  group_labels = grp_names[c(1, 4)])\n\nhead(final_result)\n#>        FeatureID         Block2                Block\n#> 1 Chem_100015755 None vs Severe 10_None vs 12_Severe\n#> 2 Chem_100001437 None vs Severe 10_None vs 12_Severe\n#> 3       Chem_503 None vs Severe 10_None vs 12_Severe\n#> 4 Chem_100009066 None vs Severe 10_None vs 12_Severe\n#> 5 Chem_100009181 None vs Severe 10_None vs 12_Severe\n#> 6 Chem_100010917 None vs Severe 10_None vs 12_Severe\n#>   FoldChange Log2FoldChange      VIP    CorPvalue Statistic\n#> 1  0.6444244     -0.6339170 2.672936 8.114814e-05 -4.854409\n#> 2  1.7109000      0.7747554 2.601041 1.550944e-04  4.858307\n#> 3  1.2218596      0.2890785 2.541717 2.544812e-04  4.456220\n#> 4  0.5199556     -0.9435396 2.549095 2.397091e-04 -4.400999\n#> 5  0.5667863     -0.8191231 2.469432 4.460156e-04 -4.108909\n#> 6  0.5638085     -0.8267228 2.369314 9.073991e-04 -3.748881\n#>         Pvalue AdjustedPvalue Mean Abundance (All)\n#> 1 0.0001301058     0.04202417              3841099\n#> 2 0.0001184340     0.04202417              1246453\n#> 3 0.0002529654     0.05447188             63358904\n#> 4 0.0003436084     0.05549276              2243154\n#> 5 0.0007169002     0.09262350              1817773\n#> 6 0.0019076334     0.17057034              1192929\n#>   Mean Abundance None Mean Abundance Severe  metabolitesID\n#> 1           2952496.1             4581602.1 Chem_100015755\n#> 2           1611743.8              942044.4 Chem_100001437\n#> 3          70323857.2            57554776.3       Chem_503\n#> 4           1491869.7             2869225.1 Chem_100009066\n#> 5           1282914.5             2263488.8 Chem_100009181\n#> 6            838913.8             1487941.0 Chem_100010917\n#>                                      BIOCHEMICAL\n#> 1 ceramide (d18:1/20:0, d16:1/22:0, d20:1/18:0)*\n#> 2                 cysteine-glutathione disulfide\n#> 3                                         serine\n#> 4          1-palmitoyl-2-oleoyl-GPI (16:0/18:1)*\n#> 5           1-stearoyl-2-oleoyl-GPI (18:0/18:1)*\n#> 6     palmitoyl-oleoyl-glycerol (16:0/18:1) [2]*\n#>   SUPER.PATHWAY                              SUB.PATHWAY\n#> 1         Lipid                                Ceramides\n#> 2    Amino Acid                   Glutathione Metabolism\n#> 3    Amino Acid Glycine, Serine and Threonine Metabolism\n#> 4         Lipid                Phosphatidylinositol (PI)\n#> 5         Lipid                Phosphatidylinositol (PI)\n#> 6         Lipid                           Diacylglycerol\n#>   COMPID        PLATFORM CHEMICALID   RI     MASS  PUBCHEM\n#> 1  57440  LC/MS Pos Late  100015755 3920 594.5820     <NA>\n#> 2  35159 LC/MS Pos Early  100001437 2465 427.0952  3080690\n#> 3   1648 LC/MS Pos Early        503 1239 106.0499     5951\n#> 4  52669  LC/MS Pos Late  100009066 3140 854.5753 71296232\n#> 5  52726  LC/MS Pos Late  100009181 3711 882.6066     <NA>\n#> 6  54942  LC/MS Pos Late  100010917 3695 612.5562  5282283\n#>          CAS   KEGG SampleIDHMDBID\n#> 1       <NA>   <NA>           <NA>\n#> 2 13081-14-6 R00900    HMDB0000656\n#> 3    56-45-1 C00065    HMDB0000187\n#> 4       <NA>   <NA>    HMDB0009783\n#> 5       <NA>   <NA>           <NA>\n#> 6       <NA> C13861    HMDB0007102"},{"path":"DifferetialAnalysis.html","id":"一键生成差异结果","chapter":"11 Differetial Analysis","heading":"11.9 一键生成差异结果","text":"MicrobiomeAnalysis::run_metabolomeDA函数提供一键式生成差异结果。","code":"\nfinal_result <- MicrobiomeAnalysis::run_metabolomeDA(\n  object_raw = se_filter,\n  object_norm = se_scale,\n  variable = \"LiverFatClass\",\n  variable_name = grp_names[c(1, 4)],\n  DA_method = \"all\")\n#> PLS-DA\n#> 22 samples x 646 variables and 1 response\n#> standard scaling of predictors and response(s)\n#>       R2X(cum) R2Y(cum) Q2(cum) RMSEE pre ort pR2Y  pQ2\n#> Total    0.101    0.836   0.555 0.212   1   0  0.1 0.05\n\nhead(final_result)\n#>        FeatureID         Block2                Block\n#> 1 Chem_100015755 None vs Severe 10_None vs 12_Severe\n#> 2 Chem_100001437 None vs Severe 10_None vs 12_Severe\n#> 3       Chem_503 None vs Severe 10_None vs 12_Severe\n#> 4 Chem_100009066 None vs Severe 10_None vs 12_Severe\n#> 5 Chem_100009181 None vs Severe 10_None vs 12_Severe\n#> 6 Chem_100010917 None vs Severe 10_None vs 12_Severe\n#>   FoldChange Log2FoldChange      VIP    CorPvalue Statistic\n#> 1  0.6444244     -0.6339170 2.672936 8.114814e-05 -4.854409\n#> 2  1.7109000      0.7747554 2.601041 1.550944e-04  4.858307\n#> 3  1.2218596      0.2890785 2.541717 2.544812e-04  4.456220\n#> 4  0.5199556     -0.9435396 2.549095 2.397091e-04 -4.400999\n#> 5  0.5667863     -0.8191231 2.469432 4.460156e-04 -4.108909\n#> 6  0.5638085     -0.8267228 2.369314 9.073991e-04 -3.748881\n#>         Pvalue AdjustedPvalue Mean Abundance (All)\n#> 1 0.0001301058     0.04202417              3841099\n#> 2 0.0001184340     0.04202417              1246453\n#> 3 0.0002529654     0.05447188             63358904\n#> 4 0.0003436084     0.05549276              2243154\n#> 5 0.0007169002     0.09262350              1817773\n#> 6 0.0019076334     0.17057034              1192929\n#>   Mean Abundance None Mean Abundance Severe  metabolitesID\n#> 1           2952496.1             4581602.1 Chem_100015755\n#> 2           1611743.8              942044.4 Chem_100001437\n#> 3          70323857.2            57554776.3       Chem_503\n#> 4           1491869.7             2869225.1 Chem_100009066\n#> 5           1282914.5             2263488.8 Chem_100009181\n#> 6            838913.8             1487941.0 Chem_100010917\n#>                                      BIOCHEMICAL\n#> 1 ceramide (d18:1/20:0, d16:1/22:0, d20:1/18:0)*\n#> 2                 cysteine-glutathione disulfide\n#> 3                                         serine\n#> 4          1-palmitoyl-2-oleoyl-GPI (16:0/18:1)*\n#> 5           1-stearoyl-2-oleoyl-GPI (18:0/18:1)*\n#> 6     palmitoyl-oleoyl-glycerol (16:0/18:1) [2]*\n#>   SUPER.PATHWAY                              SUB.PATHWAY\n#> 1         Lipid                                Ceramides\n#> 2    Amino Acid                   Glutathione Metabolism\n#> 3    Amino Acid Glycine, Serine and Threonine Metabolism\n#> 4         Lipid                Phosphatidylinositol (PI)\n#> 5         Lipid                Phosphatidylinositol (PI)\n#> 6         Lipid                           Diacylglycerol\n#>   COMPID        PLATFORM CHEMICALID   RI     MASS  PUBCHEM\n#> 1  57440  LC/MS Pos Late  100015755 3920 594.5820     <NA>\n#> 2  35159 LC/MS Pos Early  100001437 2465 427.0952  3080690\n#> 3   1648 LC/MS Pos Early        503 1239 106.0499     5951\n#> 4  52669  LC/MS Pos Late  100009066 3140 854.5753 71296232\n#> 5  52726  LC/MS Pos Late  100009181 3711 882.6066     <NA>\n#> 6  54942  LC/MS Pos Late  100010917 3695 612.5562  5282283\n#>          CAS   KEGG SampleIDHMDBID\n#> 1       <NA>   <NA>           <NA>\n#> 2 13081-14-6 R00900    HMDB0000656\n#> 3    56-45-1 C00065    HMDB0000187\n#> 4       <NA>   <NA>    HMDB0009783\n#> 5       <NA>   <NA>           <NA>\n#> 6       <NA> C13861    HMDB0007102"},{"path":"DifferetialAnalysis.html","id":"可视化结果","chapter":"11 Differetial Analysis","heading":"11.10 可视化结果","text":"以火山图展示差异结果，使用MicrobiomeAnalysis::plot_volcano画图。","code":"\nget_volcano <- function(\n    inputdata,\n    group_names,\n    group_labels,\n    group_colors,\n    x_index,\n    x_cutoff,\n    y_index,\n    y_cutoff,\n    topN_features,\n    plot = TRUE) {\n  \n  # inputdata = final_result\n  # group_names = c(\"None\", \"Severe\")\n  # group_labels = c(\"None\", \"Severe\")\n  # group_colors = c(\"red\", \"blue\")\n  # x_index = \"Log2FoldChange\"\n  # x_cutoff = 0.5\n  # y_index = \"AdjustedPvalue\"\n  # y_cutoff = 0.5\n  # plot = FALSE\n  \n  selected_group2 <- paste(group_labels, collapse = \" vs \") \n  dat <- inputdata %>%\n    dplyr::filter(Block2 %in% selected_group2) \n  plotdata <- dat %>%\n    dplyr::mutate(FeatureID = paste(FeatureID, sep = \":\")) %>%\n    dplyr::select(all_of(c(\"FeatureID\", \"Block2\", x_index, y_index)))\n  \n  if (!any(colnames(plotdata) %in% \"TaxaID\")) {\n    colnames(plotdata)[1] <- \"TaxaID\"\n  }\n  if (y_index == \"CorPvalue\") {\n    colnames(plotdata)[which(colnames(plotdata) == y_index)] <- \"Pvalue\"\n    y_index <- \"Pvalue\"\n  }\n \n  \n  pl <- MicrobiomeAnalysis::plot_volcano(\n      da_res = plotdata,\n      group_names = group_labels,\n      x_index = x_index,\n      x_index_cutoff = x_cutoff,\n      y_index = y_index,\n      y_index_cutoff = y_cutoff,\n      group_colors = c(group_colors[1], \"grey\", group_colors[2]),\n      topN = topN_features,\n      add_enrich_arrow = TRUE)\n  \n  if (plot) {\n    res <- pl\n  } else {\n    colnames(plotdata)[which(colnames(plotdata) == x_index)] <- \"Xindex\"\n    colnames(plotdata)[which(colnames(plotdata) == y_index)] <- \"Yindex\"\n    \n    datsignif <- plotdata %>%\n      dplyr::filter(abs(Xindex) > x_cutoff) %>%\n      dplyr::filter(Yindex < y_cutoff)\n    \n    colnames(datsignif)[which(colnames(datsignif) == \"Xindex\")] <- x_index\n    colnames(datsignif)[which(colnames(datsignif) == \"Yindex\")] <- y_index\n        \n    res <- list(figure = pl,\n                data = datsignif)\n    \n  }\n  \n  return(res)\n}\n\nfinal_result$FeatureID <- final_result$BIOCHEMICAL\n\nlgfc_FDR_vol <- get_volcano(\n  inputdata = final_result,\n  group_names = c(\"None\", \"Severe\"),\n  group_labels = c(\"None\", \"Severe\"),\n  group_colors = c(\"red\", \"blue\"),\n  x_index = \"Log2FoldChange\",\n  x_cutoff = 0.5,\n  y_index = \"AdjustedPvalue\",\n  y_cutoff = 0.5,\n  topN_features = 10,\n  plot = FALSE)\n\nlgfc_FDR_vol$figure"},{"path":"DifferetialAnalysis.html","id":"输出结果","chapter":"11 Differetial Analysis","heading":"11.11 输出结果","text":"","code":"\nif(!dir.exists(\"./InputData/result/DA/\")) {\n  dir.create(\"./InputData/result/DA/\", recursive = TRUE)\n}\n\nwrite.table(final_result, \"./InputData/result/DA/Metabolites_FC_VIP_ttest.tsv\", \n            row.names = F, quote = F, sep = \"\\t\", fileEncoding = \"UTF-8\")"},{"path":"DifferetialAnalysis.html","id":"session-info-3","chapter":"11 Differetial Analysis","heading":"11.12 Session info","text":"","code":"\ndevtools::session_info()\n#> ─ Session info ───────────────────────────────────────────\n#>  setting  value\n#>  version  R version 4.1.3 (2022-03-10)\n#>  os       macOS Big Sur/Monterey 10.16\n#>  system   x86_64, darwin17.0\n#>  ui       X11\n#>  language (EN)\n#>  collate  en_US.UTF-8\n#>  ctype    en_US.UTF-8\n#>  tz       Asia/Shanghai\n#>  date     2024-02-06\n#>  pandoc   3.1.1 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/ (via rmarkdown)\n#> \n#> ─ Packages ───────────────────────────────────────────────\n#>  package                  * version    date (UTC) lib source\n#>  ade4                       1.7-22     2023-02-06 [1] CRAN (R 4.1.2)\n#>  ANCOMBC                    2.4.0      2023-10-26 [1] Bioconductor\n#>  annotate                   1.72.0     2021-10-26 [2] Bioconductor\n#>  AnnotationDbi              1.60.2     2023-03-10 [2] Bioconductor\n#>  ape                        5.7-1      2023-03-13 [1] CRAN (R 4.1.2)\n#>  backports                  1.4.1      2021-12-13 [2] CRAN (R 4.1.0)\n#>  base64enc                  0.1-3      2015-07-28 [2] CRAN (R 4.1.0)\n#>  beachmat                   2.10.0     2021-10-26 [2] Bioconductor\n#>  beeswarm                   0.4.0      2021-06-01 [2] CRAN (R 4.1.0)\n#>  Biobase                  * 2.54.0     2021-10-26 [2] Bioconductor\n#>  BiocGenerics             * 0.40.0     2021-10-26 [2] Bioconductor\n#>  BiocNeighbors              1.12.0     2021-10-26 [2] Bioconductor\n#>  BiocParallel               1.28.3     2021-12-09 [2] Bioconductor\n#>  BiocSingular               1.10.0     2021-10-26 [2] Bioconductor\n#>  biomformat                 1.22.0     2021-10-26 [2] Bioconductor\n#>  Biostrings                 2.62.0     2021-10-26 [2] Bioconductor\n#>  bit                        4.0.5      2022-11-15 [2] CRAN (R 4.1.2)\n#>  bit64                      4.0.5      2020-08-30 [2] CRAN (R 4.1.0)\n#>  bitops                     1.0-7      2021-04-24 [2] CRAN (R 4.1.0)\n#>  blob                       1.2.4      2023-03-17 [2] CRAN (R 4.1.2)\n#>  bluster                    1.4.0      2021-10-26 [2] Bioconductor\n#>  bookdown                   0.34       2023-05-09 [2] CRAN (R 4.1.2)\n#>  boot                       1.3-28.1   2022-11-22 [2] CRAN (R 4.1.2)\n#>  bslib                      0.6.0      2023-11-21 [1] CRAN (R 4.1.3)\n#>  cachem                     1.0.8      2023-05-01 [2] CRAN (R 4.1.2)\n#>  callr                      3.7.3      2022-11-02 [2] CRAN (R 4.1.2)\n#>  caTools                    1.18.2     2021-03-28 [2] CRAN (R 4.1.0)\n#>  cellranger                 1.1.0      2016-07-27 [2] CRAN (R 4.1.0)\n#>  checkmate                  2.2.0      2023-04-27 [2] CRAN (R 4.1.2)\n#>  class                      7.3-22     2023-05-03 [2] CRAN (R 4.1.2)\n#>  cli                        3.6.1      2023-03-23 [2] CRAN (R 4.1.2)\n#>  cluster                    2.1.4      2022-08-22 [2] CRAN (R 4.1.2)\n#>  codetools                  0.2-19     2023-02-01 [2] CRAN (R 4.1.2)\n#>  colorspace                 2.1-0      2023-01-23 [2] CRAN (R 4.1.2)\n#>  cowplot                    1.1.2      2023-12-15 [1] CRAN (R 4.1.3)\n#>  crayon                     1.5.2      2022-09-29 [2] CRAN (R 4.1.2)\n#>  CVXR                       1.0-12     2024-02-02 [1] CRAN (R 4.1.3)\n#>  data.table                 1.14.8     2023-02-17 [2] CRAN (R 4.1.2)\n#>  DBI                        1.1.3      2022-06-18 [2] CRAN (R 4.1.2)\n#>  DECIPHER                   2.22.0     2021-10-26 [2] Bioconductor\n#>  decontam                   1.14.0     2021-10-26 [2] Bioconductor\n#>  DelayedArray               0.20.0     2021-10-26 [2] Bioconductor\n#>  DelayedMatrixStats         1.16.0     2021-10-26 [2] Bioconductor\n#>  DescTools                  0.99.49    2023-05-17 [2] CRAN (R 4.1.3)\n#>  DESeq2                     1.34.0     2021-10-26 [2] Bioconductor\n#>  devtools                   2.4.5      2022-10-11 [2] CRAN (R 4.1.2)\n#>  digest                     0.6.33     2023-07-07 [1] CRAN (R 4.1.3)\n#>  DirichletMultinomial       1.36.0     2021-10-26 [2] Bioconductor\n#>  doParallel                 1.0.17     2022-02-07 [2] CRAN (R 4.1.2)\n#>  doRNG                      1.8.6      2023-01-16 [2] CRAN (R 4.1.2)\n#>  downlit                    0.4.3      2023-06-29 [2] CRAN (R 4.1.3)\n#>  dplyr                    * 1.1.4      2023-11-17 [1] CRAN (R 4.1.3)\n#>  e1071                      1.7-13     2023-02-01 [2] CRAN (R 4.1.2)\n#>  ellipsis                   0.3.2      2021-04-29 [2] CRAN (R 4.1.0)\n#>  energy                     1.7-11     2022-12-22 [1] CRAN (R 4.1.2)\n#>  evaluate                   0.21       2023-05-05 [2] CRAN (R 4.1.2)\n#>  Exact                      3.2        2022-09-25 [2] CRAN (R 4.1.2)\n#>  expm                       0.999-7    2023-01-09 [2] CRAN (R 4.1.2)\n#>  fansi                      1.0.4      2023-01-22 [2] CRAN (R 4.1.2)\n#>  farver                     2.1.1      2022-07-06 [2] CRAN (R 4.1.2)\n#>  fastmap                    1.1.1      2023-02-24 [2] CRAN (R 4.1.2)\n#>  forcats                  * 1.0.0      2023-01-29 [1] CRAN (R 4.1.2)\n#>  foreach                    1.5.2      2022-02-02 [2] CRAN (R 4.1.2)\n#>  foreign                    0.8-84     2022-12-06 [2] CRAN (R 4.1.2)\n#>  Formula                    1.2-5      2023-02-24 [2] CRAN (R 4.1.2)\n#>  fs                         1.6.2      2023-04-25 [2] CRAN (R 4.1.2)\n#>  genefilter                 1.76.0     2021-10-26 [2] Bioconductor\n#>  geneplotter                1.72.0     2021-10-26 [2] Bioconductor\n#>  generics                   0.1.3      2022-07-05 [2] CRAN (R 4.1.2)\n#>  GenomeInfoDb             * 1.30.1     2022-01-30 [2] Bioconductor\n#>  GenomeInfoDbData           1.2.7      2022-03-09 [2] Bioconductor\n#>  GenomicRanges            * 1.46.1     2021-11-18 [2] Bioconductor\n#>  ggbeeswarm                 0.7.2      2023-04-29 [1] CRAN (R 4.1.2)\n#>  ggplot2                  * 3.4.4      2023-10-12 [1] CRAN (R 4.1.3)\n#>  ggrepel                  * 0.9.3      2023-02-03 [1] CRAN (R 4.1.2)\n#>  gld                        2.6.6      2022-10-23 [2] CRAN (R 4.1.2)\n#>  glmnet                     4.1-7      2023-03-23 [2] CRAN (R 4.1.2)\n#>  glue                       1.6.2      2022-02-24 [2] CRAN (R 4.1.2)\n#>  gmp                        0.7-1      2023-02-07 [2] CRAN (R 4.1.2)\n#>  gplots                     3.1.3      2022-04-25 [2] CRAN (R 4.1.2)\n#>  gridExtra                  2.3        2017-09-09 [2] CRAN (R 4.1.0)\n#>  gsl                        2.1-8      2023-01-24 [2] CRAN (R 4.1.2)\n#>  gtable                     0.3.3      2023-03-21 [2] CRAN (R 4.1.2)\n#>  gtools                     3.9.4      2022-11-27 [2] CRAN (R 4.1.2)\n#>  highr                      0.10       2022-12-22 [2] CRAN (R 4.1.2)\n#>  Hmisc                      5.1-0      2023-05-08 [1] CRAN (R 4.1.2)\n#>  hms                        1.1.3      2023-03-21 [2] CRAN (R 4.1.2)\n#>  htmlTable                  2.4.1      2022-07-07 [2] CRAN (R 4.1.2)\n#>  htmltools                  0.5.7      2023-11-03 [1] CRAN (R 4.1.3)\n#>  htmlwidgets                1.6.2      2023-03-17 [2] CRAN (R 4.1.2)\n#>  httpuv                     1.6.11     2023-05-11 [2] CRAN (R 4.1.3)\n#>  httr                       1.4.6      2023-05-08 [2] CRAN (R 4.1.2)\n#>  igraph                     1.5.0      2023-06-16 [1] CRAN (R 4.1.3)\n#>  IRanges                  * 2.28.0     2021-10-26 [2] Bioconductor\n#>  irlba                      2.3.5.1    2022-10-03 [2] CRAN (R 4.1.2)\n#>  iterators                  1.0.14     2022-02-05 [2] CRAN (R 4.1.2)\n#>  jquerylib                  0.1.4      2021-04-26 [2] CRAN (R 4.1.0)\n#>  jsonlite                   1.8.7      2023-06-29 [2] CRAN (R 4.1.3)\n#>  KEGGREST                   1.34.0     2021-10-26 [2] Bioconductor\n#>  KernSmooth                 2.23-22    2023-07-10 [2] CRAN (R 4.1.3)\n#>  knitr                      1.43       2023-05-25 [2] CRAN (R 4.1.3)\n#>  labeling                   0.4.2      2020-10-20 [2] CRAN (R 4.1.0)\n#>  later                      1.3.1      2023-05-02 [2] CRAN (R 4.1.2)\n#>  lattice                    0.21-8     2023-04-05 [2] CRAN (R 4.1.2)\n#>  lazyeval                   0.2.2      2019-03-15 [2] CRAN (R 4.1.0)\n#>  lifecycle                  1.0.3      2022-10-07 [2] CRAN (R 4.1.2)\n#>  limma                      3.50.3     2022-04-07 [2] Bioconductor\n#>  lme4                       1.1-34     2023-07-04 [1] CRAN (R 4.1.3)\n#>  lmerTest                   3.1-3      2020-10-23 [1] CRAN (R 4.1.0)\n#>  lmom                       2.9        2022-05-29 [2] CRAN (R 4.1.2)\n#>  locfit                     1.5-9.8    2023-06-11 [2] CRAN (R 4.1.3)\n#>  lubridate                * 1.9.2      2023-02-10 [2] CRAN (R 4.1.2)\n#>  magrittr                   2.0.3      2022-03-30 [2] CRAN (R 4.1.2)\n#>  MASS                       7.3-60     2023-05-04 [1] CRAN (R 4.1.2)\n#>  Matrix                     1.6-5      2024-01-11 [1] CRAN (R 4.1.3)\n#>  MatrixGenerics           * 1.6.0      2021-10-26 [2] Bioconductor\n#>  matrixStats              * 1.1.0      2023-11-07 [1] CRAN (R 4.1.3)\n#>  memoise                    2.0.1      2021-11-26 [2] CRAN (R 4.1.0)\n#>  metagenomeSeq              1.36.0     2021-10-26 [2] Bioconductor\n#>  mgcv                       1.8-42     2023-03-02 [2] CRAN (R 4.1.2)\n#>  mia                        1.10.0     2023-10-24 [1] Bioconductor\n#>  MicrobiomeAnalysis       * 1.0.3      2023-12-02 [1] Bioconductor\n#>  mime                       0.12       2021-09-28 [2] CRAN (R 4.1.0)\n#>  miniUI                     0.1.1.1    2018-05-18 [2] CRAN (R 4.1.0)\n#>  minqa                      1.2.5      2022-10-19 [2] CRAN (R 4.1.2)\n#>  multcomp                   1.4-25     2023-06-20 [2] CRAN (R 4.1.3)\n#>  MultiAssayExperiment       1.20.0     2021-10-26 [2] Bioconductor\n#>  multtest                   2.50.0     2021-10-26 [2] Bioconductor\n#>  munsell                    0.5.0      2018-06-12 [2] CRAN (R 4.1.0)\n#>  mvtnorm                    1.2-2      2023-06-08 [2] CRAN (R 4.1.3)\n#>  nlme                       3.1-162    2023-01-31 [1] CRAN (R 4.1.2)\n#>  nloptr                     2.0.3      2022-05-26 [2] CRAN (R 4.1.2)\n#>  nnet                       7.3-19     2023-05-03 [2] CRAN (R 4.1.2)\n#>  numDeriv                   2016.8-1.1 2019-06-06 [2] CRAN (R 4.1.0)\n#>  permute                    0.9-7      2022-01-27 [2] CRAN (R 4.1.2)\n#>  phyloseq                   1.38.0     2021-10-26 [2] Bioconductor\n#>  pillar                     1.9.0      2023-03-22 [2] CRAN (R 4.1.2)\n#>  pkgbuild                   1.4.2      2023-06-26 [2] CRAN (R 4.1.3)\n#>  pkgconfig                  2.0.3      2019-09-22 [2] CRAN (R 4.1.0)\n#>  pkgload                    1.3.2.1    2023-07-08 [2] CRAN (R 4.1.3)\n#>  plyr                       1.8.8      2022-11-11 [1] CRAN (R 4.1.2)\n#>  png                        0.1-8      2022-11-29 [2] CRAN (R 4.1.2)\n#>  prettyunits                1.1.1      2020-01-24 [2] CRAN (R 4.1.0)\n#>  processx                   3.8.2      2023-06-30 [2] CRAN (R 4.1.3)\n#>  profvis                    0.3.8      2023-05-02 [2] CRAN (R 4.1.2)\n#>  promises                   1.2.0.1    2021-02-11 [2] CRAN (R 4.1.0)\n#>  proxy                      0.4-27     2022-06-09 [2] CRAN (R 4.1.2)\n#>  ps                         1.7.5      2023-04-18 [2] CRAN (R 4.1.2)\n#>  purrr                    * 1.0.1      2023-01-10 [1] CRAN (R 4.1.2)\n#>  R6                         2.5.1      2021-08-19 [2] CRAN (R 4.1.0)\n#>  rbibutils                  2.2.13     2023-01-13 [2] CRAN (R 4.1.2)\n#>  RColorBrewer               1.1-3      2022-04-03 [1] CRAN (R 4.1.2)\n#>  Rcpp                       1.0.11     2023-07-06 [1] CRAN (R 4.1.3)\n#>  RCurl                      1.98-1.12  2023-03-27 [2] CRAN (R 4.1.2)\n#>  Rdpack                     2.4        2022-07-20 [2] CRAN (R 4.1.2)\n#>  readr                    * 2.1.4      2023-02-10 [1] CRAN (R 4.1.2)\n#>  readxl                     1.4.3      2023-07-06 [2] CRAN (R 4.1.3)\n#>  remotes                    2.4.2      2021-11-30 [2] CRAN (R 4.1.0)\n#>  reshape2                   1.4.4      2020-04-09 [2] CRAN (R 4.1.0)\n#>  rhdf5                      2.38.1     2022-03-10 [2] Bioconductor\n#>  rhdf5filters               1.6.0      2021-10-26 [2] Bioconductor\n#>  Rhdf5lib                   1.16.0     2021-10-26 [2] Bioconductor\n#>  rlang                      1.1.1      2023-04-28 [1] CRAN (R 4.1.2)\n#>  rmarkdown                  2.23       2023-07-01 [2] CRAN (R 4.1.3)\n#>  Rmpfr                      0.9-2      2023-04-22 [2] CRAN (R 4.1.2)\n#>  rngtools                   1.5.2      2021-09-20 [2] CRAN (R 4.1.0)\n#>  rootSolve                  1.8.2.3    2021-09-29 [2] CRAN (R 4.1.0)\n#>  ropls                    * 1.26.4     2022-01-11 [2] Bioconductor\n#>  rpart                      4.1.19     2022-10-21 [2] CRAN (R 4.1.2)\n#>  RSQLite                    2.3.1      2023-04-03 [2] CRAN (R 4.1.2)\n#>  rstudioapi                 0.15.0     2023-07-07 [2] CRAN (R 4.1.3)\n#>  rsvd                       1.0.5      2021-04-16 [2] CRAN (R 4.1.0)\n#>  S4Vectors                * 0.32.4     2022-03-29 [2] Bioconductor\n#>  sandwich                   3.0-2      2022-06-15 [2] CRAN (R 4.1.2)\n#>  sass                       0.4.6      2023-05-03 [2] CRAN (R 4.1.2)\n#>  ScaledMatrix               1.2.0      2021-10-26 [2] Bioconductor\n#>  scales                     1.2.1      2022-08-20 [1] CRAN (R 4.1.2)\n#>  scater                     1.22.0     2021-10-26 [2] Bioconductor\n#>  scuttle                    1.4.0      2021-10-26 [2] Bioconductor\n#>  sessioninfo                1.2.2      2021-12-06 [2] CRAN (R 4.1.0)\n#>  shape                      1.4.6      2021-05-19 [2] CRAN (R 4.1.0)\n#>  shiny                      1.7.4.1    2023-07-06 [2] CRAN (R 4.1.3)\n#>  SingleCellExperiment       1.16.0     2021-10-26 [2] Bioconductor\n#>  sparseMatrixStats          1.6.0      2021-10-26 [2] Bioconductor\n#>  stringi                    1.7.12     2023-01-11 [2] CRAN (R 4.1.2)\n#>  stringr                  * 1.5.1      2023-11-14 [1] CRAN (R 4.1.3)\n#>  SummarizedExperiment     * 1.24.0     2021-10-26 [2] Bioconductor\n#>  survival                   3.5-5      2023-03-12 [2] CRAN (R 4.1.2)\n#>  TH.data                    1.1-2      2023-04-17 [2] CRAN (R 4.1.2)\n#>  tibble                   * 3.2.1      2023-03-20 [1] CRAN (R 4.1.2)\n#>  tidyr                    * 1.3.0      2023-01-24 [1] CRAN (R 4.1.2)\n#>  tidyselect                 1.2.0      2022-10-10 [2] CRAN (R 4.1.2)\n#>  tidytree                   0.4.2      2022-12-18 [2] CRAN (R 4.1.2)\n#>  tidyverse                * 2.0.0      2023-02-22 [1] CRAN (R 4.1.2)\n#>  timechange                 0.2.0      2023-01-11 [2] CRAN (R 4.1.2)\n#>  treeio                     1.18.1     2021-11-14 [2] Bioconductor\n#>  TreeSummarizedExperiment   2.2.0      2021-10-26 [2] Bioconductor\n#>  tzdb                       0.4.0      2023-05-12 [2] CRAN (R 4.1.3)\n#>  urlchecker                 1.0.1      2021-11-30 [2] CRAN (R 4.1.0)\n#>  usethis                    2.2.2      2023-07-06 [2] CRAN (R 4.1.3)\n#>  utf8                       1.2.3      2023-01-31 [2] CRAN (R 4.1.2)\n#>  vctrs                      0.6.5      2023-12-01 [1] CRAN (R 4.1.3)\n#>  vegan                      2.6-4      2022-10-11 [1] CRAN (R 4.1.2)\n#>  vipor                      0.4.5      2017-03-22 [2] CRAN (R 4.1.0)\n#>  viridis                    0.6.3      2023-05-03 [2] CRAN (R 4.1.2)\n#>  viridisLite                0.4.2      2023-05-02 [2] CRAN (R 4.1.2)\n#>  withr                      2.5.0      2022-03-03 [2] CRAN (R 4.1.2)\n#>  Wrench                     1.12.0     2021-10-26 [2] Bioconductor\n#>  xfun                       0.40       2023-08-09 [1] CRAN (R 4.1.3)\n#>  XML                        3.99-0.14  2023-03-19 [2] CRAN (R 4.1.2)\n#>  xml2                       1.3.5      2023-07-06 [2] CRAN (R 4.1.3)\n#>  xtable                     1.8-4      2019-04-21 [2] CRAN (R 4.1.0)\n#>  XVector                    0.34.0     2021-10-26 [2] Bioconductor\n#>  yaml                       2.3.7      2023-01-23 [2] CRAN (R 4.1.2)\n#>  yulab.utils                0.0.6      2022-12-20 [2] CRAN (R 4.1.2)\n#>  zlibbioc                   1.40.0     2021-10-26 [2] Bioconductor\n#>  zoo                        1.8-12     2023-04-13 [2] CRAN (R 4.1.2)\n#> \n#>  [1] /Users/zouhua/Library/R/x86_64/4.1/library\n#>  [2] /Library/Frameworks/R.framework/Versions/4.1/Resources/library\n#> \n#> ──────────────────────────────────────────────────────────"},{"path":"DifferetialAnalysis.html","id":"reference-9","chapter":"11 Differetial Analysis","heading":"11.13 Reference","text":"FC/T检验/PLS-DA筛选差异代谢物方法介绍","code":""},{"path":"FunctionalAnalysis.html","id":"FunctionalAnalysis","chapter":"12 Functional Analysis","heading":"12 Functional Analysis","text":"代谢物通路包含了基因、催化酶或代谢物等上下游关系的先验知识，通过将关心的代谢物比对到通路上，再根据如超级几何分析等数学方法计算受影响的代谢物是否能够影响通路。代谢物富集分析的目的是为了解析某些差异代谢物是否落在某些pathway上（可简单理解为单个差异代谢物解释pathway较弱，同一pathway的代谢物共同解释该通路变化则证据较为robust，在很多生物领域均存在类似的处理逻辑），进而影响pathway的功能。基于pathway可分析代谢物的上下游基因或酶等影响，最终阐明作用机制。代谢组服务公司反馈回来的代谢组表一般是基于intensity也即是质谱峰强度的数据，需要做前处理方可使用。本次使用直接处理后的数据用于分析。功能分析方法主流有三类：ORA (-Representative analysis)：将表达基因ORA放置在通路内，通过超级几何检验判断这些基因是否随机出现在通路内，从而判断功能是否富集ORA (-Representative analysis)：将表达基因ORA放置在通路内，通过超级几何检验判断这些基因是否随机出现在通路内，从而判断功能是否富集GSEA (Gene set enrichment analysis)：将所有基因按照log2foldchange的可以排序基因顺序的指标排序，再计算它们出现在每个通路的累积富集分数GSEA (Gene set enrichment analysis)：将所有基因按照log2foldchange的可以排序基因顺序的指标排序，再计算它们出现在每个通路的累积富集分数ssGSEA (single sample Gene set enrichment analysis)：将每个样本的基因或代谢物表达值作为输入文件，结合对应通路数据库list，再计算每个通路的每个样本的累积富集分数ssGSEA (single sample Gene set enrichment analysis)：将每个样本的基因或代谢物表达值作为输入文件，结合对应通路数据库list，再计算每个通路的每个样本的累积富集分数注意：代谢组ID也有类似基因ID的多平台多命名问题，可以参考类似的名称转换工具包。本次直接使用cpdid，可直接用于KEGG COMPOUND数据库。","code":""},{"path":"FunctionalAnalysis.html","id":"加载r包-8","chapter":"12 Functional Analysis","heading":"12.1 加载R包","text":"","code":"\nknitr::opts_chunk$set(message = FALSE, warning = FALSE)\nlibrary(tidyverse)\nlibrary(massdatabase)\nlibrary(clusterProfiler)\nlibrary(MicrobiomeProfiler)\n\n# rm(list = ls())\noptions(stringsAsFactors = F)\noptions(future.globals.maxSize = 1000 * 1024^2)\n\ngrp_names <- c(\"None\", \"Mild\", \"Moderate\", \"Severe\")\ngrp_colors <- c(\"#7DD06F\", \"#844081\", \"#688EC1\", \"#C17E73\")"},{"path":"FunctionalAnalysis.html","id":"导入数据-6","chapter":"12 Functional Analysis","heading":"12.2 导入数据","text":"对数据OmicsDataSet-Zeybel et al. - 2022.xlsx处理后生成的，可参考数据预处理等章节。","code":"\nwrite.table(final_res, \"./InputData/result/DA/Metabolites_FC_VIP_ttest.tsv\", \nrow.names = F, quote = F, sep = \"\\t\", fileEncoding = \"UTF-8\")\ndatSignif <- data.table::fread(\"./InputData/result/DA/Metabolites_FC_VIP_ttest.tsv\")\n\n# DT::datatable(datSignif)\n\nhead(datSignif)\n#>                                         FeatureID\n#> 1: ceramide (d18:1/20:0, d16:1/22:0, d20:1/18:0)*\n#> 2:                 cysteine-glutathione disulfide\n#> 3:                                         serine\n#> 4:          1-palmitoyl-2-oleoyl-GPI (16:0/18:1)*\n#> 5:           1-stearoyl-2-oleoyl-GPI (18:0/18:1)*\n#> 6:     palmitoyl-oleoyl-glycerol (16:0/18:1) [2]*\n#>            Block2                Block FoldChange\n#> 1: None vs Severe 10_None vs 12_Severe  0.6444244\n#> 2: None vs Severe 10_None vs 12_Severe  1.7109000\n#> 3: None vs Severe 10_None vs 12_Severe  1.2218596\n#> 4: None vs Severe 10_None vs 12_Severe  0.5199556\n#> 5: None vs Severe 10_None vs 12_Severe  0.5667863\n#> 6: None vs Severe 10_None vs 12_Severe  0.5638085\n#>    Log2FoldChange      VIP    CorPvalue Statistic\n#> 1:     -0.6339170 2.672936 8.114814e-05 -4.854409\n#> 2:      0.7747554 2.601041 1.550944e-04  4.858307\n#> 3:      0.2890785 2.541717 2.544812e-04  4.456220\n#> 4:     -0.9435396 2.549095 2.397091e-04 -4.400999\n#> 5:     -0.8191231 2.469432 4.460156e-04 -4.108909\n#> 6:     -0.8267228 2.369314 9.073991e-04 -3.748881\n#>          Pvalue AdjustedPvalue Mean Abundance (All)\n#> 1: 0.0001301058     0.04202417              3841099\n#> 2: 0.0001184340     0.04202417              1246453\n#> 3: 0.0002529654     0.05447188             63358904\n#> 4: 0.0003436084     0.05549276              2243154\n#> 5: 0.0007169002     0.09262350              1817773\n#> 6: 0.0019076334     0.17057034              1192929\n#>    Mean Abundance None Mean Abundance Severe  metabolitesID\n#> 1:           2952496.1             4581602.1 Chem_100015755\n#> 2:           1611743.8              942044.4 Chem_100001437\n#> 3:          70323857.2            57554776.3       Chem_503\n#> 4:           1491869.7             2869225.1 Chem_100009066\n#> 5:           1282914.5             2263488.8 Chem_100009181\n#> 6:            838913.8             1487941.0 Chem_100010917\n#>                                       BIOCHEMICAL\n#> 1: ceramide (d18:1/20:0, d16:1/22:0, d20:1/18:0)*\n#> 2:                 cysteine-glutathione disulfide\n#> 3:                                         serine\n#> 4:          1-palmitoyl-2-oleoyl-GPI (16:0/18:1)*\n#> 5:           1-stearoyl-2-oleoyl-GPI (18:0/18:1)*\n#> 6:     palmitoyl-oleoyl-glycerol (16:0/18:1) [2]*\n#>    SUPER.PATHWAY                              SUB.PATHWAY\n#> 1:         Lipid                                Ceramides\n#> 2:    Amino Acid                   Glutathione Metabolism\n#> 3:    Amino Acid Glycine, Serine and Threonine Metabolism\n#> 4:         Lipid                Phosphatidylinositol (PI)\n#> 5:         Lipid                Phosphatidylinositol (PI)\n#> 6:         Lipid                           Diacylglycerol\n#>    COMPID        PLATFORM CHEMICALID   RI     MASS  PUBCHEM\n#> 1:  57440  LC/MS Pos Late  100015755 3920 594.5820     <NA>\n#> 2:  35159 LC/MS Pos Early  100001437 2465 427.0952  3080690\n#> 3:   1648 LC/MS Pos Early        503 1239 106.0499     5951\n#> 4:  52669  LC/MS Pos Late  100009066 3140 854.5753 71296232\n#> 5:  52726  LC/MS Pos Late  100009181 3711 882.6066     <NA>\n#> 6:  54942  LC/MS Pos Late  100010917 3695 612.5562  5282283\n#>           CAS   KEGG SampleIDHMDBID\n#> 1:       <NA>   <NA>           <NA>\n#> 2: 13081-14-6 R00900    HMDB0000656\n#> 3:    56-45-1 C00065    HMDB0000187\n#> 4:       <NA>   <NA>    HMDB0009783\n#> 5:       <NA>   <NA>           <NA>\n#> 6:       <NA> C13861    HMDB0007102"},{"path":"FunctionalAnalysis.html","id":"获取kegg-pathway和代谢物id对应关系","chapter":"12 Functional Analysis","heading":"12.3 获取KEGG pathway和代谢物ID对应关系","text":"下载KEGG pathway对应的compound信息。本次分析是针对人，因此在选择pathway的时候物种设置为人下载KEGG pathway对应的compound信息。本次分析是针对人，因此在选择pathway的时候物种设置为人读取每个pathway包含的compound后，整理成pathway和compound一一对应的关系表读取每个pathway包含的compound后，整理成pathway和compound一一对应的关系表合并1和2步骤为一个脚本，步骤1推荐使用massdatabaseR包，该步是为了获取特定物种的pathway和compound对应关系","code":"\nget_kegg_pathway_compound <- function(\n    org_id = c(\"hsa\", \"mmu\")) {\n  \n  pathway_names <- request_kegg_pathway_info(organism = org_id)\n  \n  res <- data.frame()\n  for (i in 1:nrow(pathway_names)) {\n    temp_pathway <- request_kegg_pathway(pathway_id = pathway_names$KEGG.ID[i])\n    temp_colnames <- names(temp_pathway)\n    if (all(c(\"COMPOUND\", \"ENTRY\", \"NAME\", \"CLASS\", \"PATHWAY_MAP\") %in% temp_colnames)) {\n      print(i)\n      temp_compound <- temp_pathway$COMPOUND\n      temp_class <- unlist(strsplit(temp_pathway$CLASS, \"; \"))\n      temp_df1 <- data.frame(Pathway = temp_pathway$ENTRY,\n                             NAME = temp_pathway$NAME,\n                             #DESCRIPTION = temp_pathway$DESCRIPTION,\n                             CLASS1 = temp_class[1],\n                             CLASS2 = temp_class[2],\n                             PATHWAY_MAP = temp_pathway$PATHWAY_MAP)\n      temp_df2 <- data.frame(Pathway = rep(temp_pathway$ENTRY, length(temp_compound)),\n                             COMPOUND = names(temp_compound),\n                             COMPOUND_DESCRIPTION = temp_compound)\n      \n      temp_df <- temp_df1 %>%\n        dplyr::full_join(temp_df2, by = \"Pathway\")\n      \n      res <- rbind(res, temp_df)\n    }\n  }\n  \n  return(res)\n}\n\nif(!dir.exists(\"./InputData/result/KEGG/\")) {\n  dir.create(\"./InputData/result/KEGG/\", recursive = TRUE)\n}\n\nif (file.exists(\"./InputData/result/KEGG/KEGG_COMPOUND_PATHWAY_hsa.csv\")) {\n  hsa_kegg_compound <- read.csv(\"./InputData/result/KEGG/KEGG_COMPOUND_PATHWAY_hsa.csv\") \n} else {\n  hsa_kegg_compound <- get_kegg_pathway_compound(org_id = \"hsa\")\n  write.csv(hsa_kegg_compound, \"./InputData/result/KEGG/KEGG_COMPOUND_PATHWAY_hsa.csv\", row.names = F)\n}\n\n# DT::datatable(hsa_kegg_compound)\n\nhead(hsa_kegg_compound)\n#>    Pathway\n#> 1 hsa00010\n#> 2 hsa00010\n#> 3 hsa00010\n#> 4 hsa00010\n#> 5 hsa00010\n#> 6 hsa00010\n#>                                                  NAME\n#> 1 Glycolysis / Gluconeogenesis - Homo sapiens (human)\n#> 2 Glycolysis / Gluconeogenesis - Homo sapiens (human)\n#> 3 Glycolysis / Gluconeogenesis - Homo sapiens (human)\n#> 4 Glycolysis / Gluconeogenesis - Homo sapiens (human)\n#> 5 Glycolysis / Gluconeogenesis - Homo sapiens (human)\n#> 6 Glycolysis / Gluconeogenesis - Homo sapiens (human)\n#>       CLASS1                  CLASS2\n#> 1 Metabolism Carbohydrate metabolism\n#> 2 Metabolism Carbohydrate metabolism\n#> 3 Metabolism Carbohydrate metabolism\n#> 4 Metabolism Carbohydrate metabolism\n#> 5 Metabolism Carbohydrate metabolism\n#> 6 Metabolism Carbohydrate metabolism\n#>                    PATHWAY_MAP COMPOUND\n#> 1 Glycolysis / Gluconeogenesis   C00022\n#> 2 Glycolysis / Gluconeogenesis   C00024\n#> 3 Glycolysis / Gluconeogenesis   C00031\n#> 4 Glycolysis / Gluconeogenesis   C00033\n#> 5 Glycolysis / Gluconeogenesis   C00036\n#> 6 Glycolysis / Gluconeogenesis   C00068\n#>   COMPOUND_DESCRIPTION\n#> 1             Pyruvate\n#> 2           Acetyl-CoA\n#> 3            D-Glucose\n#> 4              Acetate\n#> 5         Oxaloacetate\n#> 6  Thiamin diphosphate"},{"path":"FunctionalAnalysis.html","id":"差异代谢物筛选","chapter":"12 Functional Analysis","heading":"12.4 差异代谢物筛选","text":"根据ORA或GSEA的原理，可以选择上下调差异代谢物或者按照log2foldchange排序好的代谢物用于差异分析none: 所有代谢物none: 所有代谢物all: 所有差异代谢物all: 所有差异代谢物up (UpRegulated): 上调差异代谢物up (UpRegulated): 上调差异代谢物down (DownRegulated): 下调差异代谢物down (DownRegulated): 下调差异代谢物","code":"\nget_significant <- function(\n    dat,\n    group_names,\n    lg2fc_cutoff = 0.5,\n    pval_cutoff = 0.05,\n    qval_cutoff = 0.3) {\n\n  dat_group <- dat %>%\n    dplyr::filter(Block2 %in% paste(group_names, collapse = \" vs \")) %>%\n    dplyr::distinct()\n  \n  # remove KEGG eq \"-\" or NA\n  dat_fa <- dat_group %>% \n    dplyr::filter(KEGG != \"-\") %>%\n    dplyr::filter(!is.na(KEGG)) %>%\n    dplyr::rename(cpd_ID = KEGG)\n  \n  colnames(dat_fa)[which(colnames(dat_fa) == \"Log2FoldChange\")] <- \"lg2fc\" # Log2FoldChange (Median)\n  colnames(dat_fa)[which(colnames(dat_fa) == \"Pvalue\")] <- \"pval\"\n  colnames(dat_fa)[which(colnames(dat_fa) == \"AdjustedPvalue\")] <- \"qval\"\n  \n  # convert NA into 1\n  dat_fa$qval[is.na(dat_fa$qval)] <- 1\n  \n  # enrichment by beta and Pvalue AdjustedPvalue\n  dat_fa[which(dat_fa$lg2fc > lg2fc_cutoff &\n              dat_fa$pval < pval_cutoff &\n              dat_fa$qval < qval_cutoff),\n      \"EnrichedDir\"] <- group_names[1]\n  dat_fa[which(dat_fa$lg2fc < -lg2fc_cutoff &\n              dat_fa$pval < pval_cutoff &\n              dat_fa$qval < qval_cutoff),\n      \"EnrichedDir\"] <- group_names[2]\n  dat_fa[which(abs(dat_fa$lg2fc) <= lg2fc_cutoff |\n              dat_fa$pval >= pval_cutoff |\n              dat_fa$qval >= qval_cutoff),\n      \"EnrichedDir\"] <- \"Nonsignif\"\n\n  # dat status\n  dat_fa$EnrichedDir <- factor(dat_fa$EnrichedDir,\n                            levels = c(group_names[1], \"Nonsignif\", group_names[2]))\n  df_status <- table(dat_fa$EnrichedDir) %>% data.frame() %>%\n    stats::setNames(c(\"Group\", \"Number\"))\n  grp1_number <- with(df_status, df_status[Group %in% group_names[1], \"Number\"])\n  grp2_number <- with(df_status, df_status[Group %in% group_names[2], \"Number\"])\n  nsf_number <- with(df_status, df_status[Group %in% \"Nonsignif\", \"Number\"])\n  legend_label <- c(paste0(group_names[1], \" (\", grp1_number, \")\"),\n                    paste0(\"Nonsignif\", \" (\", nsf_number, \")\"),\n                    paste0(group_names[2], \" (\", grp2_number, \")\"))\n\n  # significant features\n  dat_signif <- dat_fa %>%\n    dplyr::arrange(lg2fc, pval, qval) %>%\n    dplyr::filter(pval < pval_cutoff) %>%\n    dplyr::filter(qval < qval_cutoff) %>%\n    dplyr::filter(abs(lg2fc) > lg2fc_cutoff) %>%\n    dplyr::select(FeatureID, Block, EnrichedDir, lg2fc, pval, qval, cpd_ID, everything()) %>%\n    dplyr::mutate(FeatureID = gsub(\"\\\\.\", \"-\", FeatureID))\n  \n  # print(table(dat_signif$EnrichedDir))\n\n  res_up <- dat_signif %>% # enriched in 1st group\n    dplyr::filter(EnrichedDir == group_names[1]) %>%\n    dplyr::mutate(Status = \"UpRegulated\")\n\n  res_down <- dat_signif %>% # enriched in 2st group\n    dplyr::filter(EnrichedDir == group_names[2]) %>%\n    dplyr::mutate(Status = \"DownRegulated\")\n\n  res <- list(none = dat_fa %>%\n                dplyr::select(FeatureID, Block, EnrichedDir, lg2fc, pval, qval, cpd_ID, everything()),\n              all = dat_signif,\n              up = res_up,\n              down = res_down)\n\n  return(res)\n}"},{"path":"FunctionalAnalysis.html","id":"富集分析","chapter":"12 Functional Analysis","heading":"12.5 富集分析","text":"用ClusterProfiler提供的enrichr和GESA做分析，这两个函数可自行配置输入pathway database，然后采用超几何检验和富集rank得分评估富集状况。除了常见的KEGG 通路富集分析外，还可以有Gene Ontology和MSigDB Hallmark gene sets等富集分析数据库。Gene Ontology: Biological Process (BP), Cellular Component (CC) 和 Molecular Function (MF)ORA: 差异代谢物的超级几何检验ORA: 差异代谢物的超级几何检验GSEA: 排好序的代谢物的富集rank打分GSEA: 排好序的代谢物的富集rank打分","code":"\nget_enrichment <- function(\n  dat,\n  ref,\n  group_names,\n  direction = c(\"none\", \"All\", \"DownRegulated\", \"UpRegulated\"), # DownRegulated->1st group; UpRegulated->2nd group \n  lg2fc_cutoff = 0.5,\n  pval_cutoff = 0.05,\n  qval_cutoff = 0.05,\n  enrich_type = c(\"ORA\", \"GSEA\")) {\n  \n  \n  temp_input <- get_significant(\n    dat = dat,\n    group_names = group_names,\n    lg2fc_cutoff = lg2fc_cutoff,\n    pval_cutoff = pval_cutoff,\n    qval_cutoff = qval_cutoff)  \n  \n  if (direction == \"All\") {\n    inputdata <- temp_input$all\n  } else if (direction == \"UpRegulated\") {\n    inputdata <- temp_input$up\n  } else if (direction == \"DownRegulated\") {\n    inputdata <- temp_input$down\n  } else if (direction == \"none\") {\n    inputdata <- temp_input$none\n  } \n  if (nrow(inputdata) == 0) {\n    stop(\"Beyond these thresholds, no significant metabolites were selected\")\n  }  \n  \n  inputdata$cpd_ID <- gsub(\"\\\\s+\\\\|\\\\s+\\\\w+\\\\d+\", \"\", inputdata$cpd_ID)\n  inputdata$cpd_ID <- gsub(\",\\\\S+\", \"\", inputdata$cpd_ID)\n  \n  ref_cln <- ref %>%\n    dplyr::select(PATHWAY_MAP, COMPOUND) %>%\n    dplyr::rename(Pathway = PATHWAY_MAP)\n\n  if (enrich_type == \"ORA\") {\n    fit <- clusterProfiler::enricher(\n                gene = inputdata$cpd_ID,\n                pvalueCutoff = 0.05,\n                pAdjustMethod = \"BH\",\n                minGSSize = 10,\n                maxGSSize = 500,\n                qvalueCutoff = 0.2,\n                TERM2GENE = ref_cln)\n  } else if (enrich_type == \"GSEA\") {\n    dat_GSEA <- inputdata %>%\n      dplyr::arrange(desc(lg2fc))\n    cpd_lg2fc <- dat_GSEA$lg2fc\n    names(cpd_lg2fc) <- dat_GSEA$cpd_ID\n    fit <- clusterProfiler::GSEA(\n                geneList = cpd_lg2fc,\n                pvalueCutoff = 0.05,\n                pAdjustMethod = \"BH\",\n                minGSSize = 10,\n                maxGSSize = 500,\n                TERM2GENE = ref_cln)\n  }\n\n  if (nrow(fit@result) != 0) {\n    if (enrich_type == \"ORA\") {\n      EA_res <- fit@result %>%\n        dplyr::filter(!is.na(Description)) %>%\n        dplyr::rename(CompoundRatio = GeneRatio,\n                      CompoundID = geneID,\n                      NAME = Description) %>%\n        dplyr::select(ID, NAME, everything())      \n    } else if (enrich_type == \"GSEA\") {\n      EA_res <- fit@result %>%\n        dplyr::filter(!is.na(Description)) %>%\n        dplyr::rename(NAME = Description) %>%\n        dplyr::select(ID, NAME, everything())       \n    }\n  } else {\n    EA_res <- NULL\n  }\n\n  res <- list(data = inputdata,\n              enrich = EA_res)\n\n  return(res)\n}"},{"path":"FunctionalAnalysis.html","id":"可视化通路","chapter":"12 Functional Analysis","heading":"12.6 可视化通路","text":"画气泡图或者条形图，根据qvalue和CompoundRatio以及Count画图","code":"\nplot_enrichment <- function(\n    inputdata,\n    qval_cutoff = 0.05,\n    topN = 10,\n    plot_type = c(\"bubble\", \"bar\"),\n    enrich_type = c(\"ORA\", \"GSEA\")) {\n  \n  if (nrow(inputdata) == 0) {\n    stop(\"No pathway please check your input\")\n  }  \n  \n  if (enrich_type == \"ORA\") {\n    \n    if (any(is.na(inputdata$qvalue))) {\n      inputdata$qvalue <- inputdata$p.adjust\n    }\n    \n    plotdata_temp <- inputdata %>%\n      # dplyr::select(ID, NAME, CompoundRatio, qvalue, Count, CLASS1, CLASS2, PATHWAY_MAP) %>%\n      dplyr::select(ID, NAME, CompoundRatio, qvalue, Count) %>%      \n      dplyr::filter(qvalue < qval_cutoff)\n    \n    if (nrow(plotdata_temp) == 0) {\n      stop(\"No pathway met the threshold of qvalue\")\n    }    \n      \n    plotdata <- plotdata_temp %>%  \n      dplyr::slice(1:topN) %>%\n      dplyr::mutate(qvalue = as.numeric(qvalue),\n                    Count = as.numeric(Count)) %>%\n      dplyr::group_by(ID) %>%\n      dplyr::mutate(CompoundRatio1 = unlist(strsplit(CompoundRatio, \"/\"))[1],\n                    CompoundRatio2 = unlist(strsplit(CompoundRatio, \"/\"))[2],\n                    CompoundRatio = as.numeric(CompoundRatio1) / as.numeric(CompoundRatio2)) %>%\n      dplyr::select(-dplyr::all_of(c(\"CompoundRatio1\", \"CompoundRatio2\"))) %>%\n      dplyr::mutate(NAME = gsub(\" - Mus musculus \\\\(house mouse\\\\)\", \"\", NAME)) %>%\n      dplyr::arrange(CompoundRatio)  %>%\n      dplyr::rename(Yvalue = CompoundRatio)\n    y_lab <- \"CompoundRatio\"\n  } else if (enrich_type == \"GSEA\") {\n    if (any(is.na(inputdata$qvalue))) {\n      inputdata$qvalues <- inputdata$p.adjust\n    }    \n    plotdata_temp <- inputdata %>%\n      # dplyr::select(ID, NAME, enrichmentScore, qvalues, setSize, CLASS1, CLASS2, PATHWAY_MAP) %>%\n      dplyr::select(ID, NAME, enrichmentScore, qvalues, setSize) %>%      \n      dplyr::filter(qvalues < qval_cutoff)\n    \n    if (nrow(plotdata_temp) == 0) {\n      stop(\"No pathway met the threshold of qvalue\")\n    }    \n      \n    plotdata <- plotdata_temp %>%  \n      dplyr::slice(1:topN) %>%\n      dplyr::rename(qvalue = qvalues,\n                    Count = setSize) %>%\n      dplyr::mutate(qvalue = as.numeric(qvalue),\n                    Count = as.numeric(Count),\n                    enrichmentScore = as.numeric(enrichmentScore)) %>%\n      dplyr::mutate(NAME = gsub(\" - Mus musculus \\\\(house mouse\\\\)\", \"\", NAME)) %>%\n      dplyr::arrange(enrichmentScore) %>%\n      dplyr::rename(Yvalue = enrichmentScore)\n    y_lab <- \"enrichmentScore\"\n  } \n\n  plotdata$NAME <- factor(plotdata$NAME, levels = as.character(plotdata$NAME))\n  \n  final_topN <- nrow(plotdata)\n  \n  if (plot_type == \"bubble\") {\n    pl <- ggplot(plotdata, aes(x = NAME, y = Yvalue)) +\n      geom_point(aes(size = Count, color = qvalue)) +\n      coord_flip() + \n      labs(x = \"\", y = y_lab, title = paste(\"Top\", final_topN, \"of Enrichment\")) +\n      theme_bw() +\n      guides(size = guide_legend(order = 1),\n             color = guide_legend(order = 2))+\n      scale_color_gradientn(name = \"q value\", \n                            colours = rainbow(5)) +\n      theme(plot.title = element_text(face = 'bold', size = 12, hjust = .5),\n            axis.title = element_text(face = 'bold', size = 11),\n            axis.text.y = element_text(face = 'bold', size = 10),\n            legend.position = \"right\")    \n  } else if (plot_type == \"bar\") {\n    pl <- ggplot(plotdata, aes(x = NAME, y = Yvalue, fill = -log(qvalue))) +\n      geom_bar(stat = \"identity\", position = position_dodge()) +\n      coord_flip() + \n      labs(x = \"\", y = y_lab, title = paste(\"Top\", final_topN, \"of Enrichment\")) +\n      theme_bw() +\n      guides(fill = guide_legend(order = 1))+\n      scale_color_gradientn(name = \"-log10(q value)\",\n                            colours = rainbow(5)) +\n      theme(plot.title = element_text(face = 'bold', size = 12, hjust = .5),\n            axis.title = element_text(face = 'bold', size = 11),\n            axis.text.y = element_text(face = 'bold', size = 10),\n            legend.position = \"right\")      \n  }\n  \n  return(pl)\n}"},{"path":"FunctionalAnalysis.html","id":"案例-1","chapter":"12 Functional Analysis","heading":"12.7 案例","text":"比较”None”和”Severe”两组的差异代谢物在KEGG通路上是否显著富集。在明确富集通路后，可聚焦在这些通路的代谢物，通过解析上下游代谢物的变化，进而阐明潜在的生物学机制。ORA: 所有差异代谢物富集分析结果结果：在设置提取差异代谢物阈值后，可以得知ORA结果下有118, 9条通路存在，再根据qvalue卡差异通路即可。差异代谢物涉及到的通路差异代谢物涉及到的通路超级几何检验后得到的统计结果pvalue等超级几何检验后得到的统计结果pvalue等结果：从上述富集通路看，ABC transporters可通过代谢Tryptophan产生影响宿主的物质如(该通路涉及到的31个代谢物)sucrose/myo-inositol/glycerol/arginine/alanine/sulfate\n/heme/uridine/betaine/taurine/maltose/histidine/cystine\n/deoxycarnitine/maltotriose/valine/phenylalanine/erythritol\n/glutamine/glucose/phosphate/leucine/serine/threonine/urea\n/choline/ornithine/glycine/aspartate/hydroxyproline/fructose综上，可对富集在该通路的代谢物的上下游基因或酶做进一步研究。GSEA: 所有差异代谢物富集分析结果","code":"\nORA_res <- get_enrichment(\n  dat = datSignif,\n  ref = hsa_kegg_compound,\n  group = grp_names[c(1, 4)],\n  direction = \"All\",  \n  lg2fc_cutoff = 0,\n  pval_cutoff = 0.5,\n  qval_cutoff = 1,\n  enrich_type = \"ORA\")\n\nhead(ORA_res$enrich[, 1:6])\n#>                                                                                      ID\n#> Central carbon metabolism in cancer                 Central carbon metabolism in cancer\n#> Protein digestion and absorption                       Protein digestion and absorption\n#> Mineral absorption                                                   Mineral absorption\n#> ABC transporters                                                       ABC transporters\n#> Aminoacyl-tRNA biosynthesis                                 Aminoacyl-tRNA biosynthesis\n#> Alanine, aspartate and glutamate metabolism Alanine, aspartate and glutamate metabolism\n#>                                                                                    NAME\n#> Central carbon metabolism in cancer                 Central carbon metabolism in cancer\n#> Protein digestion and absorption                       Protein digestion and absorption\n#> Mineral absorption                                                   Mineral absorption\n#> ABC transporters                                                       ABC transporters\n#> Aminoacyl-tRNA biosynthesis                                 Aminoacyl-tRNA biosynthesis\n#> Alanine, aspartate and glutamate metabolism Alanine, aspartate and glutamate metabolism\n#>                                             CompoundRatio\n#> Central carbon metabolism in cancer                16/119\n#> Protein digestion and absorption                   15/119\n#> Mineral absorption                                 12/119\n#> ABC transporters                                   22/119\n#> Aminoacyl-tRNA biosynthesis                        13/119\n#> Alanine, aspartate and glutamate metabolism        10/119\n#>                                              BgRatio\n#> Central carbon metabolism in cancer          37/3527\n#> Protein digestion and absorption             47/3527\n#> Mineral absorption                           29/3527\n#> ABC transporters                            139/3527\n#> Aminoacyl-tRNA biosynthesis                  52/3527\n#> Alanine, aspartate and glutamate metabolism  28/3527\n#>                                                   pvalue\n#> Central carbon metabolism in cancer         7.256749e-15\n#> Protein digestion and absorption            1.044883e-11\n#> Mineral absorption                          3.993588e-11\n#> ABC transporters                            5.026872e-10\n#> Aminoacyl-tRNA biosynthesis                 7.958555e-09\n#> Alanine, aspartate and glutamate metabolism 1.029863e-08\n#>                                                 p.adjust\n#> Central carbon metabolism in cancer         8.562964e-13\n#> Protein digestion and absorption            6.164812e-10\n#> Mineral absorption                          1.570811e-09\n#> ABC transporters                            1.482927e-08\n#> Aminoacyl-tRNA biosynthesis                 1.878219e-07\n#> Alanine, aspartate and glutamate metabolism 2.025397e-07\nORA_bubble <- plot_enrichment(\n    inputdata = ORA_res$enrich,\n    qval_cutoff = 0.05,\n    topN = 10,\n    plot_type = \"bubble\",\n    enrich_type = \"ORA\") \n\nORA_bubble\nGSEA_res <- get_enrichment(\n  dat = datSignif,\n  ref = hsa_kegg_compound,\n  group = grp_names[c(1, 4)],\n  direction = \"none\",  \n  lg2fc_cutoff = 0,\n  pval_cutoff = 1,\n  qval_cutoff = 1,\n  enrich_type = \"GSEA\")\n\nhead(GSEA_res$enrich[, 1:6])"},{"path":"FunctionalAnalysis.html","id":"问题","chapter":"12 Functional Analysis","heading":"12.8 问题","text":"上述参考数据库是基于human的，而本次数据是人肠道粪便的代谢组，它们大多数是来自于微生物。为了更精确计算富集结果，这里采用MicrobiomeProfiler提供的代谢物参考数据库先前有想过把所有微生物涉及到的代谢物和通路的对应关系提取出来，但是太麻烦了，后来找到了MicrobiomeProfiler包，它里面提供微生物代谢组数据库只需要对上述get_enrichment函数修改参考数据库即可，但它目前只提供ORA的方法(下方是沟通的邮件对话)。询问Hi，Meijun老师您好，您开发的MicrobiomeProfiler极大方便了微生物的代谢物等的功能富集分析。作为受益者，对此表示非常感谢，生信领域因为有你们这样优秀的开发者而更加美好。现在有2个问题想咨询下您：\n在KEGG pathway数据库中，不同的物种对应不同的pathway，且每个pathway下又有不同的compound和gene。比如在做人的富集分析的时候，会设置organism = > “hsa”，然后提取对应pathway里面的compound数据构建代谢物和pathway的对应关系表，但看到microbiomeprofiler在代谢物富集分析的时候，用的是KEGG > compound的数据库，该数据是没有物种区分的，这样做是合理的吗？\n在microbiomeprofiler富集分析使用的是clusterProfiler的enrichr函数，该方法只能做ORA的分析，像clusterProfiler还提供了GESA的方法，是否后期也会支持该富集分析方法？Meijun chen回复感谢来信。关于信中提到的两个问题，第一个，由于不同组织来源或者生态环境中的微生物组成及其遗传信息差异很大，此外，需要将整个微生物群落当作一个整体来研究，因此在做微生物富集分析时，我们推荐用户使用自己的背景库（即实验中检测到的全部基因作为universe，差异基因作为query list），因此未提供给用户可供选择的固定背景库；第二个问题，GSEA目前在微生物领域应用较少，我们后续会考虑支持GSEA方法。","code":"\nget_enrichment2 <- function(\n  dat = datSignif,\n  group,\n  direction = c(NULL, \"DownRegulated\", \"UpRegulated\"), # DownRegulated->1st group; UpRegulated->2nd group \n  index_names = c(\"FoldChange\", \"Log2FoldChange\", \"VIP\", \"CorPvalue\", \"Pvalue\", \"AdjustedPvalue\"),\n  index_cutoff = c(1, 1, 1, 0.05, 0.05, 0.2)) {\n \n  # dat = datSignif\n  # group = grp_names[c(1, 4)]\n  # direction = NULL\n  # index_names = c(\"Log2FoldChange\", \"AdjustedPvalue\")\n  # index_cutoff = c(0, 1)\n  \n  group_collapse <- paste(group, collapse = \" vs \")\n  signif_df <- dat %>%\n    dplyr::filter(Block2 %in% group_collapse)\n  \n  colnames(signif_df)[which(colnames(signif_df) == index_names[1])] <- \"DA_index1\"\n  colnames(signif_df)[which(colnames(signif_df) == index_names[2])] <- \"DA_index2\"\n  \n  signif_df_cln <- signif_df %>%\n    dplyr::filter(abs(DA_index1) > index_cutoff[1]) %>%\n    dplyr::filter(DA_index2 < index_cutoff[2]) %>%\n    dplyr::filter(KEGG != \"-\") %>%\n    dplyr::filter(!is.na(KEGG))\n\n  signif_df_cln$KEGG <- gsub(\"\\\\s+\\\\|\\\\s+\\\\w+\\\\d+\", \"\", signif_df_cln$KEGG)\n  \n  if (nrow(signif_df_cln) == 0) {\n    stop(\"Beyond these thresholds, no significant metabolites were selected\")\n  }\n  \n  signif_temp <- signif_df_cln %>%\n    dplyr::select(FeatureID, Block2, KEGG, BIOCHEMICAL, DA_index1, DA_index2) %>%\n    dplyr::arrange(desc(DA_index1)) %>%\n    dplyr::distinct()\n  \n  if (all(index_names[1] == \"Log2FoldChange\", direction == \"DownRegulated\", !is.null(direction))) {\n    inputdata <- signif_temp %>%\n      dplyr::filter(DA_index1 > 0)\n  } else if (all(index_names[1] == \"Log2FoldChange\", direction == \"UpRegulated\", !is.null(direction))) {\n    inputdata <- signif_temp %>%\n      dplyr::filter(DA_index1 < 0)    \n  } else if (any(index_names[1] != \"Log2FoldChange\", is.null(direction))) {\n    inputdata <- signif_temp   \n  }\n  \n  if (nrow(inputdata) == 0) {\n    stop(\"Beyond these thresholds, no significant metabolites were selected when using direction\")\n  }  \n  \n  # inputdata$cpd_ID <- paste0(\"PW_\", inputdata$cpd_ID)\n  # bitr_smpdb(inputdata$cpd_ID, from_Type = \"KEGG.ID\", to_Type = \"HMDB.ID\")\n  fit <- MicrobiomeProfiler::enrichMBKEGG(\n            metabo_list = inputdata$KEGG,\n            pvalueCutoff = 0.05,\n            pAdjustMethod = \"BH\",\n            minGSSize = 10,\n            maxGSSize = 500,\n            qvalueCutoff = 0.2)\n\n\n  if (nrow(fit@result) != 0) {\n    EA_res <- fit@result %>%\n      dplyr::filter(!is.na(Description)) %>%\n      dplyr::mutate(Group = group_collapse) %>%\n      dplyr::rename(CompoundRatio = GeneRatio,\n                    CompoundID = geneID,\n                    NAME = Description) %>%\n      dplyr::select(ID, NAME, everything()) \n  } else {\n    EA_res <- NULL\n  }\n\n  colnames(inputdata)[which(colnames(inputdata) == \"DA_index1\")] <- index_names[1]\n  colnames(inputdata)[which(colnames(inputdata) == \"DA_index2\")] <- index_names[2]  \n  \n  if (!is.null(EA_res)) {\n    EA_res$CompoundName <- NA\n    for (i in 1:nrow(EA_res)) {\n      compound_list <- unlist(strsplit(EA_res$CompoundID[i], \"\\\\/\"))\n      \n      CompoundName <- c()\n      for (j in 1:length(compound_list)) {\n        for (k in 1:nrow(inputdata)) {\n          if (compound_list[j] == inputdata$KEGG[k]) {\n            CompoundName <- c(CompoundName, inputdata$BIOCHEMICAL[k])\n          }\n        }\n      }\n      EA_res$CompoundName[i] <- paste(CompoundName, collapse = \"/\")\n    }\n    \n    res_score <- EA_res %>%\n      dplyr::select(Group, ID, NAME, \n                    CompoundRatio, BgRatio, \n                    pvalue, p.adjust, qvalue, \n                    CompoundName, everything())\n    \n  } else {\n    res_score <- EA_res\n  }\n  \n  res <- list(data = inputdata,\n              enrich = res_score)\n  \n  return(res)\n}\n\nORA_res <- get_enrichment2(\n  dat = datSignif,\n  group = grp_names[c(1, 4)],\n  direction = NULL,\n  index_names = c(\"Log2FoldChange\", \"AdjustedPvalue\"),\n  index_cutoff = c(0, 1))\n\nhead(ORA_res$enrich[, 1:6])\n#>                   Group       ID\n#> map05230 None vs Severe map05230\n#> map04974 None vs Severe map04974\n#> map02010 None vs Severe map02010\n#> map01230 None vs Severe map01230\n#> map00232 None vs Severe map00232\n#> map04978 None vs Severe map04978\n#>                                         NAME CompoundRatio\n#> map05230 Central carbon metabolism in cancer        22/192\n#> map04974    Protein digestion and absorption        20/192\n#> map02010                    ABC transporters        30/192\n#> map01230         Biosynthesis of amino acids        29/192\n#> map00232                 Caffeine metabolism        13/192\n#> map04978                  Mineral absorption        14/192\n#>           BgRatio       pvalue\n#> map05230  37/6200 1.176544e-24\n#> map04974  47/6200 1.149695e-18\n#> map02010 137/6200 5.042641e-18\n#> map01230 128/6200 7.045613e-18\n#> map00232  22/6200 6.268712e-15\n#> map04978  29/6200 2.401741e-14\nORA_bubble <- plot_enrichment(\n    inputdata = ORA_res$enrich,\n    qval_cutoff = 0.05,\n    topN = 10,\n    plot_type = \"bubble\",\n    enrich_type = \"ORA\") \n\nORA_bubble"},{"path":"FunctionalAnalysis.html","id":"ssgsea-single-sample-gene-set-enrichment-analysis","chapter":"12 Functional Analysis","heading":"12.9 ssGSEA: Single sample gene set enrichment analysis","text":"单样本基因富集分析ssGSEA是另一种寻找富集分析通路的办法，相比将不同表型的样本所有基因混合在一起做富集分析的GSEA方法，ssGSEA通过计算每个样本的富集得分，然后通过一些差异分析方法比较通路在组间的异同。原理ssGSEA是一种常用于免疫细胞浸润分析的方法。该方法通过将每个样本的基因表达数据与特定的基因集（免疫细胞基因集）进行比较，来估计该基因集在该样本中的相对富集程度。在免疫细胞浸润分析中，我们可以使用ssGSEA来估计每个样本中不同免疫细胞类型的相对丰度。具体而言，ssGSEA首先将所有基因按照其表达量从大到小进行排序，并计算在某个基因集内，基因表达量较高的基因的累积分布函数。这个累积分布函数被称为基因集富集得分（gene set enrichment score，GSE）。然后，对于每个样本，将该样本中的所有基因的表达量按照从大到小的顺序排列，计算每个位置上所对应的基因集富集得分。最后，将这些位置上的得分进行平均或加权平均，得到该样本在该基因集上的ssGSEA得分，用于估计该样本中该免疫细胞类型的相对丰度。","code":""},{"path":"FunctionalAnalysis.html","id":"加载r包-9","chapter":"12 Functional Analysis","heading":"12.9.1 加载R包","text":"","code":"\nif (!(\"GSVA\" %in% installed.packages())) {\n  # Install this package if it isn't installed yet\n  BiocManager::install(\"GSVA\", update = FALSE)\n}\n\nlibrary(GSVA)\nlibrary(tidyverse)"},{"path":"FunctionalAnalysis.html","id":"导入数据-7","chapter":"12 Functional Analysis","heading":"12.9.2 导入数据","text":"对数据OmicsDataSet-Zeybel et al. - 2022.xlsx处理后生成的，可参考数据预处理章节。se_scale.RDS用于计算单个样本的富集打分","code":"\nsaveRDS(se_scale, \"./InputData/result/QC/se_scale.RDS\", compress = TRUE)\nse_scale <- readRDS(\"./InputData/result/QC/se_scale.RDS\")"},{"path":"FunctionalAnalysis.html","id":"准备代谢组文件","chapter":"12 Functional Analysis","heading":"12.9.3 准备代谢组文件","text":"以KEGG ID作为代谢物表达谱的行名","code":"\nphenotype <- SummarizedExperiment::colData(se_scale) %>%\n  as.data.frame()\nprofile <- SummarizedExperiment::assay(se_scale) %>%\n  as.data.frame()\n\nfeature <- SummarizedExperiment::rowData(se_scale) %>%\n  as.data.frame()\n\nfeature$KEGG <- gsub(\"\\\\s+\\\\|\\\\s+\\\\w+\\\\d+\", \"\", feature$KEGG)\nfeature$KEGG <- gsub(\",\\\\S+\", \"\", feature$KEGG)\n\nfeature_cln <- feature %>%\n  dplyr::filter(KEGG != \"-\") %>%\n  dplyr::filter(!is.na(KEGG)) %>%\n  dplyr::select(metabolitesID, KEGG)\n\nunique_KEGGID <- unique(feature_cln$KEGG)\nfeature_final <- feature_cln[pmatch(unique_KEGGID, feature_cln$KEGG), , F]\n\nprofile_final <- profile[pmatch(feature_final$metabolitesID, rownames(profile)), , F]\nrownames(profile_final) <- feature_final$KEGG"},{"path":"FunctionalAnalysis.html","id":"准备kegg配置文件","chapter":"12 Functional Analysis","heading":"12.9.4 准备KEGG配置文件","text":"准备基因富集数据集，一般可以用The Molecular Signatures Database (MSigDB)，但它好像没有提供代谢组对应的数据集。方法1: 本文采用从KEGG官网下载的数据转换成gsva包所需要的数据库文件格式（每一个通路作为一个list对象，该list元素是代谢物名字）。方法2: 采用massdatabase包提供的12个在线数据库下载物种的化合物/通路数据，并将其转换成数据框格式。它主要提供了download_kegg_pathway：下载KEGG通路函数download_kegg_pathway：下载KEGG通路函数read_kegg_pathway：读取KEGG通路read_kegg_pathway：读取KEGG通路convert_kegg2metpath：转换KEGG通路convert_kegg2metpath：转换KEGG通路先前下载代码有使用过request_kegg_pathway函数，获取对应物种的KEGG信息，KEGG的物种简称见KEGG Organisms: Complete Genomes。本文使用hsa (Homo sapiens (human))。KEGG通路和基因关系 (包含pahtwya对应的module信息)KEGG通路和代谢物关系 (包含pahtwya对应的module信息)","code":"\nhallmark_gene_sets <- msigdbr::msigdbr(\n  species = \"Homo sapiens\", # Can change this to what species you need\n  category = \"H\" # Only hallmark gene sets\n)\nhsa_kegg_compound <- read.csv(\"./InputData/result/KEGG/KEGG_COMPOUND_PATHWAY_hsa.csv\") \n\nkegg_compound_gsva_list <- base::split(\n  hsa_kegg_compound$COMPOUND,\n  hsa_kegg_compound$PATHWAY_MAP)\n\nhead(kegg_compound_gsva_list, n = 2)\n#> $`ABC transporters`\n#>   [1] \"C00009\" \"C00025\" \"C00031\" \"C00032\" \"C00034\" \"C00037\"\n#>   [7] \"C00038\" \"C00041\" \"C00047\" \"C00049\" \"C00051\" \"C00059\"\n#>  [13] \"C00062\" \"C00064\" \"C00065\" \"C00070\" \"C00077\" \"C00079\"\n#>  [19] \"C00086\" \"C00088\" \"C00089\" \"C00093\" \"C00095\" \"C00098\"\n#>  [25] \"C00107\" \"C00114\" \"C00116\" \"C00120\" \"C00121\" \"C00123\"\n#>  [31] \"C00134\" \"C00135\" \"C00137\" \"C00140\" \"C00148\" \"C00151\"\n#>  [37] \"C00159\" \"C00175\" \"C00181\" \"C00183\" \"C00185\" \"C00188\"\n#>  [43] \"C00208\" \"C00212\" \"C00243\" \"C00244\" \"C00245\" \"C00255\"\n#>  [49] \"C00259\" \"C00288\" \"C00291\" \"C00294\" \"C00299\" \"C00315\"\n#>  [55] \"C00320\" \"C00330\" \"C00333\" \"C00338\" \"C00378\" \"C00379\"\n#>  [61] \"C00387\" \"C00392\" \"C00407\" \"C00430\" \"C00470\" \"C00475\"\n#>  [67] \"C00487\" \"C00491\" \"C00492\" \"C00503\" \"C00526\" \"C00559\"\n#>  [73] \"C00719\" \"C00794\" \"C00855\" \"C00865\" \"C00881\" \"C00919\"\n#>  [79] \"C00973\" \"C01083\" \"C01153\" \"C01157\" \"C01177\" \"C01181\"\n#>  [85] \"C01279\" \"C01330\" \"C01417\" \"C01487\" \"C01606\" \"C01630\"\n#>  [91] \"C01667\" \"C01674\" \"C01682\" \"C01684\" \"C01762\" \"C01834\"\n#>  [97] \"C01835\" \"C01935\" \"C01946\" \"C02160\" \"C02273\" \"C03557\"\n#> [103] \"C03611\" \"C03619\" \"C04114\" \"C04137\" \"C05349\" \"C05402\"\n#> [109] \"C05512\" \"C05776\" \"C06227\" \"C06229\" \"C06230\" \"C06232\"\n#> [115] \"C06687\" \"C06705\" \"C06706\" \"C06707\" \"C06767\" \"C07662\"\n#> [121] \"C07663\" \"C11612\" \"C13768\" \"C14818\" \"C14819\" \"C15521\"\n#> [127] \"C15719\" \"C16421\" \"C16692\" \"C19609\" \"C19872\" \"C20570\"\n#> [133] \"C20571\" \"C20572\" \"C20573\" \"C20679\" \"C21066\" \"C22040\"\n#> [139] \"G00457\"\n#> \n#> $`Acute myeloid leukemia`\n#> [1] \"C05981\"\nif (!(\"massdatabase\" %in% installed.packages())) {\n  remotes::install_github(\"tidymass/massdatabase\", dependencies = TRUE)\n}\n\nlibrary(massdatabase)\n\ndownload_kegg_pathway(\n  path = \"./InputData/KEGG/hsa_KEGG\",\n  sleep = 2,\n  organism = \"hsa\")\n\nKEGG_data <- read_kegg_pathway(\n  path = \"./InputData/KEGG/hsa_KEGG\")\n\nKEGG_pathway_database <- convert_kegg2metpath(\n  data = KEGG_data, \n  path = \"./InputData/KEGG/hsa_KEGG\")\n\nKEGG_pathway_database\nKEGG_gene_path <- data.frame()\n\nfor (i in 1:length(KEGG_data)) {\n  \n  pathID <-  KEGG_data[[i]]$pathway_id\n  pathName <- KEGG_data[[i]]$pathway_name \n  geneList <- KEGG_data[[i]]$gene_list\n  pathClass <- KEGG_data[[i]]$pathway_class\n  pathModule <- KEGG_data[[i]]$related_module\n  describtion <- paste(KEGG_data[[i]]$describtion, collapse = \";\")\n  \n  if (nrow(geneList) == 0) {\n    next\n  } else {\n    \n    temp <- geneList %>% \n      dplyr::group_by(Gene.name) %>%\n      dplyr::mutate(Gene.symbol = unlist(strsplit(Gene.name, \";\"))[1]) %>%\n      dplyr::mutate(KO.ID = stringr::str_extract(Gene.name, \"KO:K\\\\d+\")) %>%\n      dplyr::mutate(EC.ID = paste0(\"[EC\", unlist(strsplit(Gene.name, \"EC\"))[2])) %>%\n      dplyr::mutate(EC.ID = ifelse(EC.ID == \"[ECNA\", NA, EC.ID)) %>%\n      dplyr::ungroup() %>%\n      dplyr::mutate(pathway_id = pathID,\n                    pathway_name = pathName)    \n    \n    if (!is.null(describtion)) {\n      temp <- temp %>%\n        dplyr::mutate(describtion = describtion)       \n    } else {\n      temp <- temp %>%\n        dplyr::mutate(describtion = NA)       \n    }\n    \n    \n    if (!is.null(pathClass)) {\n      temp <- temp %>%\n        dplyr::mutate(pathway_class = pathClass) %>% \n        tidyr::separate(pathway_class, into = c(\"pathway_level2\", \"pathway_level1\"), sep = ';', remove = FALSE)      \n    } else {\n       temp <- temp %>%\n        dplyr::mutate(pathway_class = NA,\n                      pathway_level1 = NA,\n                      pathway_level2 = NA)      \n    }\n    \n    if (nrow(pathModule) != 0) {\n    temp <- temp %>%\n      dplyr::inner_join(\n        pathModule %>%\n          dplyr::mutate(pathway_id = pathID),\n        by = \"pathway_id\"\n      ) %>%\n      dplyr::select(pathway_id, pathway_level1, pathway_level2, Module.ID, Module.name, everything())     \n    } else {\n       temp <- temp %>%\n        dplyr::mutate(Module.ID = NA,\n                      Module.name = NA)      \n    }    \n    \n    KEGG_gene_path <- rbind(KEGG_gene_path, temp)\n  }\n}\nKEGG_metabolite_path <- data.frame()\n\nfor (j in 1:length(KEGG_data)) {\n  \n  pathID <-  KEGG_data[[j]]$pathway_id\n  pathName <- KEGG_data[[j]]$pathway_name \n  compoundList <- KEGG_data[[j]]$compound_list\n  pathClass <- KEGG_data[[j]]$pathway_class\n  pathModule <- KEGG_data[[j]]$related_module\n  describtion <- paste(KEGG_data[[j]]$describtion, collapse = \";\")\n  \n  if (nrow(compoundList) == 0) {\n    next\n  } else {\n    \n    temp <- compoundList %>% \n      dplyr::mutate(pathway_id = pathID,\n                    pathway_name = pathName)    \n    \n    if (!is.null(describtion)) {\n      temp <- temp %>%\n        dplyr::mutate(describtion = describtion)       \n    } else {\n      temp <- temp %>%\n        dplyr::mutate(describtion = NA)       \n    }\n    \n    \n    if (!is.null(pathClass)) {\n      temp <- temp %>%\n        dplyr::mutate(pathway_class = pathClass) %>% \n        tidyr::separate(pathway_class, into = c(\"pathway_level2\", \"pathway_level1\"), sep = ';', remove = FALSE)      \n    } else {\n       temp <- temp %>%\n        dplyr::mutate(pathway_class = NA,\n                      pathway_level1 = NA,\n                      pathway_level2 = NA)      \n    }\n    \n    if (nrow(pathModule) != 0) {\n    temp <- temp %>%\n      dplyr::inner_join(\n        pathModule %>%\n          dplyr::mutate(pathway_id = pathID),\n        by = \"pathway_id\"\n      ) %>%\n      dplyr::select(pathway_id, pathway_level1, pathway_level2, Module.ID, Module.name, everything())     \n    } else {\n       temp <- temp %>%\n        dplyr::mutate(Module.ID = NA,\n                      Module.name = NA)      \n    }    \n    \n    KEGG_metabolite_path <- rbind(KEGG_metabolite_path, temp)\n  }\n}"},{"path":"FunctionalAnalysis.html","id":"计算单个样本的gsea","chapter":"12 Functional Analysis","heading":"12.9.5 计算单个样本的GSEA","text":"gsva函数提供了四种计算方法，详情见?GSVA::gsva。gsva (Hänzelmann et al, 2013): GSVA拟合一个模型，并根据相对于样本分布的表达水平对基因进行排序。计算的通路水平分数是一种询问基因集中的基因与该基因集中以外的基因相比如何变化的方法。gsva (Hänzelmann et al, 2013): GSVA拟合一个模型，并根据相对于样本分布的表达水平对基因进行排序。计算的通路水平分数是一种询问基因集中的基因与该基因集中以外的基因相比如何变化的方法。ssgsea (Barbie et al, 2009)：单样本GSEA (ssGSEA)，基因集富集分析(GSEA)的扩展，计算样品和基因集的每对单独的富集分数。每个ssGSEA富集分数代表了一个特定基因集中的基因在一个样本中协调上调或下调的程度。ssgsea (Barbie et al, 2009)：单样本GSEA (ssGSEA)，基因集富集分析(GSEA)的扩展，计算样品和基因集的每对单独的富集分数。每个ssGSEA富集分数代表了一个特定基因集中的基因在一个样本中协调上调或下调的程度。zscore (Lee et al, 2008)zscore (Lee et al, 2008)plage (Tomfohr et al, 2005)plage (Tomfohr et al, 2005)","code":"\ngsva_results <- gsva(\n  as.matrix(profile_final),\n  kegg_compound_gsva_list,\n  method = \"gsva\",\n  kcdf = \"Gaussian\",\n  min.sz = 15,\n  max.sz = 500,\n  mx.diff = TRUE,\n  verbose = FALSE)\n\nhead(gsva_results[, 1:3])\n#>                                             P101001\n#> ABC transporters                        -0.20228650\n#> Aminoacyl-tRNA biosynthesis             -0.44329459\n#> Bile secretion                           0.06301039\n#> Biosynthesis of unsaturated fatty acids  0.35032037\n#> Central carbon metabolism in cancer     -0.36038134\n#> D-Amino acid metabolism                 -0.26337821\n#>                                            P101003\n#> ABC transporters                        -0.3587586\n#> Aminoacyl-tRNA biosynthesis             -0.2629152\n#> Bile secretion                           0.2382812\n#> Biosynthesis of unsaturated fatty acids  0.7107874\n#> Central carbon metabolism in cancer     -0.3790808\n#> D-Amino acid metabolism                 -0.1158670\n#>                                             P101004\n#> ABC transporters                        0.054898838\n#> Aminoacyl-tRNA biosynthesis             0.165783650\n#> Bile secretion                          0.207036545\n#> Biosynthesis of unsaturated fatty acids 0.311415933\n#> Central carbon metabolism in cancer     0.113331553\n#> D-Amino acid metabolism                 0.009637222"},{"path":"FunctionalAnalysis.html","id":"可视化结果-1","chapter":"12 Functional Analysis","heading":"12.9.6 可视化结果","text":"结果：ssgsva计算出8条通路，它们的富集得分变化用热图展示，也可以做差异检验。","code":"\nannot_df <- phenotype %>%\n  dplyr::select(\n    LiverFatClass) %>%\n  tibble::rownames_to_column(\"TempRow\") %>%\n  dplyr::arrange(desc(LiverFatClass)) %>%\n  dplyr::mutate(LiverFatClass = factor(LiverFatClass,\n                                       levels = grp_names)) %>%\n  tibble::column_to_rownames(\"TempRow\")\n\nplotdata <- gsva_results %>%\n  as.data.frame() %>%\n  dplyr::select(dplyr::all_of(rownames(annot_df))) %>%\n  as.matrix()\n\npheatmap::pheatmap(\n  plotdata,\n  annotation_col = annot_df,\n  show_colnames = FALSE,\n  cluster_cols = FALSE,\n  fontsize_row = 8,\n  cellwidth = 7,\n  cellheight = 20)"},{"path":"FunctionalAnalysis.html","id":"箱线图展示结果","chapter":"12 Functional Analysis","heading":"12.9.7 箱线图展示结果","text":"除了热图展示外，还可以用更为直观的箱线图展示并加上差异分析结果。","code":"\nlibrary(ggplot2)\n\nget_topN_boxplot <- function(\n    x,\n    y,\n    features,\n    group,\n    group_names = grp_names,\n    group_colors = grp_colors,\n    dotsize = 1.2) {\n  \n \n  # x = phenotype\n  # y = gsva_results  \n  # features = c(\"ABC transporters\")\n  # group = \"LiverFatClass\"\n  # group_names = grp_names[1:2]\n  # group_colors = grp_colors[1:2]\n  # dotsize = 1.2\n\n  # group\n  colnames(x)[which(colnames(x) == group)] <- \"Group_new\"\n  phen <- x %>%\n    dplyr::filter(Group_new %in% group_names) %>%\n    dplyr::select(Group_new) %>%\n    tibble::rownames_to_column(\"TempRowNames\")\n  \n  # profile\n  prof <- y %>% \n    as.data.frame() %>% \n    t() %>% \n    as.data.frame() %>%\n    dplyr::select(dplyr::all_of(features))\n  \n  # merge phenotype and profile\n  feature_merge <- prof %>% \n    tibble::rownames_to_column(\"TempRowNames\") %>%\n    tidyr::gather(key = \"Feature\", value = \"Abundance\", -TempRowNames) %>%\n    # dplyr::inner_join(feature, by = c(\"Feature\" = \"TempRowNames\")) %>%\n    dplyr::mutate(Feature_new = Feature) \n\n  # ordering feature\n  feature_merge$Feature <- factor(feature_merge$Feature, levels = features)\n  \n  match_order_index <- sort(pmatch(unique(phen$Group_new), group_names), decreasing = F)\n  group_names_new <- group_names[match_order_index]\n  group_colors_new <- group_colors[match_order_index]   \n  \n  mdat <- phen %>% \n    dplyr::inner_join(feature_merge, by = \"TempRowNames\")\n  mdat$Group_new <- factor(mdat$Group_new, levels = group_names_new)\n  \n  # comparison list\n  cmp <- list()\n  num <- utils::combn(length(unique(group_names_new)), 2)\n  for (i in 1:ncol(num)) {\n    cmp[[i]] <- num[, i]\n  }\n  \n  pl <-\n    ggplot(data = mdat, aes(x = Group_new, y = Abundance, fill = Group_new)) +\n      stat_boxplot(aes(color = Group_new), geom = \"errorbar\", width = 0.15) +\n      geom_boxplot(width = .4, outlier.shape = 3, outlier.size = 0.5) +\n      ggpubr::stat_compare_means(comparisons = cmp,\n                                 method = \"wilcox.test\",\n                                 hide.ns = TRUE) + \n      geom_dotplot(binaxis = \"y\", stackdir = \"center\",\n                 stackratio = 1.5, dotsize = dotsize) +\n      scale_fill_manual(values = group_colors_new) +\n      scale_color_manual(values = group_colors_new) +\n      scale_y_continuous(expand = expansion(mult = c(0.05, 0.1))) +\n      labs(x = \"\", y = \"Intensity (metabolites expression)\") +\n      guides(color = \"none\", fill = \"none\") +\n      facet_wrap(facets = \"Feature_new\", scales = \"free\", ncol = 4) +\n      theme_bw() +\n      theme(axis.title = element_text(size = 12, color = \"black\", face = \"bold\"),\n            axis.text = element_text(size = 10, color = \"black\"),\n            text = element_text(size = 9, color = \"black\"),\n            strip.text = element_text(size = 9, color = \"black\", face = \"bold\"),\n            panel.background = element_rect(fill = \"white\", colour = \"black\"),\n            strip.background = element_rect(fill = \"white\", colour = \"black\"))\n  \n  return(pl)\n}\n\n\nget_topN_boxplot(\n  x = phenotype,\n  y = gsva_results, \n  features = rownames(gsva_results)[1:2], #c(\"Bile secretion\", \"ABC transporters\")\n  group = \"LiverFatClass\",\n  group_names = grp_names,\n  group_colors = grp_colors,\n  dotsize = 1.2)"},{"path":"FunctionalAnalysis.html","id":"session-info-4","chapter":"12 Functional Analysis","heading":"12.10 Session info","text":"","code":"\ndevtools::session_info()\n#> ─ Session info ───────────────────────────────────────────\n#>  setting  value\n#>  version  R version 4.1.3 (2022-03-10)\n#>  os       macOS Big Sur/Monterey 10.16\n#>  system   x86_64, darwin17.0\n#>  ui       X11\n#>  language (EN)\n#>  collate  en_US.UTF-8\n#>  ctype    en_US.UTF-8\n#>  tz       Asia/Shanghai\n#>  date     2024-02-06\n#>  pandoc   3.1.1 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/ (via rmarkdown)\n#> \n#> ─ Packages ───────────────────────────────────────────────\n#>  package              * version    date (UTC) lib source\n#>  abind                  1.4-5      2016-07-21 [2] CRAN (R 4.1.0)\n#>  affy                   1.72.0     2021-10-26 [2] Bioconductor\n#>  affyio                 1.64.0     2021-10-26 [2] Bioconductor\n#>  annotate               1.72.0     2021-10-26 [2] Bioconductor\n#>  AnnotationDbi          1.60.2     2023-03-10 [2] Bioconductor\n#>  ape                    5.7-1      2023-03-13 [1] CRAN (R 4.1.2)\n#>  aplot                  0.1.10     2023-03-08 [2] CRAN (R 4.1.2)\n#>  attempt                0.3.1      2020-05-03 [2] CRAN (R 4.1.0)\n#>  backports              1.4.1      2021-12-13 [2] CRAN (R 4.1.0)\n#>  beachmat               2.10.0     2021-10-26 [2] Bioconductor\n#>  Biobase              * 2.54.0     2021-10-26 [2] Bioconductor\n#>  BiocGenerics         * 0.40.0     2021-10-26 [2] Bioconductor\n#>  BiocManager            1.30.21    2023-06-10 [2] CRAN (R 4.1.3)\n#>  BiocParallel           1.28.3     2021-12-09 [2] Bioconductor\n#>  BiocSingular           1.10.0     2021-10-26 [2] Bioconductor\n#>  Biostrings             2.62.0     2021-10-26 [2] Bioconductor\n#>  bit                    4.0.5      2022-11-15 [2] CRAN (R 4.1.2)\n#>  bit64                  4.0.5      2020-08-30 [2] CRAN (R 4.1.0)\n#>  bitops                 1.0-7      2021-04-24 [2] CRAN (R 4.1.0)\n#>  blob                   1.2.4      2023-03-17 [2] CRAN (R 4.1.2)\n#>  bookdown               0.34       2023-05-09 [2] CRAN (R 4.1.2)\n#>  broom                  1.0.5      2023-06-09 [2] CRAN (R 4.1.3)\n#>  bslib                  0.6.0      2023-11-21 [1] CRAN (R 4.1.3)\n#>  cachem                 1.0.8      2023-05-01 [2] CRAN (R 4.1.2)\n#>  callr                  3.7.3      2022-11-02 [2] CRAN (R 4.1.2)\n#>  car                    3.1-2      2023-03-30 [2] CRAN (R 4.1.2)\n#>  carData                3.0-5      2022-01-06 [2] CRAN (R 4.1.2)\n#>  cellranger             1.1.0      2016-07-27 [2] CRAN (R 4.1.0)\n#>  circlize               0.4.15     2022-05-10 [2] CRAN (R 4.1.2)\n#>  cli                    3.6.1      2023-03-23 [2] CRAN (R 4.1.2)\n#>  clue                   0.3-64     2023-01-31 [2] CRAN (R 4.1.2)\n#>  cluster                2.1.4      2022-08-22 [2] CRAN (R 4.1.2)\n#>  clusterProfiler      * 4.2.2      2022-01-13 [2] Bioconductor\n#>  codetools              0.2-19     2023-02-01 [2] CRAN (R 4.1.2)\n#>  colorspace             2.1-0      2023-01-23 [2] CRAN (R 4.1.2)\n#>  ComplexHeatmap         2.10.0     2021-10-26 [2] Bioconductor\n#>  config                 0.3.1      2020-12-17 [2] CRAN (R 4.1.0)\n#>  crayon                 1.5.2      2022-09-29 [2] CRAN (R 4.1.2)\n#>  curl                   5.0.1      2023-06-07 [2] CRAN (R 4.1.3)\n#>  data.table             1.14.8     2023-02-17 [2] CRAN (R 4.1.2)\n#>  DBI                    1.1.3      2022-06-18 [2] CRAN (R 4.1.2)\n#>  DelayedArray           0.20.0     2021-10-26 [2] Bioconductor\n#>  DelayedMatrixStats     1.16.0     2021-10-26 [2] Bioconductor\n#>  devtools               2.4.5      2022-10-11 [2] CRAN (R 4.1.2)\n#>  digest                 0.6.33     2023-07-07 [1] CRAN (R 4.1.3)\n#>  DO.db                  2.9        2022-04-11 [2] Bioconductor\n#>  doParallel             1.0.17     2022-02-07 [2] CRAN (R 4.1.2)\n#>  DOSE                   3.20.1     2021-11-18 [2] Bioconductor\n#>  downlit                0.4.3      2023-06-29 [2] CRAN (R 4.1.3)\n#>  downloader             0.4        2015-07-09 [2] CRAN (R 4.1.0)\n#>  dplyr                * 1.1.4      2023-11-17 [1] CRAN (R 4.1.3)\n#>  DT                     0.31       2023-12-09 [1] CRAN (R 4.1.3)\n#>  ellipsis               0.3.2      2021-04-29 [2] CRAN (R 4.1.0)\n#>  enrichplot             1.14.2     2022-02-24 [2] Bioconductor\n#>  evaluate               0.21       2023-05-05 [2] CRAN (R 4.1.2)\n#>  fansi                  1.0.4      2023-01-22 [2] CRAN (R 4.1.2)\n#>  farver                 2.1.1      2022-07-06 [2] CRAN (R 4.1.2)\n#>  fastmap                1.1.1      2023-02-24 [2] CRAN (R 4.1.2)\n#>  fastmatch              1.1-3      2021-07-23 [2] CRAN (R 4.1.0)\n#>  fgsea                  1.20.0     2021-10-26 [2] Bioconductor\n#>  forcats              * 1.0.0      2023-01-29 [1] CRAN (R 4.1.2)\n#>  foreach                1.5.2      2022-02-02 [2] CRAN (R 4.1.2)\n#>  fs                     1.6.2      2023-04-25 [2] CRAN (R 4.1.2)\n#>  furrr                  0.3.1      2022-08-15 [2] CRAN (R 4.1.2)\n#>  future                 1.33.0     2023-07-01 [2] CRAN (R 4.1.3)\n#>  generics               0.1.3      2022-07-05 [2] CRAN (R 4.1.2)\n#>  GenomeInfoDb           1.30.1     2022-01-30 [2] Bioconductor\n#>  GenomeInfoDbData       1.2.7      2022-03-09 [2] Bioconductor\n#>  GenomicRanges          1.46.1     2021-11-18 [2] Bioconductor\n#>  GetoptLong             1.0.5      2020-12-15 [2] CRAN (R 4.1.0)\n#>  ggforce                0.4.1      2022-10-04 [2] CRAN (R 4.1.2)\n#>  ggfun                  0.1.1      2023-06-24 [2] CRAN (R 4.1.3)\n#>  ggplot2              * 3.4.4      2023-10-12 [1] CRAN (R 4.1.3)\n#>  ggplotify              0.1.1      2023-06-27 [2] CRAN (R 4.1.3)\n#>  ggpubr                 0.6.0      2023-02-10 [1] CRAN (R 4.1.2)\n#>  ggraph                 2.1.0.9000 2023-07-11 [1] Github (thomasp85/ggraph@febab71)\n#>  ggrepel                0.9.3      2023-02-03 [1] CRAN (R 4.1.2)\n#>  ggsignif               0.6.4      2022-10-13 [2] CRAN (R 4.1.2)\n#>  ggtree                 3.2.1      2021-11-16 [2] Bioconductor\n#>  GlobalOptions          0.1.2      2020-06-10 [2] CRAN (R 4.1.0)\n#>  globals                0.16.2     2022-11-21 [2] CRAN (R 4.1.2)\n#>  glue                   1.6.2      2022-02-24 [2] CRAN (R 4.1.2)\n#>  GO.db                  3.14.0     2022-04-11 [2] Bioconductor\n#>  golem                  0.4.1      2023-06-05 [2] CRAN (R 4.1.3)\n#>  GOSemSim               2.20.0     2021-10-26 [2] Bioconductor\n#>  graph                  1.72.0     2021-10-26 [2] Bioconductor\n#>  graphlayouts           1.0.0      2023-05-01 [2] CRAN (R 4.1.2)\n#>  gridExtra              2.3        2017-09-09 [2] CRAN (R 4.1.0)\n#>  gridGraphics           0.5-1      2020-12-13 [2] CRAN (R 4.1.0)\n#>  GSEABase               1.56.0     2021-10-26 [2] Bioconductor\n#>  GSVA                 * 1.42.0     2021-10-26 [2] Bioconductor\n#>  gtable                 0.3.3      2023-03-21 [2] CRAN (R 4.1.2)\n#>  HDF5Array              1.22.1     2021-11-14 [2] Bioconductor\n#>  highr                  0.10       2022-12-22 [2] CRAN (R 4.1.2)\n#>  hms                    1.1.3      2023-03-21 [2] CRAN (R 4.1.2)\n#>  htmltools              0.5.7      2023-11-03 [1] CRAN (R 4.1.3)\n#>  htmlwidgets            1.6.2      2023-03-17 [2] CRAN (R 4.1.2)\n#>  httpuv                 1.6.11     2023-05-11 [2] CRAN (R 4.1.3)\n#>  httr                   1.4.6      2023-05-08 [2] CRAN (R 4.1.2)\n#>  igraph                 1.5.0      2023-06-16 [1] CRAN (R 4.1.3)\n#>  impute                 1.68.0     2021-10-26 [2] Bioconductor\n#>  IRanges                2.28.0     2021-10-26 [2] Bioconductor\n#>  irlba                  2.3.5.1    2022-10-03 [2] CRAN (R 4.1.2)\n#>  iterators              1.0.14     2022-02-05 [2] CRAN (R 4.1.2)\n#>  jquerylib              0.1.4      2021-04-26 [2] CRAN (R 4.1.0)\n#>  jsonlite               1.8.7      2023-06-29 [2] CRAN (R 4.1.3)\n#>  KEGGREST               1.34.0     2021-10-26 [2] Bioconductor\n#>  knitr                  1.43       2023-05-25 [2] CRAN (R 4.1.3)\n#>  labeling               0.4.2      2020-10-20 [2] CRAN (R 4.1.0)\n#>  later                  1.3.1      2023-05-02 [2] CRAN (R 4.1.2)\n#>  lattice                0.21-8     2023-04-05 [2] CRAN (R 4.1.2)\n#>  lazyeval               0.2.2      2019-03-15 [2] CRAN (R 4.1.0)\n#>  lifecycle              1.0.3      2022-10-07 [2] CRAN (R 4.1.2)\n#>  limma                  3.50.3     2022-04-07 [2] Bioconductor\n#>  listenv                0.9.0      2022-12-16 [2] CRAN (R 4.1.2)\n#>  lubridate            * 1.9.2      2023-02-10 [2] CRAN (R 4.1.2)\n#>  magrittr             * 2.0.3      2022-03-30 [2] CRAN (R 4.1.2)\n#>  MALDIquant             1.22.1     2023-03-20 [2] CRAN (R 4.1.2)\n#>  MASS                   7.3-60     2023-05-04 [1] CRAN (R 4.1.2)\n#>  massdatabase         * 1.0.7      2023-05-30 [2] gitlab (jaspershen/massdatabase@df83e93)\n#>  massdataset          * 1.0.24     2023-05-30 [2] gitlab (jaspershen/massdataset@b397116)\n#>  masstools            * 1.0.10     2023-05-30 [2] gitlab (jaspershen/masstools@b3c73bc)\n#>  Matrix                 1.6-5      2024-01-11 [1] CRAN (R 4.1.3)\n#>  MatrixGenerics         1.6.0      2021-10-26 [2] Bioconductor\n#>  matrixStats            1.1.0      2023-11-07 [1] CRAN (R 4.1.3)\n#>  memoise                2.0.1      2021-11-26 [2] CRAN (R 4.1.0)\n#>  metid                * 1.2.26     2023-05-30 [2] gitlab (jaspershen/metid@6bde121)\n#>  metpath              * 1.0.5      2023-05-30 [2] gitlab (jaspershen/metpath@adcad4f)\n#>  MicrobiomeProfiler   * 1.0.0      2021-10-26 [2] Bioconductor\n#>  mime                   0.12       2021-09-28 [2] CRAN (R 4.1.0)\n#>  miniUI                 0.1.1.1    2018-05-18 [2] CRAN (R 4.1.0)\n#>  MsCoreUtils            1.6.2      2022-02-24 [2] Bioconductor\n#>  MSnbase              * 2.20.4     2022-01-16 [2] Bioconductor\n#>  munsell                0.5.0      2018-06-12 [2] CRAN (R 4.1.0)\n#>  mzID                   1.32.0     2021-10-26 [2] Bioconductor\n#>  mzR                  * 2.28.0     2021-10-27 [2] Bioconductor\n#>  ncdf4                  1.21       2023-01-07 [2] CRAN (R 4.1.2)\n#>  nlme                   3.1-162    2023-01-31 [1] CRAN (R 4.1.2)\n#>  openxlsx               4.2.5.2    2023-02-06 [2] CRAN (R 4.1.2)\n#>  parallelly             1.36.0     2023-05-26 [2] CRAN (R 4.1.3)\n#>  patchwork              1.1.2      2022-08-19 [2] CRAN (R 4.1.2)\n#>  pbapply                1.7-2      2023-06-27 [2] CRAN (R 4.1.3)\n#>  pcaMethods             1.86.0     2021-10-26 [2] Bioconductor\n#>  pheatmap               1.0.12     2019-01-04 [1] CRAN (R 4.1.0)\n#>  pillar                 1.9.0      2023-03-22 [2] CRAN (R 4.1.2)\n#>  pkgbuild               1.4.2      2023-06-26 [2] CRAN (R 4.1.3)\n#>  pkgconfig              2.0.3      2019-09-22 [2] CRAN (R 4.1.0)\n#>  pkgload                1.3.2.1    2023-07-08 [2] CRAN (R 4.1.3)\n#>  plotly                 4.10.2     2023-06-03 [2] CRAN (R 4.1.3)\n#>  plyr                   1.8.8      2022-11-11 [1] CRAN (R 4.1.2)\n#>  png                    0.1-8      2022-11-29 [2] CRAN (R 4.1.2)\n#>  polyclip               1.10-4     2022-10-20 [2] CRAN (R 4.1.2)\n#>  preprocessCore         1.56.0     2021-10-26 [2] Bioconductor\n#>  prettyunits            1.1.1      2020-01-24 [2] CRAN (R 4.1.0)\n#>  processx               3.8.2      2023-06-30 [2] CRAN (R 4.1.3)\n#>  profvis                0.3.8      2023-05-02 [2] CRAN (R 4.1.2)\n#>  progress               1.2.2      2019-05-16 [2] CRAN (R 4.1.0)\n#>  promises               1.2.0.1    2021-02-11 [2] CRAN (R 4.1.0)\n#>  ProtGenerics         * 1.26.0     2021-10-26 [2] Bioconductor\n#>  ps                     1.7.5      2023-04-18 [2] CRAN (R 4.1.2)\n#>  purrr                * 1.0.1      2023-01-10 [1] CRAN (R 4.1.2)\n#>  qvalue                 2.26.0     2021-10-26 [2] Bioconductor\n#>  R6                     2.5.1      2021-08-19 [2] CRAN (R 4.1.0)\n#>  RColorBrewer           1.1-3      2022-04-03 [1] CRAN (R 4.1.2)\n#>  Rcpp                 * 1.0.11     2023-07-06 [1] CRAN (R 4.1.3)\n#>  RCurl                  1.98-1.12  2023-03-27 [2] CRAN (R 4.1.2)\n#>  Rdisop                 1.54.0     2021-10-26 [2] Bioconductor\n#>  readr                * 2.1.4      2023-02-10 [1] CRAN (R 4.1.2)\n#>  readxl                 1.4.3      2023-07-06 [2] CRAN (R 4.1.3)\n#>  remotes                2.4.2      2021-11-30 [2] CRAN (R 4.1.0)\n#>  reshape2               1.4.4      2020-04-09 [2] CRAN (R 4.1.0)\n#>  rhdf5                  2.38.1     2022-03-10 [2] Bioconductor\n#>  rhdf5filters           1.6.0      2021-10-26 [2] Bioconductor\n#>  Rhdf5lib               1.16.0     2021-10-26 [2] Bioconductor\n#>  rjson                  0.2.21     2022-01-09 [2] CRAN (R 4.1.2)\n#>  rlang                  1.1.1      2023-04-28 [1] CRAN (R 4.1.2)\n#>  rmarkdown              2.23       2023-07-01 [2] CRAN (R 4.1.3)\n#>  RSQLite                2.3.1      2023-04-03 [2] CRAN (R 4.1.2)\n#>  rstatix                0.7.2      2023-02-01 [2] CRAN (R 4.1.2)\n#>  rstudioapi             0.15.0     2023-07-07 [2] CRAN (R 4.1.3)\n#>  rsvd                   1.0.5      2021-04-16 [2] CRAN (R 4.1.0)\n#>  rvest                  1.0.3      2022-08-19 [2] CRAN (R 4.1.2)\n#>  S4Vectors            * 0.32.4     2022-03-29 [2] Bioconductor\n#>  sass                   0.4.6      2023-05-03 [2] CRAN (R 4.1.2)\n#>  ScaledMatrix           1.2.0      2021-10-26 [2] Bioconductor\n#>  scales                 1.2.1      2022-08-20 [1] CRAN (R 4.1.2)\n#>  scatterpie             0.2.1      2023-06-07 [2] CRAN (R 4.1.3)\n#>  sessioninfo            1.2.2      2021-12-06 [2] CRAN (R 4.1.0)\n#>  shadowtext             0.1.2      2022-04-22 [2] CRAN (R 4.1.2)\n#>  shape                  1.4.6      2021-05-19 [2] CRAN (R 4.1.0)\n#>  shiny                  1.7.4.1    2023-07-06 [2] CRAN (R 4.1.3)\n#>  shinycustomloader      0.9.0      2018-03-27 [2] CRAN (R 4.1.0)\n#>  shinyWidgets           0.7.6      2023-01-08 [2] CRAN (R 4.1.2)\n#>  SingleCellExperiment   1.16.0     2021-10-26 [2] Bioconductor\n#>  sparseMatrixStats      1.6.0      2021-10-26 [2] Bioconductor\n#>  stringdist             0.9.10     2022-11-07 [2] CRAN (R 4.1.2)\n#>  stringi                1.7.12     2023-01-11 [2] CRAN (R 4.1.2)\n#>  stringr              * 1.5.1      2023-11-14 [1] CRAN (R 4.1.3)\n#>  SummarizedExperiment   1.24.0     2021-10-26 [2] Bioconductor\n#>  tibble               * 3.2.1      2023-03-20 [1] CRAN (R 4.1.2)\n#>  tidygraph              1.2.3      2023-02-01 [2] CRAN (R 4.1.2)\n#>  tidyr                * 1.3.0      2023-01-24 [1] CRAN (R 4.1.2)\n#>  tidyselect             1.2.0      2022-10-10 [2] CRAN (R 4.1.2)\n#>  tidytree               0.4.2      2022-12-18 [2] CRAN (R 4.1.2)\n#>  tidyverse            * 2.0.0      2023-02-22 [1] CRAN (R 4.1.2)\n#>  timechange             0.2.0      2023-01-11 [2] CRAN (R 4.1.2)\n#>  treeio                 1.18.1     2021-11-14 [2] Bioconductor\n#>  tweenr                 2.0.2      2022-09-06 [2] CRAN (R 4.1.2)\n#>  tzdb                   0.4.0      2023-05-12 [2] CRAN (R 4.1.3)\n#>  urlchecker             1.0.1      2021-11-30 [2] CRAN (R 4.1.0)\n#>  usethis                2.2.2      2023-07-06 [2] CRAN (R 4.1.3)\n#>  utf8                   1.2.3      2023-01-31 [2] CRAN (R 4.1.2)\n#>  vctrs                  0.6.5      2023-12-01 [1] CRAN (R 4.1.3)\n#>  viridis                0.6.3      2023-05-03 [2] CRAN (R 4.1.2)\n#>  viridisLite            0.4.2      2023-05-02 [2] CRAN (R 4.1.2)\n#>  vsn                    3.62.0     2021-10-26 [2] Bioconductor\n#>  withr                  2.5.0      2022-03-03 [2] CRAN (R 4.1.2)\n#>  xfun                   0.40       2023-08-09 [1] CRAN (R 4.1.3)\n#>  XML                    3.99-0.14  2023-03-19 [2] CRAN (R 4.1.2)\n#>  xml2                   1.3.5      2023-07-06 [2] CRAN (R 4.1.3)\n#>  xtable                 1.8-4      2019-04-21 [2] CRAN (R 4.1.0)\n#>  XVector                0.34.0     2021-10-26 [2] Bioconductor\n#>  yaml                   2.3.7      2023-01-23 [2] CRAN (R 4.1.2)\n#>  yulab.utils            0.0.6      2022-12-20 [2] CRAN (R 4.1.2)\n#>  zip                    2.3.0      2023-04-17 [2] CRAN (R 4.1.2)\n#>  zlibbioc               1.40.0     2021-10-26 [2] Bioconductor\n#> \n#>  [1] /Users/zouhua/Library/R/x86_64/4.1/library\n#>  [2] /Library/Frameworks/R.framework/Versions/4.1/Resources/library\n#> \n#> ──────────────────────────────────────────────────────────"},{"path":"FunctionalAnalysis.html","id":"reference-10","chapter":"12 Functional Analysis","heading":"12.11 Reference","text":"massdatabase githubmassdatabase githubUniveral enrichment analysisUniveral enrichment analysisGene set variation analysis - RNA-seqGene set variation analysis - RNA-seq","code":""},{"path":"MetOriginAnalysis.html","id":"MetOriginAnalysis","chapter":"13 MetOrigin Analysis","heading":"13 MetOrigin Analysis","text":"微生物群及其代谢产物与人类健康和疾病密切相关。然而，理解微生物组和代谢物之间复杂的相互作用是具有挑战性的。在研究肠道代谢物时，代谢物的来源是一个无法避免的问题即代谢物到底是来自肠道微生物的代谢还是宿主本身代谢产生的。2022年Yu, Gang et.al.发表的1提供了一个可以区分为微生物还是宿主代谢物的工具。该工具的核心是一个人工检验过具有微生物和宿主等标签的代谢物数据库。微生物独有的代谢物微生物独有的代谢物宿主独有代谢物宿主独有代谢物两者都可以代谢的代谢物两者都可以代谢的代谢物其他类型（未知）其他类型（未知）该工具没有提供R版本，需要到其网站使用。本教程只提供如何准备网站所需的输入文件。","code":""},{"path":"MetOriginAnalysis.html","id":"加载r包-10","chapter":"13 MetOrigin Analysis","heading":"13.1 加载R包","text":"","code":"\nknitr::opts_chunk$set(message = FALSE, warning = FALSE)\nlibrary(tidyverse)\n\n\n# rm(list = ls())\noptions(stringsAsFactors = F)\noptions(future.globals.maxSize = 1000 * 1024^2)\n\ngrp_names <- c(\"None\", \"Mild\", \"Moderate\", \"Severe\")\ngrp_colors <- c(\"#7DD06F\", \"#844081\", \"#688EC1\", \"#C17E73\")"},{"path":"MetOriginAnalysis.html","id":"导入数据-8","chapter":"13 MetOrigin Analysis","heading":"13.2 导入数据","text":"对数据OmicsDataSet-Zeybel et al. - 2022.xlsx处理后生成的，可参考数据预处理等章节。","code":"\nwrite.table(final_res, \"./InputData/result/DA/Metabolites_FC_VIP_ttest.tsv\", \nrow.names = F, quote = F, sep = \"\\t\", fileEncoding = \"UTF-8\")\ndatSignif <- data.table::fread(\"./InputData/result/DA/Metabolites_FC_VIP_ttest.tsv\")\n\n# DT::datatable(datSignif)\n\nhead(datSignif)\n#>                                         FeatureID\n#> 1: ceramide (d18:1/20:0, d16:1/22:0, d20:1/18:0)*\n#> 2:                 cysteine-glutathione disulfide\n#> 3:                                         serine\n#> 4:          1-palmitoyl-2-oleoyl-GPI (16:0/18:1)*\n#> 5:           1-stearoyl-2-oleoyl-GPI (18:0/18:1)*\n#> 6:     palmitoyl-oleoyl-glycerol (16:0/18:1) [2]*\n#>            Block2                Block FoldChange\n#> 1: None vs Severe 10_None vs 12_Severe  0.6444244\n#> 2: None vs Severe 10_None vs 12_Severe  1.7109000\n#> 3: None vs Severe 10_None vs 12_Severe  1.2218596\n#> 4: None vs Severe 10_None vs 12_Severe  0.5199556\n#> 5: None vs Severe 10_None vs 12_Severe  0.5667863\n#> 6: None vs Severe 10_None vs 12_Severe  0.5638085\n#>    Log2FoldChange      VIP    CorPvalue Statistic\n#> 1:     -0.6339170 2.672936 8.114814e-05 -4.854409\n#> 2:      0.7747554 2.601041 1.550944e-04  4.858307\n#> 3:      0.2890785 2.541717 2.544812e-04  4.456220\n#> 4:     -0.9435396 2.549095 2.397091e-04 -4.400999\n#> 5:     -0.8191231 2.469432 4.460156e-04 -4.108909\n#> 6:     -0.8267228 2.369314 9.073991e-04 -3.748881\n#>          Pvalue AdjustedPvalue Mean Abundance (All)\n#> 1: 0.0001301058     0.04202417              3841099\n#> 2: 0.0001184340     0.04202417              1246453\n#> 3: 0.0002529654     0.05447188             63358904\n#> 4: 0.0003436084     0.05549276              2243154\n#> 5: 0.0007169002     0.09262350              1817773\n#> 6: 0.0019076334     0.17057034              1192929\n#>    Mean Abundance None Mean Abundance Severe  metabolitesID\n#> 1:           2952496.1             4581602.1 Chem_100015755\n#> 2:           1611743.8              942044.4 Chem_100001437\n#> 3:          70323857.2            57554776.3       Chem_503\n#> 4:           1491869.7             2869225.1 Chem_100009066\n#> 5:           1282914.5             2263488.8 Chem_100009181\n#> 6:            838913.8             1487941.0 Chem_100010917\n#>                                       BIOCHEMICAL\n#> 1: ceramide (d18:1/20:0, d16:1/22:0, d20:1/18:0)*\n#> 2:                 cysteine-glutathione disulfide\n#> 3:                                         serine\n#> 4:          1-palmitoyl-2-oleoyl-GPI (16:0/18:1)*\n#> 5:           1-stearoyl-2-oleoyl-GPI (18:0/18:1)*\n#> 6:     palmitoyl-oleoyl-glycerol (16:0/18:1) [2]*\n#>    SUPER.PATHWAY                              SUB.PATHWAY\n#> 1:         Lipid                                Ceramides\n#> 2:    Amino Acid                   Glutathione Metabolism\n#> 3:    Amino Acid Glycine, Serine and Threonine Metabolism\n#> 4:         Lipid                Phosphatidylinositol (PI)\n#> 5:         Lipid                Phosphatidylinositol (PI)\n#> 6:         Lipid                           Diacylglycerol\n#>    COMPID        PLATFORM CHEMICALID   RI     MASS  PUBCHEM\n#> 1:  57440  LC/MS Pos Late  100015755 3920 594.5820     <NA>\n#> 2:  35159 LC/MS Pos Early  100001437 2465 427.0952  3080690\n#> 3:   1648 LC/MS Pos Early        503 1239 106.0499     5951\n#> 4:  52669  LC/MS Pos Late  100009066 3140 854.5753 71296232\n#> 5:  52726  LC/MS Pos Late  100009181 3711 882.6066     <NA>\n#> 6:  54942  LC/MS Pos Late  100010917 3695 612.5562  5282283\n#>           CAS   KEGG SampleIDHMDBID\n#> 1:       <NA>   <NA>           <NA>\n#> 2: 13081-14-6 R00900    HMDB0000656\n#> 3:    56-45-1 C00065    HMDB0000187\n#> 4:       <NA>   <NA>    HMDB0009783\n#> 5:       <NA>   <NA>           <NA>\n#> 6:       <NA> C13861    HMDB0007102"},{"path":"MetOriginAnalysis.html","id":"准备输入文件","chapter":"13 MetOrigin Analysis","heading":"13.3 准备输入文件","text":"网站需要的输入文件必须要以代谢物的名称如HMDBID等作为代谢物唯一标识，本文也将用HMDBID。除此之外，还需要设置表明代谢物差异富集方向的列Diff。metabolite table must contain least one column “HMDBID”, “KEGGID” “Name”, column 0/1 values indicating statistical significance (1-significant, 0-nonsignificant). “Diff” column missing, metabolites considered differential metabolites.","code":"\nget_metabolites <- function(\n  dat,\n  group_names,\n  index_names = c(\"FoldChange\", \"Log2FoldChange\", \"VIP\", \"CorPvalue\", \"Pvalue\", \"AdjustedPvalue\"),\n  index_cutoff = c(1, 1, 1, 0.05, 0.05, 0.2)) {\n  \n  \n  colnames(dat)[which(colnames(dat) == \"SampleIDHMDBID\")] <- \"HMDB\"\n  colnames(dat)[which(colnames(dat) == \"KEGG\")] <- \"cpd_ID\"\n  colnames(dat)[which(colnames(dat) == \"BIOCHEMICAL\")] <- \"Compounds\"\n  dat$HMDB <- gsub(\",\\\\S+\", \"\", dat$HMDB)\n  \n  temp_dat <- dat %>%\n    dplyr::filter(Block2 %in% group_names) %>%\n    dplyr::filter(HMDB != \"-\")\n  \n  colnames(temp_dat)[which(colnames(temp_dat) == index_names[1])] <- \"DA_index1\"\n  colnames(temp_dat)[which(colnames(temp_dat) == index_names[2])] <- \"DA_index2\"\n  \n  temp_dat_diff <- temp_dat %>%\n    dplyr::filter(abs(DA_index1) > index_cutoff[1]) %>%\n    dplyr::filter(DA_index2 < index_cutoff[2]) %>%\n    dplyr::mutate(Diff = 1)\n  \n  if (nrow(temp_dat_diff) == 0) {\n    stop(\"Beyond these thresholds, no significant metabolites were selected\")\n  }\n  \n  temp_dat_nodiff <- temp_dat %>%\n    dplyr::filter(!HMDB %in% temp_dat_diff$HMDB) %>%\n    dplyr::mutate(Diff = 0)\n  \n  res <- rbind(temp_dat_diff, temp_dat_nodiff) %>%\n    dplyr::select(HMDB, cpd_ID, Compounds, DA_index1, DA_index2, Diff) %>%\n    dplyr::rename(HMDBID = HMDB,\n                  KEGGID = cpd_ID,\n                  Name = Compounds) %>%\n    dplyr::select(HMDBID, KEGGID, Name, Diff)\n\n  return(res)\n}\n\npre_data <- get_metabolites(\n  dat = datSignif,\n  group_names = \"None vs Severe\",\n  index_names = c(\"Log2FoldChange\", \"AdjustedPvalue\"),\n  index_cutoff = c(0, 0.9))\n  \nhead(pre_data)\n#>         HMDBID KEGGID\n#> 1: HMDB0000656 R00900\n#> 2: HMDB0000187 C00065\n#> 3: HMDB0009783   <NA>\n#> 4: HMDB0007102 C13861\n#> 5: HMDB0004950   <NA>\n#> 6: HMDB0000177 C00135\n#>                                          Name Diff\n#> 1:             cysteine-glutathione disulfide    1\n#> 2:                                     serine    1\n#> 3:      1-palmitoyl-2-oleoyl-GPI (16:0/18:1)*    1\n#> 4: palmitoyl-oleoyl-glycerol (16:0/18:1) [2]*    1\n#> 5:       N-stearoyl-sphingosine (d18:1/18:0)*    1\n#> 6:                                  histidine    1"},{"path":"MetOriginAnalysis.html","id":"输出结果文件","chapter":"13 MetOrigin Analysis","heading":"13.4 输出结果文件","text":"csv file used inputs MetOrigin website.","code":"\nif(!dir.exists(\"./InputData/result/MetOrigin\")) {\n  dir.create(\"./InputData/result/MetOrigin\", recursive = TRUE)\n}\n\nwrite.csv(pre_data, \"./InputData/result/MetOrigin/MetOrigin_inputs.csv\", row.names = F)"},{"path":"MetOriginAnalysis.html","id":"metorigin-user-tutorial","chapter":"13 MetOrigin Analysis","heading":"13.5 MetOrigin User Tutorial","text":"MetOrigin comprises five parts:Load dataPlease select analysis mode first “Simple MetOrigin Analysis” “Deep MetOrigin Analysis”. can try “Load Example Data” upload data. Host information needs confirmed moving next step.Origin AnalysisThis step identify metabolites come : host, bacteria, , unknown?Function AnalysisThis step perform metabolic pathway enrichment analysis according different categories metabolites: metabolites belonging host, bacteria, .Sankey NetworkThis step link possible bacteria may participate specific metabolic reaction, helping identify important interplay bacteria metabolites.Download ResultsAll analysis results can downloaded data exploration.See details please go tutorial (MetOrigin website):","code":""},{"path":"MetOriginAnalysis.html","id":"结果解析","chapter":"13 MetOrigin Analysis","heading":"13.6 结果解析","text":"溯源分析：条形图和韦恩图展示代谢物的来源溯源分析：条形图和韦恩图展示代谢物的来源功能分析：分别用不同来源的差异代谢物做超几何富集分析，判断它们富集在哪些通路功能分析：分别用不同来源的差异代谢物做超几何富集分析，判断它们富集在哪些通路桑基图网络分析：某个特定代谢通路的微生物对代谢物的贡献程度，不同颜色表明微生物对代谢物的上下调关系桑基图网络分析：某个特定代谢通路的微生物对代谢物的贡献程度，不同颜色表明微生物对代谢物的上下调关系","code":""},{"path":"MetOriginAnalysis.html","id":"session-info-5","chapter":"13 MetOrigin Analysis","heading":"13.7 Session info","text":"","code":"\ndevtools::session_info()\n#> ─ Session info ───────────────────────────────────────────\n#>  setting  value\n#>  version  R version 4.1.3 (2022-03-10)\n#>  os       macOS Big Sur/Monterey 10.16\n#>  system   x86_64, darwin17.0\n#>  ui       X11\n#>  language (EN)\n#>  collate  en_US.UTF-8\n#>  ctype    en_US.UTF-8\n#>  tz       Asia/Shanghai\n#>  date     2024-02-06\n#>  pandoc   3.1.1 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/ (via rmarkdown)\n#> \n#> ─ Packages ───────────────────────────────────────────────\n#>  package     * version date (UTC) lib source\n#>  bookdown      0.34    2023-05-09 [2] CRAN (R 4.1.2)\n#>  bslib         0.6.0   2023-11-21 [1] CRAN (R 4.1.3)\n#>  cachem        1.0.8   2023-05-01 [2] CRAN (R 4.1.2)\n#>  callr         3.7.3   2022-11-02 [2] CRAN (R 4.1.2)\n#>  cli           3.6.1   2023-03-23 [2] CRAN (R 4.1.2)\n#>  colorspace    2.1-0   2023-01-23 [2] CRAN (R 4.1.2)\n#>  crayon        1.5.2   2022-09-29 [2] CRAN (R 4.1.2)\n#>  data.table    1.14.8  2023-02-17 [2] CRAN (R 4.1.2)\n#>  devtools      2.4.5   2022-10-11 [2] CRAN (R 4.1.2)\n#>  digest        0.6.33  2023-07-07 [1] CRAN (R 4.1.3)\n#>  downlit       0.4.3   2023-06-29 [2] CRAN (R 4.1.3)\n#>  dplyr       * 1.1.4   2023-11-17 [1] CRAN (R 4.1.3)\n#>  ellipsis      0.3.2   2021-04-29 [2] CRAN (R 4.1.0)\n#>  evaluate      0.21    2023-05-05 [2] CRAN (R 4.1.2)\n#>  fansi         1.0.4   2023-01-22 [2] CRAN (R 4.1.2)\n#>  fastmap       1.1.1   2023-02-24 [2] CRAN (R 4.1.2)\n#>  forcats     * 1.0.0   2023-01-29 [1] CRAN (R 4.1.2)\n#>  fs            1.6.2   2023-04-25 [2] CRAN (R 4.1.2)\n#>  generics      0.1.3   2022-07-05 [2] CRAN (R 4.1.2)\n#>  ggplot2     * 3.4.4   2023-10-12 [1] CRAN (R 4.1.3)\n#>  glue          1.6.2   2022-02-24 [2] CRAN (R 4.1.2)\n#>  gtable        0.3.3   2023-03-21 [2] CRAN (R 4.1.2)\n#>  hms           1.1.3   2023-03-21 [2] CRAN (R 4.1.2)\n#>  htmltools     0.5.7   2023-11-03 [1] CRAN (R 4.1.3)\n#>  htmlwidgets   1.6.2   2023-03-17 [2] CRAN (R 4.1.2)\n#>  httpuv        1.6.11  2023-05-11 [2] CRAN (R 4.1.3)\n#>  jquerylib     0.1.4   2021-04-26 [2] CRAN (R 4.1.0)\n#>  jsonlite      1.8.7   2023-06-29 [2] CRAN (R 4.1.3)\n#>  knitr         1.43    2023-05-25 [2] CRAN (R 4.1.3)\n#>  later         1.3.1   2023-05-02 [2] CRAN (R 4.1.2)\n#>  lifecycle     1.0.3   2022-10-07 [2] CRAN (R 4.1.2)\n#>  lubridate   * 1.9.2   2023-02-10 [2] CRAN (R 4.1.2)\n#>  magrittr      2.0.3   2022-03-30 [2] CRAN (R 4.1.2)\n#>  memoise       2.0.1   2021-11-26 [2] CRAN (R 4.1.0)\n#>  mime          0.12    2021-09-28 [2] CRAN (R 4.1.0)\n#>  miniUI        0.1.1.1 2018-05-18 [2] CRAN (R 4.1.0)\n#>  munsell       0.5.0   2018-06-12 [2] CRAN (R 4.1.0)\n#>  pillar        1.9.0   2023-03-22 [2] CRAN (R 4.1.2)\n#>  pkgbuild      1.4.2   2023-06-26 [2] CRAN (R 4.1.3)\n#>  pkgconfig     2.0.3   2019-09-22 [2] CRAN (R 4.1.0)\n#>  pkgload       1.3.2.1 2023-07-08 [2] CRAN (R 4.1.3)\n#>  prettyunits   1.1.1   2020-01-24 [2] CRAN (R 4.1.0)\n#>  processx      3.8.2   2023-06-30 [2] CRAN (R 4.1.3)\n#>  profvis       0.3.8   2023-05-02 [2] CRAN (R 4.1.2)\n#>  promises      1.2.0.1 2021-02-11 [2] CRAN (R 4.1.0)\n#>  ps            1.7.5   2023-04-18 [2] CRAN (R 4.1.2)\n#>  purrr       * 1.0.1   2023-01-10 [1] CRAN (R 4.1.2)\n#>  R6            2.5.1   2021-08-19 [2] CRAN (R 4.1.0)\n#>  Rcpp          1.0.11  2023-07-06 [1] CRAN (R 4.1.3)\n#>  readr       * 2.1.4   2023-02-10 [1] CRAN (R 4.1.2)\n#>  remotes       2.4.2   2021-11-30 [2] CRAN (R 4.1.0)\n#>  rlang         1.1.1   2023-04-28 [1] CRAN (R 4.1.2)\n#>  rmarkdown     2.23    2023-07-01 [2] CRAN (R 4.1.3)\n#>  rstudioapi    0.15.0  2023-07-07 [2] CRAN (R 4.1.3)\n#>  sass          0.4.6   2023-05-03 [2] CRAN (R 4.1.2)\n#>  scales        1.2.1   2022-08-20 [1] CRAN (R 4.1.2)\n#>  sessioninfo   1.2.2   2021-12-06 [2] CRAN (R 4.1.0)\n#>  shiny         1.7.4.1 2023-07-06 [2] CRAN (R 4.1.3)\n#>  stringi       1.7.12  2023-01-11 [2] CRAN (R 4.1.2)\n#>  stringr     * 1.5.1   2023-11-14 [1] CRAN (R 4.1.3)\n#>  tibble      * 3.2.1   2023-03-20 [1] CRAN (R 4.1.2)\n#>  tidyr       * 1.3.0   2023-01-24 [1] CRAN (R 4.1.2)\n#>  tidyselect    1.2.0   2022-10-10 [2] CRAN (R 4.1.2)\n#>  tidyverse   * 2.0.0   2023-02-22 [1] CRAN (R 4.1.2)\n#>  timechange    0.2.0   2023-01-11 [2] CRAN (R 4.1.2)\n#>  tzdb          0.4.0   2023-05-12 [2] CRAN (R 4.1.3)\n#>  urlchecker    1.0.1   2021-11-30 [2] CRAN (R 4.1.0)\n#>  usethis       2.2.2   2023-07-06 [2] CRAN (R 4.1.3)\n#>  utf8          1.2.3   2023-01-31 [2] CRAN (R 4.1.2)\n#>  vctrs         0.6.5   2023-12-01 [1] CRAN (R 4.1.3)\n#>  withr         2.5.0   2022-03-03 [2] CRAN (R 4.1.2)\n#>  xfun          0.40    2023-08-09 [1] CRAN (R 4.1.3)\n#>  xml2          1.3.5   2023-07-06 [2] CRAN (R 4.1.3)\n#>  xtable        1.8-4   2019-04-21 [2] CRAN (R 4.1.0)\n#>  yaml          2.3.7   2023-01-23 [2] CRAN (R 4.1.2)\n#> \n#>  [1] /Users/zouhua/Library/R/x86_64/4.1/library\n#>  [2] /Library/Frameworks/R.framework/Versions/4.1/Resources/library\n#> \n#> ──────────────────────────────────────────────────────────"},{"path":"MetOriginAnalysis.html","id":"reference-11","chapter":"13 MetOrigin Analysis","heading":"13.8 Reference","text":"metorigin website","code":""},{"path":"OtherAnalysis.html","id":"OtherAnalysis","chapter":"14 Other Analysis","heading":"14 Other Analysis","text":"除了常见的功能分析，还有其他的功能分析方法或R包。本章节主要介绍其他功能分析的方法以及结果解析。","code":""},{"path":"OtherAnalysis.html","id":"fella-an-r-package-to-enrich-metabolomics-data","chapter":"14 Other Analysis","heading":"14.1 FELLA: an R package to enrich metabolomics data","text":"FELLA（2）发表于2018年，现谷歌引用67次，它是一个专门用于代谢组通路分析的R包。基于前期分析得到的差异代谢物来构建基于网络的富集分析。结果包括代谢通路、模块、酶、反应及代谢物。那么除了能够提供通路列表，FELLA还能够生成输入代谢物相关的中间物质（如模块、酶、反应）。可以反映特定研究条件下代谢通路之间的交集以及靶向潜在的酶和代谢物。它包含了以下三步：Block : local database从数据库抓取数据后，将其处理转存在本地；Block : local database从数据库抓取数据后，将其处理转存在本地；Block II: enrichment analysis将关心的代谢物作为输入，做富集分析；Block II: enrichment analysis将关心的代谢物作为输入，做富集分析；Block III: exporting results导出数据。Block III: exporting results导出数据。","code":""},{"path":"OtherAnalysis.html","id":"加载r包-11","chapter":"14 Other Analysis","heading":"14.1.1 加载R包","text":"","code":"\nknitr::opts_chunk$set(message = FALSE, warning = FALSE)\nlibrary(tidyverse)\nlibrary(FELLA)\n\n# rm(list = ls())\noptions(stringsAsFactors = F)\noptions(future.globals.maxSize = 1000 * 1024^2)\n\ngrp_names <- c(\"None\", \"Mild\", \"Moderate\", \"Severe\")\ngrp_colors <- c(\"#7DD06F\", \"#844081\", \"#688EC1\", \"#C17E73\")"},{"path":"OtherAnalysis.html","id":"背景数据库生成","chapter":"14 Other Analysis","heading":"14.1.2 背景数据库生成","text":"代谢组测试数据是来自病人血清，但也提供构建小鼠的通路背景数据库（每次下载数据库可能会发生变化，因为官网可能更新过）人的KEGG背景数据库从KEGG官网下载数据；构建背景数据库；导入内存环境.小鼠的KEGG背景数据库从KEGG官网下载数据；构建背景数据库；基因名字转换成entrez ID，酶转换成entrez ID；导入内存环境.","code":"\nlibrary(KEGGREST)\nlibrary(igraph)\n\ntmpdir <- \"./InputData/FELLA/hsa\"\n\nif (!file.exists(\"./InputData/FELLA/hsa/keggdata.graph.RData\")) {\n  set.seed(123)\n  # 下载KEGG\n  graph <- buildGraphFromKEGGREST(\n    organism = \"hsa\", \n    filter.path = \"hsa01100\")\n  \n  tmpdir <- \"./InputData/FELLA/hsa\"\n  unlink(tmpdir, recursive = TRUE)\n  \n  # 构建数据库\n  buildDataFromGraph(\n    keggdata.graph = graph,\n    databaseDir = tmpdir,\n    internalDir = FALSE,\n    matrices = \"none\",\n    normality = \"diffusion\",\n    niter = 100)  \n}\n\n# 导入数据库进内存\nfella.data <- loadKEGGdata(\n  databaseDir = tmpdir,\n  internalDir = FALSE,\n  loadMatrix = \"none\")\n\nfella.data\n#> General data:\n#> - KEGG graph:\n#>   * Nodes:  11891 \n#>   * Edges:  38085 \n#>   * Density:  0.0002693728 \n#>   * Categories:\n#>     + pathway [349]\n#>     + module [193]\n#>     + enzyme [1195]\n#>     + reaction [5856]\n#>     + compound [4298]\n#>   * Size:  5.9 Mb \n#> - KEGG names are ready.\n#> -----------------------------\n#> Hypergeometric test:\n#> - Matrix not loaded.\n#> -----------------------------\n#> Heat diffusion:\n#> - Matrix not loaded.\n#> - RowSums are ready.\n#> -----------------------------\n#> PageRank:\n#> - Matrix not loaded.\n#> - RowSums not loaded.\nlibrary(KEGGREST)\nlibrary(igraph)\nlibrary(org.Mm.eg.db)\n\ntmpdir <- \"./InputData/FELLA/mmu\"\n\nif (!file.exists(\"./InputData/FELLA/mmu/keggdata.graph.RData\")) {\n  set.seed(123)\n  # 下载KEGG\ngraph <- buildGraphFromKEGGREST(\n  organism = \"mmu\",\n  filter.path = c(\"01100\", \"01200\", \"01210\", \"01212\", \"01230\"))\n  \n  tmpdir <- \"./InputData/FELLA/mmu\"\n  unlink(tmpdir, recursive = TRUE)\n  \n  # 构建数据库\n  buildDataFromGraph(\n    keggdata.graph = graph,\n    databaseDir = tmpdir,\n    internalDir = FALSE,\n    matrices = \"none\",\n    normality = \"diffusion\",\n    niter = 100)  \n  \n  alias2entrez <- as.list(org.Mm.eg.db::org.Mm.egSYMBOL2EG)\n  entrez2ec <- KEGGREST::keggLink(\"enzyme\", \"mmu\")\n  entrez2path <- KEGGREST::keggLink(\"pathway\", \"mmu\")\n\n}\n\n# 导入数据库进内存\nfella.data <- loadKEGGdata(\n  databaseDir = tmpdir,\n  internalDir = FALSE,\n  loadMatrix = \"none\")\n\nfella.data"},{"path":"OtherAnalysis.html","id":"导入数据-9","chapter":"14 Other Analysis","heading":"14.1.3 导入数据","text":"对数据OmicsDataSet-Zeybel et al. - 2022.xlsx处理后生成的，可参考数据预处理等章节。","code":"\nwrite.table(final_res, \"./InputData/result/DA/Metabolites_FC_VIP_ttest.tsv\", \nrow.names = F, quote = F, sep = \"\\t\", fileEncoding = \"UTF-8\")\ndatSignif <- data.table::fread(\"./InputData/result/DA/Metabolites_FC_VIP_ttest.tsv\")\n\n# DT::datatable(datSignif)\n\nhead(datSignif)\n#>                                         FeatureID\n#> 1: ceramide (d18:1/20:0, d16:1/22:0, d20:1/18:0)*\n#> 2:                 cysteine-glutathione disulfide\n#> 3:                                         serine\n#> 4:          1-palmitoyl-2-oleoyl-GPI (16:0/18:1)*\n#> 5:           1-stearoyl-2-oleoyl-GPI (18:0/18:1)*\n#> 6:     palmitoyl-oleoyl-glycerol (16:0/18:1) [2]*\n#>            Block2                Block FoldChange\n#> 1: None vs Severe 10_None vs 12_Severe  0.6444244\n#> 2: None vs Severe 10_None vs 12_Severe  1.7109000\n#> 3: None vs Severe 10_None vs 12_Severe  1.2218596\n#> 4: None vs Severe 10_None vs 12_Severe  0.5199556\n#> 5: None vs Severe 10_None vs 12_Severe  0.5667863\n#> 6: None vs Severe 10_None vs 12_Severe  0.5638085\n#>    Log2FoldChange      VIP    CorPvalue Statistic\n#> 1:     -0.6339170 2.672936 8.114814e-05 -4.854409\n#> 2:      0.7747554 2.601041 1.550944e-04  4.858307\n#> 3:      0.2890785 2.541717 2.544812e-04  4.456220\n#> 4:     -0.9435396 2.549095 2.397091e-04 -4.400999\n#> 5:     -0.8191231 2.469432 4.460156e-04 -4.108909\n#> 6:     -0.8267228 2.369314 9.073991e-04 -3.748881\n#>          Pvalue AdjustedPvalue Mean Abundance (All)\n#> 1: 0.0001301058     0.04202417              3841099\n#> 2: 0.0001184340     0.04202417              1246453\n#> 3: 0.0002529654     0.05447188             63358904\n#> 4: 0.0003436084     0.05549276              2243154\n#> 5: 0.0007169002     0.09262350              1817773\n#> 6: 0.0019076334     0.17057034              1192929\n#>    Mean Abundance None Mean Abundance Severe  metabolitesID\n#> 1:           2952496.1             4581602.1 Chem_100015755\n#> 2:           1611743.8              942044.4 Chem_100001437\n#> 3:          70323857.2            57554776.3       Chem_503\n#> 4:           1491869.7             2869225.1 Chem_100009066\n#> 5:           1282914.5             2263488.8 Chem_100009181\n#> 6:            838913.8             1487941.0 Chem_100010917\n#>                                       BIOCHEMICAL\n#> 1: ceramide (d18:1/20:0, d16:1/22:0, d20:1/18:0)*\n#> 2:                 cysteine-glutathione disulfide\n#> 3:                                         serine\n#> 4:          1-palmitoyl-2-oleoyl-GPI (16:0/18:1)*\n#> 5:           1-stearoyl-2-oleoyl-GPI (18:0/18:1)*\n#> 6:     palmitoyl-oleoyl-glycerol (16:0/18:1) [2]*\n#>    SUPER.PATHWAY                              SUB.PATHWAY\n#> 1:         Lipid                                Ceramides\n#> 2:    Amino Acid                   Glutathione Metabolism\n#> 3:    Amino Acid Glycine, Serine and Threonine Metabolism\n#> 4:         Lipid                Phosphatidylinositol (PI)\n#> 5:         Lipid                Phosphatidylinositol (PI)\n#> 6:         Lipid                           Diacylglycerol\n#>    COMPID        PLATFORM CHEMICALID   RI     MASS  PUBCHEM\n#> 1:  57440  LC/MS Pos Late  100015755 3920 594.5820     <NA>\n#> 2:  35159 LC/MS Pos Early  100001437 2465 427.0952  3080690\n#> 3:   1648 LC/MS Pos Early        503 1239 106.0499     5951\n#> 4:  52669  LC/MS Pos Late  100009066 3140 854.5753 71296232\n#> 5:  52726  LC/MS Pos Late  100009181 3711 882.6066     <NA>\n#> 6:  54942  LC/MS Pos Late  100010917 3695 612.5562  5282283\n#>           CAS   KEGG SampleIDHMDBID\n#> 1:       <NA>   <NA>           <NA>\n#> 2: 13081-14-6 R00900    HMDB0000656\n#> 3:    56-45-1 C00065    HMDB0000187\n#> 4:       <NA>   <NA>    HMDB0009783\n#> 5:       <NA>   <NA>           <NA>\n#> 6:       <NA> C13861    HMDB0007102"},{"path":"OtherAnalysis.html","id":"准备输入代谢物","chapter":"14 Other Analysis","heading":"14.1.4 准备输入代谢物","text":"代谢物的ID要是KEGG ID，需要注意⚠️。随机挑选5个代谢物用于分析。","code":"\nset.seed(123)\n\ndatSignif$KEGG <- gsub(\",\\\\S+\", \"\", datSignif$KEGG)\n\ndatSignif_KEGG <- datSignif %>%\n  dplyr::filter(!is.na(KEGG)) %>%\n  dplyr::filter(SUPER.PATHWAY == \"Amino Acid\") %>%\n  dplyr::select(BIOCHEMICAL, KEGG) \n\ntarget_metabolites <- datSignif_KEGG[sample(1:nrow(datSignif_KEGG), 5), ,]\n\nhead(target_metabolites)\n#>             BIOCHEMICAL   KEGG\n#> 1:   N-formylmethionine C03145\n#> 2:        phenylalanine C00079\n#> 3:           asparagine C00152\n#> 4: methionine sulfoxide C02989\n#> 5:            ornithine C00077"},{"path":"OtherAnalysis.html","id":"富集分析-1","chapter":"14 Other Analysis","heading":"14.1.5 富集分析","text":"富集分析的方法有三种超几何检验超几何检验Diffusion（有意义子网络）Diffusion（有意义子网络）PageRank（和Diffusion类似，对网络进行排序）PageRank（和Diffusion类似，对网络进行排序）统计分析：对Diffusion和PageRank提供了两种统计方法Normal approximation(approx = “normality”)，基于无效假设的分析的期望值和协方差矩阵的z-score计算得到得分值Normal approximation(approx = “normality”)，基于无效假设的分析的期望值和协方差矩阵的z-score计算得到得分值Monte Carlo trials(approx = “simulation”)，随机变量的蒙特卡罗实验计算得分值Monte Carlo trials(approx = “simulation”)，随机变量的蒙特卡罗实验计算得分值可通过method选择不同富集方法，本次运行选择diffusion可通过method选择不同富集方法，本次运行选择diffusion结果：展示了diffusion方法下富集的结果, 有104个节点。可视化结果输出富集分析结果表格","code":"\nmyAnalysis <- enrich(\n    compounds = target_metabolites$KEGG, \n    method = \"diffusion\", # listMethods()\n    approx = \"normality\", \n    data = fella.data)\n\nshow(myAnalysis)\n#> Compounds in the input: 5\n#> [1] \"C03145\" \"C00079\" \"C00152\" \"C02989\" \"C00077\"\n#> Background compounds: all available compounds (default)\n#> -----------------------------\n#> Hypergeometric test: not performed\n#> -----------------------------\n#> Heat diffusion: ready.\n#> P-scores under 0.05:  172\n#> -----------------------------\n#> PageRank: not performed\nplot(\n    x = myAnalysis, \n    method = \"diffusion\", \n    main = \"diffusion analysis in FELLA\", \n    threshold = 0.1, \n    data = fella.data,\n    nlimit = 100)\nmyTable <- generateResultsTable(\n    object = myAnalysis, \n    method = \"diffusion\", \n    threshold = 0.1, \n    data = fella.data)\n\nknitr::kable(head(myTable, 10), format = \"html\")"},{"path":"OtherAnalysis.html","id":"结果解析-1","chapter":"14 Other Analysis","heading":"14.1.6 结果解析","text":"筛选的5个代谢物富集在(diffusion)“hsa00250”和”hsa00270”等通路，并且这些通路大部分和氨基酸代谢相关；筛选的5个代谢物富集在(diffusion)“hsa00250”和”hsa00270”等通路，并且这些通路大部分和氨基酸代谢相关；除了代谢通路外，还有代谢模块等其他更为具体的通路组成，比如酶和反应等；除了代谢通路外，还有代谢模块等其他更为具体的通路组成，比如酶和反应等；相比传统的富集分析，FELLA能将代谢通路各个层级混合在一起做成网络分析是其特点，比如p53 signaling pathway - Homo sapiens (human)相关的酶是ribonucleoside-diphosphate reductase，该酶又和反应5-fluorodeoxyuridine-diphosphate相关。相比传统的富集分析，FELLA能将代谢通路各个层级混合在一起做成网络分析是其特点，比如p53 signaling pathway - Homo sapiens (human)相关的酶是ribonucleoside-diphosphate reductase，该酶又和反应5-fluorodeoxyuridine-diphosphate相关。","code":""},{"path":"OtherAnalysis.html","id":"pathview-代谢物数据可视化kegg通路图","chapter":"14 Other Analysis","heading":"14.2 Pathview: 代谢物数据可视化KEGG通路图","text":"Pathview（Pathway based data integration visualization，https://pathview.uncc.edu/）是一个用于KEGG通路可视化的工具集，能够将多种生物的基因或代谢物映射到该物种的KEGG通路图上，例如在转录组、蛋白组或代谢组中展示差异表达的基因、蛋白或代谢物等。本教程是基于代谢组数据，使用代谢组KEGGID (如C00064）等。","code":""},{"path":"OtherAnalysis.html","id":"安装pathview包","chapter":"14 Other Analysis","heading":"14.2.1 安装pathview包","text":"","code":"\nif (!requireNamespace(\"pathview\", quietly=TRUE)) {\n  BiocManager::install('pathview')\n}"},{"path":"OtherAnalysis.html","id":"准备输入数据","chapter":"14 Other Analysis","heading":"14.2.2 准备输入数据","text":"筛选包含Log2FoldChange和KEGG的代谢物输入数据（pathview要求输入数据包含差异倍数以及代谢物的KEGGID）。","code":"\nset.seed(123)\n\ndatSignif <- data.table::fread(\"./InputData/result/DA/Metabolites_FC_VIP_ttest.tsv\")\n\ndatSignif$KEGG <- gsub(\",\\\\S+\", \"\", datSignif$KEGG)\n\ndatSignif_KEGG <- datSignif %>%\n  dplyr::filter(!is.na(KEGG)) %>%\n  dplyr::filter(SUPER.PATHWAY == \"Amino Acid\") %>%\n  dplyr::select(BIOCHEMICAL, KEGG, Log2FoldChange) \n\n# head(datSignif_KEGG)\n\ncompound_data <- datSignif_KEGG$Log2FoldChange\nnames(compound_data) <- datSignif_KEGG$KEGG\n\ncompound_data[1:6]\n#>     R00900     C00065     C00135     C05568     C01188 \n#>  0.7747554  0.2890785  0.1947889  0.3253860 -0.4819788 \n#>     C00719 \n#>  0.2584803"},{"path":"OtherAnalysis.html","id":"运行pathview","chapter":"14 Other Analysis","heading":"14.2.3 运行pathview","text":"根据myTable可以看到富集在00250和00310等通路，最后选择00250通路展示。\nFigure 14.1: KEGG 00250 pathway\n结果：蓝色和黄色表示富集方向，能看到3个颜色明显的代谢物在该通路中发挥的作用。","code":"\nlibrary(pathview)\n\npl <- pathview(\n  cpd.data = compound_data,\n  cpd.idtype   = \"kegg\",\n  species      = \"hsa\", \n  kegg.native  = TRUE,\n  pathway.id   = \"hsa00250\",\n  out.suffix   = \"compound\",\n  limit        = list(gene=1, cpd=max(abs(datSignif_KEGG$Log2FoldChange))))#> [1] TRUE"},{"path":"OtherAnalysis.html","id":"apear-an-r-package-for-autonomous-visualisation-of-pathway-enrichment-networks","chapter":"14 Other Analysis","heading":"14.3 aPEAR: an R package for autonomous visualisation of pathway enrichment networks","text":"interpretation pathway enrichment analysis results frequently complicated overwhelming redundant list significantly affected pathways. , present R package aPEAR (Advanced Pathway Enrichment Analysis Representation) leverages similarities pathway gene sets represents network interconnected clusters. cluster assigned meaningful name highlights main biological themes experiment. approach enables automated objective overview data without manual time-consuming parameter tweaking.aPEAR利用通路间的相似性将通路进行聚类，方便解释通路富集分析的结果。aPEAR提供一个enrichmentNetwork函数，将结果可视化成网络。其原理：pairwise similarity pathway gene sets evaluated using Jaccard index (default), cosine similarity, correlation similarity metrics.pairwise similarity pathway gene sets evaluated using Jaccard index (default), cosine similarity, correlation similarity metrics.similarity matrix used detect clusters redundant pathways using Markov (default) (Van Dongen 2008), hierarchical, spectral (John et al. 2020) clustering algorithms.similarity matrix used detect clusters redundant pathways using Markov (default) (Van Dongen 2008), hierarchical, spectral (John et al. 2020) clustering algorithms.所有通路的基因计算成对相似性 (默认使用Jaccard距离)。所有通路的基因计算成对相似性 (默认使用Jaccard距离)。将冗余的通路聚类在一起。将冗余的通路聚类在一起。","code":""},{"path":"OtherAnalysis.html","id":"安装apear包","chapter":"14 Other Analysis","heading":"14.3.1 安装aPEAR包","text":"","code":"\nif (!requireNamespace(\"aPEAR\", quietly=TRUE)) {\n  BiocManager::install('aPEAR')\n}"},{"path":"OtherAnalysis.html","id":"准备输入数据-1","chapter":"14 Other Analysis","heading":"14.3.2 准备输入数据","text":"筛选包含Log2FoldChange和KEGG的代谢物输入数据。","code":"\nset.seed(123)\n\ndatSignif <- data.table::fread(\"./InputData/result/DA/Metabolites_FC_VIP_ttest.tsv\")\ndatSignif$KEGG <- gsub(\",\\\\S+\", \"\", datSignif$KEGG)\ndatSignif_KEGG <- datSignif %>%\n  dplyr::filter(!is.na(KEGG)) %>%\n  dplyr::filter(SUPER.PATHWAY == \"Amino Acid\") %>%\n  dplyr::select(BIOCHEMICAL, KEGG, Log2FoldChange) \n\n\nhsa_kegg_compound <- read.csv(\"./InputData/result/KEGG/KEGG_COMPOUND_PATHWAY_hsa.csv\") \nref_cln <- hsa_kegg_compound %>%\n    dplyr::select(PATHWAY_MAP, COMPOUND) %>%\n    dplyr::rename(Pathway = PATHWAY_MAP)"},{"path":"OtherAnalysis.html","id":"富集分析-2","chapter":"14 Other Analysis","heading":"14.3.3 富集分析","text":"采用ORA富集分析方法","code":"\nORA_fit <- clusterProfiler::enricher(\n  gene = datSignif_KEGG$KEGG,\n  pvalueCutoff = 0.05,\n  pAdjustMethod = \"BH\",\n  minGSSize = 10,\n  maxGSSize = 500,\n  qvalueCutoff = 0.2,\n  TERM2GENE = ref_cln)"},{"path":"OtherAnalysis.html","id":"apear网络图","chapter":"14 Other Analysis","heading":"14.3.4 aPEAR网络图","text":"aPEAR画网络图结果:节点表示显著通路，边表示相关性，颜色表示标准化后的富集得分；节点表示显著通路，边表示相关性，颜色表示标准化后的富集得分；每个簇分类了一个具有生物学意义的名称；每个簇分类了一个具有生物学意义的名称；NES值表示聚类簇通路的重要性，NES越高通路越重要。NES值表示聚类簇通路的重要性，NES越高通路越重要。","code":"\nlibrary(aPEAR)\n\nenrichmentNetwork(\n  ORA_fit@result,\n  fontSize = 3,\n  outerCutoff = 0.5,\n  drawEllipses = TRUE,\n  repelLabels = TRUE)"},{"path":"OtherAnalysis.html","id":"session-info-6","chapter":"14 Other Analysis","heading":"14.4 Session info","text":"","code":"\ndevtools::session_info()\n#> ─ Session info ───────────────────────────────────────────\n#>  setting  value\n#>  version  R version 4.1.3 (2022-03-10)\n#>  os       macOS Big Sur/Monterey 10.16\n#>  system   x86_64, darwin17.0\n#>  ui       X11\n#>  language (EN)\n#>  collate  en_US.UTF-8\n#>  ctype    en_US.UTF-8\n#>  tz       Asia/Shanghai\n#>  date     2024-02-06\n#>  pandoc   3.1.1 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/ (via rmarkdown)\n#> \n#> ─ Packages ───────────────────────────────────────────────\n#>  package          * version    date (UTC) lib source\n#>  AnnotationDbi      1.60.2     2023-03-10 [2] Bioconductor\n#>  ape                5.7-1      2023-03-13 [1] CRAN (R 4.1.2)\n#>  aPEAR            * 1.0.0      2023-06-12 [1] CRAN (R 4.1.3)\n#>  aplot              0.1.10     2023-03-08 [2] CRAN (R 4.1.2)\n#>  arules             1.7-6      2023-03-23 [1] CRAN (R 4.1.2)\n#>  bayesbio           1.0.0      2016-05-24 [1] CRAN (R 4.1.0)\n#>  Biobase            2.54.0     2021-10-26 [2] Bioconductor\n#>  BiocGenerics       0.40.0     2021-10-26 [2] Bioconductor\n#>  BiocParallel       1.28.3     2021-12-09 [2] Bioconductor\n#>  Biostrings         2.62.0     2021-10-26 [2] Bioconductor\n#>  bit                4.0.5      2022-11-15 [2] CRAN (R 4.1.2)\n#>  bit64              4.0.5      2020-08-30 [2] CRAN (R 4.1.0)\n#>  bitops             1.0-7      2021-04-24 [2] CRAN (R 4.1.0)\n#>  blob               1.2.4      2023-03-17 [2] CRAN (R 4.1.2)\n#>  bookdown           0.34       2023-05-09 [2] CRAN (R 4.1.2)\n#>  bslib              0.6.0      2023-11-21 [1] CRAN (R 4.1.3)\n#>  cachem             1.0.8      2023-05-01 [2] CRAN (R 4.1.2)\n#>  callr              3.7.3      2022-11-02 [2] CRAN (R 4.1.2)\n#>  cli                3.6.1      2023-03-23 [2] CRAN (R 4.1.2)\n#>  clusterProfiler    4.2.2      2022-01-13 [2] Bioconductor\n#>  colorspace         2.1-0      2023-01-23 [2] CRAN (R 4.1.2)\n#>  crayon             1.5.2      2022-09-29 [2] CRAN (R 4.1.2)\n#>  data.table         1.14.8     2023-02-17 [2] CRAN (R 4.1.2)\n#>  DBI                1.1.3      2022-06-18 [2] CRAN (R 4.1.2)\n#>  devtools           2.4.5      2022-10-11 [2] CRAN (R 4.1.2)\n#>  digest             0.6.33     2023-07-07 [1] CRAN (R 4.1.3)\n#>  DO.db              2.9        2022-04-11 [2] Bioconductor\n#>  DOSE               3.20.1     2021-11-18 [2] Bioconductor\n#>  downlit            0.4.3      2023-06-29 [2] CRAN (R 4.1.3)\n#>  downloader         0.4        2015-07-09 [2] CRAN (R 4.1.0)\n#>  dplyr            * 1.1.4      2023-11-17 [1] CRAN (R 4.1.3)\n#>  ellipsis           0.3.2      2021-04-29 [2] CRAN (R 4.1.0)\n#>  enrichplot         1.14.2     2022-02-24 [2] Bioconductor\n#>  evaluate           0.21       2023-05-05 [2] CRAN (R 4.1.2)\n#>  expm               0.999-7    2023-01-09 [2] CRAN (R 4.1.2)\n#>  fansi              1.0.4      2023-01-22 [2] CRAN (R 4.1.2)\n#>  farver             2.1.1      2022-07-06 [2] CRAN (R 4.1.2)\n#>  fastmap            1.1.1      2023-02-24 [2] CRAN (R 4.1.2)\n#>  fastmatch          1.1-3      2021-07-23 [2] CRAN (R 4.1.0)\n#>  FELLA            * 1.14.0     2021-10-26 [1] Bioconductor\n#>  fgsea              1.20.0     2021-10-26 [2] Bioconductor\n#>  forcats          * 1.0.0      2023-01-29 [1] CRAN (R 4.1.2)\n#>  fs                 1.6.2      2023-04-25 [2] CRAN (R 4.1.2)\n#>  generics           0.1.3      2022-07-05 [2] CRAN (R 4.1.2)\n#>  GenomeInfoDb       1.30.1     2022-01-30 [2] Bioconductor\n#>  GenomeInfoDbData   1.2.7      2022-03-09 [2] Bioconductor\n#>  ggforce            0.4.1      2022-10-04 [2] CRAN (R 4.1.2)\n#>  ggfun              0.1.1      2023-06-24 [2] CRAN (R 4.1.3)\n#>  ggplot2          * 3.4.4      2023-10-12 [1] CRAN (R 4.1.3)\n#>  ggplotify          0.1.1      2023-06-27 [2] CRAN (R 4.1.3)\n#>  ggraph             2.1.0.9000 2023-07-11 [1] Github (thomasp85/ggraph@febab71)\n#>  ggrepel            0.9.3      2023-02-03 [1] CRAN (R 4.1.2)\n#>  ggtree             3.2.1      2021-11-16 [2] Bioconductor\n#>  glue               1.6.2      2022-02-24 [2] CRAN (R 4.1.2)\n#>  GO.db              3.14.0     2022-04-11 [2] Bioconductor\n#>  GOSemSim           2.20.0     2021-10-26 [2] Bioconductor\n#>  graph              1.72.0     2021-10-26 [2] Bioconductor\n#>  graphlayouts       1.0.0      2023-05-01 [2] CRAN (R 4.1.2)\n#>  gridExtra          2.3        2017-09-09 [2] CRAN (R 4.1.0)\n#>  gridGraphics       0.5-1      2020-12-13 [2] CRAN (R 4.1.0)\n#>  gtable             0.3.3      2023-03-21 [2] CRAN (R 4.1.2)\n#>  highr              0.10       2022-12-22 [2] CRAN (R 4.1.2)\n#>  hms                1.1.3      2023-03-21 [2] CRAN (R 4.1.2)\n#>  htmltools          0.5.7      2023-11-03 [1] CRAN (R 4.1.3)\n#>  htmlwidgets        1.6.2      2023-03-17 [2] CRAN (R 4.1.2)\n#>  httpuv             1.6.11     2023-05-11 [2] CRAN (R 4.1.3)\n#>  httr               1.4.6      2023-05-08 [2] CRAN (R 4.1.2)\n#>  igraph           * 1.5.0      2023-06-16 [1] CRAN (R 4.1.3)\n#>  IRanges            2.28.0     2021-10-26 [2] Bioconductor\n#>  jquerylib          0.1.4      2021-04-26 [2] CRAN (R 4.1.0)\n#>  jsonlite           1.8.7      2023-06-29 [2] CRAN (R 4.1.3)\n#>  KEGGgraph          1.54.0     2021-10-26 [2] Bioconductor\n#>  KEGGREST         * 1.34.0     2021-10-26 [2] Bioconductor\n#>  knitr              1.43       2023-05-25 [2] CRAN (R 4.1.3)\n#>  labeling           0.4.2      2020-10-20 [2] CRAN (R 4.1.0)\n#>  later              1.3.1      2023-05-02 [2] CRAN (R 4.1.2)\n#>  lattice            0.21-8     2023-04-05 [2] CRAN (R 4.1.2)\n#>  lazyeval           0.2.2      2019-03-15 [2] CRAN (R 4.1.0)\n#>  lifecycle          1.0.3      2022-10-07 [2] CRAN (R 4.1.2)\n#>  lsa                0.73.3     2022-05-09 [1] CRAN (R 4.1.2)\n#>  lubridate        * 1.9.2      2023-02-10 [2] CRAN (R 4.1.2)\n#>  magrittr           2.0.3      2022-03-30 [2] CRAN (R 4.1.2)\n#>  MASS               7.3-60     2023-05-04 [1] CRAN (R 4.1.2)\n#>  Matrix             1.6-5      2024-01-11 [1] CRAN (R 4.1.3)\n#>  MCL                1.0        2015-03-11 [1] CRAN (R 4.1.0)\n#>  memoise            2.0.1      2021-11-26 [2] CRAN (R 4.1.0)\n#>  mime               0.12       2021-09-28 [2] CRAN (R 4.1.0)\n#>  miniUI             0.1.1.1    2018-05-18 [2] CRAN (R 4.1.0)\n#>  munsell            0.5.0      2018-06-12 [2] CRAN (R 4.1.0)\n#>  nlme               3.1-162    2023-01-31 [1] CRAN (R 4.1.2)\n#>  org.Hs.eg.db       3.16.0     2023-03-22 [2] Bioconductor\n#>  patchwork          1.1.2      2022-08-19 [2] CRAN (R 4.1.2)\n#>  pathview         * 1.34.0     2021-10-26 [1] Bioconductor\n#>  pillar             1.9.0      2023-03-22 [2] CRAN (R 4.1.2)\n#>  pkgbuild           1.4.2      2023-06-26 [2] CRAN (R 4.1.3)\n#>  pkgconfig          2.0.3      2019-09-22 [2] CRAN (R 4.1.0)\n#>  pkgload            1.3.2.1    2023-07-08 [2] CRAN (R 4.1.3)\n#>  plyr               1.8.8      2022-11-11 [1] CRAN (R 4.1.2)\n#>  png                0.1-8      2022-11-29 [2] CRAN (R 4.1.2)\n#>  polyclip           1.10-4     2022-10-20 [2] CRAN (R 4.1.2)\n#>  prettyunits        1.1.1      2020-01-24 [2] CRAN (R 4.1.0)\n#>  processx           3.8.2      2023-06-30 [2] CRAN (R 4.1.3)\n#>  profvis            0.3.8      2023-05-02 [2] CRAN (R 4.1.2)\n#>  promises           1.2.0.1    2021-02-11 [2] CRAN (R 4.1.0)\n#>  ps                 1.7.5      2023-04-18 [2] CRAN (R 4.1.2)\n#>  purrr            * 1.0.1      2023-01-10 [1] CRAN (R 4.1.2)\n#>  qvalue             2.26.0     2021-10-26 [2] Bioconductor\n#>  R6                 2.5.1      2021-08-19 [2] CRAN (R 4.1.0)\n#>  RColorBrewer       1.1-3      2022-04-03 [1] CRAN (R 4.1.2)\n#>  Rcpp               1.0.11     2023-07-06 [1] CRAN (R 4.1.3)\n#>  RCurl              1.98-1.12  2023-03-27 [2] CRAN (R 4.1.2)\n#>  readr            * 2.1.4      2023-02-10 [1] CRAN (R 4.1.2)\n#>  remotes            2.4.2      2021-11-30 [2] CRAN (R 4.1.0)\n#>  reshape2           1.4.4      2020-04-09 [2] CRAN (R 4.1.0)\n#>  Rgraphviz          2.38.0     2021-10-26 [2] Bioconductor\n#>  rlang              1.1.1      2023-04-28 [1] CRAN (R 4.1.2)\n#>  rmarkdown          2.23       2023-07-01 [2] CRAN (R 4.1.3)\n#>  RSQLite            2.3.1      2023-04-03 [2] CRAN (R 4.1.2)\n#>  rstudioapi         0.15.0     2023-07-07 [2] CRAN (R 4.1.3)\n#>  S4Vectors          0.32.4     2022-03-29 [2] Bioconductor\n#>  sass               0.4.6      2023-05-03 [2] CRAN (R 4.1.2)\n#>  scales             1.2.1      2022-08-20 [1] CRAN (R 4.1.2)\n#>  scatterpie         0.2.1      2023-06-07 [2] CRAN (R 4.1.3)\n#>  sessioninfo        1.2.2      2021-12-06 [2] CRAN (R 4.1.0)\n#>  shadowtext         0.1.2      2022-04-22 [2] CRAN (R 4.1.2)\n#>  shiny              1.7.4.1    2023-07-06 [2] CRAN (R 4.1.3)\n#>  SnowballC          0.7.1      2023-04-25 [2] CRAN (R 4.1.2)\n#>  stringi            1.7.12     2023-01-11 [2] CRAN (R 4.1.2)\n#>  stringr          * 1.5.1      2023-11-14 [1] CRAN (R 4.1.3)\n#>  tibble           * 3.2.1      2023-03-20 [1] CRAN (R 4.1.2)\n#>  tidygraph          1.2.3      2023-02-01 [2] CRAN (R 4.1.2)\n#>  tidyr            * 1.3.0      2023-01-24 [1] CRAN (R 4.1.2)\n#>  tidyselect         1.2.0      2022-10-10 [2] CRAN (R 4.1.2)\n#>  tidytree           0.4.2      2022-12-18 [2] CRAN (R 4.1.2)\n#>  tidyverse        * 2.0.0      2023-02-22 [1] CRAN (R 4.1.2)\n#>  timechange         0.2.0      2023-01-11 [2] CRAN (R 4.1.2)\n#>  treeio             1.18.1     2021-11-14 [2] Bioconductor\n#>  tweenr             2.0.2      2022-09-06 [2] CRAN (R 4.1.2)\n#>  tzdb               0.4.0      2023-05-12 [2] CRAN (R 4.1.3)\n#>  urlchecker         1.0.1      2021-11-30 [2] CRAN (R 4.1.0)\n#>  usethis            2.2.2      2023-07-06 [2] CRAN (R 4.1.3)\n#>  utf8               1.2.3      2023-01-31 [2] CRAN (R 4.1.2)\n#>  vctrs              0.6.5      2023-12-01 [1] CRAN (R 4.1.3)\n#>  viridis            0.6.3      2023-05-03 [2] CRAN (R 4.1.2)\n#>  viridisLite        0.4.2      2023-05-02 [2] CRAN (R 4.1.2)\n#>  withr              2.5.0      2022-03-03 [2] CRAN (R 4.1.2)\n#>  xfun               0.40       2023-08-09 [1] CRAN (R 4.1.3)\n#>  XML                3.99-0.14  2023-03-19 [2] CRAN (R 4.1.2)\n#>  xml2               1.3.5      2023-07-06 [2] CRAN (R 4.1.3)\n#>  xtable             1.8-4      2019-04-21 [2] CRAN (R 4.1.0)\n#>  XVector            0.34.0     2021-10-26 [2] Bioconductor\n#>  yaml               2.3.7      2023-01-23 [2] CRAN (R 4.1.2)\n#>  yulab.utils        0.0.6      2022-12-20 [2] CRAN (R 4.1.2)\n#>  zlibbioc           1.40.0     2021-10-26 [2] Bioconductor\n#> \n#>  [1] /Users/zouhua/Library/R/x86_64/4.1/library\n#>  [2] /Library/Frameworks/R.framework/Versions/4.1/Resources/library\n#> \n#> ──────────────────────────────────────────────────────────"},{"path":"OtherAnalysis.html","id":"reference-12","chapter":"14 Other Analysis","heading":"14.5 Reference","text":"FELLA githubFELLA githubThe MetaRbolomics bookThe MetaRbolomics book","code":""},{"path":"randomforestalgorithm.html","id":"randomforestalgorithm","chapter":"15 Random Forest Algorithm","heading":"15 Random Forest Algorithm","text":"随机森林是常用的非线性用于构建分类器的算法，它是由数目众多的弱决策树构建成森林进而对结果进行投票判断标签的方法。随机森林用于分类器的算法过程，随机切分样本，然后选择2/3用于建模，剩余1/3用于验证袋外误差；随机切分样本，然后选择2/3用于建模，剩余1/3用于验证袋外误差；随机选择特征构建决策树，每个叶子节点分成二类；随机选择特征构建决策树，每个叶子节点分成二类；根据GINI系数判断分类内部纯度程度，进行裁剪树枝；根据GINI系数判断分类内部纯度程度，进行裁剪树枝；1/3数据预测，根据每个决策树的结果投票确定标签；1/3数据预测，根据每个决策树的结果投票确定标签；输出标签结果，并给出OOB rate；输出标签结果，并给出OOB rate；随机的含义在于样本和特征是随机选择去构建决策树，这可以有效避免偏差，另外弱分类器组成强分类器也即是多棵决策树组成森林能提升模型效果。随机的含义在于样本和特征是随机选择去构建决策树，这可以有效避免偏差，另外弱分类器组成强分类器也即是多棵决策树组成森林能提升模型效果。本文旨在通过R实现随机森林的应用，总共包含：下载数据加载R包数据切割调参（选择最佳决策树数目）建模（重要性得分）多次建模选择最佳特征数目（基于OOB rate）多元回归分析筛选相关特征风险得分重新建模模型效能评估","code":""},{"path":"randomforestalgorithm.html","id":"下载数据","chapter":"15 Random Forest Algorithm","heading":"15.1 下载数据","text":"可以点击此处下载数据clean_data.csv或使用wget该数据集包含569份恶性和良性肿瘤的样本的32类指标，通过这些特征构建区分恶性和良性肿瘤的随机森林分类器.Breast Cancer datasets available machine learning repository maintained University California, Irvine. dataset contains 569 samples malignant benign tumor cells.","code":"wget https://github.com/HuaZou/DraftNotes/blob/main/InputData/Breast_cancer/clean_data.csv"},{"path":"randomforestalgorithm.html","id":"加载r包-12","chapter":"15 Random Forest Algorithm","heading":"15.2 加载R包","text":"","code":"\nknitr::opts_chunk$set(message = FALSE, warning = FALSE)\nlibrary(dplyr)\nlibrary(tibble)\nlibrary(randomForest)\nlibrary(ggplot2)\nlibrary(data.table)\nlibrary(caret)\nlibrary(pROC)\n\n# rm(list = ls())\noptions(stringsAsFactors = F)\noptions(future.globals.maxSize = 1000 * 1024^2)\n\ngroup_names <- c(\"M\", \"B\")"},{"path":"randomforestalgorithm.html","id":"加载数据","chapter":"15 Random Forest Algorithm","heading":"15.3 加载数据","text":"","code":"\ndatset <- data.table::fread(\"./InputData/Breast_cancer/clean_data.csv\")\n\nhead(datset)\n#>    V1 diagnosis radius_mean texture_mean perimeter_mean\n#> 1:  0         M       17.99        10.38         122.80\n#> 2:  1         M       20.57        17.77         132.90\n#> 3:  2         M       19.69        21.25         130.00\n#> 4:  3         M       11.42        20.38          77.58\n#> 5:  4         M       20.29        14.34         135.10\n#> 6:  5         M       12.45        15.70          82.57\n#>    area_mean smoothness_mean compactness_mean\n#> 1:    1001.0         0.11840          0.27760\n#> 2:    1326.0         0.08474          0.07864\n#> 3:    1203.0         0.10960          0.15990\n#> 4:     386.1         0.14250          0.28390\n#> 5:    1297.0         0.10030          0.13280\n#> 6:     477.1         0.12780          0.17000\n#>    concavity_mean concave points_mean symmetry_mean\n#> 1:         0.3001             0.14710        0.2419\n#> 2:         0.0869             0.07017        0.1812\n#> 3:         0.1974             0.12790        0.2069\n#> 4:         0.2414             0.10520        0.2597\n#> 5:         0.1980             0.10430        0.1809\n#> 6:         0.1578             0.08089        0.2087\n#>    fractal_dimension_mean radius_se texture_se perimeter_se\n#> 1:                0.07871    1.0950     0.9053        8.589\n#> 2:                0.05667    0.5435     0.7339        3.398\n#> 3:                0.05999    0.7456     0.7869        4.585\n#> 4:                0.09744    0.4956     1.1560        3.445\n#> 5:                0.05883    0.7572     0.7813        5.438\n#> 6:                0.07613    0.3345     0.8902        2.217\n#>    area_se smoothness_se compactness_se concavity_se\n#> 1:  153.40      0.006399        0.04904      0.05373\n#> 2:   74.08      0.005225        0.01308      0.01860\n#> 3:   94.03      0.006150        0.04006      0.03832\n#> 4:   27.23      0.009110        0.07458      0.05661\n#> 5:   94.44      0.011490        0.02461      0.05688\n#> 6:   27.19      0.007510        0.03345      0.03672\n#>    concave points_se symmetry_se fractal_dimension_se\n#> 1:           0.01587     0.03003             0.006193\n#> 2:           0.01340     0.01389             0.003532\n#> 3:           0.02058     0.02250             0.004571\n#> 4:           0.01867     0.05963             0.009208\n#> 5:           0.01885     0.01756             0.005115\n#> 6:           0.01137     0.02165             0.005082\n#>    radius_worst texture_worst perimeter_worst area_worst\n#> 1:        25.38         17.33          184.60     2019.0\n#> 2:        24.99         23.41          158.80     1956.0\n#> 3:        23.57         25.53          152.50     1709.0\n#> 4:        14.91         26.50           98.87      567.7\n#> 5:        22.54         16.67          152.20     1575.0\n#> 6:        15.47         23.75          103.40      741.6\n#>    smoothness_worst compactness_worst concavity_worst\n#> 1:           0.1622            0.6656          0.7119\n#> 2:           0.1238            0.1866          0.2416\n#> 3:           0.1444            0.4245          0.4504\n#> 4:           0.2098            0.8663          0.6869\n#> 5:           0.1374            0.2050          0.4000\n#> 6:           0.1791            0.5249          0.5355\n#>    concave points_worst symmetry_worst\n#> 1:               0.2654         0.4601\n#> 2:               0.1860         0.2750\n#> 3:               0.2430         0.3613\n#> 4:               0.2575         0.6638\n#> 5:               0.1625         0.2364\n#> 6:               0.1741         0.3985\n#>    fractal_dimension_worst\n#> 1:                 0.11890\n#> 2:                 0.08902\n#> 3:                 0.08758\n#> 4:                 0.17300\n#> 5:                 0.07678\n#> 6:                 0.12440"},{"path":"randomforestalgorithm.html","id":"数据切割","chapter":"15 Random Forest Algorithm","heading":"15.4 数据切割","text":"对数据集按照70%的比例划分成训练集和测试集，其中训练集用于构建模型，测试集用于评估模型效能。另外，在这一步前也有教程对特征进行选择，筛选组间差异大的特征用于建模。这里使用 caret::createDataPartition函数进行划分数据集，它能够根据组间比例合理分割数据。","code":"\nmdat <- datset %>%\n  dplyr::select(-V1) %>%\n  dplyr::rename(Group = diagnosis) %>%\n  dplyr::mutate(Group = factor(Group, levels = group_names)) %>%\n  data.frame()\ncolnames(mdat) <- make.names(colnames(mdat))\n\n\nset.seed(123)\ntrainIndex <- caret::createDataPartition(\n          mdat$Group, \n          p = 0.7, \n          list = FALSE, \n          times = 1)\n\ntrainData <- mdat[trainIndex, ]\nX_train <- trainData[, -1]\ny_train <- trainData[, 1]\n\ntestData <- mdat[-trainIndex, ]\nX_test <- testData[, -1]\ny_test <- testData[, 1]"},{"path":"randomforestalgorithm.html","id":"调参选择最佳决策树数目","chapter":"15 Random Forest Algorithm","heading":"15.5 调参（选择最佳决策树数目）","text":"随机森林算法的参数众多，本文选择对mtry和ntree两个参数进行调参，其他均使用默认参数。mtry：随机选择特征数目ntree：构成森林的决策树数目结果：\n最佳随机特征数目（使用32个特征用于建模，从中随机抽取7个特征构建决策树）：7\n最佳决策树数目：1000\n结果：最佳随机特征数目（使用32个特征用于建模，从中随机抽取7个特征构建决策树）：7最佳决策树数目：1000","code":"\n\nRUN <- F\n\nif (RUN) {\n  # N-repeat K-fold cross-validation\n  myControl <- trainControl(\n    method = \"repeatedcv\",\n    number = 10,\n    repeats = 3,\n    search = \"random\",\n    classProbs = TRUE,\n    verboseIter = TRUE,\n    allowParallel = TRUE)\n  \n  # customRF\n  # https://machinelearningmastery.com/tune-machine-learning-algorithms-in-r/\n  customRF <- list(type = \"Classification\",\n                   library = \"randomForest\",\n                   loop = NULL)\n  \n  customRF$parameters <- data.frame(\n    parameter = c(\"mtry\", \"ntree\"),\n    class = rep(\"numeric\", 2),\n    label = c(\"mtry\", \"ntree\"))\n  \n  customRF$grid <- function(x, y, len = NULL, search = \"grid\") {}\n  customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {\n    randomForest(x, y, mtry = param$mtry, ntree=param$ntree, ...)\n  }\n  \n  customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL) {\n    predict(modelFit, newdata)\n  }\n  \n  customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL) {\n    predict(modelFit, newdata, type = \"prob\")\n  }\n  \n  customRF$sort <- function(x) {x[order(x[, 1]), ]}\n  customRF$levels <- function(x) {x$classes}\n  \n  # tuning parameters\n  tuneGrid <- expand.grid(\n    .mtry = c(12:15), # sqrt(ncol(X_train))\n    .ntree = seq(1000, 2000, 500))\n  \n  # Register parallel cores\n  doParallel::registerDoParallel(4)\n  \n  # train model\n  set.seed(123)\n  tune_fit <- train(\n    Group ~.,\n    data = trainData,\n    method = customRF, #\"rf\",\n    trControl = myControl,\n    tuneGrid = tuneGrid,\n    metric = \"Accuracy\",\n    verbose = FALSE)\n  \n  ## Plot model accuracy vs different values of Cost\n  print(plot(tune_fit))\n  \n  ## Print the best tuning parameter that maximizes model accuracy\n  optimalVar <- data.frame(tune_fit$results[which.max(tune_fit$results[, 3]), ])\n  print(optimalVar)  \n} \n\noptimalVar <- list(mtry = 10, ntree = 1000)"},{"path":"randomforestalgorithm.html","id":"建模","chapter":"15 Random Forest Algorithm","heading":"15.6 建模","text":"使用上述最佳参数建模结果：\n该模型的袋外误差OOB仅为4.01%，也即是准确率高达95.99%。\n结果：该模型的袋外误差OOB仅为4.01%，也即是准确率高达95.99%。","code":"\nset.seed(123)\nrf_fit <- randomForest(\n  Group ~ .,\n  data = trainData,\n  importance = TRUE,\n  proximity = TRUE,\n  mtry = optimalVar$mtry,\n  ntree = optimalVar$ntree)\n\nrf_fit\n#> \n#> Call:\n#>  randomForest(formula = Group ~ ., data = trainData, importance = TRUE,      proximity = TRUE, mtry = optimalVar$mtry, ntree = optimalVar$ntree) \n#>                Type of random forest: classification\n#>                      Number of trees: 1000\n#> No. of variables tried at each split: 10\n#> \n#>         OOB estimate of  error rate: 4.01%\n#> Confusion matrix:\n#>     M   B class.error\n#> M 140   9  0.06040268\n#> B   7 243  0.02800000"},{"path":"randomforestalgorithm.html","id":"特征的重要性得分","chapter":"15 Random Forest Algorithm","heading":"15.7 特征的重要性得分","text":"获取所有特征的重要性得分，此处使用MeanDecreaseAccuracy。","code":"\nimp_biomarker <- tibble::as_tibble(round(importance(rf_fit), 2), rownames = \"Features\") %>% \n  dplyr::arrange(desc(MeanDecreaseAccuracy))\nimp_biomarker\n#> # A tibble: 30 × 5\n#>    Features                 M     B MeanDecreaseAccuracy\n#>    <chr>                <dbl> <dbl>                <dbl>\n#>  1 radius_worst         16.4  23.4                  25.9\n#>  2 concave.points_worst 15.0  21.2                  25.2\n#>  3 area_worst           16.9  20.4                  24.4\n#>  4 concave.points_mean  17.3  14.9                  22.3\n#>  5 perimeter_worst      15.6  17.2                  21.8\n#>  6 area_se               8.81 17.5                  19.3\n#>  7 concavity_worst      15.4   7.74                 17.8\n#>  8 concavity_mean        9.93 12.8                  16.4\n#>  9 texture_worst        13.3  10.9                  15.9\n#> 10 radius_se             6.94 12.6                  14.7\n#> # ℹ 20 more rows\n#> # ℹ 1 more variable: MeanDecreaseGini <dbl>"},{"path":"randomforestalgorithm.html","id":"多次建模选择最佳特征数目基于oob-rate","chapter":"15 Random Forest Algorithm","heading":"15.8 多次建模选择最佳特征数目（基于OOB rate）","text":"上述模型选了所有32个特征用于建模，这是单次建模的结果，为了更好确定最佳特征数目，采用五次建模的结果寻找最小OOB rate对应的特征数目作为最佳特征数目。另外，最佳决策树数目参考第一次模型的 1000，也作为本次最佳决策树数目。optimal number biomarkers chosen min cv.error结果：\n袋外误差OOB rate从特征数目为1到特征数目为20呈快速下降趋势，虽然下降数目仅在小数点二位上；\n最佳特征数目是22，也即是选择重要性得分最高的22个特征即可（原本是32个特征，剔除10个特征用于建模）。\n结果：袋外误差OOB rate从特征数目为1到特征数目为20呈快速下降趋势，虽然下降数目仅在小数点二位上；袋外误差OOB rate从特征数目为1到特征数目为20呈快速下降趋势，虽然下降数目仅在小数点二位上；最佳特征数目是22，也即是选择重要性得分最高的22个特征即可（原本是32个特征，剔除10个特征用于建模）。最佳特征数目是22，也即是选择重要性得分最高的22个特征即可（原本是32个特征，剔除10个特征用于建模）。importance optimal biomarkerimportance optimal biomarker结果：\nMeanDecreaseAccuracy得分最高的是area_worst（MDA = 24.52%）\n结果：MeanDecreaseAccuracy得分最高的是area_worst（MDA = 24.52%）","code":"\nerror.cv <- c()\nfor (i in 1:5){\n  print(i)\n  set.seed(i)\n  fit <- rfcv(trainx = X_train, \n              trainy = y_train, \n              cv.fold = 5, \n              scale = \"log\", \n              step = 0.9,\n              ntree = optimalVar$ntree)\n  error.cv <- cbind(error.cv, fit$error.cv)\n}\n#> [1] 1\n#> [1] 2\n#> [1] 3\n#> [1] 4\n#> [1] 5\n\nn.var <- as.numeric(rownames(error.cv))\ncolnames(error.cv) <- paste('error', 1:5, sep = '.')\nerr.mean <- apply(error.cv, 1, mean)\nerr.df <- data.frame(num = n.var, \n                     err.mean = err.mean,\n                     error.cv) \nhead(err.df[, 1:6])\n#>    num   err.mean    error.1    error.2    error.3\n#> 30  30 0.04260652 0.04511278 0.04511278 0.04010025\n#> 27  27 0.04260652 0.04511278 0.04511278 0.04260652\n#> 24  24 0.04260652 0.04761905 0.04511278 0.04010025\n#> 22  22 0.04160401 0.04260652 0.04511278 0.04010025\n#> 20  20 0.04260652 0.04761905 0.04260652 0.04260652\n#> 18  18 0.04360902 0.04511278 0.04511278 0.04010025\n#>       error.4\n#> 30 0.04260652\n#> 27 0.04010025\n#> 24 0.04010025\n#> 22 0.04010025\n#> 20 0.04010025\n#> 18 0.04511278\noptimal <- err.df$num[which(err.df$err.mean == min(err.df$err.mean))]\nmain_theme <- \n  theme(\n    panel.background = element_blank(),\n    panel.grid = element_blank(),\n    axis.line.x = element_line(linewidth = 0.5, color = \"black\"),\n    axis.line.y = element_line(linewidth = 0.5, color = \"black\"),\n    axis.ticks = element_line(color = \"black\"),\n    axis.text = element_text(color = \"black\", size = 12),\n    legend.position = \"right\",\n    legend.background = element_blank(),\n    legend.key = element_blank(),\n    legend.text = element_text(size = 12),\n    text = element_text(family = \"sans\", size = 12))\n\npl <- \n  ggplot(data = err.df, aes(x = err.df$num)) + \n    geom_line(aes(y = err.df$error.1), color = 'grey', linewidth = 0.5) + \n    geom_line(aes(y = err.df$error.2), color = 'grey', linewidth = 0.5) +\n    geom_line(aes(y = err.df$error.3), color = 'grey', linewidth = 0.5) +\n    geom_line(aes(y = err.df$error.4), color = 'grey', linewidth = 0.5) +\n    geom_line(aes(y = err.df$error.5), color = 'grey', linewidth = 0.5) +\n    geom_line(aes(y = err.df$err.mean), color = 'black', linewidth = 0.5) + \n    geom_vline(xintercept = optimal, color = 'red', lwd = 0.36, linetype = 2) + \n    coord_trans(x = \"log2\") +\n    scale_x_continuous(breaks = c(1, 5, 10, 20, 30)) +\n    labs(x = 'Number of Features ', y = 'Cross-validation error rate') + \n    annotate(\"text\", \n             x = optimal, \n             y = max(err.df$err.mean), \n             label = paste(\"Optimal = \", optimal, sep = \"\"),\n             color = \"red\") +\n    main_theme\npl\nimp_biomarker[1:optimal, ] %>%\n  dplyr::select(Features, MeanDecreaseAccuracy) %>%\n  dplyr::arrange(MeanDecreaseAccuracy) %>%\n  dplyr::mutate(Features = forcats::fct_inorder(Features)) %>%\n  ggplot(aes(x = Features, y = MeanDecreaseAccuracy))+\n    geom_bar(stat = \"identity\", fill = \"white\", color = \"blue\") +\n    labs(x = \"\", y = \"Mean decrease accuracy\") +\n    coord_flip() +\n    main_theme"},{"path":"randomforestalgorithm.html","id":"多元回归分析筛选相关特征","chapter":"15 Random Forest Algorithm","heading":"15.9 多元回归分析筛选相关特征","text":"上述22个特征在建模过程还是偏多，可以通过多元回归分析筛选与响应变量（分类变量）最相关的自变量。转换字符型标签成数值型标准化自变量，降低不同单位的影响采用logist regression算法该步骤可选择也可不选择，因为后续分析发现如果严格按照pvalue < 0.05则仅能筛选到2-3个特征。结果：\n在选择Pr(>|z|) < 0.05后，结果不好，后将阈值设置为Pr(>|z|) < 0.2，最终5个特征符合要求。\n结果：在选择Pr(>|z|) < 0.05后，结果不好，后将阈值设置为Pr(>|z|) < 0.2，最终5个特征符合要求。","code":"\nmdat_mulvar <- mdat |>\n  dplyr::select(all_of(c(\"Group\", imp_biomarker[1:optimal, ]$Features))) |>\n  dplyr::mutate(Group = ifelse(Group == group_names[1], 1, 0))\n\nmdat_mulvar[, -1] <- scale(mdat_mulvar[, -1], center = TRUE, scale = TRUE)\n\nfma <- formula(paste0(colnames(mdat_mulvar)[1], \" ~ \", \n              paste(colnames(mdat_mulvar)[2:ncol(mdat_mulvar)], collapse = \" + \")))\n\nfit <- glm(fma, data = mdat_mulvar, family = \"binomial\")\n\ndat_coef <- coef(summary(fit)) |> \n  as.data.frame() |>\n  dplyr::slice(-1) |>\n  dplyr::filter(`Pr(>|z|)` < 0.2) |>\n  tibble::rownames_to_column(\"FeatureID\")\n\nhead(dat_coef)\n#>           FeatureID  Estimate Std. Error   z value\n#> 1   concavity_worst  8.093168  4.4049617  1.837285\n#> 2     texture_worst  1.942546  1.4717008  1.319932\n#> 3 compactness_worst -4.415926  2.4731083 -1.785577\n#> 4    symmetry_worst  1.354215  0.7515816  1.801820\n#> 5 concave.points_se  4.185960  2.2931514  1.825418\n#> 6      concavity_se -6.405829  2.9571126 -2.166244\n#>     Pr(>|z|)\n#> 1 0.06616790\n#> 2 0.18685757\n#> 3 0.07416774\n#> 4 0.07157373\n#> 5 0.06793796\n#> 6 0.03029252"},{"path":"randomforestalgorithm.html","id":"疾病风险得分","chapter":"15 Random Forest Algorithm","heading":"15.10 疾病风险得分","text":"nomogram是一类可以可视化上述5个特征对恶性肿瘤贡献的图形，它也是通过多元线性回归对疾病贡献得到打分，然后分别累加各个特征对疾病的得分得到一个总分，最后总分对应疾病分享百分比。该处没有对自变量进行标准化，本来是要做的，但考虑到每个指标所含有的临床学意义，就使用了原始值。结果：concave points_mean(凹点), concavity_worst(凹度), texture_worst(质地) 和 symmetry_worst(对称) 都随着数值增大获得更高的疾病得分， 而 compactness_mean(紧密) 则是数值越高，疾病得分越低。综合这五个指标的疾病得分即可获得疾病总得分，然后再对应到疾病风险概率上。Notice: 上述四个指标均与乳腺癌发生正相关，而最后一个指标则是负相关，这在临床上也是符合要求的比如:concave points_mean_= 0.04 (20 points)concavity_worst = 1.2 (20 points)texture_worst = 25 (10 points)symmetry_worst = 0.4 (10 points)compactness_mean = 0.25 (20 points)计算得分总和:20 + 20 + 10 + 10 + 20 = 80\n80分对应疾病风险概率是100%，也即是说某位检查者的上述五类指标符合该要求，意味着她有100%的概率患有恶性乳腺癌。","code":"\nlibrary(rms)\n\nselected_columns <- c(\"Group\", dat_coef$FeatureID)\nnom_optimal <- trainData %>%\n  dplyr::select(all_of(selected_columns)) |>\n  dplyr::mutate(Group = ifelse(Group == \"B\", 0, 1))\n\nddist <- datadist(nom_optimal[, -1])\noptions(datadist = \"ddist\")\nfit_nom <- lrm(formula(paste0(colnames(nom_optimal)[1], \" ~ \", \n              paste(colnames(nom_optimal)[2:ncol(nom_optimal)], collapse = \" + \"))),\n         data = nom_optimal)\nnom <- nomogram(fit_nom, fun = plogis, funlabel = \"Risk of Disease\")\nplot(nom)"},{"path":"randomforestalgorithm.html","id":"重新建模","chapter":"15 Random Forest Algorithm","heading":"15.11 重新建模","text":"使用上述五个指标重新建模ConfusionMatrixperformance classifierAUROCAUPRC","code":"\nselected_columns <- c(\"Group\", dat_coef$FeatureID)\n\ntrainData_optimal <- trainData %>%\n  dplyr::select(all_of(selected_columns))\n\ntestData_optimal <- testData %>%\n  dplyr::select(all_of(selected_columns))\n\nset.seed(123)\nrf_fit_optimal <- randomForest(\n  Group ~ ., \n  data = trainData_optimal, \n  importance = TRUE, \n  proximity = TRUE,\n  ntree = optimalVar$ntree)\n\nrf_fit_optimal\n#> \n#> Call:\n#>  randomForest(formula = Group ~ ., data = trainData_optimal, importance = TRUE,      proximity = TRUE, ntree = optimalVar$ntree) \n#>                Type of random forest: classification\n#>                      Number of trees: 1000\n#> No. of variables tried at each split: 2\n#> \n#>         OOB estimate of  error rate: 12.03%\n#> Confusion matrix:\n#>     M   B class.error\n#> M 127  22    0.147651\n#> B  26 224    0.104000\ngroup_names <- c(\"B\", \"M\")\npred_raw <- predict(rf_fit_optimal, newdata = testData_optimal, type = \"response\")\nprint(caret::confusionMatrix(pred_raw, testData_optimal$Group))\n#> Confusion Matrix and Statistics\n#> \n#>           Reference\n#> Prediction  M  B\n#>          M 52 14\n#>          B 11 93\n#>                                           \n#>                Accuracy : 0.8529          \n#>                  95% CI : (0.7906, 0.9025)\n#>     No Information Rate : 0.6294          \n#>     P-Value [Acc > NIR] : 9.513e-11       \n#>                                           \n#>                   Kappa : 0.6878          \n#>                                           \n#>  Mcnemar's Test P-Value : 0.6892          \n#>                                           \n#>             Sensitivity : 0.8254          \n#>             Specificity : 0.8692          \n#>          Pos Pred Value : 0.7879          \n#>          Neg Pred Value : 0.8942          \n#>              Prevalence : 0.3706          \n#>          Detection Rate : 0.3059          \n#>    Detection Prevalence : 0.3882          \n#>       Balanced Accuracy : 0.8473          \n#>                                           \n#>        'Positive' Class : M               \n#> \npred_prob <- predict(rf_fit_optimal, newdata = testData_optimal, type = \"prob\")  \nEvaluate_index <- function(\n    DataTest, \n    PredProb = pred_prob, \n    label = group_names[1], \n    PredRaw = pred_raw) {\n  \n  # DataTest = testData\n  # PredProb = pred_prob\n  # label = group_names[1]\n  # PredRaw = pred_raw\n  \n  # ROC object\n  rocobj <- roc(DataTest$Group, PredProb[, 1])\n  \n  # confusionMatrix\n  con_matrix <- table(PredRaw, DataTest$Group)\n  \n  # index\n  TP <- con_matrix[1, 1]\n  FN <- con_matrix[2, 1]\n  FP <- con_matrix[1, 2]\n  TN <- con_matrix[2, 2]\n  \n  rocbj_df <- data.frame(threshold = round(rocobj$thresholds, 3),\n                         sensitivities = round(rocobj$sensitivities, 3),\n                         specificities = round(rocobj$specificities, 3),\n                         value = rocobj$sensitivities + \n                           rocobj$specificities)\n  max_value_row <- which(max(rocbj_df$value) == rocbj_df$value)[1]\n  \n  threshold <- rocbj_df$threshold[max_value_row]\n  sen <- round(TP / (TP + FN), 3) # caret::sensitivity(con_matrix)\n  spe <- round(TN / (TN + FP), 3) # caret::specificity(con_matrix)\n  acc <- round((TP + TN) / (TP + TN + FP + FN), 3) # Accuracy\n  pre <- round(TP / (TP + FP), 3) # precision\n  rec <- round(TP / (TP + FN), 3) # recall\n  #F1S <- round(2 * TP / (TP + TN + FP + FN + TP - TN), 3)# F1-Score\n  F1S <- round(2 * TP / (2 * TP + FP + FN), 3)# F1-Score\n  youden <- sen + spe - 1 # youden index\n  \n  index_df <- data.frame(Index = c(\"Threshold\", \"Sensitivity\",\n                                   \"Specificity\", \"Accuracy\",\n                                   \"Precision\", \"Recall\",\n                                   \"F1 Score\", \"Youden index\"),\n                         Value = c(threshold, sen, spe,\n                                   acc, pre, rec, F1S, youden)) %>%\n    stats::setNames(c(\"Index\", label))\n  \n  return(index_df)\n}\n\nEvaluate_index(\n    DataTest = testData, \n    PredProb = pred_prob, \n    label = group_names[1], \n    PredRaw = pred_raw)\n#>          Index     B\n#> 1    Threshold 0.312\n#> 2  Sensitivity 0.825\n#> 3  Specificity 0.869\n#> 4     Accuracy 0.853\n#> 5    Precision 0.788\n#> 6       Recall 0.825\n#> 7     F1 Score 0.806\n#> 8 Youden index 0.694\nAUROC <- function(\n    DataTest, \n    PredProb = pred_prob, \n    label = group_names[1], \n    DataProf = profile) {\n  \n  # DataTest = testData\n  # PredProb = pred_prob\n  # label = group_names[1]\n  # DataProf = profile\n  \n  # ROC object\n  rocobj <- roc(DataTest$Group, PredProb[, 1])\n  \n  # Youden index: cutoff point\n  # plot(rocobj,\n  #      legacy.axes = TRUE,\n  #      of = \"thresholds\", \n  #      thresholds = \"best\", \n  #      print.thres=\"best\")\n  \n  # AUROC data\n  roc <- data.frame(tpr = rocobj$sensitivities,\n                    fpr = 1 - rocobj$specificities)\n  \n  # AUC 95% CI\n  rocobj_CI <- roc(DataTest$Group, PredProb[, 1], \n                   ci = TRUE, percent = TRUE)\n  roc_CI <- round(as.numeric(rocobj_CI$ci)/100, 3)\n  roc_CI_lab <- paste0(label, \n                       \" (\", \"AUC=\", roc_CI[2], \n                       \", 95%CI \", roc_CI[1], \"-\", roc_CI[3], \n                       \")\")\n  # ROC dataframe\n  rocbj_df <- data.frame(threshold = round(rocobj$thresholds, 3),\n                         sensitivities = round(rocobj$sensitivities, 3),\n                         specificities = round(rocobj$specificities, 3),\n                         value = rocobj$sensitivities + \n                           rocobj$specificities)\n  max_value_row <- which(max(rocbj_df$value) == rocbj_df$value)\n  threshold <- rocbj_df$threshold[max_value_row]\n  \n  # plot\n  pl <- ggplot(data = roc, aes(x = fpr, y = tpr)) +\n    geom_path(color = \"red\", size = 1) +\n    geom_abline(intercept = 0, slope = 1, \n                color = \"grey\", linewidth = 1, linetype = 2) +\n    labs(x = \"False Positive Rate (1 - Specificity)\",\n         y = \"True Positive Rate\",\n         title = paste0(\"AUROC (\", DataProf, \" Features)\")) +\n    annotate(\"text\", \n             x = 1 - rocbj_df$specificities[max_value_row] + 0.15, \n             y = rocbj_df$sensitivities[max_value_row] - 0.05, \n             label = paste0(threshold, \" (\", \n                            rocbj_df$specificities[max_value_row], \",\",\n                            rocbj_df$sensitivities[max_value_row], \")\"),\n             size=5, family=\"serif\") +\n    annotate(\"point\", \n             x = 1 - rocbj_df$specificities[max_value_row], \n             y = rocbj_df$sensitivities[max_value_row], \n             color = \"black\", size = 2) +    \n    annotate(\"text\", \n             x = .75, y = .25, \n             label = roc_CI_lab,\n             size = 5, family = \"serif\") +\n    coord_cartesian(xlim = c(0, 1), ylim = c(0, 1)) +\n    theme_bw() +\n    theme(panel.background = element_rect(fill = \"transparent\"),\n          plot.title = element_text(color = \"black\", size = 14, face = \"bold\"),\n          axis.ticks.length = unit(0.4, \"lines\"),\n          axis.ticks = element_line(color = \"black\"),\n          axis.line = element_line(size = .5, color = \"black\"),\n          axis.title = element_text(color = \"black\", size = 12, face = \"bold\"),\n          axis.text = element_text(color = \"black\", size = 10),\n          text = element_text(size = 8, color = \"black\", family = \"serif\"))\n  \n  res <- list(rocobj = rocobj,\n              roc_CI = roc_CI_lab,\n              roc_pl = pl)\n  \n  return(res)\n}\n\nAUROC_res <- AUROC(\n    DataTest = testData, \n    PredProb = pred_prob, \n    label = group_names[1], \n    DataProf = optimal)\n\nAUROC_res$roc_pl\nAUPRC <- function(\n    DataTest, \n    PredProb = pred_prob, \n    DataProf = optimal) {\n  \n  # DataTest = testData\n  # PredProb = pred_prob\n  # DataProf = optimal\n  \n  # ROC object\n  rocobj <- roc(DataTest$Group, PredProb[, 1])\n  \n  # p-r value \n  dat_PR <- coords(rocobj, \"all\", ret = c(\"precision\", \"recall\"))\n  \n  # AUPRC data\n  prc <- data.frame(precision = dat_PR$precision,\n                    recall = dat_PR$recall)\n  \n  # plot\n  pl <- ggplot(data = prc, aes(x = recall, y = precision)) +\n    geom_path(color = \"red\", size = 1) +\n    labs(x = \"Recall\",\n         y = \"Precision\",\n         title = paste0(\"AUPRC (\", DataProf, \" Features)\")) +\n    coord_cartesian(xlim = c(0, 1), ylim = c(0, 1)) +\n    theme_bw() +\n    theme(panel.background = element_rect(fill = \"transparent\"),\n          plot.title = element_text(color = \"black\", size = 14, face = \"bold\"),\n          axis.ticks.length = unit(0.4, \"lines\"),\n          axis.ticks = element_line(color = \"black\"),\n          axis.line = element_line(size = .5, color = \"black\"),\n          axis.title = element_text(color = \"black\", size = 12, face = \"bold\"),\n          axis.text = element_text(color = \"black\", size = 10),\n          text = element_text(size = 8, color = \"black\", family = \"serif\"))\n  \n  res <- list(dat_PR = dat_PR,\n              PC_pl = pl)\n  \n  return(res)\n}\n\nAUPRC_res <- AUPRC(\n    DataTest = testData, \n    PredProb = pred_prob, \n    DataProf = optimal)\n\nAUPRC_res$PC_pl"},{"path":"randomforestalgorithm.html","id":"final-biomarkers","chapter":"15 Random Forest Algorithm","heading":"15.12 Final biomarkers","text":"importance score","code":"\nimp_biomarker |> \n  dplyr::filter(Features %in% dat_coef$FeatureID) |>\n  dplyr::select(Features, MeanDecreaseAccuracy) |>\n  dplyr::arrange(MeanDecreaseAccuracy) |>\n  dplyr::mutate(Features = forcats::fct_inorder(Features)) |>\n  ggplot(aes(x = Features, y = MeanDecreaseAccuracy))+\n    geom_bar(stat = \"identity\", fill = \"white\", color = \"blue\") +\n    labs(x = \"\", y = \"Mean decrease accuracy\") +\n    coord_flip() +\n    main_theme"},{"path":"randomforestalgorithm.html","id":"systemic-information-6","chapter":"15 Random Forest Algorithm","heading":"15.13 systemic information","text":"","code":"\ndevtools::session_info()\n#> ─ Session info ───────────────────────────────────────────\n#>  setting  value\n#>  version  R version 4.1.3 (2022-03-10)\n#>  os       macOS Big Sur/Monterey 10.16\n#>  system   x86_64, darwin17.0\n#>  ui       X11\n#>  language (EN)\n#>  collate  en_US.UTF-8\n#>  ctype    en_US.UTF-8\n#>  tz       Asia/Shanghai\n#>  date     2024-02-06\n#>  pandoc   3.1.1 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/ (via rmarkdown)\n#> \n#> ─ Packages ───────────────────────────────────────────────\n#>  package      * version    date (UTC) lib source\n#>  backports      1.4.1      2021-12-13 [2] CRAN (R 4.1.0)\n#>  base64enc      0.1-3      2015-07-28 [2] CRAN (R 4.1.0)\n#>  bookdown       0.34       2023-05-09 [2] CRAN (R 4.1.2)\n#>  bslib          0.6.0      2023-11-21 [1] CRAN (R 4.1.3)\n#>  cachem         1.0.8      2023-05-01 [2] CRAN (R 4.1.2)\n#>  callr          3.7.3      2022-11-02 [2] CRAN (R 4.1.2)\n#>  caret        * 6.0-94     2023-03-21 [2] CRAN (R 4.1.2)\n#>  checkmate      2.2.0      2023-04-27 [2] CRAN (R 4.1.2)\n#>  class          7.3-22     2023-05-03 [2] CRAN (R 4.1.2)\n#>  cli            3.6.1      2023-03-23 [2] CRAN (R 4.1.2)\n#>  cluster        2.1.4      2022-08-22 [2] CRAN (R 4.1.2)\n#>  codetools      0.2-19     2023-02-01 [2] CRAN (R 4.1.2)\n#>  colorspace     2.1-0      2023-01-23 [2] CRAN (R 4.1.2)\n#>  crayon         1.5.2      2022-09-29 [2] CRAN (R 4.1.2)\n#>  data.table   * 1.14.8     2023-02-17 [2] CRAN (R 4.1.2)\n#>  devtools       2.4.5      2022-10-11 [2] CRAN (R 4.1.2)\n#>  digest         0.6.33     2023-07-07 [1] CRAN (R 4.1.3)\n#>  downlit        0.4.3      2023-06-29 [2] CRAN (R 4.1.3)\n#>  dplyr        * 1.1.4      2023-11-17 [1] CRAN (R 4.1.3)\n#>  e1071          1.7-13     2023-02-01 [2] CRAN (R 4.1.2)\n#>  ellipsis       0.3.2      2021-04-29 [2] CRAN (R 4.1.0)\n#>  evaluate       0.21       2023-05-05 [2] CRAN (R 4.1.2)\n#>  fansi          1.0.4      2023-01-22 [2] CRAN (R 4.1.2)\n#>  farver         2.1.1      2022-07-06 [2] CRAN (R 4.1.2)\n#>  fastmap        1.1.1      2023-02-24 [2] CRAN (R 4.1.2)\n#>  forcats        1.0.0      2023-01-29 [1] CRAN (R 4.1.2)\n#>  foreach        1.5.2      2022-02-02 [2] CRAN (R 4.1.2)\n#>  foreign        0.8-84     2022-12-06 [2] CRAN (R 4.1.2)\n#>  Formula        1.2-5      2023-02-24 [2] CRAN (R 4.1.2)\n#>  fs             1.6.2      2023-04-25 [2] CRAN (R 4.1.2)\n#>  future         1.33.0     2023-07-01 [2] CRAN (R 4.1.3)\n#>  future.apply   1.11.0     2023-05-21 [2] CRAN (R 4.1.3)\n#>  generics       0.1.3      2022-07-05 [2] CRAN (R 4.1.2)\n#>  ggplot2      * 3.4.4      2023-10-12 [1] CRAN (R 4.1.3)\n#>  globals        0.16.2     2022-11-21 [2] CRAN (R 4.1.2)\n#>  glue           1.6.2      2022-02-24 [2] CRAN (R 4.1.2)\n#>  gower          1.0.1      2022-12-22 [2] CRAN (R 4.1.2)\n#>  gridExtra      2.3        2017-09-09 [2] CRAN (R 4.1.0)\n#>  gtable         0.3.3      2023-03-21 [2] CRAN (R 4.1.2)\n#>  hardhat        1.3.0      2023-03-30 [2] CRAN (R 4.1.2)\n#>  highr          0.10       2022-12-22 [2] CRAN (R 4.1.2)\n#>  Hmisc        * 5.1-0      2023-05-08 [1] CRAN (R 4.1.2)\n#>  htmlTable      2.4.1      2022-07-07 [2] CRAN (R 4.1.2)\n#>  htmltools      0.5.7      2023-11-03 [1] CRAN (R 4.1.3)\n#>  htmlwidgets    1.6.2      2023-03-17 [2] CRAN (R 4.1.2)\n#>  httpuv         1.6.11     2023-05-11 [2] CRAN (R 4.1.3)\n#>  ipred          0.9-14     2023-03-09 [2] CRAN (R 4.1.2)\n#>  iterators      1.0.14     2022-02-05 [2] CRAN (R 4.1.2)\n#>  jquerylib      0.1.4      2021-04-26 [2] CRAN (R 4.1.0)\n#>  jsonlite       1.8.7      2023-06-29 [2] CRAN (R 4.1.3)\n#>  knitr          1.43       2023-05-25 [2] CRAN (R 4.1.3)\n#>  labeling       0.4.2      2020-10-20 [2] CRAN (R 4.1.0)\n#>  later          1.3.1      2023-05-02 [2] CRAN (R 4.1.2)\n#>  lattice      * 0.21-8     2023-04-05 [2] CRAN (R 4.1.2)\n#>  lava           1.7.2.1    2023-02-27 [2] CRAN (R 4.1.2)\n#>  lifecycle      1.0.3      2022-10-07 [2] CRAN (R 4.1.2)\n#>  listenv        0.9.0      2022-12-16 [2] CRAN (R 4.1.2)\n#>  lubridate      1.9.2      2023-02-10 [2] CRAN (R 4.1.2)\n#>  magrittr       2.0.3      2022-03-30 [2] CRAN (R 4.1.2)\n#>  MASS           7.3-60     2023-05-04 [1] CRAN (R 4.1.2)\n#>  Matrix         1.6-5      2024-01-11 [1] CRAN (R 4.1.3)\n#>  MatrixModels   0.5-2      2023-07-10 [2] CRAN (R 4.1.3)\n#>  memoise        2.0.1      2021-11-26 [2] CRAN (R 4.1.0)\n#>  mime           0.12       2021-09-28 [2] CRAN (R 4.1.0)\n#>  miniUI         0.1.1.1    2018-05-18 [2] CRAN (R 4.1.0)\n#>  ModelMetrics   1.2.2.2    2020-03-17 [2] CRAN (R 4.1.0)\n#>  multcomp       1.4-25     2023-06-20 [2] CRAN (R 4.1.3)\n#>  munsell        0.5.0      2018-06-12 [2] CRAN (R 4.1.0)\n#>  mvtnorm        1.2-2      2023-06-08 [2] CRAN (R 4.1.3)\n#>  nlme           3.1-162    2023-01-31 [1] CRAN (R 4.1.2)\n#>  nnet           7.3-19     2023-05-03 [2] CRAN (R 4.1.2)\n#>  parallelly     1.36.0     2023-05-26 [2] CRAN (R 4.1.3)\n#>  pillar         1.9.0      2023-03-22 [2] CRAN (R 4.1.2)\n#>  pkgbuild       1.4.2      2023-06-26 [2] CRAN (R 4.1.3)\n#>  pkgconfig      2.0.3      2019-09-22 [2] CRAN (R 4.1.0)\n#>  pkgload        1.3.2.1    2023-07-08 [2] CRAN (R 4.1.3)\n#>  plyr           1.8.8      2022-11-11 [1] CRAN (R 4.1.2)\n#>  polspline      1.1.23     2023-06-29 [1] CRAN (R 4.1.3)\n#>  prettyunits    1.1.1      2020-01-24 [2] CRAN (R 4.1.0)\n#>  pROC         * 1.18.4     2023-07-06 [2] CRAN (R 4.1.3)\n#>  processx       3.8.2      2023-06-30 [2] CRAN (R 4.1.3)\n#>  prodlim        2023.03.31 2023-04-02 [2] CRAN (R 4.1.2)\n#>  profvis        0.3.8      2023-05-02 [2] CRAN (R 4.1.2)\n#>  promises       1.2.0.1    2021-02-11 [2] CRAN (R 4.1.0)\n#>  proxy          0.4-27     2022-06-09 [2] CRAN (R 4.1.2)\n#>  ps             1.7.5      2023-04-18 [2] CRAN (R 4.1.2)\n#>  purrr          1.0.1      2023-01-10 [1] CRAN (R 4.1.2)\n#>  quantreg       5.95       2023-04-08 [2] CRAN (R 4.1.2)\n#>  R6             2.5.1      2021-08-19 [2] CRAN (R 4.1.0)\n#>  randomForest * 4.7-1.1    2022-05-23 [2] CRAN (R 4.1.2)\n#>  Rcpp           1.0.11     2023-07-06 [1] CRAN (R 4.1.3)\n#>  recipes        1.0.6      2023-04-25 [2] CRAN (R 4.1.2)\n#>  remotes        2.4.2      2021-11-30 [2] CRAN (R 4.1.0)\n#>  reshape2       1.4.4      2020-04-09 [2] CRAN (R 4.1.0)\n#>  rlang          1.1.1      2023-04-28 [1] CRAN (R 4.1.2)\n#>  rmarkdown      2.23       2023-07-01 [2] CRAN (R 4.1.3)\n#>  rms          * 6.7-0      2023-05-08 [1] CRAN (R 4.1.2)\n#>  rpart          4.1.19     2022-10-21 [2] CRAN (R 4.1.2)\n#>  rstudioapi     0.15.0     2023-07-07 [2] CRAN (R 4.1.3)\n#>  sandwich       3.0-2      2022-06-15 [2] CRAN (R 4.1.2)\n#>  sass           0.4.6      2023-05-03 [2] CRAN (R 4.1.2)\n#>  scales         1.2.1      2022-08-20 [1] CRAN (R 4.1.2)\n#>  sessioninfo    1.2.2      2021-12-06 [2] CRAN (R 4.1.0)\n#>  shiny          1.7.4.1    2023-07-06 [2] CRAN (R 4.1.3)\n#>  SparseM        1.81       2021-02-18 [2] CRAN (R 4.1.0)\n#>  stringi        1.7.12     2023-01-11 [2] CRAN (R 4.1.2)\n#>  stringr        1.5.1      2023-11-14 [1] CRAN (R 4.1.3)\n#>  survival       3.5-5      2023-03-12 [2] CRAN (R 4.1.2)\n#>  TH.data        1.1-2      2023-04-17 [2] CRAN (R 4.1.2)\n#>  tibble       * 3.2.1      2023-03-20 [1] CRAN (R 4.1.2)\n#>  tidyselect     1.2.0      2022-10-10 [2] CRAN (R 4.1.2)\n#>  timechange     0.2.0      2023-01-11 [2] CRAN (R 4.1.2)\n#>  timeDate       4022.108   2023-01-07 [2] CRAN (R 4.1.2)\n#>  urlchecker     1.0.1      2021-11-30 [2] CRAN (R 4.1.0)\n#>  usethis        2.2.2      2023-07-06 [2] CRAN (R 4.1.3)\n#>  utf8           1.2.3      2023-01-31 [2] CRAN (R 4.1.2)\n#>  vctrs          0.6.5      2023-12-01 [1] CRAN (R 4.1.3)\n#>  withr          2.5.0      2022-03-03 [2] CRAN (R 4.1.2)\n#>  xfun           0.40       2023-08-09 [1] CRAN (R 4.1.3)\n#>  xml2           1.3.5      2023-07-06 [2] CRAN (R 4.1.3)\n#>  xtable         1.8-4      2019-04-21 [2] CRAN (R 4.1.0)\n#>  yaml           2.3.7      2023-01-23 [2] CRAN (R 4.1.2)\n#>  zoo            1.8-12     2023-04-13 [2] CRAN (R 4.1.2)\n#> \n#>  [1] /Users/zouhua/Library/R/x86_64/4.1/library\n#>  [2] /Library/Frameworks/R.framework/Versions/4.1/Resources/library\n#> \n#> ──────────────────────────────────────────────────────────"},{"path":"XGBoostalgorithm.html","id":"XGBoostalgorithm","chapter":"16 XGBoost Algorithm","heading":"16 XGBoost Algorithm","text":"XGBoost Extreme Gradient Boosting algorithm decision tree based machine learning algorithm uses process called boosting help improve performance.basic classification modeling process involves obtaining dataset, creating features independent variables, using predict dependent variable target class. classification datasets require preparation can used classifiers, also usually require creation additional features process called feature engineering.“Gradient boosting machine learning technique regression, classification tasks, produces prediction model form ensemble weak prediction models, typically decision trees. decision tree weak learner, resulting algorithm called gradient boosted trees, usually outperforms random forest. builds model stage-wise fashion like boosting methods , generalizes allowing optimization arbitrary differentiable loss function” Note: XGBoost ditinguished gradient boosting techniques regularization mechanism prevent overfitting.","code":""},{"path":"XGBoostalgorithm.html","id":"data-preparation","chapter":"16 XGBoost Algorithm","heading":"16.0.1 Data Preparation","text":"data table: clean_data.csv group information (Row->samples;Column->features)可以点击此处下载数据clean_data.csv或使用wget该数据集包含569份恶性和良性肿瘤的样本的32类指标，通过这些特征构建区分恶性和良性肿瘤的随机森林分类器.Breast Cancer datasets available machine learning repository maintained University California, Irvine. dataset contains 569 samples malignant benign tumor cells.","code":"wget https://github.com/HuaZou/DraftNotes/blob/main/InputData/Breast_cancer/clean_data.csv"},{"path":"XGBoostalgorithm.html","id":"data-description","chapter":"16 XGBoost Algorithm","heading":"16.0.2 Data Description","text":"Feature table:\nM samples x N Features\nFeature table:M samples x N Featuresmetadata\nmain response/independent variable: diagnosis: M vs B\nmetadatamain response/independent variable: diagnosis: M vs B","code":""},{"path":"XGBoostalgorithm.html","id":"data-preprocessing","chapter":"16 XGBoost Algorithm","heading":"16.0.3 Data Preprocessing","text":"Prevalence filtering: reducing sparsity data (default: 10%)","code":""},{"path":"XGBoostalgorithm.html","id":"data-partition","chapter":"16 XGBoost Algorithm","heading":"16.0.4 Data Partition","text":"train dataset: 80% 70% (default 70%);test dataset: 20% 30% (default 30%).","code":""},{"path":"XGBoostalgorithm.html","id":"feature-selection","chapter":"16 XGBoost Algorithm","heading":"16.0.5 Feature Selection","text":"Importance features random forest;Feature selection taken training set, avoiding overfitting.","code":""},{"path":"XGBoostalgorithm.html","id":"model-training","chapter":"16 XGBoost Algorithm","heading":"16.0.6 Model training","text":"Base model construction higher performanceTuning hyperparametersBest model building evaluations","code":""},{"path":"XGBoostalgorithm.html","id":"python-environment","chapter":"16 XGBoost Algorithm","heading":"16.0.7 python environment","text":"","code":"\nlibrary(reticulate)\n\n# myenvs <- conda_list()\n# \n# envname <- myenvs$name[2]\n# use_condaenv(envname, required = TRUE)\n# # or\nuse_condaenv(\"base\", required = TRUE)"},{"path":"XGBoostalgorithm.html","id":"loading-required-packages","chapter":"16 XGBoost Algorithm","heading":"16.1 Loading required packages","text":"","code":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport pandas as pd\nimport numpy as np\nimport time\nimport random\n\n# machine learning\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\n#from xgboost import XGBClassifier\nimport xgboost as xgb\n\n#classes for grid search and cross-validation, function for splitting data and evaluating models\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import confusion_matrix \nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom skopt import BayesSearchCV\n\n# plotting \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.style.use('fivethirtyeight')\nsns.set_style(\"darkgrid\")\n\nplt.rcParams['figure.figsize'] = (8, 4)\nplt.rcParams[\"axes.linewidth\"] = 1"},{"path":"XGBoostalgorithm.html","id":"data-preparation-1","chapter":"16 XGBoost Algorithm","heading":"16.2 Data Preparation","text":"Breast Cancer datasets available machine learning repository maintained University California, Irvine. dataset contains 569 samples malignant benign tumor cells.\nfirst two columns dataset store unique ID numbers samples corresponding diagnosis (M=malignant, B=benign), respectively.\ncolumns 3-32 contain 30 real-value features computed digitized images cell nuclei, can used build model predict whether tumor benign malignant.","code":"dat = pd.read_csv(\"InputData/Breast_cancer/clean_data.csv\", index_col=0)\n\ndat.head()\n#>   diagnosis  radius_mean  ...  symmetry_worst  fractal_dimension_worst\n#> 0         M        17.99  ...          0.4601                  0.11890\n#> 1         M        20.57  ...          0.2750                  0.08902\n#> 2         M        19.69  ...          0.3613                  0.08758\n#> 3         M        11.42  ...          0.6638                  0.17300\n#> 4         M        20.29  ...          0.2364                  0.07678\n#> \n#> [5 rows x 31 columns]"},{"path":"XGBoostalgorithm.html","id":"xgboost-classification","chapter":"16 XGBoost Algorithm","heading":"16.3 XGBoost classification","text":"Transforming group labelTransforming group labelPrincipal component analysisPrincipal component analysisData partitionData partitionFeaeture selectionFeaeture selectionBase modelBase modelTuning hyperparametersTuning hyperparametersBuilding final modelBuilding final modelEvaluating model performanceEvaluating model performance","code":""},{"path":"XGBoostalgorithm.html","id":"transforming-label","chapter":"16 XGBoost Algorithm","heading":"16.3.1 Transforming label","text":"Machine learning accept string labels categorical variablesB -> 0M -> 1","code":"#creating deepcopy of model instances\nfrom copy import deepcopy\n\ngroup_names = ['B', \"M\"]\n\ndat_copy = deepcopy(dat)\ndat_copy['diagnosis'] = dat_copy['diagnosis'].map({'B':0, 'M':1})\ndat_copy.head(n=6)\n#>    diagnosis  radius_mean  ...  symmetry_worst  fractal_dimension_worst\n#> 0          1        17.99  ...          0.4601                  0.11890\n#> 1          1        20.57  ...          0.2750                  0.08902\n#> 2          1        19.69  ...          0.3613                  0.08758\n#> 3          1        11.42  ...          0.6638                  0.17300\n#> 4          1        20.29  ...          0.2364                  0.07678\n#> 5          1        12.45  ...          0.3985                  0.12440\n#> \n#> [6 rows x 31 columns]"},{"path":"XGBoostalgorithm.html","id":"principal-component-analysis","chapter":"16 XGBoost Algorithm","heading":"16.3.2 Principal component analysis","text":"","code":"from sklearn.decomposition import PCA\n#from sklearn.preprocessing import StandardScaler\n\ndata_remove = dat_copy.drop(['diagnosis'], axis = 1)\n\n#sc = StandardScaler()\n#sc.fit_transform(data_remove)\n\npca = PCA(n_components=2)\npca.fit(data_remove)PCA(n_components=2)PCA(n_components=2)data_remove_pca = pca.transform(data_remove)\n\nPCA_df = pd.DataFrame()\nPCA_df['PCA_1'] = data_remove_pca[:, 0]\nPCA_df['PCA_2'] = data_remove_pca[:, 1]\nPCA_df['diagnosis'] = dat['diagnosis'].tolist()\n\nplt.figure(figsize=(4, 4))\nsns.scatterplot(data = PCA_df,\n                x = 'PCA_1', \n                y = 'PCA_2',\n                hue = 'diagnosis')\n\nplt.title(\"PCA\")\nplt.xlabel(\"First Principal Component\")\nplt.ylabel(\"Second Principal Component\")\nplt.legend(loc='lower right', fontsize=\"8\")\nplt.show()"},{"path":"XGBoostalgorithm.html","id":"data-partition-1","chapter":"16 XGBoost Algorithm","heading":"16.3.3 Data partition","text":"Creating train test dataset probability 0.7","code":"X = data_remove\nY = dat_copy.diagnosis\n\nx_train, x_test, y_train, y_test = train_test_split(\n    X,\n    Y,\n    test_size = 0.30,\n    random_state = 123)\n\n# Cleaning test sets to avoid future warning messages\ny_train = y_train.values.ravel() \ny_test = y_test.values.ravel() \n\nprint(\"training dataset:\", x_train.shape[0], \"sampels;\", x_train.shape[1], \"features\")\n#> training dataset: 398 sampels; 30 features\nprint(\"test dataset:\", x_test.shape[0], \"sampels;\", x_test.shape[1], \"features\")\n#> test dataset: 171 sampels; 30 features"},{"path":"XGBoostalgorithm.html","id":"feature-selection-1","chapter":"16 XGBoost Algorithm","heading":"16.3.4 Feature selection","text":"use importance random forest select features selectFromModel, selecting thoese features importance greater mean importance features default. following parameters:estimator: base estimator transformer builtthreshold: threshold value use feature selection (mean default)Remained features","code":"from sklearn.feature_selection import SelectFromModel\nfrom sklearn.ensemble import RandomForestClassifier\n\nsel = SelectFromModel(estimator=RandomForestClassifier(n_estimators = 1000),\n                      threshold=\"mean\")\nsel.fit(x_train, y_train)SelectFromModel(estimator=RandomForestClassifier(n_estimators=1000),\n                threshold='mean')SelectFromModel(estimator=RandomForestClassifier(n_estimators=1000),\n                threshold='mean')RandomForestClassifier(n_estimators=1000)RandomForestClassifier(n_estimators=1000)\n# estimator parameters\nprint(\"the parameters of estimator\", sel.get_params())\n#> the parameters of estimator {'estimator__bootstrap': True, 'estimator__ccp_alpha': 0.0, 'estimator__class_weight': None, 'estimator__criterion': 'gini', 'estimator__max_depth': None, 'estimator__max_features': 'sqrt', 'estimator__max_leaf_nodes': None, 'estimator__max_samples': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__n_estimators': 1000, 'estimator__n_jobs': None, 'estimator__oob_score': False, 'estimator__random_state': None, 'estimator__verbose': 0, 'estimator__warm_start': False, 'estimator': RandomForestClassifier(n_estimators=1000), 'importance_getter': 'auto', 'max_features': None, 'norm_order': 1, 'prefit': False, 'threshold': 'mean'}\n\n# selected features\nselected_features = x_train.columns[(sel.get_support())]\nx_train_select = x_train[selected_features]\n\n\nprint(\"training dataset:\", x_train_select.shape[0], \"sampels;\", x_train_select.shape[1], \"features\")\n#> training dataset: 398 sampels; 9 featuresx_train_select = x_train[selected_features]\nx_test_select = x_test[selected_features]\n\nprint(\"training dataset:\", x_train_select.shape[0], \"sampels;\", x_train_select.shape[1], \"features\")\n#> training dataset: 398 sampels; 9 features\nprint(\"test dataset:\", x_test_select.shape[0], \"sampels;\", x_test_select.shape[1], \"features\")\n#> test dataset: 171 sampels; 9 features"},{"path":"XGBoostalgorithm.html","id":"base-model","chapter":"16 XGBoost Algorithm","heading":"16.3.5 Base model","text":"base model feature importance AUC, Confusion Matrix","code":"base_fit = xgb.XGBClassifier(\n    objective='binary:logistic',\n    booster='gbtree',\n    eval_metric='auc',\n    tree_method='hist',\n    grow_policy='lossguide',\n    use_label_encoder=False)\n\n\nbase_fit.fit(x_train_select, y_train)XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric='auc', feature_types=None,\n              gamma=None, gpu_id=None, grow_policy='lossguide',\n              importance_type=None, interaction_constraints=None,\n              learning_rate=None, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, n_estimators=100, n_jobs=None,\n              num_parallel_tree=None, predictor=None, random_state=None, ...)XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric='auc', feature_types=None,\n              gamma=None, gpu_id=None, grow_policy='lossguide',\n              importance_type=None, interaction_constraints=None,\n              learning_rate=None, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, n_estimators=100, n_jobs=None,\n              num_parallel_tree=None, predictor=None, random_state=None, ...)\ny_pred = base_fit.predict(x_test_select)\naccuracy = accuracy_score(y_test, y_pred)\n\nprint(\"Accuracy of base XBGoost model: {:.2f}\".format(accuracy))\n#> Accuracy of base XBGoost model: 0.96"},{"path":"XGBoostalgorithm.html","id":"k-cross-validataion-for-n_estimators","chapter":"16 XGBoost Algorithm","heading":"16.3.6 K cross validataion for n_estimators","text":"relationship loss number tree","code":"def estimate_num_trees(X, y):\n    num_trees = range(10, 200, 10)\n    cv_errors = []\n\n    for n in num_trees:\n        xgb_classifier = xgb.XGBClassifier(n_estimators=n, objective='binary:logistic', eval_metric='logloss', random_state=42)\n        cv_scores = cross_val_score(xgb_classifier, X, y, cv=5, scoring='neg_log_loss')\n        cv_errors.append(-np.mean(cv_scores))\n\n    return num_trees, cv_errors\n\ndef plot_error_vs_trees(num_trees, cv_errors):\n    plt.figure(figsize=(10, 6))\n    plt.plot(num_trees, cv_errors, marker='o', linestyle='-')\n    plt.xlabel('No. of estimators')\n    plt.ylabel('Loss')\n    plt.grid(True)\n    plt.show()\n\nnum_trees, cv_errors = estimate_num_trees(x_train_select, y_train)\nplot_error_vs_trees(num_trees, cv_errors)"},{"path":"XGBoostalgorithm.html","id":"tuning-parameters","chapter":"16 XGBoost Algorithm","heading":"16.3.7 Tuning parameters","text":"executing grid search algorithms, benchmark model fitted. calling fit() method, default parameters obtained stored later use. Since GridSearchCV take inputs lists, single parameter values also wrapped. calling fit() GridSearchCV instance, cross-validation performed, results extracted, scores computed stored dictionary.takes much time iterate whole parameter grid, setting verbosity 1 help monitor process. However, wall time equal printed fitting time, hence loop cycle time also tracked printed.learning_rate/eta: Step size shrinkage used update prevents overfitting. boosting step, can directly get weights new features(typical values: 0.01-0.2).max_depth: Maximum depth tree. Increasing value make model complex likely overfit (typical values: 1-10).n_estimators: number decision tree.colsample_bytree: fraction features can used train tree. large value means almost features can used build decision tree (typical values: 0.5-0.9).min_child_weight: defines minimum sum weights observations required child. larger min_child_weight , conservative algorithm .gamma: Minimum loss reduction required make partition leaf node tree (typical values: 0-0.5).alpha/reg_alpha: L1 regularization term weights. Increasing value make model conservative (typical values: 0-1).lambda/reg_lambda: L2 regularization term weights. Increasing value make model conservative (typical values: 0-1).Grid search“Grid search process searches exhaustively manually specified subset hyperparameter space targeted algorithm…evaluate(s) cost function based generated hyperparameter sets”Randomized search“Random search…selects value hyperparameter independently using probability distribution…evaluate(s) cost function based generated hyperparameter sets”Bayesian search“…build probability model objective function use select promising hyperparameters evaluate true objective function”","code":"#extracting default parameters from benchmark model\ndefault_params = {}\ngparams = base_fit.get_params()\n\n#default parameters have to be wrapped in lists - even single values - so GridSearchCV can take them as inputs\nfor key in gparams.keys():\n    gp = gparams[key]\n    default_params[key] = [gp]\n\n#benchmark model. Grid search is not performed, since only single values are provided as parameter grid.\n#However, cross-validation is still executed\nclf0 = GridSearchCV(estimator=base_fit, \n                    scoring='accuracy', \n                    param_grid=default_params, \n                    return_train_score=True, \n                    verbose=1, \n                    cv=3)\nclf0.fit(x_train_select, y_train)GridSearchCV(cv=3,\n             estimator=XGBClassifier(base_score=None, booster='gbtree',\n                                     callbacks=None, colsample_bylevel=None,\n                                     colsample_bynode=None,\n                                     colsample_bytree=None,\n                                     early_stopping_rounds=None,\n                                     enable_categorical=False,\n                                     eval_metric='auc', feature_types=None,\n                                     gamma=None, gpu_id=None,\n                                     grow_policy='lossguide',\n                                     importance_type=None,\n                                     interaction_constraints=None,\n                                     learnin...\n                         'max_cat_threshold': [None],\n                         'max_cat_to_onehot': [None], 'max_delta_step': [None],\n                         'max_depth': [None], 'max_leaves': [None],\n                         'min_child_weight': [None], 'missing': [nan],\n                         'monotone_constraints': [None], 'n_estimators': [100],\n                         'n_jobs': [None], 'num_parallel_tree': [None],\n                         'objective': ['binary:logistic'], 'predictor': [None], ...},\n             return_train_score=True, scoring='accuracy', verbose=1)GridSearchCV(cv=3,\n             estimator=XGBClassifier(base_score=None, booster='gbtree',\n                                     callbacks=None, colsample_bylevel=None,\n                                     colsample_bynode=None,\n                                     colsample_bytree=None,\n                                     early_stopping_rounds=None,\n                                     enable_categorical=False,\n                                     eval_metric='auc', feature_types=None,\n                                     gamma=None, gpu_id=None,\n                                     grow_policy='lossguide',\n                                     importance_type=None,\n                                     interaction_constraints=None,\n                                     learnin...\n                         'max_cat_threshold': [None],\n                         'max_cat_to_onehot': [None], 'max_delta_step': [None],\n                         'max_depth': [None], 'max_leaves': [None],\n                         'min_child_weight': [None], 'missing': [nan],\n                         'monotone_constraints': [None], 'n_estimators': [100],\n                         'n_jobs': [None], 'num_parallel_tree': [None],\n                         'objective': ['binary:logistic'], 'predictor': [None], ...},\n             return_train_score=True, scoring='accuracy', verbose=1)XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric='auc', feature_types=None,\n              gamma=None, gpu_id=None, grow_policy='lossguide',\n              importance_type=None, interaction_constraints=None,\n              learning_rate=None, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, n_estimators=100, n_jobs=None,\n              num_parallel_tree=None, predictor=None, random_state=None, ...)XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric='auc', feature_types=None,\n              gamma=None, gpu_id=None, grow_policy='lossguide',\n              importance_type=None, interaction_constraints=None,\n              learning_rate=None, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, n_estimators=100, n_jobs=None,\n              num_parallel_tree=None, predictor=None, random_state=None, ...)\n#results dataframe\ndf = pd.DataFrame(clf0.cv_results_)\n\n#predictions - inputs to confusion matrix\ntest_predictions = clf0.predict(x_test_select)\n\n#confusion matrices\ncfm_test = confusion_matrix(y_test, test_predictions)\n\n#best parameters\nbp0 = clf0.best_params_\n\ndf.head()\n#>    mean_fit_time  std_fit_time  ...  mean_train_score  std_train_score\n#> 0       0.032066      0.004569  ...               1.0              0.0\n#> \n#> [1 rows x 56 columns]# tuning parameters\nparam_grid = {\n    'learning_rate': [0.01, 0.03, 0.06, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5, 0.6, 0.7],\n    'max_depth': [x for x in range(5, 15, 1)],\n    'n_estimators': [x for x in range(10, 150, 30)],\n    'colsample_bytree': [np.round(x, 2) for x in np.arange(0.5, 1, 0.1)],\n    'min_child_weight': [x for x in range(0, 11, 1)],    \n    'gamma': [0, 0.1 ,0.2 ,0.4, 0.8, 1.6, 3.2, 6.4, 12.8, 25.6, 51.2, 102.4, 200],          \n    'reg_alpha': [0, 0.1, 0.2, 0.4, 0.8, 1.6, 3.2, 6.4, 12.8, 25.6, 51.2, 102.4, 200],\n    'reg_lambda': [0, 0.1, 0.2, 0.4, 0.8, 1.6, 3.2, 6.4, 12.8, 25.6, 51.2, 102.4, 200]\n    }\n    \nparam_grid\n#> {'learning_rate': [0.01, 0.03, 0.06, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5, 0.6, 0.7], 'max_depth': [5, 6, 7, 8, 9, 10, 11, 12, 13, 14], 'n_estimators': [10, 40, 70, 100, 130], 'colsample_bytree': [0.5, 0.6, 0.7, 0.8, 0.9], 'min_child_weight': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'gamma': [0, 0.1, 0.2, 0.4, 0.8, 1.6, 3.2, 6.4, 12.8, 25.6, 51.2, 102.4, 200], 'reg_alpha': [0, 0.1, 0.2, 0.4, 0.8, 1.6, 3.2, 6.4, 12.8, 25.6, 51.2, 102.4, 200], 'reg_lambda': [0, 0.1, 0.2, 0.4, 0.8, 1.6, 3.2, 6.4, 12.8, 25.6, 51.2, 102.4, 200]}#creating deepcopy of default parameters before manipulations\nparams = deepcopy(default_params)\n\n#No. of jobs\ngcvj = np.cumsum([len(x) for x in param_grid.values()])[-1]\n\n#iteration loop. Each selected parameter iterated separately\nfor i, grid_key in enumerate(param_grid.keys()):\n    \n    print(i)\n    #variable for measuring iteration time\n    loop_start = time.time()\n       \n    #creating param_grid argument for GridSearchCV:\n    #listing grid values of current iterable parameter and wrapping non-iterable parameter single values in list\n    for param_key in params.keys():\n        if param_key == grid_key:\n            params[param_key] = param_grid[grid_key]\n        else:\n            # use best parameters of last iteration\n            try:\n                param_value = [clf.best_params_[param_key]]\n                params[param_key] = param_value\n            #use benchmark model parameters for first iteration\n            except:\n                param_value = [clf0.best_params_[param_key]]\n                params[param_key] = param_value\n    \n    #classifier instance of current iteration\n    xgbc = xgb.XGBClassifier(**default_params)\n    \n    #GridSearch instance of current iteration\n    clf = GridSearchCV(estimator=xgbc, \n                    param_grid=params,\n                    scoring='accuracy', \n                    return_train_score=True, \n                    verbose=1, \n                    cv=3)\n    clf.fit(x_train_select, y_train)\n\n    #predictions - inputs to confusion matrix\n    train_predictions = clf.predict(x_train_select)\n    test_predictions = clf.predict(x_test_select)\n        \n    #confusion matrices\n    cfm_train = confusion_matrix(y_train, train_predictions)\n    cfm_test = confusion_matrix(y_test, test_predictions)\n    print(cfm_train)\n    print(cfm_test)\n    \n    #best parameters\n    bp_gs = clf.best_params_GridSearchCV(cv=3,\n             estimator=XGBClassifier(base_score=[None], booster=['gbtree'],\n                                     callbacks=[None], colsample_bylevel=[None],\n                                     colsample_bynode=[None],\n                                     colsample_bytree=[None],\n                                     early_stopping_rounds=[None],\n                                     enable_categorical=[False],\n                                     eval_metric=['auc'], feature_types=[None],\n                                     gamma=[None], gpu_id=[None],\n                                     grow_policy=['lossguide'],\n                                     importance_type=[None],\n                                     interact...\n                         'max_cat_threshold': [None],\n                         'max_cat_to_onehot': [None], 'max_delta_step': [None],\n                         'max_depth': [5], 'max_leaves': [None],\n                         'min_child_weight': [1], 'missing': [nan],\n                         'monotone_constraints': [None], 'n_estimators': [40],\n                         'n_jobs': [None], 'num_parallel_tree': [None],\n                         'objective': ['binary:logistic'], 'predictor': [None], ...},\n             return_train_score=True, scoring='accuracy', verbose=1)GridSearchCV(cv=3,\n             estimator=XGBClassifier(base_score=[None], booster=['gbtree'],\n                                     callbacks=[None], colsample_bylevel=[None],\n                                     colsample_bynode=[None],\n                                     colsample_bytree=[None],\n                                     early_stopping_rounds=[None],\n                                     enable_categorical=[False],\n                                     eval_metric=['auc'], feature_types=[None],\n                                     gamma=[None], gpu_id=[None],\n                                     grow_policy=['lossguide'],\n                                     importance_type=[None],\n                                     interact...\n                         'max_cat_threshold': [None],\n                         'max_cat_to_onehot': [None], 'max_delta_step': [None],\n                         'max_depth': [5], 'max_leaves': [None],\n                         'min_child_weight': [1], 'missing': [nan],\n                         'monotone_constraints': [None], 'n_estimators': [40],\n                         'n_jobs': [None], 'num_parallel_tree': [None],\n                         'objective': ['binary:logistic'], 'predictor': [None], ...},\n             return_train_score=True, scoring='accuracy', verbose=1)XGBClassifier(base_score=[None], booster=['gbtree'], callbacks=[None],\n              colsample_bylevel=[None], colsample_bynode=[None],\n              colsample_bytree=[None], early_stopping_rounds=[None],\n              enable_categorical=[False], eval_metric=['auc'],\n              feature_types=[None], gamma=[None], gpu_id=[None],\n              grow_policy=['lossguide'], importance_type=[None],\n              interaction_constraints=[None], learning_rate=[None],\n              max_bin=[None], max_cat_threshold=[None],\n              max_cat_to_onehot=[None], max_delta_step=[None], max_depth=[None],\n              max_leaves=[None], min_child_weight=[None], missing=[nan],\n              monotone_constraints=[None], n_estimators=[100], n_jobs=[None],\n              num_parallel_tree=[None], objective=['binary:logistic'],\n              predictor=[None], ...)XGBClassifier(base_score=[None], booster=['gbtree'], callbacks=[None],\n              colsample_bylevel=[None], colsample_bynode=[None],\n              colsample_bytree=[None], early_stopping_rounds=[None],\n              enable_categorical=[False], eval_metric=['auc'],\n              feature_types=[None], gamma=[None], gpu_id=[None],\n              grow_policy=['lossguide'], importance_type=[None],\n              interaction_constraints=[None], learning_rate=[None],\n              max_bin=[None], max_cat_threshold=[None],\n              max_cat_to_onehot=[None], max_delta_step=[None], max_depth=[None],\n              max_leaves=[None], min_child_weight=[None], missing=[nan],\n              monotone_constraints=[None], n_estimators=[100], n_jobs=[None],\n              num_parallel_tree=[None], objective=['binary:logistic'],\n              predictor=[None], ...)bp_gs\n#> {'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.8, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'auc', 'feature_types': None, 'gamma': 0, 'gpu_id': None, 'grow_policy': 'lossguide', 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.03, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 5, 'max_leaves': None, 'min_child_weight': 1, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 40, 'n_jobs': None, 'num_parallel_tree': None, 'objective': 'binary:logistic', 'predictor': None, 'random_state': None, 'reg_alpha': 0, 'reg_lambda': 0.2, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'hist', 'use_label_encoder': False, 'validate_parameters': None, 'verbosity': None}'''\n#No. of jobs\nrcvj = gcvj\n\n#unwrapping list values of default parameters\ndefault_params_xgb = {}\n\nfor key in default_params.keys():\n    default_params_xgb[key] = default_params[key][0]\n\n#providing default parameters to xgbc model, before randomized search cross-validation\nxgbc = xgb.XGBClassifier(**default_params_xgb)\n\n#Executing Randomized Search\nclf1 = RandomizedSearchCV(\n    estimator=xgbc,\n    param_distributions=param_grid, \n    scoring='accuracy',\n    return_train_score=True, \n    verbose=1, \n    cv=3, \n    n_iter=rcvj)\nclf1.fit(x_train_select, y_train)\n    \n#results dataframe\ndf1 = pd.DataFrame(clf1.cv_results_)\n\n#predictions - inputs to confusion matrix\ntrain_predictions = clf1.predict(x_train_select)\ntest_predictions = clf1.predict(x_test_select)\n    \n#confusion matrices\ncfm_train = confusion_matrix(y_train, train_predictions)\ncfm_test = confusion_matrix(y_test, test_predictions)\nprint(cfm_train)\nprint(cfm_test)\n\n#accuracy scores\naccs_train = accuracy_score(y_train, train_predictions)\naccs_test = accuracy_score(y_test, test_predictions)\n    \n#F1 scores for each train/test label\nf1s_train_p1 = f1_score(y_train, train_predictions, pos_label=1)\nf1s_train_p0 = f1_score(y_train, train_predictions, pos_label=0)\nf1s_test_p1 = f1_score(y_test, test_predictions, pos_label=1)\nf1s_test_p0 = f1_score(y_test, test_predictions, pos_label=0)\n    \n#Area Under the Receiver Operating Characteristic Curve\ntest_ras = roc_auc_score(y_test, clf1.predict_proba(x_test_select)[:,1])\n\n#best parameters\nbp_rs = clf1.best_params_\n\nbp_rs\n\n'''\n#> \"\\n#No. of jobs\\nrcvj = gcvj\\n\\n#unwrapping list values of default parameters\\ndefault_params_xgb = {}\\n\\nfor key in default_params.keys():\\n    default_params_xgb[key] = default_params[key][0]\\n\\n#providing default parameters to xgbc model, before randomized search cross-validation\\nxgbc = xgb.XGBClassifier(**default_params_xgb)\\n\\n#Executing Randomized Search\\nclf1 = RandomizedSearchCV(\\n    estimator=xgbc,\\n    param_distributions=param_grid, \\n    scoring='accuracy',\\n    return_train_score=True, \\n    verbose=1, \\n    cv=3, \\n    n_iter=rcvj)\\nclf1.fit(x_train_select, y_train)\\n    \\n#results dataframe\\ndf1 = pd.DataFrame(clf1.cv_results_)\\n\\n#predictions - inputs to confusion matrix\\ntrain_predictions = clf1.predict(x_train_select)\\ntest_predictions = clf1.predict(x_test_select)\\n    \\n#confusion matrices\\ncfm_train = confusion_matrix(y_train, train_predictions)\\ncfm_test = confusion_matrix(y_test, test_predictions)\\nprint(cfm_train)\\nprint(cfm_test)\\n\\n#accuracy scores\\naccs_train = accuracy_score(y_train, train_predictions)\\naccs_test = accuracy_score(y_test, test_predictions)\\n    \\n#F1 scores for each train/test label\\nf1s_train_p1 = f1_score(y_train, train_predictions, pos_label=1)\\nf1s_train_p0 = f1_score(y_train, train_predictions, pos_label=0)\\nf1s_test_p1 = f1_score(y_test, test_predictions, pos_label=1)\\nf1s_test_p0 = f1_score(y_test, test_predictions, pos_label=0)\\n    \\n#Area Under the Receiver Operating Characteristic Curve\\ntest_ras = roc_auc_score(y_test, clf1.predict_proba(x_test_select)[:,1])\\n\\n#best parameters\\nbp_rs = clf1.best_params_\\n\\nbp_rs\\n\\n\"'''\n\n#No. of jobs\nbcvj = int(gcvj)\n\n#unwrapping list values of default parameters\ndefault_params_xgb = {}\n\nfor key in default_params.keys():\n    default_params_xgb[key] = default_params[key][0]\n\n#providing default parameters to xgbc model, before randomized search cross-validation\nxgbc = xgb.XGBClassifier(**default_params_xgb)\n\nclf2 = BayesSearchCV(\n    estimator=xgbc, \n    search_spaces=param_grid, \n    n_iter=bcvj, \n    scoring='accuracy', \n    cv=3, \n    return_train_score=True, \n    verbose=3)\nclf2.fit(x_train_select, y_train)\n    \n#results dataframe\ndf2 = pd.DataFrame(clf2.cv_results_)\n\n#predictions - inputs to confusion matrix\ntrain_predictions = clf2.predict(x_train_select)\ntest_predictions = clf2.predict(x_test_select)\n    \n#confusion matrices\ncfm_train = confusion_matrix(y_train, train_predictions)\ncfm_test = confusion_matrix(y_test, test_predictions)\nprint(cfm_train)\nprint(cfm_test)\n\n\n#accuracy scores\naccs_train = accuracy_score(y_train, train_predictions)\naccs_test = accuracy_score(y_test, test_predictions)\n    \n#F1 scores for each train/test label\nf1s_train_p1 = f1_score(y_train, train_predictions, pos_label=1)\nf1s_train_p0 = f1_score(y_train, train_predictions, pos_label=0)\nf1s_test_p1 = f1_score(y_test, test_predictions, pos_label=1)\nf1s_test_p0 = f1_score(y_test, test_predictions, pos_label=0)\n    \n#Area Under the Receiver Operating Characteristic Curve\ntest_ras = roc_auc_score(y_test, clf2.predict_proba(x_test_select)[:,1])\n\n\n#best parameters\nbp_bs = clf2.best_params_\n\nbp_bs\n\n'''\n#> \"\\n\\n#No. of jobs\\nbcvj = int(gcvj)\\n\\n#unwrapping list values of default parameters\\ndefault_params_xgb = {}\\n\\nfor key in default_params.keys():\\n    default_params_xgb[key] = default_params[key][0]\\n\\n#providing default parameters to xgbc model, before randomized search cross-validation\\nxgbc = xgb.XGBClassifier(**default_params_xgb)\\n\\nclf2 = BayesSearchCV(\\n    estimator=xgbc, \\n    search_spaces=param_grid, \\n    n_iter=bcvj, \\n    scoring='accuracy', \\n    cv=3, \\n    return_train_score=True, \\n    verbose=3)\\nclf2.fit(x_train_select, y_train)\\n    \\n#results dataframe\\ndf2 = pd.DataFrame(clf2.cv_results_)\\n\\n#predictions - inputs to confusion matrix\\ntrain_predictions = clf2.predict(x_train_select)\\ntest_predictions = clf2.predict(x_test_select)\\n    \\n#confusion matrices\\ncfm_train = confusion_matrix(y_train, train_predictions)\\ncfm_test = confusion_matrix(y_test, test_predictions)\\nprint(cfm_train)\\nprint(cfm_test)\\n\\n\\n#accuracy scores\\naccs_train = accuracy_score(y_train, train_predictions)\\naccs_test = accuracy_score(y_test, test_predictions)\\n    \\n#F1 scores for each train/test label\\nf1s_train_p1 = f1_score(y_train, train_predictions, pos_label=1)\\nf1s_train_p0 = f1_score(y_train, train_predictions, pos_label=0)\\nf1s_test_p1 = f1_score(y_test, test_predictions, pos_label=1)\\nf1s_test_p0 = f1_score(y_test, test_predictions, pos_label=0)\\n    \\n#Area Under the Receiver Operating Characteristic Curve\\ntest_ras = roc_auc_score(y_test, clf2.predict_proba(x_test_select)[:,1])\\n\\n\\n#best parameters\\nbp_bs = clf2.best_params_\\n\\nbp_bs\\n\\n\""},{"path":"XGBoostalgorithm.html","id":"build-final-classifier","chapter":"16 XGBoost Algorithm","heading":"16.3.8 Build final classifier","text":"optimal parameters build classifier","code":"final_params = bp_gs\n#final_params = bp_rs\n#final_params = bp_bs\n\nxgb_final = xgb.XGBClassifier(**final_params)\n\nxgb_final.fit(x_train_select, y_train)XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=0.8, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric='auc', feature_types=None,\n              gamma=0, gpu_id=None, grow_policy='lossguide',\n              importance_type=None, interaction_constraints=None,\n              learning_rate=0.03, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n              max_leaves=None, min_child_weight=1, missing=nan,\n              monotone_constraints=None, n_estimators=40, n_jobs=None,\n              num_parallel_tree=None, predictor=None, random_state=None, ...)XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=0.8, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric='auc', feature_types=None,\n              gamma=0, gpu_id=None, grow_policy='lossguide',\n              importance_type=None, interaction_constraints=None,\n              learning_rate=0.03, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n              max_leaves=None, min_child_weight=1, missing=nan,\n              monotone_constraints=None, n_estimators=40, n_jobs=None,\n              num_parallel_tree=None, predictor=None, random_state=None, ...)\nclassifier_score = xgb_final.score(x_train_select, y_train)\n\nprint('\\nThe classifier accuracy score is {:03.2f}\\n'.format(classifier_score))\n#> \n#> The classifier accuracy score is 0.99"},{"path":"XGBoostalgorithm.html","id":"evaluating-model-performance","chapter":"16 XGBoost Algorithm","heading":"16.3.9 Evaluating model performance","text":"confusion matrix display performanceROC MetricsROC shows AUC sensitivity specificityclassification report","code":"import matplotlib.pyplot as plt\nfrom IPython.display import Image, display\nfrom sklearn import metrics, preprocessing\n\npredicted = xgb_final.predict(x_test_select)\naccuracy = accuracy_score(y_test, predicted)\n\ncm = metrics.confusion_matrix(y_test, predicted)\n\nfig, ax = plt.subplots(figsize=(3, 3))\nax.matshow(cm, cmap=plt.cm.Reds, alpha=0.3)\nfor i in range(cm.shape[0]):\n     for j in range(cm.shape[1]):\n         ax.text(x=j, y=i,\n                s=cm[i, j], \n                va='center', ha='center')\nplt.xlabel('Predicted Values', )\nplt.ylabel('Actual Values')\n\nax.set_xticklabels([''] + group_names)\nax.set_yticklabels([''] + group_names)\n\nplt.show()y_pred = xgb_final.predict(x_test_select)\n\naccuracy = accuracy_score(y_test, y_pred)\nconf_matrix = confusion_matrix(y_test, y_pred)\nclassification_rep = classification_report(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\n\ntn, fp, fn, tp = conf_matrix.ravel()\nspecificity = tn / (tn + fp)\nsensitivity = tn / (tn + fn)\nfalse_positive_rate = fp / (fp + tn)\n\nindex_df = pd.DataFrame([['Accuracy', accuracy], \n                         ['Specificity', specificity],\n                         ['Sensitivity', sensitivity],\n                         ['Precision', precision], \n                         ['Recall', recall],\n                         ['F1 score', f1],\n                         ['False Positive Rate', false_positive_rate]], \n    columns=['Index', 'Value'])\n\nindex_df\n#>                  Index     Value\n#> 0             Accuracy  0.959064\n#> 1          Specificity  0.970874\n#> 2          Sensitivity  0.961538\n#> 3            Precision  0.955224\n#> 4               Recall  0.941176\n#> 5             F1 score  0.948148\n#> 6  False Positive Rate  0.029126predictions_prob = xgb_final.predict_proba(x_test_select)[:, 1]\n\nfpr2, tpr2, _ = roc_curve(y_test,\n                          predictions_prob,\n                          pos_label = 1)\n\nauc_rf = auc(fpr2, tpr2)\n\ndef plot_roc_curve(fpr, tpr, auc, estimator, xlim=None, ylim=None):\n\n    my_estimators = {\n        'knn': ['Kth Nearest Neighbor', 'deeppink'],\n        'rf': ['Random Forest', 'red'],\n        'XGBoost': ['XGBoost', 'purple']}\n\n    plot_title = my_estimators[estimator][0]\n    color_value = my_estimators[estimator][1]\n\n    fig, ax = plt.subplots(figsize=(5, 5))\n    ax.set_facecolor('#fafafa')\n\n    plt.plot(fpr, tpr, color=color_value, linewidth=1)\n    plt.title('ROC Curve For {0} (AUC = {1: 0.3f})'.format(plot_title, auc))\n\n    plt.plot([0, 1], [0, 1], 'k--', linewidth=1) # Add Diagonal line\n    plt.plot([0, 0], [1, 0], 'k--', linewidth=1, color = 'grey')\n    plt.plot([1, 0], [1, 1], 'k--', linewidth=1, color = 'grey')\n    if xlim is not None:\n        plt.xlim(*xlim)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.show()\n\nplot_roc_curve(fpr2, tpr2, auc_rf, 'XGBoost',\n               xlim=(-0.01, 1.05), \n               ylim=(0.001, 1.05))def print_class_report(predictions, alg_name):\n\n    print('Classification Report for {0}:'.format(alg_name))\n    print(classification_report(predictions, \n            y_test, \n            target_names = group_names))\n\nclass_report = print_class_report(predicted, 'XGBoost')\n#> Classification Report for XGBoost:\n#>               precision    recall  f1-score   support\n#> \n#>            B       0.97      0.96      0.97       104\n#>            M       0.94      0.96      0.95        67\n#> \n#>     accuracy                           0.96       171\n#>    macro avg       0.96      0.96      0.96       171\n#> weighted avg       0.96      0.96      0.96       171"},{"path":"XGBoostalgorithm.html","id":"feature-importance","chapter":"16 XGBoost Algorithm","heading":"16.3.10 Feature Importance","text":"","code":"plt.figure(figsize = (16, 12))\n#> <Figure size 1600x1200 with 0 Axes>\n\nxgb.plot_importance(xgb_final)\n#> <Axes: title={'center': 'Feature importance'}, xlabel='F score', ylabel='Features'>\n\nplt.show()"},{"path":"XGBoostalgorithm.html","id":"save-model","chapter":"16 XGBoost Algorithm","heading":"16.3.11 Save model","text":"save machine learning model using Python’s pickle module","code":"import pickle\n\n''' \n# save classification model as a pickle file\nmodel_pkl_file = \"XGBoost.pkl\"  \n\nwith open(model_pkl_file, 'wb') as file:  \n    pickle.dump(xgb_final, file)\n\n\n# load model from pickle file\nwith open(model_pkl_file, 'rb') as file:  \n    rfc_final = pickle.load(file)\n'''\n#> ' \\n# save classification model as a pickle file\\nmodel_pkl_file = \"XGBoost.pkl\"  \\n\\nwith open(model_pkl_file, \\'wb\\') as file:  \\n    pickle.dump(xgb_final, file)\\n\\n\\n# load model from pickle file\\nwith open(model_pkl_file, \\'rb\\') as file:  \\n    rfc_final = pickle.load(file)\\n'"},{"path":"XGBoostalgorithm.html","id":"session-info-7","chapter":"16 XGBoost Algorithm","heading":"16.4 Session info","text":"","code":"import session_info\n\n\nsession_info.show()\n#> -----\n#> IPython             8.14.0\n#> matplotlib          3.7.2\n#> numpy               1.23.3\n#> pandas              2.0.3\n#> seaborn             0.12.2\n#> session_info        1.0.0\n#> sklearn             1.3.0\n#> skopt               0.9.0\n#> xgboost             1.7.6\n#> -----\n#> Python 3.9.16 | packaged by conda-forge | (main, Feb  1 2023, 21:50:49) [Clang 14.0.6 ]\n#> macOS-10.16-x86_64-i386-64bit\n#> -----\n#> Session information updated at 2024-02-06 13:57"},{"path":"XGBoostalgorithm.html","id":"reference-13","chapter":"16 XGBoost Algorithm","heading":"16.5 Reference","text":"Binary Classification: XGBoost Hyperparameter Tuning Scenarios Non-exhaustive Grid Search Cross-ValidationBinary Classification: XGBoost Hyperparameter Tuning Scenarios Non-exhaustive Grid Search Cross-ValidationFeature Selection Using Random forestFeature Selection Using Random forest","code":""},{"path":"Metageomics.html","id":"Metageomics","chapter":"17 Metageomics","heading":"17 Metageomics","text":"本文聚焦用生物信息学的方法挖掘宏基因组数据背后的生物学意义。从环境中提取包含所有微生物的DNA，然后建库测序获取fastq等二代测序数据，生信是指对这些数据进行处理和提取它们背后的生物学意义，解析出对环境影响产生相应的微生物。宏基因组数据分析的优劣点宏基因组数据分析的优劣点相关数据分析工具相关数据分析工具","code":""},{"path":"Metageomics.html","id":"宏基因组介绍","chapter":"17 Metageomics","heading":"17.1 宏基因组介绍","text":"metagenomics通常有多种含义，它包含基于marker genes测序，如我们常说的16s rRNA基因测序或者真菌的ITS测序（扩增子测序范畴）基于marker genes测序，如我们常说的16s rRNA基因测序或者真菌的ITS测序（扩增子测序范畴）shotgun metagenome测序，也就是所有DNA都采用鸟枪法打断测序（通过DNA insert size筛选测序片段）shotgun metagenome测序，也就是所有DNA都采用鸟枪法打断测序（通过DNA insert size筛选测序片段）另一种是meta-transcriptome测序（宏转录组）另一种是meta-transcriptome测序（宏转录组）不同测序方法的目的是不同的，比如仅仅想知道环境中有什么物种存在，采用标记基因16s rRNA DNA测序即可 （16s metagenomics）比如仅仅想知道环境中有什么物种存在，采用标记基因16s rRNA DNA测序即可 （16s metagenomics）比如想知道环境中有什么物种存在且它们发挥什么功能，采用shotgun metagenome测所有DNA即可 (Metagenomics)比如想知道环境中有什么物种存在且它们发挥什么功能，采用shotgun metagenome测所有DNA即可 (Metagenomics)但是如果想知道当前环境中微生物正在发挥什么功能，则采用检测mRNA，蛋白质或代谢组即可 (Metatranscriptomics, Metaproteomics Metametabolomics)但是如果想知道当前环境中微生物正在发挥什么功能，则采用检测mRNA，蛋白质或代谢组即可 (Metatranscriptomics, Metaproteomics Metametabolomics)+快速低成本识别大多数细菌和真核生物-不能捕获其它非靶点基因-扩增子偏好性（PCR过程中存在，三代测序全长16s rRNA基因可以避免该问题）-不能捕获病毒表征环境中微生物的存在微生态学基于rRNA标记基因的进化树研究+没有偏好性+可检测细菌、古菌、病毒和真核生物+可从头组装微生物组-需大量reads-reads可能来自于宿主-物种分类需参考数据库可知晓环境的当前多个类型微生物存在情况功能基因组学研究病原微生物检测系统进化树+识别活跃状态下的基因和通路-mRNA是不稳定的易降解-多个纯化和扩增mRNA的步骤容易引入较多的噪音挑战：生态系统的复杂性（微生物数目和种类繁多，相互关系复杂）生态系统的复杂性（微生物数目和种类繁多，相互关系复杂）数据库的完整性（较多微生物缺乏参考数据库）数据库的完整性（较多微生物缺乏参考数据库）测序深度（稀少微量的微生物无法检测出来）测序深度（稀少微量的微生物无法检测出来）计算资源（微生物从头组装等需要消耗巨量的计算资源）计算资源（微生物从头组装等需要消耗巨量的计算资源）","code":""},{"path":"Metageomics.html","id":"宏基因组常用分析流程","chapter":"17 Metageomics","heading":"17.1.1 宏基因组常用分析流程","text":"参考 review methods databases metagenomic classification assembly (Ref:)3\nFigure 4.1: Common analysis procedures metagenomics data\nFigure1. Common analysis procedures metagenomics data. Note order analysis steps can shuffled. example, reads might binned assembly taxonomic assignment, downstream algorithms can work subset data.上述步骤分为：fastq质量控制：去除低质量的reads（FastQC, fastp, Fastq_screen, BBtools, Trimmomatic, Cutadapt, khmer/diginorm, MultiQC）fastq质量控制：去除低质量的reads（FastQC, fastp, Fastq_screen, BBtools, Trimmomatic, Cutadapt, khmer/diginorm, MultiQC）metagenome组装：从头组装reads成基因组 (微生物比对分类等软件：Kraken, CLARK, Kallisto, Kaiju, GOTTCHA, Centrifuge, Metaphlan2/3, mOTU, Mash, sourmash; 微生物组装：Megahit, SPAdes, MetaSPAdes, IDBA-UD, MOCAT2)metagenome组装：从头组装reads成基因组 (微生物比对分类等软件：Kraken, CLARK, Kallisto, Kaiju, GOTTCHA, Centrifuge, Metaphlan2/3, mOTU, Mash, sourmash; 微生物组装：Megahit, SPAdes, MetaSPAdes, IDBA-UD, MOCAT2)binning分箱：组装后的分箱，获得精度更高的微生物组 (COCACOLA, CONCOCT, MetaBAT, VizBin)binning分箱：组装后的分箱，获得精度更高的微生物组 (COCACOLA, CONCOCT, MetaBAT, VizBin)物种注释：将得到的基因组草图注释到参考数据库获得物种分类信息 (质量控制：BUSCO, CheckM)物种注释：将得到的基因组草图注释到参考数据库获得物种分类信息 (质量控制：BUSCO, CheckM)下游分析下游分析这些步骤涉及软件众多。","code":""},{"path":"Metageomics.html","id":"reference-14","chapter":"17 Metageomics","heading":"17.2 Reference","text":"Breitwieser, Florian P., Jennifer Lu, Steven L. Salzberg. “review methods databases metagenomic classification assembly.” Briefings bioinformatics 20.4 (2019): 1125-1136.Breitwieser, Florian P., Jennifer Lu, Steven L. Salzberg. “review methods databases metagenomic classification assembly.” Briefings bioinformatics 20.4 (2019): 1125-1136.https://trainings.migale.inrae.fr/posts/2022-06-20-module24/content/slides.html#15https://trainings.migale.inrae.fr/posts/2022-06-20-module24/content/slides.html#15","code":""},{"path":"Notes.html","id":"Notes","chapter":"18 Notes","heading":"18 Notes","text":"Put daily work records microbiota repository","code":""},{"path":"Notes.html","id":"review","chapter":"18 Notes","heading":"18.1 Review","text":"practical guide amplicon metagenomic analysis microbiome dataCurrent challenges best-practice protocols microbiome analysisShotgun metagenomics, sampling analysisTargeting gut tumor microbiota cancerMicrobiota health diseasesThe gut microbiota–brain axis behaviour brain disordersGut microbiota human metabolic health diseaseGut microbiota human NAFLD: disentangling microbial signatures metabolic disordersMicrobiome datasets compositional: optionalCritical Assessment Metagenome Interpretation: second round challengesNext steps 15 stimulating years human gut microbiome researchRethinking healthy eating light gut microbiomeEcosystem-specific microbiota microbiome databases era big dataComputational methods challenges inanalyzing intratumoral microbiome dataThe impact gut microbiome extra-intestinal autoimmune diseases","code":""},{"path":"Notes.html","id":"method","chapter":"18 Notes","heading":"18.2 Method","text":"Analysis microbial compositions: review normalization differential abundance analysisMicrobiome differential abundance methods produce different results across 38 datasetsFaecal microbiome-based machine learning multi-class disease diagnosisNetwork-based machine learning approach topredict immunotherapy response cancer patientsNetCoMi: network construction comparison microbiome data RPopulation structure discovery meta-analyzed microbial communities inflammatory bowel disease using MMUPHin","code":""},{"path":"Notes.html","id":"research-article","chapter":"18 Notes","heading":"18.3 Research article","text":"","code":""},{"path":"Notes.html","id":"longitudinal-study","chapter":"18 Notes","heading":"18.3.1 Longitudinal study","text":"Acute persistent effects commonly used antibiotics gut microbiome resistome healthy adults","code":""},{"path":"Notes.html","id":"nafld-non-alcoholic-fatty-liver-disease","chapter":"18 Notes","heading":"18.3.2 NAFLD: non-alcoholic fatty liver disease","text":"Gut microbiota human NAFLD: disentangling microbial signatures metabolic disordersCharacterization microbiome metabolite analyses patients metabolic associated fatty liver disease type II diabetes mellitusMultiomics Analysis Reveals Impact Microbiota Host Metabolism Hepatic Steatosis","code":""},{"path":"Notes.html","id":"mechanism","chapter":"18 Notes","heading":"18.3.3 Mechanism","text":"Microbiota alterations proline metabolism impact depression","code":""},{"path":"Notes.html","id":"ici","chapter":"18 Notes","heading":"18.3.4 ICI","text":"Intestinal Akkermansia muciniphila predicts clinical response PD-1 blockade patients advanced non-small-cell lung cancerGut microbial structural variation associates immune checkpoint inhibitor responseMulti-kingdom gut microbiota analyses define bacterial-fungal interplay microbial markers pan-cancer immunotherapy across cohorts","code":""},{"path":"Notes.html","id":"blood-microbiota","chapter":"18 Notes","heading":"18.3.5 Blood microbiota","text":"Microbiome analyses blood tissues suggest cancer diagnostic approach","code":""},{"path":"Notes.html","id":"database","chapter":"18 Notes","heading":"18.4 Database","text":"Integrated Microbial Genomes Microbiomes (JGI-IMG/M)16S_rRNA_Microbiome_DatasetsEarth Microbiome Project (EMP)Human Oral Microbiome Database (HOMD)Integrative Human Microbiome Project (HMP)Unifed Human Gastrointestinal Genome (UHGG)Global Microbial Gene Catalog (GMGC)Comprehensive Antibiotic Resistance DatabasemicrobioTA: atlas microbiome multiple disease tissues Homo sapiens Mus musculusmicrobiome-metabolome dataMetagenomic Data","code":""},{"path":"Notes.html","id":"benchmark","chapter":"18 Notes","heading":"18.5 Benchmark","text":"Comprehensive benchmarking ensemble approaches metagenomic classifiers","code":""},{"path":"Notes.html","id":"pipeline","chapter":"18 Notes","heading":"18.6 Pipeline","text":"Humann2: Species-level functional profiling metagenomes metatranscriptomesbinny: binny: automated binning algorithm recover high-quality genomes complex metagenomic datasets","code":""},{"path":"Notes.html","id":"data-analysis-materials","chapter":"18 Notes","heading":"18.7 Data Analysis Materials","text":"microVizmixOmicsAdvanced Regression MethodsOrchestrating Microbiome AnalysisAdvanced Multivariate Analyses RStatistical tools high-throughput data analysis: STHDAStatistical Analysis Microbiome Data RDoing Meta-Analysis R: Hands-GuideConstrained ordinationMACHINE LEARNING 2021 SPRINGVisualisation proteomics data using R BioconductorLightGBM R-packageMastering Software Development R","code":""},{"path":"Notes.html","id":"lab","chapter":"18 Notes","heading":"18.8 Lab","text":"Zeller Team: Zeller team develops analysis strategies tools investigate microbiome contributes human health, disease progression treatment success, shaped host factors nutrition drug intake.Huttenhower lab: lab try learn use microbiome predict disease onset, progression, outcomes, well developing ways modify health maintenance therapy.KOST LAB: working group uses tractable, laboratory-based model systems address fundamental biological questions different levels biological organization.Daniel Croll lab: lab Daniel Croll wants understand pathogens evolve cause disease.Honda Lab: aim identify specific intestinal bacterial species influence host immune cells inducing functions differentiation.Borenstein lab: computational study human microbiome complex microbial ecosystems.Gore Lab: Gore Lab studies interactions individuals determine evolutionary ecological dynamics multi-species microbial communities. particular focus alternative stables states, community assembly, cross-feeding, emergence “cheater” strategies. laboratory composed interdisciplinary group scientists interested learning effectively combine experiments, theory, modeling.bhattlab: human gut microbiota STANFORD MEDICAL SCHOOL.","code":""},{"path":"Notes.html","id":"job-view","chapter":"18 Notes","heading":"18.9 Job view","text":"Science Jobs hunter","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
