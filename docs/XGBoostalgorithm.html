<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 14 XGBoost Algorithm | 生物信息随记</title>
<meta name="author" content="Hua Zou">
<meta name="description" content="The XGBoost or Extreme Gradient Boosting algorithm is a decision tree based machine learning algorithm which uses a process called boosting to help improve performance. The basic classification...">
<meta name="generator" content="bookdown 0.34 with bs4_book()">
<meta property="og:title" content="Chapter 14 XGBoost Algorithm | 生物信息随记">
<meta property="og:type" content="book">
<meta property="og:url" content="https://zouhua.top/DraftNotes/XGBoostalgorithm.html">
<meta property="og:description" content="The XGBoost or Extreme Gradient Boosting algorithm is a decision tree based machine learning algorithm which uses a process called boosting to help improve performance. The basic classification...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 14 XGBoost Algorithm | 生物信息随记">
<meta name="twitter:description" content="The XGBoost or Extreme Gradient Boosting algorithm is a decision tree based machine learning algorithm which uses a process called boosting to help improve performance. The basic classification...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><link href="libs/Poppins-0.4.6/font.css" rel="stylesheet">
<script src="libs/bs3compat-0.6.0/transition.js"></script><script src="libs/bs3compat-0.6.0/tabs.js"></script><script src="libs/bs3compat-0.6.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/htmlwidgets-1.6.2/htmlwidgets.js"></script><link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet">
<script src="libs/datatables-binding-0.28/datatables.js"></script><link href="libs/dt-core-1.13.4/css/jquery.dataTables.min.css" rel="stylesheet">
<link href="libs/dt-core-1.13.4/css/jquery.dataTables.extra.css" rel="stylesheet">
<script src="libs/dt-core-1.13.4/js/jquery.dataTables.min.js"></script><link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet">
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="assets/style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">生物信息随记</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html"><span class="header-section-number">1</span> 介绍</a></li>
<li class="book-part">Data Set</li>
<li><a class="" href="ZeybelDataset.html"><span class="header-section-number">2</span> Zeybel Dataset</a></li>
<li class="book-part">Statistical Methods</li>
<li><a class="" href="GEEandMLM.html"><span class="header-section-number">3</span> GEE and MLM</a></li>
<li><a class="" href="HypothesisTestingMethods.html"><span class="header-section-number">4</span> Hypothesis Testing Methods</a></li>
<li><a class="" href="BatchEffectCorrection.html"><span class="header-section-number">5</span> Batch Effect Correction</a></li>
<li><a class="" href="LinearModelonMicrobialCommunity.html"><span class="header-section-number">6</span> Linear Model on Microbial Community</a></li>
<li class="book-part">Metabolomics Data Analysis</li>
<li><a class="" href="dataprocessing.html"><span class="header-section-number">7</span> Data Processing</a></li>
<li><a class="" href="DimensionReduction.html"><span class="header-section-number">8</span> Dimension Reduction</a></li>
<li><a class="" href="DifferetialAnalysis.html"><span class="header-section-number">9</span> Differetial Analysis</a></li>
<li><a class="" href="FunctionalAnalysis.html"><span class="header-section-number">10</span> Functional Analysis</a></li>
<li><a class="" href="MetOriginAnalysis.html"><span class="header-section-number">11</span> MetOrigin Analysis</a></li>
<li><a class="" href="OtherAnalysis.html"><span class="header-section-number">12</span> Other Analysis</a></li>
<li class="book-part">Machine Learning</li>
<li><a class="" href="randomforestalgorithm.html"><span class="header-section-number">13</span> Random Forest Algorithm</a></li>
<li><a class="active" href="XGBoostalgorithm.html"><span class="header-section-number">14</span> XGBoost Algorithm</a></li>
<li class="book-part">Knowledge</li>
<li><a class="" href="Metageomics.html"><span class="header-section-number">15</span> Metageomics</a></li>
<li><a class="" href="Notes.html"><span class="header-section-number">16</span> Notes</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/HuaZou/DraftNotes">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="XGBoostalgorithm" class="section level1" number="14">
<h1>
<span class="header-section-number">14</span> XGBoost Algorithm<a class="anchor" aria-label="anchor" href="#XGBoostalgorithm"><i class="fas fa-link"></i></a>
</h1>
<blockquote>
<p>The XGBoost or Extreme Gradient Boosting algorithm is a decision tree based machine learning algorithm which uses a process called boosting to help improve performance.</p>
<p>The basic classification modeling process involves obtaining a dataset, creating features of independent variables, and using them to predict a dependent variable or target class. Most classification datasets require some preparation before they can be used by classifiers, and also usually require the creation of additional features through a process called feature engineering.</p>
<p>“Gradient boosting is a machine learning technique for regression, classification and other tasks, which produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees. When a decision tree is the weak learner, the resulting algorithm is called gradient boosted trees, which usually outperforms random forest. It builds the model in a stage-wise fashion like other boosting methods do, and it generalizes them by allowing optimization of an arbitrary differentiable loss function” Note: XGBoost is ditinguished from other gradient boosting techniques by its regularization mechanism to prevent overfitting.</p>
</blockquote>
<div id="data-preparation" class="section level3" number="14.0.1">
<h3>
<span class="header-section-number">14.0.1</span> Data Preparation<a class="anchor" aria-label="anchor" href="#data-preparation"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>
<strong>data table</strong>: <code>clean_data.csv</code> with group information (Row-&gt;samples;Column-&gt;features)</li>
</ul>
<p>可以点击此处下载数据<a href="https://github.com/HuaZou/DraftNotes/blob/main/InputData/Breast_cancer/clean_data.csv">clean_data.csv</a>或使用<code>wget</code></p>
<div class="sourceCode" id="cb206"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb206-1"><a href="XGBoostalgorithm.html#cb206-1" tabindex="-1"></a><span class="fu">wget</span> https://github.com/HuaZou/DraftNotes/blob/main/InputData/Breast_cancer/clean_data.csv</span></code></pre></div>
<blockquote>
<p>该数据集包含569份恶性和良性肿瘤的样本的32类指标，通过这些特征构建区分恶性和良性肿瘤的随机森林分类器.</p>
</blockquote>
<blockquote>
<p>The Breast Cancer datasets is available machine learning repository maintained by the University of California, Irvine. The dataset contains 569 samples of malignant and benign tumor cells.</p>
</blockquote>
</div>
<div id="data-description" class="section level3" number="14.0.2">
<h3>
<span class="header-section-number">14.0.2</span> Data Description<a class="anchor" aria-label="anchor" href="#data-description"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>
<p><strong>Feature table</strong>:</p>
<ul>
<li>M samples x N Features</li>
</ul>
</li>
<li>
<p><strong>metadata</strong></p>
<ul>
<li>main response/independent variable: <code>diagnosis: M vs B</code>
</li>
</ul>
</li>
</ul>
</div>
<div id="data-preprocessing" class="section level3" number="14.0.3">
<h3>
<span class="header-section-number">14.0.3</span> Data Preprocessing<a class="anchor" aria-label="anchor" href="#data-preprocessing"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>
<strong>Prevalence filtering</strong>: reducing the sparsity of data (default: 10%)</li>
</ul>
</div>
<div id="data-partition" class="section level3" number="14.0.4">
<h3>
<span class="header-section-number">14.0.4</span> Data Partition<a class="anchor" aria-label="anchor" href="#data-partition"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>train dataset: 80% or 70% (default 70%);</li>
<li>test dataset: 20% or 30% (default 30%).</li>
</ul>
</div>
<div id="feature-selection" class="section level3" number="14.0.5">
<h3>
<span class="header-section-number">14.0.5</span> Feature Selection<a class="anchor" aria-label="anchor" href="#feature-selection"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>Importance of features by random forest;</li>
</ul>
<p>Feature selection should be taken only in training set, which avoiding overfitting.</p>
</div>
<div id="model-training" class="section level3" number="14.0.6">
<h3>
<span class="header-section-number">14.0.6</span> Model training<a class="anchor" aria-label="anchor" href="#model-training"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>Base model construction with higher performance</li>
<li>Tuning the hyperparameters</li>
<li>Best model building and evaluations</li>
</ul>
</div>
<div id="python-environment" class="section level3" number="14.0.7">
<h3>
<span class="header-section-number">14.0.7</span> python environment<a class="anchor" aria-label="anchor" href="#python-environment"><i class="fas fa-link"></i></a>
</h3>
<div class="sourceCode" id="cb207"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://rstudio.github.io/reticulate/">reticulate</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># myenvs &lt;- conda_list()</span></span>
<span><span class="co"># </span></span>
<span><span class="co"># envname &lt;- myenvs$name[2]</span></span>
<span><span class="co"># use_condaenv(envname, required = TRUE)</span></span>
<span><span class="co"># # or</span></span>
<span><span class="fu"><a href="https://rstudio.github.io/reticulate/reference/use_python.html">use_condaenv</a></span><span class="op">(</span><span class="st">"base"</span>, required <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
</div>
<div id="loading-required-packages" class="section level2" number="14.1">
<h2>
<span class="header-section-number">14.1</span> Loading required packages<a class="anchor" aria-label="anchor" href="#loading-required-packages"><i class="fas fa-link"></i></a>
</h2>
<div class="sourceCode" id="cb208"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb208-1"><a href="XGBoostalgorithm.html#cb208-1" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb208-2"><a href="XGBoostalgorithm.html#cb208-2" tabindex="-1"></a>warnings.filterwarnings(<span class="st">'ignore'</span>)</span>
<span id="cb208-3"><a href="XGBoostalgorithm.html#cb208-3" tabindex="-1"></a></span>
<span id="cb208-4"><a href="XGBoostalgorithm.html#cb208-4" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb208-5"><a href="XGBoostalgorithm.html#cb208-5" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb208-6"><a href="XGBoostalgorithm.html#cb208-6" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb208-7"><a href="XGBoostalgorithm.html#cb208-7" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb208-8"><a href="XGBoostalgorithm.html#cb208-8" tabindex="-1"></a></span>
<span id="cb208-9"><a href="XGBoostalgorithm.html#cb208-9" tabindex="-1"></a><span class="co"># machine learning</span></span>
<span id="cb208-10"><a href="XGBoostalgorithm.html#cb208-10" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> LabelEncoder</span>
<span id="cb208-11"><a href="XGBoostalgorithm.html#cb208-11" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb208-12"><a href="XGBoostalgorithm.html#cb208-12" tabindex="-1"></a></span>
<span id="cb208-13"><a href="XGBoostalgorithm.html#cb208-13" tabindex="-1"></a><span class="co">#from xgboost import XGBClassifier</span></span>
<span id="cb208-14"><a href="XGBoostalgorithm.html#cb208-14" tabindex="-1"></a><span class="im">import</span> xgboost <span class="im">as</span> xgb</span>
<span id="cb208-15"><a href="XGBoostalgorithm.html#cb208-15" tabindex="-1"></a></span>
<span id="cb208-16"><a href="XGBoostalgorithm.html#cb208-16" tabindex="-1"></a><span class="co">#classes for grid search and cross-validation, function for splitting data and evaluating models</span></span>
<span id="cb208-17"><a href="XGBoostalgorithm.html#cb208-17" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb208-18"><a href="XGBoostalgorithm.html#cb208-18" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> f1_score</span>
<span id="cb208-19"><a href="XGBoostalgorithm.html#cb208-19" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_auc_score</span>
<span id="cb208-20"><a href="XGBoostalgorithm.html#cb208-20" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_curve, auc</span>
<span id="cb208-21"><a href="XGBoostalgorithm.html#cb208-21" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix </span>
<span id="cb208-22"><a href="XGBoostalgorithm.html#cb208-22" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> precision_score</span>
<span id="cb208-23"><a href="XGBoostalgorithm.html#cb208-23" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> recall_score</span>
<span id="cb208-24"><a href="XGBoostalgorithm.html#cb208-24" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> cross_val_score</span>
<span id="cb208-25"><a href="XGBoostalgorithm.html#cb208-25" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report</span>
<span id="cb208-26"><a href="XGBoostalgorithm.html#cb208-26" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV, RandomizedSearchCV</span>
<span id="cb208-27"><a href="XGBoostalgorithm.html#cb208-27" tabindex="-1"></a><span class="im">from</span> skopt <span class="im">import</span> BayesSearchCV</span>
<span id="cb208-28"><a href="XGBoostalgorithm.html#cb208-28" tabindex="-1"></a></span>
<span id="cb208-29"><a href="XGBoostalgorithm.html#cb208-29" tabindex="-1"></a><span class="co"># plotting </span></span>
<span id="cb208-30"><a href="XGBoostalgorithm.html#cb208-30" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb208-31"><a href="XGBoostalgorithm.html#cb208-31" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb208-32"><a href="XGBoostalgorithm.html#cb208-32" tabindex="-1"></a></span>
<span id="cb208-33"><a href="XGBoostalgorithm.html#cb208-33" tabindex="-1"></a>plt.style.use(<span class="st">'fivethirtyeight'</span>)</span>
<span id="cb208-34"><a href="XGBoostalgorithm.html#cb208-34" tabindex="-1"></a>sns.set_style(<span class="st">"darkgrid"</span>)</span>
<span id="cb208-35"><a href="XGBoostalgorithm.html#cb208-35" tabindex="-1"></a></span>
<span id="cb208-36"><a href="XGBoostalgorithm.html#cb208-36" tabindex="-1"></a>plt.rcParams[<span class="st">'figure.figsize'</span>] <span class="op">=</span> (<span class="dv">8</span>, <span class="dv">4</span>)</span>
<span id="cb208-37"><a href="XGBoostalgorithm.html#cb208-37" tabindex="-1"></a>plt.rcParams[<span class="st">"axes.linewidth"</span>] <span class="op">=</span> <span class="dv">1</span></span></code></pre></div>
</div>
<div id="data-preparation-1" class="section level2" number="14.2">
<h2>
<span class="header-section-number">14.2</span> Data Preparation<a class="anchor" aria-label="anchor" href="#data-preparation-1"><i class="fas fa-link"></i></a>
</h2>
<blockquote>
<p>The Breast Cancer datasets is available machine learning repository maintained by the University of California, Irvine. The dataset contains 569 samples of malignant and benign tumor cells.
The first two columns in the dataset store the unique ID numbers of the samples and the corresponding diagnosis (M=malignant, B=benign), respectively.
The columns 3-32 contain 30 real-value features that have been computed from digitized images of the cell nuclei, which can be used to build a model to predict whether a tumor is benign or malignant.</p>
</blockquote>
<div class="sourceCode" id="cb209"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb209-1"><a href="XGBoostalgorithm.html#cb209-1" tabindex="-1"></a>dat <span class="op">=</span> pd.read_csv(<span class="st">"InputData/Breast_cancer/clean_data.csv"</span>, index_col<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb209-2"><a href="XGBoostalgorithm.html#cb209-2" tabindex="-1"></a></span>
<span id="cb209-3"><a href="XGBoostalgorithm.html#cb209-3" tabindex="-1"></a>dat.head()</span>
<span id="cb209-4"><a href="XGBoostalgorithm.html#cb209-4" tabindex="-1"></a><span class="co">#&gt;   diagnosis  radius_mean  ...  symmetry_worst  fractal_dimension_worst</span></span>
<span id="cb209-5"><a href="XGBoostalgorithm.html#cb209-5" tabindex="-1"></a><span class="co">#&gt; 0         M        17.99  ...          0.4601                  0.11890</span></span>
<span id="cb209-6"><a href="XGBoostalgorithm.html#cb209-6" tabindex="-1"></a><span class="co">#&gt; 1         M        20.57  ...          0.2750                  0.08902</span></span>
<span id="cb209-7"><a href="XGBoostalgorithm.html#cb209-7" tabindex="-1"></a><span class="co">#&gt; 2         M        19.69  ...          0.3613                  0.08758</span></span>
<span id="cb209-8"><a href="XGBoostalgorithm.html#cb209-8" tabindex="-1"></a><span class="co">#&gt; 3         M        11.42  ...          0.6638                  0.17300</span></span>
<span id="cb209-9"><a href="XGBoostalgorithm.html#cb209-9" tabindex="-1"></a><span class="co">#&gt; 4         M        20.29  ...          0.2364                  0.07678</span></span>
<span id="cb209-10"><a href="XGBoostalgorithm.html#cb209-10" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb209-11"><a href="XGBoostalgorithm.html#cb209-11" tabindex="-1"></a><span class="co">#&gt; [5 rows x 31 columns]</span></span></code></pre></div>
</div>
<div id="xgboost-classification" class="section level2" number="14.3">
<h2>
<span class="header-section-number">14.3</span> XGBoost classification<a class="anchor" aria-label="anchor" href="#xgboost-classification"><i class="fas fa-link"></i></a>
</h2>
<ul>
<li><p>Transforming group label</p></li>
<li><p>Principal component analysis</p></li>
<li><p>Data partition</p></li>
<li><p>Feaeture selection</p></li>
<li><p>Base model</p></li>
<li><p>Tuning hyperparameters</p></li>
<li><p>Building final model</p></li>
<li><p>Evaluating model performance</p></li>
</ul>
<div id="transforming-label" class="section level3" number="14.3.1">
<h3>
<span class="header-section-number">14.3.1</span> Transforming label<a class="anchor" aria-label="anchor" href="#transforming-label"><i class="fas fa-link"></i></a>
</h3>
<p>Machine learning does not accept string labels for categorical variables</p>
<ul>
<li>B -&gt; 0</li>
<li>M -&gt; 1</li>
</ul>
<div class="sourceCode" id="cb210"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb210-1"><a href="XGBoostalgorithm.html#cb210-1" tabindex="-1"></a><span class="co">#creating deepcopy of model instances</span></span>
<span id="cb210-2"><a href="XGBoostalgorithm.html#cb210-2" tabindex="-1"></a><span class="im">from</span> copy <span class="im">import</span> deepcopy</span>
<span id="cb210-3"><a href="XGBoostalgorithm.html#cb210-3" tabindex="-1"></a></span>
<span id="cb210-4"><a href="XGBoostalgorithm.html#cb210-4" tabindex="-1"></a>group_names <span class="op">=</span> [<span class="st">'B'</span>, <span class="st">"M"</span>]</span>
<span id="cb210-5"><a href="XGBoostalgorithm.html#cb210-5" tabindex="-1"></a></span>
<span id="cb210-6"><a href="XGBoostalgorithm.html#cb210-6" tabindex="-1"></a>dat_copy <span class="op">=</span> deepcopy(dat)</span>
<span id="cb210-7"><a href="XGBoostalgorithm.html#cb210-7" tabindex="-1"></a>dat_copy[<span class="st">'diagnosis'</span>] <span class="op">=</span> dat_copy[<span class="st">'diagnosis'</span>].<span class="bu">map</span>({<span class="st">'B'</span>:<span class="dv">0</span>, <span class="st">'M'</span>:<span class="dv">1</span>})</span>
<span id="cb210-8"><a href="XGBoostalgorithm.html#cb210-8" tabindex="-1"></a>dat_copy.head(n<span class="op">=</span><span class="dv">6</span>)</span>
<span id="cb210-9"><a href="XGBoostalgorithm.html#cb210-9" tabindex="-1"></a><span class="co">#&gt;    diagnosis  radius_mean  ...  symmetry_worst  fractal_dimension_worst</span></span>
<span id="cb210-10"><a href="XGBoostalgorithm.html#cb210-10" tabindex="-1"></a><span class="co">#&gt; 0          1        17.99  ...          0.4601                  0.11890</span></span>
<span id="cb210-11"><a href="XGBoostalgorithm.html#cb210-11" tabindex="-1"></a><span class="co">#&gt; 1          1        20.57  ...          0.2750                  0.08902</span></span>
<span id="cb210-12"><a href="XGBoostalgorithm.html#cb210-12" tabindex="-1"></a><span class="co">#&gt; 2          1        19.69  ...          0.3613                  0.08758</span></span>
<span id="cb210-13"><a href="XGBoostalgorithm.html#cb210-13" tabindex="-1"></a><span class="co">#&gt; 3          1        11.42  ...          0.6638                  0.17300</span></span>
<span id="cb210-14"><a href="XGBoostalgorithm.html#cb210-14" tabindex="-1"></a><span class="co">#&gt; 4          1        20.29  ...          0.2364                  0.07678</span></span>
<span id="cb210-15"><a href="XGBoostalgorithm.html#cb210-15" tabindex="-1"></a><span class="co">#&gt; 5          1        12.45  ...          0.3985                  0.12440</span></span>
<span id="cb210-16"><a href="XGBoostalgorithm.html#cb210-16" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb210-17"><a href="XGBoostalgorithm.html#cb210-17" tabindex="-1"></a><span class="co">#&gt; [6 rows x 31 columns]</span></span></code></pre></div>
</div>
<div id="principal-component-analysis" class="section level3" number="14.3.2">
<h3>
<span class="header-section-number">14.3.2</span> Principal component analysis<a class="anchor" aria-label="anchor" href="#principal-component-analysis"><i class="fas fa-link"></i></a>
</h3>
<div class="sourceCode" id="cb211"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb211-1"><a href="XGBoostalgorithm.html#cb211-1" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb211-2"><a href="XGBoostalgorithm.html#cb211-2" tabindex="-1"></a><span class="co">#from sklearn.preprocessing import StandardScaler</span></span>
<span id="cb211-3"><a href="XGBoostalgorithm.html#cb211-3" tabindex="-1"></a></span>
<span id="cb211-4"><a href="XGBoostalgorithm.html#cb211-4" tabindex="-1"></a>data_remove <span class="op">=</span> dat_copy.drop([<span class="st">'diagnosis'</span>], axis <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb211-5"><a href="XGBoostalgorithm.html#cb211-5" tabindex="-1"></a></span>
<span id="cb211-6"><a href="XGBoostalgorithm.html#cb211-6" tabindex="-1"></a><span class="co">#sc = StandardScaler()</span></span>
<span id="cb211-7"><a href="XGBoostalgorithm.html#cb211-7" tabindex="-1"></a><span class="co">#sc.fit_transform(data_remove)</span></span>
<span id="cb211-8"><a href="XGBoostalgorithm.html#cb211-8" tabindex="-1"></a></span>
<span id="cb211-9"><a href="XGBoostalgorithm.html#cb211-9" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb211-10"><a href="XGBoostalgorithm.html#cb211-10" tabindex="-1"></a>pca.fit(data_remove)</span></code></pre></div>
<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style>
<div id="sk-container-id-1" class="sk-top-container">
<div class="sk-text-repr-fallback">
<pre>PCA(n_components=2)</pre>
<b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b>
</div>
<div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">PCA</label><div class="sk-toggleable__content"><pre>PCA(n_components=2)</pre></div>
</div></div></div>
</div>
<div class="sourceCode" id="cb212"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb212-1"><a href="XGBoostalgorithm.html#cb212-1" tabindex="-1"></a>data_remove_pca <span class="op">=</span> pca.transform(data_remove)</span>
<span id="cb212-2"><a href="XGBoostalgorithm.html#cb212-2" tabindex="-1"></a></span>
<span id="cb212-3"><a href="XGBoostalgorithm.html#cb212-3" tabindex="-1"></a>PCA_df <span class="op">=</span> pd.DataFrame()</span>
<span id="cb212-4"><a href="XGBoostalgorithm.html#cb212-4" tabindex="-1"></a>PCA_df[<span class="st">'PCA_1'</span>] <span class="op">=</span> data_remove_pca[:, <span class="dv">0</span>]</span>
<span id="cb212-5"><a href="XGBoostalgorithm.html#cb212-5" tabindex="-1"></a>PCA_df[<span class="st">'PCA_2'</span>] <span class="op">=</span> data_remove_pca[:, <span class="dv">1</span>]</span>
<span id="cb212-6"><a href="XGBoostalgorithm.html#cb212-6" tabindex="-1"></a>PCA_df[<span class="st">'diagnosis'</span>] <span class="op">=</span> dat[<span class="st">'diagnosis'</span>].tolist()</span>
<span id="cb212-7"><a href="XGBoostalgorithm.html#cb212-7" tabindex="-1"></a></span>
<span id="cb212-8"><a href="XGBoostalgorithm.html#cb212-8" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">4</span>, <span class="dv">4</span>))</span>
<span id="cb212-9"><a href="XGBoostalgorithm.html#cb212-9" tabindex="-1"></a>sns.scatterplot(data <span class="op">=</span> PCA_df,</span>
<span id="cb212-10"><a href="XGBoostalgorithm.html#cb212-10" tabindex="-1"></a>                x <span class="op">=</span> <span class="st">'PCA_1'</span>, </span>
<span id="cb212-11"><a href="XGBoostalgorithm.html#cb212-11" tabindex="-1"></a>                y <span class="op">=</span> <span class="st">'PCA_2'</span>,</span>
<span id="cb212-12"><a href="XGBoostalgorithm.html#cb212-12" tabindex="-1"></a>                hue <span class="op">=</span> <span class="st">'diagnosis'</span>)</span>
<span id="cb212-13"><a href="XGBoostalgorithm.html#cb212-13" tabindex="-1"></a></span>
<span id="cb212-14"><a href="XGBoostalgorithm.html#cb212-14" tabindex="-1"></a>plt.title(<span class="st">"PCA"</span>)</span>
<span id="cb212-15"><a href="XGBoostalgorithm.html#cb212-15" tabindex="-1"></a>plt.xlabel(<span class="st">"First Principal Component"</span>)</span>
<span id="cb212-16"><a href="XGBoostalgorithm.html#cb212-16" tabindex="-1"></a>plt.ylabel(<span class="st">"Second Principal Component"</span>)</span>
<span id="cb212-17"><a href="XGBoostalgorithm.html#cb212-17" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">'lower right'</span>, fontsize<span class="op">=</span><span class="st">"8"</span>)</span>
<span id="cb212-18"><a href="XGBoostalgorithm.html#cb212-18" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="inline-figure"><img src="71-MachineLearing_XGBoost_files/figure-html/unnamed-chunk-6-1.png" width="100%"></div>
</div>
<div id="data-partition-1" class="section level3" number="14.3.3">
<h3>
<span class="header-section-number">14.3.3</span> Data partition<a class="anchor" aria-label="anchor" href="#data-partition-1"><i class="fas fa-link"></i></a>
</h3>
<p>Creating train and test dataset under probability 0.7</p>
<div class="sourceCode" id="cb213"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb213-1"><a href="XGBoostalgorithm.html#cb213-1" tabindex="-1"></a>X <span class="op">=</span> data_remove</span>
<span id="cb213-2"><a href="XGBoostalgorithm.html#cb213-2" tabindex="-1"></a>Y <span class="op">=</span> dat_copy.diagnosis</span>
<span id="cb213-3"><a href="XGBoostalgorithm.html#cb213-3" tabindex="-1"></a></span>
<span id="cb213-4"><a href="XGBoostalgorithm.html#cb213-4" tabindex="-1"></a>x_train, x_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb213-5"><a href="XGBoostalgorithm.html#cb213-5" tabindex="-1"></a>    X,</span>
<span id="cb213-6"><a href="XGBoostalgorithm.html#cb213-6" tabindex="-1"></a>    Y,</span>
<span id="cb213-7"><a href="XGBoostalgorithm.html#cb213-7" tabindex="-1"></a>    test_size <span class="op">=</span> <span class="fl">0.30</span>,</span>
<span id="cb213-8"><a href="XGBoostalgorithm.html#cb213-8" tabindex="-1"></a>    random_state <span class="op">=</span> <span class="dv">123</span>)</span>
<span id="cb213-9"><a href="XGBoostalgorithm.html#cb213-9" tabindex="-1"></a></span>
<span id="cb213-10"><a href="XGBoostalgorithm.html#cb213-10" tabindex="-1"></a><span class="co"># Cleaning test sets to avoid future warning messages</span></span>
<span id="cb213-11"><a href="XGBoostalgorithm.html#cb213-11" tabindex="-1"></a>y_train <span class="op">=</span> y_train.values.ravel() </span>
<span id="cb213-12"><a href="XGBoostalgorithm.html#cb213-12" tabindex="-1"></a>y_test <span class="op">=</span> y_test.values.ravel() </span>
<span id="cb213-13"><a href="XGBoostalgorithm.html#cb213-13" tabindex="-1"></a></span>
<span id="cb213-14"><a href="XGBoostalgorithm.html#cb213-14" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"training dataset:"</span>, x_train.shape[<span class="dv">0</span>], <span class="st">"sampels;"</span>, x_train.shape[<span class="dv">1</span>], <span class="st">"features"</span>)</span>
<span id="cb213-15"><a href="XGBoostalgorithm.html#cb213-15" tabindex="-1"></a><span class="co">#&gt; training dataset: 398 sampels; 30 features</span></span>
<span id="cb213-16"><a href="XGBoostalgorithm.html#cb213-16" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"test dataset:"</span>, x_test.shape[<span class="dv">0</span>], <span class="st">"sampels;"</span>, x_test.shape[<span class="dv">1</span>], <span class="st">"features"</span>)</span>
<span id="cb213-17"><a href="XGBoostalgorithm.html#cb213-17" tabindex="-1"></a><span class="co">#&gt; test dataset: 171 sampels; 30 features</span></span></code></pre></div>
</div>
<div id="feature-selection-1" class="section level3" number="14.3.4">
<h3>
<span class="header-section-number">14.3.4</span> Feature selection<a class="anchor" aria-label="anchor" href="#feature-selection-1"><i class="fas fa-link"></i></a>
</h3>
<p>We use the <strong>importance of random forest</strong> to select features by <code>selectFromModel</code>, selecting thoese features which importance is greater than the mean importance of all features by default. The following parameters:</p>
<ul>
<li>
<strong>estimator</strong>: The base estimator from which the transformer is built</li>
<li>
<strong>threshold</strong>: The threshold value to use for feature selection (mean default)</li>
</ul>
<div class="sourceCode" id="cb214"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb214-1"><a href="XGBoostalgorithm.html#cb214-1" tabindex="-1"></a><span class="im">from</span> sklearn.feature_selection <span class="im">import</span> SelectFromModel</span>
<span id="cb214-2"><a href="XGBoostalgorithm.html#cb214-2" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb214-3"><a href="XGBoostalgorithm.html#cb214-3" tabindex="-1"></a></span>
<span id="cb214-4"><a href="XGBoostalgorithm.html#cb214-4" tabindex="-1"></a>sel <span class="op">=</span> SelectFromModel(estimator<span class="op">=</span>RandomForestClassifier(n_estimators <span class="op">=</span> <span class="dv">1000</span>),</span>
<span id="cb214-5"><a href="XGBoostalgorithm.html#cb214-5" tabindex="-1"></a>                      threshold<span class="op">=</span><span class="st">"mean"</span>)</span>
<span id="cb214-6"><a href="XGBoostalgorithm.html#cb214-6" tabindex="-1"></a>sel.fit(x_train, y_train)</span></code></pre></div>
<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style>
<div id="sk-container-id-2" class="sk-top-container">
<div class="sk-text-repr-fallback">
<pre>SelectFromModel(estimator=RandomForestClassifier(n_estimators=1000),
                threshold='mean')</pre>
<b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b>
</div>
<div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped">
<div class="sk-label-container"><div class="sk-label sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox"><label for="sk-estimator-id-2" class="sk-toggleable__label sk-toggleable__label-arrow">SelectFromModel</label><div class="sk-toggleable__content"><pre>SelectFromModel(estimator=RandomForestClassifier(n_estimators=1000),
                threshold='mean')</pre></div>
</div></div>
<div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item">
<div class="sk-label-container"><div class="sk-label sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox"><label for="sk-estimator-id-3" class="sk-toggleable__label sk-toggleable__label-arrow">estimator: RandomForestClassifier</label><div class="sk-toggleable__content"><pre>RandomForestClassifier(n_estimators=1000)</pre></div>
</div></div>
<div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-4" type="checkbox"><label for="sk-estimator-id-4" class="sk-toggleable__label sk-toggleable__label-arrow">RandomForestClassifier</label><div class="sk-toggleable__content"><pre>RandomForestClassifier(n_estimators=1000)</pre></div>
</div></div></div>
</div></div></div>
</div></div>
</div>
<div class="sourceCode" id="cb215"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb215-1"><a href="XGBoostalgorithm.html#cb215-1" tabindex="-1"></a></span>
<span id="cb215-2"><a href="XGBoostalgorithm.html#cb215-2" tabindex="-1"></a><span class="co"># estimator parameters</span></span>
<span id="cb215-3"><a href="XGBoostalgorithm.html#cb215-3" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"the parameters of estimator"</span>, sel.get_params())</span>
<span id="cb215-4"><a href="XGBoostalgorithm.html#cb215-4" tabindex="-1"></a><span class="co">#&gt; the parameters of estimator {'estimator__bootstrap': True, 'estimator__ccp_alpha': 0.0, 'estimator__class_weight': None, 'estimator__criterion': 'gini', 'estimator__max_depth': None, 'estimator__max_features': 'sqrt', 'estimator__max_leaf_nodes': None, 'estimator__max_samples': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__n_estimators': 1000, 'estimator__n_jobs': None, 'estimator__oob_score': False, 'estimator__random_state': None, 'estimator__verbose': 0, 'estimator__warm_start': False, 'estimator': RandomForestClassifier(n_estimators=1000), 'importance_getter': 'auto', 'max_features': None, 'norm_order': 1, 'prefit': False, 'threshold': 'mean'}</span></span>
<span id="cb215-5"><a href="XGBoostalgorithm.html#cb215-5" tabindex="-1"></a></span>
<span id="cb215-6"><a href="XGBoostalgorithm.html#cb215-6" tabindex="-1"></a><span class="co"># selected features</span></span>
<span id="cb215-7"><a href="XGBoostalgorithm.html#cb215-7" tabindex="-1"></a>selected_features <span class="op">=</span> x_train.columns[(sel.get_support())]</span>
<span id="cb215-8"><a href="XGBoostalgorithm.html#cb215-8" tabindex="-1"></a>x_train_select <span class="op">=</span> x_train[selected_features]</span>
<span id="cb215-9"><a href="XGBoostalgorithm.html#cb215-9" tabindex="-1"></a></span>
<span id="cb215-10"><a href="XGBoostalgorithm.html#cb215-10" tabindex="-1"></a></span>
<span id="cb215-11"><a href="XGBoostalgorithm.html#cb215-11" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"training dataset:"</span>, x_train_select.shape[<span class="dv">0</span>], <span class="st">"sampels;"</span>, x_train_select.shape[<span class="dv">1</span>], <span class="st">"features"</span>)</span>
<span id="cb215-12"><a href="XGBoostalgorithm.html#cb215-12" tabindex="-1"></a><span class="co">#&gt; training dataset: 398 sampels; 8 features</span></span></code></pre></div>
<ul>
<li>Remained features</li>
</ul>
<div class="sourceCode" id="cb216"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb216-1"><a href="XGBoostalgorithm.html#cb216-1" tabindex="-1"></a>x_train_select <span class="op">=</span> x_train[selected_features]</span>
<span id="cb216-2"><a href="XGBoostalgorithm.html#cb216-2" tabindex="-1"></a>x_test_select <span class="op">=</span> x_test[selected_features]</span>
<span id="cb216-3"><a href="XGBoostalgorithm.html#cb216-3" tabindex="-1"></a></span>
<span id="cb216-4"><a href="XGBoostalgorithm.html#cb216-4" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"training dataset:"</span>, x_train_select.shape[<span class="dv">0</span>], <span class="st">"sampels;"</span>, x_train_select.shape[<span class="dv">1</span>], <span class="st">"features"</span>)</span>
<span id="cb216-5"><a href="XGBoostalgorithm.html#cb216-5" tabindex="-1"></a><span class="co">#&gt; training dataset: 398 sampels; 8 features</span></span>
<span id="cb216-6"><a href="XGBoostalgorithm.html#cb216-6" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"test dataset:"</span>, x_test_select.shape[<span class="dv">0</span>], <span class="st">"sampels;"</span>, x_test_select.shape[<span class="dv">1</span>], <span class="st">"features"</span>)</span>
<span id="cb216-7"><a href="XGBoostalgorithm.html#cb216-7" tabindex="-1"></a><span class="co">#&gt; test dataset: 171 sampels; 8 features</span></span></code></pre></div>
</div>
<div id="base-model" class="section level3" number="14.3.5">
<h3>
<span class="header-section-number">14.3.5</span> Base model<a class="anchor" aria-label="anchor" href="#base-model"><i class="fas fa-link"></i></a>
</h3>
<p>base model for feature importance and AUC, Confusion Matrix</p>
<div class="sourceCode" id="cb217"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb217-1"><a href="XGBoostalgorithm.html#cb217-1" tabindex="-1"></a>base_fit <span class="op">=</span> xgb.XGBClassifier(</span>
<span id="cb217-2"><a href="XGBoostalgorithm.html#cb217-2" tabindex="-1"></a>    objective<span class="op">=</span><span class="st">'binary:logistic'</span>,</span>
<span id="cb217-3"><a href="XGBoostalgorithm.html#cb217-3" tabindex="-1"></a>    booster<span class="op">=</span><span class="st">'gbtree'</span>,</span>
<span id="cb217-4"><a href="XGBoostalgorithm.html#cb217-4" tabindex="-1"></a>    eval_metric<span class="op">=</span><span class="st">'auc'</span>,</span>
<span id="cb217-5"><a href="XGBoostalgorithm.html#cb217-5" tabindex="-1"></a>    tree_method<span class="op">=</span><span class="st">'hist'</span>,</span>
<span id="cb217-6"><a href="XGBoostalgorithm.html#cb217-6" tabindex="-1"></a>    grow_policy<span class="op">=</span><span class="st">'lossguide'</span>,</span>
<span id="cb217-7"><a href="XGBoostalgorithm.html#cb217-7" tabindex="-1"></a>    use_label_encoder<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb217-8"><a href="XGBoostalgorithm.html#cb217-8" tabindex="-1"></a></span>
<span id="cb217-9"><a href="XGBoostalgorithm.html#cb217-9" tabindex="-1"></a></span>
<span id="cb217-10"><a href="XGBoostalgorithm.html#cb217-10" tabindex="-1"></a>base_fit.fit(x_train_select, y_train)</span></code></pre></div>
<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style>
<div id="sk-container-id-3" class="sk-top-container">
<div class="sk-text-repr-fallback">
<pre>XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric='auc', feature_types=None,
              gamma=None, gpu_id=None, grow_policy='lossguide',
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, n_estimators=100, n_jobs=None,
              num_parallel_tree=None, predictor=None, random_state=None, ...)</pre>
<b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b>
</div>
<div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-5" type="checkbox" checked><label for="sk-estimator-id-5" class="sk-toggleable__label sk-toggleable__label-arrow">XGBClassifier</label><div class="sk-toggleable__content"><pre>XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric='auc', feature_types=None,
              gamma=None, gpu_id=None, grow_policy='lossguide',
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, n_estimators=100, n_jobs=None,
              num_parallel_tree=None, predictor=None, random_state=None, ...)</pre></div>
</div></div></div>
</div>
<div class="sourceCode" id="cb218"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb218-1"><a href="XGBoostalgorithm.html#cb218-1" tabindex="-1"></a></span>
<span id="cb218-2"><a href="XGBoostalgorithm.html#cb218-2" tabindex="-1"></a>y_pred <span class="op">=</span> base_fit.predict(x_test_select)</span>
<span id="cb218-3"><a href="XGBoostalgorithm.html#cb218-3" tabindex="-1"></a>accuracy <span class="op">=</span> accuracy_score(y_test, y_pred)</span>
<span id="cb218-4"><a href="XGBoostalgorithm.html#cb218-4" tabindex="-1"></a></span>
<span id="cb218-5"><a href="XGBoostalgorithm.html#cb218-5" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Accuracy of base XBGoost model: </span><span class="sc">{:.2f}</span><span class="st">"</span>.<span class="bu">format</span>(accuracy))</span>
<span id="cb218-6"><a href="XGBoostalgorithm.html#cb218-6" tabindex="-1"></a><span class="co">#&gt; Accuracy of base XBGoost model: 0.96</span></span></code></pre></div>
</div>
<div id="k-cross-validataion-for-n_estimators" class="section level3" number="14.3.6">
<h3>
<span class="header-section-number">14.3.6</span> K cross validataion for n_estimators<a class="anchor" aria-label="anchor" href="#k-cross-validataion-for-n_estimators"><i class="fas fa-link"></i></a>
</h3>
<p>The relationship between loss and number of tree</p>
<div class="sourceCode" id="cb219"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb219-1"><a href="XGBoostalgorithm.html#cb219-1" tabindex="-1"></a><span class="kw">def</span> estimate_num_trees(X, y):</span>
<span id="cb219-2"><a href="XGBoostalgorithm.html#cb219-2" tabindex="-1"></a>    num_trees <span class="op">=</span> <span class="bu">range</span>(<span class="dv">10</span>, <span class="dv">200</span>, <span class="dv">10</span>)</span>
<span id="cb219-3"><a href="XGBoostalgorithm.html#cb219-3" tabindex="-1"></a>    cv_errors <span class="op">=</span> []</span>
<span id="cb219-4"><a href="XGBoostalgorithm.html#cb219-4" tabindex="-1"></a></span>
<span id="cb219-5"><a href="XGBoostalgorithm.html#cb219-5" tabindex="-1"></a>    <span class="cf">for</span> n <span class="kw">in</span> num_trees:</span>
<span id="cb219-6"><a href="XGBoostalgorithm.html#cb219-6" tabindex="-1"></a>        xgb_classifier <span class="op">=</span> xgb.XGBClassifier(n_estimators<span class="op">=</span>n, objective<span class="op">=</span><span class="st">'binary:logistic'</span>, eval_metric<span class="op">=</span><span class="st">'logloss'</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb219-7"><a href="XGBoostalgorithm.html#cb219-7" tabindex="-1"></a>        cv_scores <span class="op">=</span> cross_val_score(xgb_classifier, X, y, cv<span class="op">=</span><span class="dv">5</span>, scoring<span class="op">=</span><span class="st">'neg_log_loss'</span>)</span>
<span id="cb219-8"><a href="XGBoostalgorithm.html#cb219-8" tabindex="-1"></a>        cv_errors.append(<span class="op">-</span>np.mean(cv_scores))</span>
<span id="cb219-9"><a href="XGBoostalgorithm.html#cb219-9" tabindex="-1"></a></span>
<span id="cb219-10"><a href="XGBoostalgorithm.html#cb219-10" tabindex="-1"></a>    <span class="cf">return</span> num_trees, cv_errors</span>
<span id="cb219-11"><a href="XGBoostalgorithm.html#cb219-11" tabindex="-1"></a></span>
<span id="cb219-12"><a href="XGBoostalgorithm.html#cb219-12" tabindex="-1"></a><span class="kw">def</span> plot_error_vs_trees(num_trees, cv_errors):</span>
<span id="cb219-13"><a href="XGBoostalgorithm.html#cb219-13" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb219-14"><a href="XGBoostalgorithm.html#cb219-14" tabindex="-1"></a>    plt.plot(num_trees, cv_errors, marker<span class="op">=</span><span class="st">'o'</span>, linestyle<span class="op">=</span><span class="st">'-'</span>)</span>
<span id="cb219-15"><a href="XGBoostalgorithm.html#cb219-15" tabindex="-1"></a>    plt.xlabel(<span class="st">'No. of estimators'</span>)</span>
<span id="cb219-16"><a href="XGBoostalgorithm.html#cb219-16" tabindex="-1"></a>    plt.ylabel(<span class="st">'Loss'</span>)</span>
<span id="cb219-17"><a href="XGBoostalgorithm.html#cb219-17" tabindex="-1"></a>    plt.grid(<span class="va">True</span>)</span>
<span id="cb219-18"><a href="XGBoostalgorithm.html#cb219-18" tabindex="-1"></a>    plt.show()</span>
<span id="cb219-19"><a href="XGBoostalgorithm.html#cb219-19" tabindex="-1"></a></span>
<span id="cb219-20"><a href="XGBoostalgorithm.html#cb219-20" tabindex="-1"></a>num_trees, cv_errors <span class="op">=</span> estimate_num_trees(x_train_select, y_train)</span>
<span id="cb219-21"><a href="XGBoostalgorithm.html#cb219-21" tabindex="-1"></a>plot_error_vs_trees(num_trees, cv_errors)</span></code></pre></div>
<div class="inline-figure"><img src="71-MachineLearing_XGBoost_files/figure-html/unnamed-chunk-11-3.png" width="100%"></div>
</div>
<div id="tuning-parameters" class="section level3" number="14.3.7">
<h3>
<span class="header-section-number">14.3.7</span> Tuning parameters<a class="anchor" aria-label="anchor" href="#tuning-parameters"><i class="fas fa-link"></i></a>
</h3>
<blockquote>
<p>Before executing grid search algorithms, a benchmark model has to be fitted. By calling the fit() method, default parameters are obtained and stored for later use. Since GridSearchCV take inputs in lists, single parameter values also have to be wrapped. By calling fit() on the GridSearchCV instance, the cross-validation is performed, results are extracted, scores are computed and stored in a dictionary.</p>
</blockquote>
<p>It takes much time to iterate over the whole parameter grid, so setting the verbosity to 1 help to monitor the process. However, wall time does not equal the printed fitting time, hence the loop cycle time is also tracked and printed.</p>
<ul>
<li>
<strong>learning_rate/eta</strong>: Step size shrinkage used in update to prevents overfitting. After each boosting step, we can directly get the weights of new features(typical values: 0.01-0.2).</li>
<li>
<strong>max_depth</strong>: Maximum depth of a tree. Increasing this value will make the model more complex and more likely to overfit (typical values: 1-10).</li>
<li><del><strong>n_estimators</strong>: The number of decision tree.</del></li>
<li>
<strong>colsample_bytree</strong>: fraction of the features that can be used to train each tree. A large value means almost all features can be used to build the decision tree (typical values: 0.5-0.9).</li>
<li>
<strong>min_child_weight</strong>: It defines the minimum sum of weights of all observations required in a child. The larger min_child_weight is, the more conservative the algorithm will be.</li>
<li>
<strong>gamma</strong>: Minimum loss reduction required to make a further partition on a leaf node of the tree (typical values: 0-0.5).</li>
<li>
<strong>alpha/reg_alpha</strong>: L1 regularization term on weights. Increasing this value will make model more conservative (typical values: 0-1).</li>
<li>
<strong>lambda/reg_lambda</strong>: L2 regularization term on weights. Increasing this value will make model more conservative (typical values: 0-1).</li>
</ul>
<div class="sourceCode" id="cb220"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb220-1"><a href="XGBoostalgorithm.html#cb220-1" tabindex="-1"></a><span class="co">#extracting default parameters from benchmark model</span></span>
<span id="cb220-2"><a href="XGBoostalgorithm.html#cb220-2" tabindex="-1"></a>default_params <span class="op">=</span> {}</span>
<span id="cb220-3"><a href="XGBoostalgorithm.html#cb220-3" tabindex="-1"></a>gparams <span class="op">=</span> base_fit.get_params()</span>
<span id="cb220-4"><a href="XGBoostalgorithm.html#cb220-4" tabindex="-1"></a></span>
<span id="cb220-5"><a href="XGBoostalgorithm.html#cb220-5" tabindex="-1"></a><span class="co">#default parameters have to be wrapped in lists - even single values - so GridSearchCV can take them as inputs</span></span>
<span id="cb220-6"><a href="XGBoostalgorithm.html#cb220-6" tabindex="-1"></a><span class="cf">for</span> key <span class="kw">in</span> gparams.keys():</span>
<span id="cb220-7"><a href="XGBoostalgorithm.html#cb220-7" tabindex="-1"></a>    gp <span class="op">=</span> gparams[key]</span>
<span id="cb220-8"><a href="XGBoostalgorithm.html#cb220-8" tabindex="-1"></a>    default_params[key] <span class="op">=</span> [gp]</span>
<span id="cb220-9"><a href="XGBoostalgorithm.html#cb220-9" tabindex="-1"></a></span>
<span id="cb220-10"><a href="XGBoostalgorithm.html#cb220-10" tabindex="-1"></a><span class="co">#benchmark model. Grid search is not performed, since only single values are provided as parameter grid.</span></span>
<span id="cb220-11"><a href="XGBoostalgorithm.html#cb220-11" tabindex="-1"></a><span class="co">#However, cross-validation is still executed</span></span>
<span id="cb220-12"><a href="XGBoostalgorithm.html#cb220-12" tabindex="-1"></a>clf0 <span class="op">=</span> GridSearchCV(estimator<span class="op">=</span>base_fit, </span>
<span id="cb220-13"><a href="XGBoostalgorithm.html#cb220-13" tabindex="-1"></a>                    scoring<span class="op">=</span><span class="st">'accuracy'</span>, </span>
<span id="cb220-14"><a href="XGBoostalgorithm.html#cb220-14" tabindex="-1"></a>                    param_grid<span class="op">=</span>default_params, </span>
<span id="cb220-15"><a href="XGBoostalgorithm.html#cb220-15" tabindex="-1"></a>                    return_train_score<span class="op">=</span><span class="va">True</span>, </span>
<span id="cb220-16"><a href="XGBoostalgorithm.html#cb220-16" tabindex="-1"></a>                    verbose<span class="op">=</span><span class="dv">1</span>, </span>
<span id="cb220-17"><a href="XGBoostalgorithm.html#cb220-17" tabindex="-1"></a>                    cv<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb220-18"><a href="XGBoostalgorithm.html#cb220-18" tabindex="-1"></a>clf0.fit(x_train_select, y_train)</span></code></pre></div>
<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style>
<div id="sk-container-id-4" class="sk-top-container">
<div class="sk-text-repr-fallback">
<pre>GridSearchCV(cv=3,
             estimator=XGBClassifier(base_score=None, booster='gbtree',
                                     callbacks=None, colsample_bylevel=None,
                                     colsample_bynode=None,
                                     colsample_bytree=None,
                                     early_stopping_rounds=None,
                                     enable_categorical=False,
                                     eval_metric='auc', feature_types=None,
                                     gamma=None, gpu_id=None,
                                     grow_policy='lossguide',
                                     importance_type=None,
                                     interaction_constraints=None,
                                     learnin...
                         'max_cat_threshold': [None],
                         'max_cat_to_onehot': [None], 'max_delta_step': [None],
                         'max_depth': [None], 'max_leaves': [None],
                         'min_child_weight': [None], 'missing': [nan],
                         'monotone_constraints': [None], 'n_estimators': [100],
                         'n_jobs': [None], 'num_parallel_tree': [None],
                         'objective': ['binary:logistic'], 'predictor': [None], ...},
             return_train_score=True, scoring='accuracy', verbose=1)</pre>
<b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b>
</div>
<div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped">
<div class="sk-label-container"><div class="sk-label sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-6" type="checkbox"><label for="sk-estimator-id-6" class="sk-toggleable__label sk-toggleable__label-arrow">GridSearchCV</label><div class="sk-toggleable__content"><pre>GridSearchCV(cv=3,
             estimator=XGBClassifier(base_score=None, booster='gbtree',
                                     callbacks=None, colsample_bylevel=None,
                                     colsample_bynode=None,
                                     colsample_bytree=None,
                                     early_stopping_rounds=None,
                                     enable_categorical=False,
                                     eval_metric='auc', feature_types=None,
                                     gamma=None, gpu_id=None,
                                     grow_policy='lossguide',
                                     importance_type=None,
                                     interaction_constraints=None,
                                     learnin...
                         'max_cat_threshold': [None],
                         'max_cat_to_onehot': [None], 'max_delta_step': [None],
                         'max_depth': [None], 'max_leaves': [None],
                         'min_child_weight': [None], 'missing': [nan],
                         'monotone_constraints': [None], 'n_estimators': [100],
                         'n_jobs': [None], 'num_parallel_tree': [None],
                         'objective': ['binary:logistic'], 'predictor': [None], ...},
             return_train_score=True, scoring='accuracy', verbose=1)</pre></div>
</div></div>
<div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item">
<div class="sk-label-container"><div class="sk-label sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-7" type="checkbox"><label for="sk-estimator-id-7" class="sk-toggleable__label sk-toggleable__label-arrow">estimator: XGBClassifier</label><div class="sk-toggleable__content"><pre>XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric='auc', feature_types=None,
              gamma=None, gpu_id=None, grow_policy='lossguide',
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, n_estimators=100, n_jobs=None,
              num_parallel_tree=None, predictor=None, random_state=None, ...)</pre></div>
</div></div>
<div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-8" type="checkbox"><label for="sk-estimator-id-8" class="sk-toggleable__label sk-toggleable__label-arrow">XGBClassifier</label><div class="sk-toggleable__content"><pre>XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric='auc', feature_types=None,
              gamma=None, gpu_id=None, grow_policy='lossguide',
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, n_estimators=100, n_jobs=None,
              num_parallel_tree=None, predictor=None, random_state=None, ...)</pre></div>
</div></div></div>
</div></div></div>
</div></div>
</div>
<div class="sourceCode" id="cb221"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb221-1"><a href="XGBoostalgorithm.html#cb221-1" tabindex="-1"></a></span>
<span id="cb221-2"><a href="XGBoostalgorithm.html#cb221-2" tabindex="-1"></a><span class="co">#results dataframe</span></span>
<span id="cb221-3"><a href="XGBoostalgorithm.html#cb221-3" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(clf0.cv_results_)</span>
<span id="cb221-4"><a href="XGBoostalgorithm.html#cb221-4" tabindex="-1"></a></span>
<span id="cb221-5"><a href="XGBoostalgorithm.html#cb221-5" tabindex="-1"></a><span class="co">#predictions - inputs to confusion matrix</span></span>
<span id="cb221-6"><a href="XGBoostalgorithm.html#cb221-6" tabindex="-1"></a>test_predictions <span class="op">=</span> clf0.predict(x_test_select)</span>
<span id="cb221-7"><a href="XGBoostalgorithm.html#cb221-7" tabindex="-1"></a></span>
<span id="cb221-8"><a href="XGBoostalgorithm.html#cb221-8" tabindex="-1"></a><span class="co">#confusion matrices</span></span>
<span id="cb221-9"><a href="XGBoostalgorithm.html#cb221-9" tabindex="-1"></a>cfm_test <span class="op">=</span> confusion_matrix(y_test, test_predictions)</span>
<span id="cb221-10"><a href="XGBoostalgorithm.html#cb221-10" tabindex="-1"></a></span>
<span id="cb221-11"><a href="XGBoostalgorithm.html#cb221-11" tabindex="-1"></a><span class="co">#best parameters</span></span>
<span id="cb221-12"><a href="XGBoostalgorithm.html#cb221-12" tabindex="-1"></a>bp0 <span class="op">=</span> clf0.best_params_</span>
<span id="cb221-13"><a href="XGBoostalgorithm.html#cb221-13" tabindex="-1"></a></span>
<span id="cb221-14"><a href="XGBoostalgorithm.html#cb221-14" tabindex="-1"></a>df.head()</span>
<span id="cb221-15"><a href="XGBoostalgorithm.html#cb221-15" tabindex="-1"></a><span class="co">#&gt;    mean_fit_time  std_fit_time  ...  mean_train_score  std_train_score</span></span>
<span id="cb221-16"><a href="XGBoostalgorithm.html#cb221-16" tabindex="-1"></a><span class="co">#&gt; 0       0.023831      0.001426  ...          0.998742         0.001779</span></span>
<span id="cb221-17"><a href="XGBoostalgorithm.html#cb221-17" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb221-18"><a href="XGBoostalgorithm.html#cb221-18" tabindex="-1"></a><span class="co">#&gt; [1 rows x 56 columns]</span></span></code></pre></div>
<div class="sourceCode" id="cb222"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb222-1"><a href="XGBoostalgorithm.html#cb222-1" tabindex="-1"></a><span class="co"># tuning parameters</span></span>
<span id="cb222-2"><a href="XGBoostalgorithm.html#cb222-2" tabindex="-1"></a>param_grid <span class="op">=</span> {</span>
<span id="cb222-3"><a href="XGBoostalgorithm.html#cb222-3" tabindex="-1"></a>    <span class="st">'learning_rate'</span>: [<span class="fl">0.01</span>, <span class="fl">0.03</span>, <span class="fl">0.06</span>, <span class="fl">0.1</span>, <span class="fl">0.15</span>, <span class="fl">0.2</span>, <span class="fl">0.25</span>, <span class="fl">0.3</span>, <span class="fl">0.4</span>, <span class="fl">0.5</span>, <span class="fl">0.6</span>, <span class="fl">0.7</span>],</span>
<span id="cb222-4"><a href="XGBoostalgorithm.html#cb222-4" tabindex="-1"></a>    <span class="st">'max_depth'</span>: [x <span class="cf">for</span> x <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>, <span class="dv">15</span>, <span class="dv">1</span>)],</span>
<span id="cb222-5"><a href="XGBoostalgorithm.html#cb222-5" tabindex="-1"></a>    <span class="st">'n_estimators'</span>: [x <span class="cf">for</span> x <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>, <span class="dv">150</span>, <span class="dv">30</span>)],</span>
<span id="cb222-6"><a href="XGBoostalgorithm.html#cb222-6" tabindex="-1"></a>    <span class="st">'colsample_bytree'</span>: [np.<span class="bu">round</span>(x, <span class="dv">2</span>) <span class="cf">for</span> x <span class="kw">in</span> np.arange(<span class="fl">0.5</span>, <span class="dv">1</span>, <span class="fl">0.1</span>)],</span>
<span id="cb222-7"><a href="XGBoostalgorithm.html#cb222-7" tabindex="-1"></a>    <span class="st">'min_child_weight'</span>: [x <span class="cf">for</span> x <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="dv">11</span>, <span class="dv">1</span>)],    </span>
<span id="cb222-8"><a href="XGBoostalgorithm.html#cb222-8" tabindex="-1"></a>    <span class="st">'gamma'</span>: [<span class="dv">0</span>, <span class="fl">0.1</span> ,<span class="fl">0.2</span> ,<span class="fl">0.4</span>, <span class="fl">0.8</span>, <span class="fl">1.6</span>, <span class="fl">3.2</span>, <span class="fl">6.4</span>, <span class="fl">12.8</span>, <span class="fl">25.6</span>, <span class="fl">51.2</span>, <span class="fl">102.4</span>, <span class="dv">200</span>],          </span>
<span id="cb222-9"><a href="XGBoostalgorithm.html#cb222-9" tabindex="-1"></a>    <span class="st">'reg_alpha'</span>: [<span class="dv">0</span>, <span class="fl">0.1</span>, <span class="fl">0.2</span>, <span class="fl">0.4</span>, <span class="fl">0.8</span>, <span class="fl">1.6</span>, <span class="fl">3.2</span>, <span class="fl">6.4</span>, <span class="fl">12.8</span>, <span class="fl">25.6</span>, <span class="fl">51.2</span>, <span class="fl">102.4</span>, <span class="dv">200</span>],</span>
<span id="cb222-10"><a href="XGBoostalgorithm.html#cb222-10" tabindex="-1"></a>    <span class="st">'reg_lambda'</span>: [<span class="dv">0</span>, <span class="fl">0.1</span>, <span class="fl">0.2</span>, <span class="fl">0.4</span>, <span class="fl">0.8</span>, <span class="fl">1.6</span>, <span class="fl">3.2</span>, <span class="fl">6.4</span>, <span class="fl">12.8</span>, <span class="fl">25.6</span>, <span class="fl">51.2</span>, <span class="fl">102.4</span>, <span class="dv">200</span>]</span>
<span id="cb222-11"><a href="XGBoostalgorithm.html#cb222-11" tabindex="-1"></a>    }</span>
<span id="cb222-12"><a href="XGBoostalgorithm.html#cb222-12" tabindex="-1"></a>    </span>
<span id="cb222-13"><a href="XGBoostalgorithm.html#cb222-13" tabindex="-1"></a>param_grid</span>
<span id="cb222-14"><a href="XGBoostalgorithm.html#cb222-14" tabindex="-1"></a><span class="co">#&gt; {'learning_rate': [0.01, 0.03, 0.06, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5, 0.6, 0.7], 'max_depth': [5, 6, 7, 8, 9, 10, 11, 12, 13, 14], 'n_estimators': [10, 40, 70, 100, 130], 'colsample_bytree': [0.5, 0.6, 0.7, 0.8, 0.9], 'min_child_weight': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'gamma': [0, 0.1, 0.2, 0.4, 0.8, 1.6, 3.2, 6.4, 12.8, 25.6, 51.2, 102.4, 200], 'reg_alpha': [0, 0.1, 0.2, 0.4, 0.8, 1.6, 3.2, 6.4, 12.8, 25.6, 51.2, 102.4, 200], 'reg_lambda': [0, 0.1, 0.2, 0.4, 0.8, 1.6, 3.2, 6.4, 12.8, 25.6, 51.2, 102.4, 200]}</span></span></code></pre></div>
<ul>
<li>Grid search</li>
</ul>
<blockquote>
<p>“Grid search is a process that searches exhaustively through a manually specified subset of the hyperparameter space of the targeted algorithm…and evaluate(s) the cost function based on the generated hyperparameter sets”</p>
</blockquote>
<div class="sourceCode" id="cb223"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb223-1"><a href="XGBoostalgorithm.html#cb223-1" tabindex="-1"></a><span class="co">#creating deepcopy of default parameters before manipulations</span></span>
<span id="cb223-2"><a href="XGBoostalgorithm.html#cb223-2" tabindex="-1"></a>params <span class="op">=</span> deepcopy(default_params)</span>
<span id="cb223-3"><a href="XGBoostalgorithm.html#cb223-3" tabindex="-1"></a></span>
<span id="cb223-4"><a href="XGBoostalgorithm.html#cb223-4" tabindex="-1"></a><span class="co">#No. of jobs</span></span>
<span id="cb223-5"><a href="XGBoostalgorithm.html#cb223-5" tabindex="-1"></a>gcvj <span class="op">=</span> np.cumsum([<span class="bu">len</span>(x) <span class="cf">for</span> x <span class="kw">in</span> param_grid.values()])[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb223-6"><a href="XGBoostalgorithm.html#cb223-6" tabindex="-1"></a></span>
<span id="cb223-7"><a href="XGBoostalgorithm.html#cb223-7" tabindex="-1"></a><span class="co">#iteration loop. Each selected parameter iterated separately</span></span>
<span id="cb223-8"><a href="XGBoostalgorithm.html#cb223-8" tabindex="-1"></a><span class="cf">for</span> i, grid_key <span class="kw">in</span> <span class="bu">enumerate</span>(param_grid.keys()):</span>
<span id="cb223-9"><a href="XGBoostalgorithm.html#cb223-9" tabindex="-1"></a>    </span>
<span id="cb223-10"><a href="XGBoostalgorithm.html#cb223-10" tabindex="-1"></a>    <span class="bu">print</span>(i)</span>
<span id="cb223-11"><a href="XGBoostalgorithm.html#cb223-11" tabindex="-1"></a>    <span class="co">#variable for measuring iteration time</span></span>
<span id="cb223-12"><a href="XGBoostalgorithm.html#cb223-12" tabindex="-1"></a>    loop_start <span class="op">=</span> time.time()</span>
<span id="cb223-13"><a href="XGBoostalgorithm.html#cb223-13" tabindex="-1"></a>       </span>
<span id="cb223-14"><a href="XGBoostalgorithm.html#cb223-14" tabindex="-1"></a>    <span class="co">#creating param_grid argument for GridSearchCV:</span></span>
<span id="cb223-15"><a href="XGBoostalgorithm.html#cb223-15" tabindex="-1"></a>    <span class="co">#listing grid values of current iterable parameter and wrapping non-iterable parameter single values in list</span></span>
<span id="cb223-16"><a href="XGBoostalgorithm.html#cb223-16" tabindex="-1"></a>    <span class="cf">for</span> param_key <span class="kw">in</span> params.keys():</span>
<span id="cb223-17"><a href="XGBoostalgorithm.html#cb223-17" tabindex="-1"></a>        <span class="cf">if</span> param_key <span class="op">==</span> grid_key:</span>
<span id="cb223-18"><a href="XGBoostalgorithm.html#cb223-18" tabindex="-1"></a>            params[param_key] <span class="op">=</span> param_grid[grid_key]</span>
<span id="cb223-19"><a href="XGBoostalgorithm.html#cb223-19" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb223-20"><a href="XGBoostalgorithm.html#cb223-20" tabindex="-1"></a>            <span class="co"># use best parameters of last iteration</span></span>
<span id="cb223-21"><a href="XGBoostalgorithm.html#cb223-21" tabindex="-1"></a>            <span class="cf">try</span>:</span>
<span id="cb223-22"><a href="XGBoostalgorithm.html#cb223-22" tabindex="-1"></a>                param_value <span class="op">=</span> [clf.best_params_[param_key]]</span>
<span id="cb223-23"><a href="XGBoostalgorithm.html#cb223-23" tabindex="-1"></a>                params[param_key] <span class="op">=</span> param_value</span>
<span id="cb223-24"><a href="XGBoostalgorithm.html#cb223-24" tabindex="-1"></a>            <span class="co">#use benchmark model parameters for first iteration</span></span>
<span id="cb223-25"><a href="XGBoostalgorithm.html#cb223-25" tabindex="-1"></a>            <span class="cf">except</span>:</span>
<span id="cb223-26"><a href="XGBoostalgorithm.html#cb223-26" tabindex="-1"></a>                param_value <span class="op">=</span> [clf0.best_params_[param_key]]</span>
<span id="cb223-27"><a href="XGBoostalgorithm.html#cb223-27" tabindex="-1"></a>                params[param_key] <span class="op">=</span> param_value</span>
<span id="cb223-28"><a href="XGBoostalgorithm.html#cb223-28" tabindex="-1"></a>    </span>
<span id="cb223-29"><a href="XGBoostalgorithm.html#cb223-29" tabindex="-1"></a>    <span class="co">#classifier instance of current iteration</span></span>
<span id="cb223-30"><a href="XGBoostalgorithm.html#cb223-30" tabindex="-1"></a>    xgbc <span class="op">=</span> xgb.XGBClassifier(<span class="op">**</span>default_params)</span>
<span id="cb223-31"><a href="XGBoostalgorithm.html#cb223-31" tabindex="-1"></a>    </span>
<span id="cb223-32"><a href="XGBoostalgorithm.html#cb223-32" tabindex="-1"></a>    <span class="co">#GridSearch instance of current iteration</span></span>
<span id="cb223-33"><a href="XGBoostalgorithm.html#cb223-33" tabindex="-1"></a>    clf <span class="op">=</span> GridSearchCV(estimator<span class="op">=</span>xgbc, </span>
<span id="cb223-34"><a href="XGBoostalgorithm.html#cb223-34" tabindex="-1"></a>                    param_grid<span class="op">=</span>params,</span>
<span id="cb223-35"><a href="XGBoostalgorithm.html#cb223-35" tabindex="-1"></a>                    scoring<span class="op">=</span><span class="st">'accuracy'</span>, </span>
<span id="cb223-36"><a href="XGBoostalgorithm.html#cb223-36" tabindex="-1"></a>                    return_train_score<span class="op">=</span><span class="va">True</span>, </span>
<span id="cb223-37"><a href="XGBoostalgorithm.html#cb223-37" tabindex="-1"></a>                    verbose<span class="op">=</span><span class="dv">1</span>, </span>
<span id="cb223-38"><a href="XGBoostalgorithm.html#cb223-38" tabindex="-1"></a>                    cv<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb223-39"><a href="XGBoostalgorithm.html#cb223-39" tabindex="-1"></a>    clf.fit(x_train_select, y_train)</span>
<span id="cb223-40"><a href="XGBoostalgorithm.html#cb223-40" tabindex="-1"></a></span>
<span id="cb223-41"><a href="XGBoostalgorithm.html#cb223-41" tabindex="-1"></a>    <span class="co">#predictions - inputs to confusion matrix</span></span>
<span id="cb223-42"><a href="XGBoostalgorithm.html#cb223-42" tabindex="-1"></a>    train_predictions <span class="op">=</span> clf.predict(x_train_select)</span>
<span id="cb223-43"><a href="XGBoostalgorithm.html#cb223-43" tabindex="-1"></a>    test_predictions <span class="op">=</span> clf.predict(x_test_select)</span>
<span id="cb223-44"><a href="XGBoostalgorithm.html#cb223-44" tabindex="-1"></a>        </span>
<span id="cb223-45"><a href="XGBoostalgorithm.html#cb223-45" tabindex="-1"></a>    <span class="co">#confusion matrices</span></span>
<span id="cb223-46"><a href="XGBoostalgorithm.html#cb223-46" tabindex="-1"></a>    cfm_train <span class="op">=</span> confusion_matrix(y_train, train_predictions)</span>
<span id="cb223-47"><a href="XGBoostalgorithm.html#cb223-47" tabindex="-1"></a>    cfm_test <span class="op">=</span> confusion_matrix(y_test, test_predictions)</span>
<span id="cb223-48"><a href="XGBoostalgorithm.html#cb223-48" tabindex="-1"></a>    <span class="bu">print</span>(cfm_train)</span>
<span id="cb223-49"><a href="XGBoostalgorithm.html#cb223-49" tabindex="-1"></a>    <span class="bu">print</span>(cfm_test)</span>
<span id="cb223-50"><a href="XGBoostalgorithm.html#cb223-50" tabindex="-1"></a>    </span>
<span id="cb223-51"><a href="XGBoostalgorithm.html#cb223-51" tabindex="-1"></a>    <span class="co">#best parameters</span></span>
<span id="cb223-52"><a href="XGBoostalgorithm.html#cb223-52" tabindex="-1"></a>    bp_gs <span class="op">=</span> clf.best_params_</span></code></pre></div>
<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style>
<div id="sk-container-id-5" class="sk-top-container">
<div class="sk-text-repr-fallback">
<pre>GridSearchCV(cv=3,
             estimator=XGBClassifier(base_score=[None], booster=['gbtree'],
                                     callbacks=[None], colsample_bylevel=[None],
                                     colsample_bynode=[None],
                                     colsample_bytree=[None],
                                     early_stopping_rounds=[None],
                                     enable_categorical=[False],
                                     eval_metric=['auc'], feature_types=[None],
                                     gamma=[None], gpu_id=[None],
                                     grow_policy=['lossguide'],
                                     importance_type=[None],
                                     interact...
                         'max_cat_threshold': [None],
                         'max_cat_to_onehot': [None], 'max_delta_step': [None],
                         'max_depth': [5], 'max_leaves': [None],
                         'min_child_weight': [0], 'missing': [nan],
                         'monotone_constraints': [None], 'n_estimators': [70],
                         'n_jobs': [None], 'num_parallel_tree': [None],
                         'objective': ['binary:logistic'], 'predictor': [None], ...},
             return_train_score=True, scoring='accuracy', verbose=1)</pre>
<b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b>
</div>
<div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped">
<div class="sk-label-container"><div class="sk-label sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-9" type="checkbox"><label for="sk-estimator-id-9" class="sk-toggleable__label sk-toggleable__label-arrow">GridSearchCV</label><div class="sk-toggleable__content"><pre>GridSearchCV(cv=3,
             estimator=XGBClassifier(base_score=[None], booster=['gbtree'],
                                     callbacks=[None], colsample_bylevel=[None],
                                     colsample_bynode=[None],
                                     colsample_bytree=[None],
                                     early_stopping_rounds=[None],
                                     enable_categorical=[False],
                                     eval_metric=['auc'], feature_types=[None],
                                     gamma=[None], gpu_id=[None],
                                     grow_policy=['lossguide'],
                                     importance_type=[None],
                                     interact...
                         'max_cat_threshold': [None],
                         'max_cat_to_onehot': [None], 'max_delta_step': [None],
                         'max_depth': [5], 'max_leaves': [None],
                         'min_child_weight': [0], 'missing': [nan],
                         'monotone_constraints': [None], 'n_estimators': [70],
                         'n_jobs': [None], 'num_parallel_tree': [None],
                         'objective': ['binary:logistic'], 'predictor': [None], ...},
             return_train_score=True, scoring='accuracy', verbose=1)</pre></div>
</div></div>
<div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item">
<div class="sk-label-container"><div class="sk-label sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-10" type="checkbox"><label for="sk-estimator-id-10" class="sk-toggleable__label sk-toggleable__label-arrow">estimator: XGBClassifier</label><div class="sk-toggleable__content"><pre>XGBClassifier(base_score=[None], booster=['gbtree'], callbacks=[None],
              colsample_bylevel=[None], colsample_bynode=[None],
              colsample_bytree=[None], early_stopping_rounds=[None],
              enable_categorical=[False], eval_metric=['auc'],
              feature_types=[None], gamma=[None], gpu_id=[None],
              grow_policy=['lossguide'], importance_type=[None],
              interaction_constraints=[None], learning_rate=[None],
              max_bin=[None], max_cat_threshold=[None],
              max_cat_to_onehot=[None], max_delta_step=[None], max_depth=[None],
              max_leaves=[None], min_child_weight=[None], missing=[nan],
              monotone_constraints=[None], n_estimators=[100], n_jobs=[None],
              num_parallel_tree=[None], objective=['binary:logistic'],
              predictor=[None], ...)</pre></div>
</div></div>
<div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-11" type="checkbox"><label for="sk-estimator-id-11" class="sk-toggleable__label sk-toggleable__label-arrow">XGBClassifier</label><div class="sk-toggleable__content"><pre>XGBClassifier(base_score=[None], booster=['gbtree'], callbacks=[None],
              colsample_bylevel=[None], colsample_bynode=[None],
              colsample_bytree=[None], early_stopping_rounds=[None],
              enable_categorical=[False], eval_metric=['auc'],
              feature_types=[None], gamma=[None], gpu_id=[None],
              grow_policy=['lossguide'], importance_type=[None],
              interaction_constraints=[None], learning_rate=[None],
              max_bin=[None], max_cat_threshold=[None],
              max_cat_to_onehot=[None], max_delta_step=[None], max_depth=[None],
              max_leaves=[None], min_child_weight=[None], missing=[nan],
              monotone_constraints=[None], n_estimators=[100], n_jobs=[None],
              num_parallel_tree=[None], objective=['binary:logistic'],
              predictor=[None], ...)</pre></div>
</div></div></div>
</div></div></div>
</div></div>
</div>
<div class="sourceCode" id="cb224"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb224-1"><a href="XGBoostalgorithm.html#cb224-1" tabindex="-1"></a>bp_gs</span>
<span id="cb224-2"><a href="XGBoostalgorithm.html#cb224-2" tabindex="-1"></a><span class="co">#&gt; {'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.5, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'auc', 'feature_types': None, 'gamma': 0.1, 'gpu_id': None, 'grow_policy': 'lossguide', 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.03, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 5, 'max_leaves': None, 'min_child_weight': 0, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 70, 'n_jobs': None, 'num_parallel_tree': None, 'objective': 'binary:logistic', 'predictor': None, 'random_state': None, 'reg_alpha': 0, 'reg_lambda': 0.2, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': 'hist', 'use_label_encoder': False, 'validate_parameters': None, 'verbosity': None}</span></span></code></pre></div>
<ul>
<li>Randomized search</li>
</ul>
<blockquote>
<p>“Random search…selects a value for each hyperparameter independently using a probability distribution…and evaluate(s) the cost function based on the generated hyperparameter sets”</p>
</blockquote>
<div class="sourceCode" id="cb225"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb225-1"><a href="XGBoostalgorithm.html#cb225-1" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb225-2"><a href="XGBoostalgorithm.html#cb225-2" tabindex="-1"></a><span class="co">#No. of jobs</span></span>
<span id="cb225-3"><a href="XGBoostalgorithm.html#cb225-3" tabindex="-1"></a><span class="co">rcvj = gcvj</span></span>
<span id="cb225-4"><a href="XGBoostalgorithm.html#cb225-4" tabindex="-1"></a></span>
<span id="cb225-5"><a href="XGBoostalgorithm.html#cb225-5" tabindex="-1"></a><span class="co">#unwrapping list values of default parameters</span></span>
<span id="cb225-6"><a href="XGBoostalgorithm.html#cb225-6" tabindex="-1"></a><span class="co">default_params_xgb = {}</span></span>
<span id="cb225-7"><a href="XGBoostalgorithm.html#cb225-7" tabindex="-1"></a></span>
<span id="cb225-8"><a href="XGBoostalgorithm.html#cb225-8" tabindex="-1"></a><span class="co">for key in default_params.keys():</span></span>
<span id="cb225-9"><a href="XGBoostalgorithm.html#cb225-9" tabindex="-1"></a><span class="co">    default_params_xgb[key] = default_params[key][0]</span></span>
<span id="cb225-10"><a href="XGBoostalgorithm.html#cb225-10" tabindex="-1"></a></span>
<span id="cb225-11"><a href="XGBoostalgorithm.html#cb225-11" tabindex="-1"></a><span class="co">#providing default parameters to xgbc model, before randomized search cross-validation</span></span>
<span id="cb225-12"><a href="XGBoostalgorithm.html#cb225-12" tabindex="-1"></a><span class="co">xgbc = xgb.XGBClassifier(**default_params_xgb)</span></span>
<span id="cb225-13"><a href="XGBoostalgorithm.html#cb225-13" tabindex="-1"></a></span>
<span id="cb225-14"><a href="XGBoostalgorithm.html#cb225-14" tabindex="-1"></a><span class="co">#Executing Randomized Search</span></span>
<span id="cb225-15"><a href="XGBoostalgorithm.html#cb225-15" tabindex="-1"></a><span class="co">clf1 = RandomizedSearchCV(</span></span>
<span id="cb225-16"><a href="XGBoostalgorithm.html#cb225-16" tabindex="-1"></a><span class="co">    estimator=xgbc,</span></span>
<span id="cb225-17"><a href="XGBoostalgorithm.html#cb225-17" tabindex="-1"></a><span class="co">    param_distributions=param_grid, </span></span>
<span id="cb225-18"><a href="XGBoostalgorithm.html#cb225-18" tabindex="-1"></a><span class="co">    scoring='accuracy',</span></span>
<span id="cb225-19"><a href="XGBoostalgorithm.html#cb225-19" tabindex="-1"></a><span class="co">    return_train_score=True, </span></span>
<span id="cb225-20"><a href="XGBoostalgorithm.html#cb225-20" tabindex="-1"></a><span class="co">    verbose=1, </span></span>
<span id="cb225-21"><a href="XGBoostalgorithm.html#cb225-21" tabindex="-1"></a><span class="co">    cv=3, </span></span>
<span id="cb225-22"><a href="XGBoostalgorithm.html#cb225-22" tabindex="-1"></a><span class="co">    n_iter=rcvj)</span></span>
<span id="cb225-23"><a href="XGBoostalgorithm.html#cb225-23" tabindex="-1"></a><span class="co">clf1.fit(x_train_select, y_train)</span></span>
<span id="cb225-24"><a href="XGBoostalgorithm.html#cb225-24" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb225-25"><a href="XGBoostalgorithm.html#cb225-25" tabindex="-1"></a><span class="co">#results dataframe</span></span>
<span id="cb225-26"><a href="XGBoostalgorithm.html#cb225-26" tabindex="-1"></a><span class="co">df1 = pd.DataFrame(clf1.cv_results_)</span></span>
<span id="cb225-27"><a href="XGBoostalgorithm.html#cb225-27" tabindex="-1"></a></span>
<span id="cb225-28"><a href="XGBoostalgorithm.html#cb225-28" tabindex="-1"></a><span class="co">#predictions - inputs to confusion matrix</span></span>
<span id="cb225-29"><a href="XGBoostalgorithm.html#cb225-29" tabindex="-1"></a><span class="co">train_predictions = clf1.predict(x_train_select)</span></span>
<span id="cb225-30"><a href="XGBoostalgorithm.html#cb225-30" tabindex="-1"></a><span class="co">test_predictions = clf1.predict(x_test_select)</span></span>
<span id="cb225-31"><a href="XGBoostalgorithm.html#cb225-31" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb225-32"><a href="XGBoostalgorithm.html#cb225-32" tabindex="-1"></a><span class="co">#confusion matrices</span></span>
<span id="cb225-33"><a href="XGBoostalgorithm.html#cb225-33" tabindex="-1"></a><span class="co">cfm_train = confusion_matrix(y_train, train_predictions)</span></span>
<span id="cb225-34"><a href="XGBoostalgorithm.html#cb225-34" tabindex="-1"></a><span class="co">cfm_test = confusion_matrix(y_test, test_predictions)</span></span>
<span id="cb225-35"><a href="XGBoostalgorithm.html#cb225-35" tabindex="-1"></a><span class="co">print(cfm_train)</span></span>
<span id="cb225-36"><a href="XGBoostalgorithm.html#cb225-36" tabindex="-1"></a><span class="co">print(cfm_test)</span></span>
<span id="cb225-37"><a href="XGBoostalgorithm.html#cb225-37" tabindex="-1"></a></span>
<span id="cb225-38"><a href="XGBoostalgorithm.html#cb225-38" tabindex="-1"></a><span class="co">#accuracy scores</span></span>
<span id="cb225-39"><a href="XGBoostalgorithm.html#cb225-39" tabindex="-1"></a><span class="co">accs_train = accuracy_score(y_train, train_predictions)</span></span>
<span id="cb225-40"><a href="XGBoostalgorithm.html#cb225-40" tabindex="-1"></a><span class="co">accs_test = accuracy_score(y_test, test_predictions)</span></span>
<span id="cb225-41"><a href="XGBoostalgorithm.html#cb225-41" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb225-42"><a href="XGBoostalgorithm.html#cb225-42" tabindex="-1"></a><span class="co">#F1 scores for each train/test label</span></span>
<span id="cb225-43"><a href="XGBoostalgorithm.html#cb225-43" tabindex="-1"></a><span class="co">f1s_train_p1 = f1_score(y_train, train_predictions, pos_label=1)</span></span>
<span id="cb225-44"><a href="XGBoostalgorithm.html#cb225-44" tabindex="-1"></a><span class="co">f1s_train_p0 = f1_score(y_train, train_predictions, pos_label=0)</span></span>
<span id="cb225-45"><a href="XGBoostalgorithm.html#cb225-45" tabindex="-1"></a><span class="co">f1s_test_p1 = f1_score(y_test, test_predictions, pos_label=1)</span></span>
<span id="cb225-46"><a href="XGBoostalgorithm.html#cb225-46" tabindex="-1"></a><span class="co">f1s_test_p0 = f1_score(y_test, test_predictions, pos_label=0)</span></span>
<span id="cb225-47"><a href="XGBoostalgorithm.html#cb225-47" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb225-48"><a href="XGBoostalgorithm.html#cb225-48" tabindex="-1"></a><span class="co">#Area Under the Receiver Operating Characteristic Curve</span></span>
<span id="cb225-49"><a href="XGBoostalgorithm.html#cb225-49" tabindex="-1"></a><span class="co">test_ras = roc_auc_score(y_test, clf1.predict_proba(x_test_select)[:,1])</span></span>
<span id="cb225-50"><a href="XGBoostalgorithm.html#cb225-50" tabindex="-1"></a></span>
<span id="cb225-51"><a href="XGBoostalgorithm.html#cb225-51" tabindex="-1"></a><span class="co">#best parameters</span></span>
<span id="cb225-52"><a href="XGBoostalgorithm.html#cb225-52" tabindex="-1"></a><span class="co">bp_rs = clf1.best_params_</span></span>
<span id="cb225-53"><a href="XGBoostalgorithm.html#cb225-53" tabindex="-1"></a></span>
<span id="cb225-54"><a href="XGBoostalgorithm.html#cb225-54" tabindex="-1"></a><span class="co">bp_rs</span></span>
<span id="cb225-55"><a href="XGBoostalgorithm.html#cb225-55" tabindex="-1"></a></span>
<span id="cb225-56"><a href="XGBoostalgorithm.html#cb225-56" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb225-57"><a href="XGBoostalgorithm.html#cb225-57" tabindex="-1"></a><span class="co">#&gt; "\n#No. of jobs\nrcvj = gcvj\n\n#unwrapping list values of default parameters\ndefault_params_xgb = {}\n\nfor key in default_params.keys():\n    default_params_xgb[key] = default_params[key][0]\n\n#providing default parameters to xgbc model, before randomized search cross-validation\nxgbc = xgb.XGBClassifier(**default_params_xgb)\n\n#Executing Randomized Search\nclf1 = RandomizedSearchCV(\n    estimator=xgbc,\n    param_distributions=param_grid, \n    scoring='accuracy',\n    return_train_score=True, \n    verbose=1, \n    cv=3, \n    n_iter=rcvj)\nclf1.fit(x_train_select, y_train)\n    \n#results dataframe\ndf1 = pd.DataFrame(clf1.cv_results_)\n\n#predictions - inputs to confusion matrix\ntrain_predictions = clf1.predict(x_train_select)\ntest_predictions = clf1.predict(x_test_select)\n    \n#confusion matrices\ncfm_train = confusion_matrix(y_train, train_predictions)\ncfm_test = confusion_matrix(y_test, test_predictions)\nprint(cfm_train)\nprint(cfm_test)\n\n#accuracy scores\naccs_train = accuracy_score(y_train, train_predictions)\naccs_test = accuracy_score(y_test, test_predictions)\n    \n#F1 scores for each train/test label\nf1s_train_p1 = f1_score(y_train, train_predictions, pos_label=1)\nf1s_train_p0 = f1_score(y_train, train_predictions, pos_label=0)\nf1s_test_p1 = f1_score(y_test, test_predictions, pos_label=1)\nf1s_test_p0 = f1_score(y_test, test_predictions, pos_label=0)\n    \n#Area Under the Receiver Operating Characteristic Curve\ntest_ras = roc_auc_score(y_test, clf1.predict_proba(x_test_select)[:,1])\n\n#best parameters\nbp_rs = clf1.best_params_\n\nbp_rs\n\n"</span></span></code></pre></div>
<ul>
<li>Bayesian search</li>
</ul>
<blockquote>
<p>“…build a probability model of the objective function and use it to select the most promising hyperparameters to evaluate in the true objective function”</p>
</blockquote>
<div class="sourceCode" id="cb226"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb226-1"><a href="XGBoostalgorithm.html#cb226-1" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb226-2"><a href="XGBoostalgorithm.html#cb226-2" tabindex="-1"></a></span>
<span id="cb226-3"><a href="XGBoostalgorithm.html#cb226-3" tabindex="-1"></a><span class="co">#No. of jobs</span></span>
<span id="cb226-4"><a href="XGBoostalgorithm.html#cb226-4" tabindex="-1"></a><span class="co">bcvj = int(gcvj)</span></span>
<span id="cb226-5"><a href="XGBoostalgorithm.html#cb226-5" tabindex="-1"></a></span>
<span id="cb226-6"><a href="XGBoostalgorithm.html#cb226-6" tabindex="-1"></a><span class="co">#unwrapping list values of default parameters</span></span>
<span id="cb226-7"><a href="XGBoostalgorithm.html#cb226-7" tabindex="-1"></a><span class="co">default_params_xgb = {}</span></span>
<span id="cb226-8"><a href="XGBoostalgorithm.html#cb226-8" tabindex="-1"></a></span>
<span id="cb226-9"><a href="XGBoostalgorithm.html#cb226-9" tabindex="-1"></a><span class="co">for key in default_params.keys():</span></span>
<span id="cb226-10"><a href="XGBoostalgorithm.html#cb226-10" tabindex="-1"></a><span class="co">    default_params_xgb[key] = default_params[key][0]</span></span>
<span id="cb226-11"><a href="XGBoostalgorithm.html#cb226-11" tabindex="-1"></a></span>
<span id="cb226-12"><a href="XGBoostalgorithm.html#cb226-12" tabindex="-1"></a><span class="co">#providing default parameters to xgbc model, before randomized search cross-validation</span></span>
<span id="cb226-13"><a href="XGBoostalgorithm.html#cb226-13" tabindex="-1"></a><span class="co">xgbc = xgb.XGBClassifier(**default_params_xgb)</span></span>
<span id="cb226-14"><a href="XGBoostalgorithm.html#cb226-14" tabindex="-1"></a></span>
<span id="cb226-15"><a href="XGBoostalgorithm.html#cb226-15" tabindex="-1"></a><span class="co">clf2 = BayesSearchCV(</span></span>
<span id="cb226-16"><a href="XGBoostalgorithm.html#cb226-16" tabindex="-1"></a><span class="co">    estimator=xgbc, </span></span>
<span id="cb226-17"><a href="XGBoostalgorithm.html#cb226-17" tabindex="-1"></a><span class="co">    search_spaces=param_grid, </span></span>
<span id="cb226-18"><a href="XGBoostalgorithm.html#cb226-18" tabindex="-1"></a><span class="co">    n_iter=bcvj, </span></span>
<span id="cb226-19"><a href="XGBoostalgorithm.html#cb226-19" tabindex="-1"></a><span class="co">    scoring='accuracy', </span></span>
<span id="cb226-20"><a href="XGBoostalgorithm.html#cb226-20" tabindex="-1"></a><span class="co">    cv=3, </span></span>
<span id="cb226-21"><a href="XGBoostalgorithm.html#cb226-21" tabindex="-1"></a><span class="co">    return_train_score=True, </span></span>
<span id="cb226-22"><a href="XGBoostalgorithm.html#cb226-22" tabindex="-1"></a><span class="co">    verbose=3)</span></span>
<span id="cb226-23"><a href="XGBoostalgorithm.html#cb226-23" tabindex="-1"></a><span class="co">clf2.fit(x_train_select, y_train)</span></span>
<span id="cb226-24"><a href="XGBoostalgorithm.html#cb226-24" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb226-25"><a href="XGBoostalgorithm.html#cb226-25" tabindex="-1"></a><span class="co">#results dataframe</span></span>
<span id="cb226-26"><a href="XGBoostalgorithm.html#cb226-26" tabindex="-1"></a><span class="co">df2 = pd.DataFrame(clf2.cv_results_)</span></span>
<span id="cb226-27"><a href="XGBoostalgorithm.html#cb226-27" tabindex="-1"></a></span>
<span id="cb226-28"><a href="XGBoostalgorithm.html#cb226-28" tabindex="-1"></a><span class="co">#predictions - inputs to confusion matrix</span></span>
<span id="cb226-29"><a href="XGBoostalgorithm.html#cb226-29" tabindex="-1"></a><span class="co">train_predictions = clf2.predict(x_train_select)</span></span>
<span id="cb226-30"><a href="XGBoostalgorithm.html#cb226-30" tabindex="-1"></a><span class="co">test_predictions = clf2.predict(x_test_select)</span></span>
<span id="cb226-31"><a href="XGBoostalgorithm.html#cb226-31" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb226-32"><a href="XGBoostalgorithm.html#cb226-32" tabindex="-1"></a><span class="co">#confusion matrices</span></span>
<span id="cb226-33"><a href="XGBoostalgorithm.html#cb226-33" tabindex="-1"></a><span class="co">cfm_train = confusion_matrix(y_train, train_predictions)</span></span>
<span id="cb226-34"><a href="XGBoostalgorithm.html#cb226-34" tabindex="-1"></a><span class="co">cfm_test = confusion_matrix(y_test, test_predictions)</span></span>
<span id="cb226-35"><a href="XGBoostalgorithm.html#cb226-35" tabindex="-1"></a><span class="co">print(cfm_train)</span></span>
<span id="cb226-36"><a href="XGBoostalgorithm.html#cb226-36" tabindex="-1"></a><span class="co">print(cfm_test)</span></span>
<span id="cb226-37"><a href="XGBoostalgorithm.html#cb226-37" tabindex="-1"></a></span>
<span id="cb226-38"><a href="XGBoostalgorithm.html#cb226-38" tabindex="-1"></a></span>
<span id="cb226-39"><a href="XGBoostalgorithm.html#cb226-39" tabindex="-1"></a><span class="co">#accuracy scores</span></span>
<span id="cb226-40"><a href="XGBoostalgorithm.html#cb226-40" tabindex="-1"></a><span class="co">accs_train = accuracy_score(y_train, train_predictions)</span></span>
<span id="cb226-41"><a href="XGBoostalgorithm.html#cb226-41" tabindex="-1"></a><span class="co">accs_test = accuracy_score(y_test, test_predictions)</span></span>
<span id="cb226-42"><a href="XGBoostalgorithm.html#cb226-42" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb226-43"><a href="XGBoostalgorithm.html#cb226-43" tabindex="-1"></a><span class="co">#F1 scores for each train/test label</span></span>
<span id="cb226-44"><a href="XGBoostalgorithm.html#cb226-44" tabindex="-1"></a><span class="co">f1s_train_p1 = f1_score(y_train, train_predictions, pos_label=1)</span></span>
<span id="cb226-45"><a href="XGBoostalgorithm.html#cb226-45" tabindex="-1"></a><span class="co">f1s_train_p0 = f1_score(y_train, train_predictions, pos_label=0)</span></span>
<span id="cb226-46"><a href="XGBoostalgorithm.html#cb226-46" tabindex="-1"></a><span class="co">f1s_test_p1 = f1_score(y_test, test_predictions, pos_label=1)</span></span>
<span id="cb226-47"><a href="XGBoostalgorithm.html#cb226-47" tabindex="-1"></a><span class="co">f1s_test_p0 = f1_score(y_test, test_predictions, pos_label=0)</span></span>
<span id="cb226-48"><a href="XGBoostalgorithm.html#cb226-48" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb226-49"><a href="XGBoostalgorithm.html#cb226-49" tabindex="-1"></a><span class="co">#Area Under the Receiver Operating Characteristic Curve</span></span>
<span id="cb226-50"><a href="XGBoostalgorithm.html#cb226-50" tabindex="-1"></a><span class="co">test_ras = roc_auc_score(y_test, clf2.predict_proba(x_test_select)[:,1])</span></span>
<span id="cb226-51"><a href="XGBoostalgorithm.html#cb226-51" tabindex="-1"></a></span>
<span id="cb226-52"><a href="XGBoostalgorithm.html#cb226-52" tabindex="-1"></a></span>
<span id="cb226-53"><a href="XGBoostalgorithm.html#cb226-53" tabindex="-1"></a><span class="co">#best parameters</span></span>
<span id="cb226-54"><a href="XGBoostalgorithm.html#cb226-54" tabindex="-1"></a><span class="co">bp_bs = clf2.best_params_</span></span>
<span id="cb226-55"><a href="XGBoostalgorithm.html#cb226-55" tabindex="-1"></a></span>
<span id="cb226-56"><a href="XGBoostalgorithm.html#cb226-56" tabindex="-1"></a><span class="co">bp_bs</span></span>
<span id="cb226-57"><a href="XGBoostalgorithm.html#cb226-57" tabindex="-1"></a></span>
<span id="cb226-58"><a href="XGBoostalgorithm.html#cb226-58" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb226-59"><a href="XGBoostalgorithm.html#cb226-59" tabindex="-1"></a><span class="co">#&gt; "\n\n#No. of jobs\nbcvj = int(gcvj)\n\n#unwrapping list values of default parameters\ndefault_params_xgb = {}\n\nfor key in default_params.keys():\n    default_params_xgb[key] = default_params[key][0]\n\n#providing default parameters to xgbc model, before randomized search cross-validation\nxgbc = xgb.XGBClassifier(**default_params_xgb)\n\nclf2 = BayesSearchCV(\n    estimator=xgbc, \n    search_spaces=param_grid, \n    n_iter=bcvj, \n    scoring='accuracy', \n    cv=3, \n    return_train_score=True, \n    verbose=3)\nclf2.fit(x_train_select, y_train)\n    \n#results dataframe\ndf2 = pd.DataFrame(clf2.cv_results_)\n\n#predictions - inputs to confusion matrix\ntrain_predictions = clf2.predict(x_train_select)\ntest_predictions = clf2.predict(x_test_select)\n    \n#confusion matrices\ncfm_train = confusion_matrix(y_train, train_predictions)\ncfm_test = confusion_matrix(y_test, test_predictions)\nprint(cfm_train)\nprint(cfm_test)\n\n\n#accuracy scores\naccs_train = accuracy_score(y_train, train_predictions)\naccs_test = accuracy_score(y_test, test_predictions)\n    \n#F1 scores for each train/test label\nf1s_train_p1 = f1_score(y_train, train_predictions, pos_label=1)\nf1s_train_p0 = f1_score(y_train, train_predictions, pos_label=0)\nf1s_test_p1 = f1_score(y_test, test_predictions, pos_label=1)\nf1s_test_p0 = f1_score(y_test, test_predictions, pos_label=0)\n    \n#Area Under the Receiver Operating Characteristic Curve\ntest_ras = roc_auc_score(y_test, clf2.predict_proba(x_test_select)[:,1])\n\n\n#best parameters\nbp_bs = clf2.best_params_\n\nbp_bs\n\n"</span></span></code></pre></div>
</div>
<div id="build-final-classifier" class="section level3" number="14.3.8">
<h3>
<span class="header-section-number">14.3.8</span> Build final classifier<a class="anchor" aria-label="anchor" href="#build-final-classifier"><i class="fas fa-link"></i></a>
</h3>
<p>The optimal parameters to build classifier</p>
<div class="sourceCode" id="cb227"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb227-1"><a href="XGBoostalgorithm.html#cb227-1" tabindex="-1"></a>final_params <span class="op">=</span> bp_gs</span>
<span id="cb227-2"><a href="XGBoostalgorithm.html#cb227-2" tabindex="-1"></a><span class="co">#final_params = bp_rs</span></span>
<span id="cb227-3"><a href="XGBoostalgorithm.html#cb227-3" tabindex="-1"></a><span class="co">#final_params = bp_bs</span></span>
<span id="cb227-4"><a href="XGBoostalgorithm.html#cb227-4" tabindex="-1"></a></span>
<span id="cb227-5"><a href="XGBoostalgorithm.html#cb227-5" tabindex="-1"></a>xgb_final <span class="op">=</span> xgb.XGBClassifier(<span class="op">**</span>final_params)</span>
<span id="cb227-6"><a href="XGBoostalgorithm.html#cb227-6" tabindex="-1"></a></span>
<span id="cb227-7"><a href="XGBoostalgorithm.html#cb227-7" tabindex="-1"></a>xgb_final.fit(x_train_select, y_train)</span></code></pre></div>
<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style>
<div id="sk-container-id-6" class="sk-top-container">
<div class="sk-text-repr-fallback">
<pre>XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.5, early_stopping_rounds=None,
              enable_categorical=False, eval_metric='auc', feature_types=None,
              gamma=0.1, gpu_id=None, grow_policy='lossguide',
              importance_type=None, interaction_constraints=None,
              learning_rate=0.03, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,
              max_leaves=None, min_child_weight=0, missing=nan,
              monotone_constraints=None, n_estimators=70, n_jobs=None,
              num_parallel_tree=None, predictor=None, random_state=None, ...)</pre>
<b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b>
</div>
<div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-12" type="checkbox" checked><label for="sk-estimator-id-12" class="sk-toggleable__label sk-toggleable__label-arrow">XGBClassifier</label><div class="sk-toggleable__content"><pre>XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.5, early_stopping_rounds=None,
              enable_categorical=False, eval_metric='auc', feature_types=None,
              gamma=0.1, gpu_id=None, grow_policy='lossguide',
              importance_type=None, interaction_constraints=None,
              learning_rate=0.03, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,
              max_leaves=None, min_child_weight=0, missing=nan,
              monotone_constraints=None, n_estimators=70, n_jobs=None,
              num_parallel_tree=None, predictor=None, random_state=None, ...)</pre></div>
</div></div></div>
</div>
<div class="sourceCode" id="cb228"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb228-1"><a href="XGBoostalgorithm.html#cb228-1" tabindex="-1"></a></span>
<span id="cb228-2"><a href="XGBoostalgorithm.html#cb228-2" tabindex="-1"></a>classifier_score <span class="op">=</span> xgb_final.score(x_train_select, y_train)</span>
<span id="cb228-3"><a href="XGBoostalgorithm.html#cb228-3" tabindex="-1"></a></span>
<span id="cb228-4"><a href="XGBoostalgorithm.html#cb228-4" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'</span><span class="ch">\n</span><span class="st">The classifier accuracy score is </span><span class="sc">{:03.2f}</span><span class="ch">\n</span><span class="st">'</span>.<span class="bu">format</span>(classifier_score))</span>
<span id="cb228-5"><a href="XGBoostalgorithm.html#cb228-5" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb228-6"><a href="XGBoostalgorithm.html#cb228-6" tabindex="-1"></a><span class="co">#&gt; The classifier accuracy score is 1.00</span></span></code></pre></div>
</div>
<div id="evaluating-model-performance" class="section level3" number="14.3.9">
<h3>
<span class="header-section-number">14.3.9</span> Evaluating model performance<a class="anchor" aria-label="anchor" href="#evaluating-model-performance"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>confusion matrix to display the performance</li>
</ul>
<div class="sourceCode" id="cb229"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb229-1"><a href="XGBoostalgorithm.html#cb229-1" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb229-2"><a href="XGBoostalgorithm.html#cb229-2" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> Image, display</span>
<span id="cb229-3"><a href="XGBoostalgorithm.html#cb229-3" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> metrics, preprocessing</span>
<span id="cb229-4"><a href="XGBoostalgorithm.html#cb229-4" tabindex="-1"></a></span>
<span id="cb229-5"><a href="XGBoostalgorithm.html#cb229-5" tabindex="-1"></a>predicted <span class="op">=</span> xgb_final.predict(x_test_select)</span>
<span id="cb229-6"><a href="XGBoostalgorithm.html#cb229-6" tabindex="-1"></a>accuracy <span class="op">=</span> accuracy_score(y_test, predicted)</span>
<span id="cb229-7"><a href="XGBoostalgorithm.html#cb229-7" tabindex="-1"></a></span>
<span id="cb229-8"><a href="XGBoostalgorithm.html#cb229-8" tabindex="-1"></a>cm <span class="op">=</span> metrics.confusion_matrix(y_test, predicted)</span>
<span id="cb229-9"><a href="XGBoostalgorithm.html#cb229-9" tabindex="-1"></a></span>
<span id="cb229-10"><a href="XGBoostalgorithm.html#cb229-10" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">3</span>))</span>
<span id="cb229-11"><a href="XGBoostalgorithm.html#cb229-11" tabindex="-1"></a>ax.matshow(cm, cmap<span class="op">=</span>plt.cm.Reds, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb229-12"><a href="XGBoostalgorithm.html#cb229-12" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(cm.shape[<span class="dv">0</span>]):</span>
<span id="cb229-13"><a href="XGBoostalgorithm.html#cb229-13" tabindex="-1"></a>     <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(cm.shape[<span class="dv">1</span>]):</span>
<span id="cb229-14"><a href="XGBoostalgorithm.html#cb229-14" tabindex="-1"></a>         ax.text(x<span class="op">=</span>j, y<span class="op">=</span>i,</span>
<span id="cb229-15"><a href="XGBoostalgorithm.html#cb229-15" tabindex="-1"></a>                s<span class="op">=</span>cm[i, j], </span>
<span id="cb229-16"><a href="XGBoostalgorithm.html#cb229-16" tabindex="-1"></a>                va<span class="op">=</span><span class="st">'center'</span>, ha<span class="op">=</span><span class="st">'center'</span>)</span>
<span id="cb229-17"><a href="XGBoostalgorithm.html#cb229-17" tabindex="-1"></a>plt.xlabel(<span class="st">'Predicted Values'</span>, )</span>
<span id="cb229-18"><a href="XGBoostalgorithm.html#cb229-18" tabindex="-1"></a>plt.ylabel(<span class="st">'Actual Values'</span>)</span>
<span id="cb229-19"><a href="XGBoostalgorithm.html#cb229-19" tabindex="-1"></a></span>
<span id="cb229-20"><a href="XGBoostalgorithm.html#cb229-20" tabindex="-1"></a>ax.set_xticklabels([<span class="st">''</span>] <span class="op">+</span> group_names)</span>
<span id="cb229-21"><a href="XGBoostalgorithm.html#cb229-21" tabindex="-1"></a>ax.set_yticklabels([<span class="st">''</span>] <span class="op">+</span> group_names)</span>
<span id="cb229-22"><a href="XGBoostalgorithm.html#cb229-22" tabindex="-1"></a></span>
<span id="cb229-23"><a href="XGBoostalgorithm.html#cb229-23" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="inline-figure"><img src="71-MachineLearing_XGBoost_files/figure-html/unnamed-chunk-18-5.png" width="100%"></div>
<div class="sourceCode" id="cb230"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb230-1"><a href="XGBoostalgorithm.html#cb230-1" tabindex="-1"></a>y_pred <span class="op">=</span> xgb_final.predict(x_test_select)</span>
<span id="cb230-2"><a href="XGBoostalgorithm.html#cb230-2" tabindex="-1"></a></span>
<span id="cb230-3"><a href="XGBoostalgorithm.html#cb230-3" tabindex="-1"></a>accuracy <span class="op">=</span> accuracy_score(y_test, y_pred)</span>
<span id="cb230-4"><a href="XGBoostalgorithm.html#cb230-4" tabindex="-1"></a>conf_matrix <span class="op">=</span> confusion_matrix(y_test, y_pred)</span>
<span id="cb230-5"><a href="XGBoostalgorithm.html#cb230-5" tabindex="-1"></a>classification_rep <span class="op">=</span> classification_report(y_test, y_pred)</span>
<span id="cb230-6"><a href="XGBoostalgorithm.html#cb230-6" tabindex="-1"></a>f1 <span class="op">=</span> f1_score(y_test, y_pred)</span>
<span id="cb230-7"><a href="XGBoostalgorithm.html#cb230-7" tabindex="-1"></a>precision <span class="op">=</span> precision_score(y_test, y_pred)</span>
<span id="cb230-8"><a href="XGBoostalgorithm.html#cb230-8" tabindex="-1"></a>recall <span class="op">=</span> recall_score(y_test, y_pred)</span>
<span id="cb230-9"><a href="XGBoostalgorithm.html#cb230-9" tabindex="-1"></a></span>
<span id="cb230-10"><a href="XGBoostalgorithm.html#cb230-10" tabindex="-1"></a>tn, fp, fn, tp <span class="op">=</span> conf_matrix.ravel()</span>
<span id="cb230-11"><a href="XGBoostalgorithm.html#cb230-11" tabindex="-1"></a>specificity <span class="op">=</span> tn <span class="op">/</span> (tn <span class="op">+</span> fp)</span>
<span id="cb230-12"><a href="XGBoostalgorithm.html#cb230-12" tabindex="-1"></a>sensitivity <span class="op">=</span> tn <span class="op">/</span> (tn <span class="op">+</span> fn)</span>
<span id="cb230-13"><a href="XGBoostalgorithm.html#cb230-13" tabindex="-1"></a>false_positive_rate <span class="op">=</span> fp <span class="op">/</span> (fp <span class="op">+</span> tn)</span>
<span id="cb230-14"><a href="XGBoostalgorithm.html#cb230-14" tabindex="-1"></a></span>
<span id="cb230-15"><a href="XGBoostalgorithm.html#cb230-15" tabindex="-1"></a>index_df <span class="op">=</span> pd.DataFrame([[<span class="st">'Accuracy'</span>, accuracy], </span>
<span id="cb230-16"><a href="XGBoostalgorithm.html#cb230-16" tabindex="-1"></a>                         [<span class="st">'Specificity'</span>, specificity],</span>
<span id="cb230-17"><a href="XGBoostalgorithm.html#cb230-17" tabindex="-1"></a>                         [<span class="st">'Sensitivity'</span>, sensitivity],</span>
<span id="cb230-18"><a href="XGBoostalgorithm.html#cb230-18" tabindex="-1"></a>                         [<span class="st">'Precision'</span>, precision], </span>
<span id="cb230-19"><a href="XGBoostalgorithm.html#cb230-19" tabindex="-1"></a>                         [<span class="st">'Recall'</span>, recall],</span>
<span id="cb230-20"><a href="XGBoostalgorithm.html#cb230-20" tabindex="-1"></a>                         [<span class="st">'F1 score'</span>, f1],</span>
<span id="cb230-21"><a href="XGBoostalgorithm.html#cb230-21" tabindex="-1"></a>                         [<span class="st">'False Positive Rate'</span>, false_positive_rate]], </span>
<span id="cb230-22"><a href="XGBoostalgorithm.html#cb230-22" tabindex="-1"></a>    columns<span class="op">=</span>[<span class="st">'Index'</span>, <span class="st">'Value'</span>])</span>
<span id="cb230-23"><a href="XGBoostalgorithm.html#cb230-23" tabindex="-1"></a></span>
<span id="cb230-24"><a href="XGBoostalgorithm.html#cb230-24" tabindex="-1"></a>index_df</span>
<span id="cb230-25"><a href="XGBoostalgorithm.html#cb230-25" tabindex="-1"></a><span class="co">#&gt;                  Index     Value</span></span>
<span id="cb230-26"><a href="XGBoostalgorithm.html#cb230-26" tabindex="-1"></a><span class="co">#&gt; 0             Accuracy  0.959064</span></span>
<span id="cb230-27"><a href="XGBoostalgorithm.html#cb230-27" tabindex="-1"></a><span class="co">#&gt; 1          Specificity  0.970874</span></span>
<span id="cb230-28"><a href="XGBoostalgorithm.html#cb230-28" tabindex="-1"></a><span class="co">#&gt; 2          Sensitivity  0.961538</span></span>
<span id="cb230-29"><a href="XGBoostalgorithm.html#cb230-29" tabindex="-1"></a><span class="co">#&gt; 3            Precision  0.955224</span></span>
<span id="cb230-30"><a href="XGBoostalgorithm.html#cb230-30" tabindex="-1"></a><span class="co">#&gt; 4               Recall  0.941176</span></span>
<span id="cb230-31"><a href="XGBoostalgorithm.html#cb230-31" tabindex="-1"></a><span class="co">#&gt; 5             F1 score  0.948148</span></span>
<span id="cb230-32"><a href="XGBoostalgorithm.html#cb230-32" tabindex="-1"></a><span class="co">#&gt; 6  False Positive Rate  0.029126</span></span></code></pre></div>
<ul>
<li>ROC Metrics</li>
</ul>
<p>ROC shows the AUC of sensitivity and specificity</p>
<div class="sourceCode" id="cb231"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb231-1"><a href="XGBoostalgorithm.html#cb231-1" tabindex="-1"></a>predictions_prob <span class="op">=</span> xgb_final.predict_proba(x_test_select)[:, <span class="dv">1</span>]</span>
<span id="cb231-2"><a href="XGBoostalgorithm.html#cb231-2" tabindex="-1"></a></span>
<span id="cb231-3"><a href="XGBoostalgorithm.html#cb231-3" tabindex="-1"></a>fpr2, tpr2, _ <span class="op">=</span> roc_curve(y_test,</span>
<span id="cb231-4"><a href="XGBoostalgorithm.html#cb231-4" tabindex="-1"></a>                          predictions_prob,</span>
<span id="cb231-5"><a href="XGBoostalgorithm.html#cb231-5" tabindex="-1"></a>                          pos_label <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb231-6"><a href="XGBoostalgorithm.html#cb231-6" tabindex="-1"></a></span>
<span id="cb231-7"><a href="XGBoostalgorithm.html#cb231-7" tabindex="-1"></a>auc_rf <span class="op">=</span> auc(fpr2, tpr2)</span>
<span id="cb231-8"><a href="XGBoostalgorithm.html#cb231-8" tabindex="-1"></a></span>
<span id="cb231-9"><a href="XGBoostalgorithm.html#cb231-9" tabindex="-1"></a><span class="kw">def</span> plot_roc_curve(fpr, tpr, auc, estimator, xlim<span class="op">=</span><span class="va">None</span>, ylim<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb231-10"><a href="XGBoostalgorithm.html#cb231-10" tabindex="-1"></a></span>
<span id="cb231-11"><a href="XGBoostalgorithm.html#cb231-11" tabindex="-1"></a>    my_estimators <span class="op">=</span> {</span>
<span id="cb231-12"><a href="XGBoostalgorithm.html#cb231-12" tabindex="-1"></a>        <span class="st">'knn'</span>: [<span class="st">'Kth Nearest Neighbor'</span>, <span class="st">'deeppink'</span>],</span>
<span id="cb231-13"><a href="XGBoostalgorithm.html#cb231-13" tabindex="-1"></a>        <span class="st">'rf'</span>: [<span class="st">'Random Forest'</span>, <span class="st">'red'</span>],</span>
<span id="cb231-14"><a href="XGBoostalgorithm.html#cb231-14" tabindex="-1"></a>        <span class="st">'XGBoost'</span>: [<span class="st">'XGBoost'</span>, <span class="st">'purple'</span>]}</span>
<span id="cb231-15"><a href="XGBoostalgorithm.html#cb231-15" tabindex="-1"></a></span>
<span id="cb231-16"><a href="XGBoostalgorithm.html#cb231-16" tabindex="-1"></a>    plot_title <span class="op">=</span> my_estimators[estimator][<span class="dv">0</span>]</span>
<span id="cb231-17"><a href="XGBoostalgorithm.html#cb231-17" tabindex="-1"></a>    color_value <span class="op">=</span> my_estimators[estimator][<span class="dv">1</span>]</span>
<span id="cb231-18"><a href="XGBoostalgorithm.html#cb231-18" tabindex="-1"></a></span>
<span id="cb231-19"><a href="XGBoostalgorithm.html#cb231-19" tabindex="-1"></a>    fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">5</span>, <span class="dv">5</span>))</span>
<span id="cb231-20"><a href="XGBoostalgorithm.html#cb231-20" tabindex="-1"></a>    ax.set_facecolor(<span class="st">'#fafafa'</span>)</span>
<span id="cb231-21"><a href="XGBoostalgorithm.html#cb231-21" tabindex="-1"></a></span>
<span id="cb231-22"><a href="XGBoostalgorithm.html#cb231-22" tabindex="-1"></a>    plt.plot(fpr, tpr, color<span class="op">=</span>color_value, linewidth<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb231-23"><a href="XGBoostalgorithm.html#cb231-23" tabindex="-1"></a>    plt.title(<span class="st">'ROC Curve For </span><span class="sc">{0}</span><span class="st"> (AUC = </span><span class="sc">{1: 0.3f}</span><span class="st">)'</span>.<span class="bu">format</span>(plot_title, auc))</span>
<span id="cb231-24"><a href="XGBoostalgorithm.html#cb231-24" tabindex="-1"></a></span>
<span id="cb231-25"><a href="XGBoostalgorithm.html#cb231-25" tabindex="-1"></a>    plt.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>], <span class="st">'k--'</span>, linewidth<span class="op">=</span><span class="dv">1</span>) <span class="co"># Add Diagonal line</span></span>
<span id="cb231-26"><a href="XGBoostalgorithm.html#cb231-26" tabindex="-1"></a>    plt.plot([<span class="dv">0</span>, <span class="dv">0</span>], [<span class="dv">1</span>, <span class="dv">0</span>], <span class="st">'k--'</span>, linewidth<span class="op">=</span><span class="dv">1</span>, color <span class="op">=</span> <span class="st">'grey'</span>)</span>
<span id="cb231-27"><a href="XGBoostalgorithm.html#cb231-27" tabindex="-1"></a>    plt.plot([<span class="dv">1</span>, <span class="dv">0</span>], [<span class="dv">1</span>, <span class="dv">1</span>], <span class="st">'k--'</span>, linewidth<span class="op">=</span><span class="dv">1</span>, color <span class="op">=</span> <span class="st">'grey'</span>)</span>
<span id="cb231-28"><a href="XGBoostalgorithm.html#cb231-28" tabindex="-1"></a>    <span class="cf">if</span> xlim <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb231-29"><a href="XGBoostalgorithm.html#cb231-29" tabindex="-1"></a>        plt.xlim(<span class="op">*</span>xlim)</span>
<span id="cb231-30"><a href="XGBoostalgorithm.html#cb231-30" tabindex="-1"></a>    <span class="cf">if</span> ylim <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb231-31"><a href="XGBoostalgorithm.html#cb231-31" tabindex="-1"></a>        plt.ylim(<span class="op">*</span>ylim)</span>
<span id="cb231-32"><a href="XGBoostalgorithm.html#cb231-32" tabindex="-1"></a>    plt.xlabel(<span class="st">'False Positive Rate'</span>)</span>
<span id="cb231-33"><a href="XGBoostalgorithm.html#cb231-33" tabindex="-1"></a>    plt.ylabel(<span class="st">'True Positive Rate'</span>)</span>
<span id="cb231-34"><a href="XGBoostalgorithm.html#cb231-34" tabindex="-1"></a>    plt.show()</span>
<span id="cb231-35"><a href="XGBoostalgorithm.html#cb231-35" tabindex="-1"></a></span>
<span id="cb231-36"><a href="XGBoostalgorithm.html#cb231-36" tabindex="-1"></a>plot_roc_curve(fpr2, tpr2, auc_rf, <span class="st">'XGBoost'</span>,</span>
<span id="cb231-37"><a href="XGBoostalgorithm.html#cb231-37" tabindex="-1"></a>               xlim<span class="op">=</span>(<span class="op">-</span><span class="fl">0.01</span>, <span class="fl">1.05</span>), </span>
<span id="cb231-38"><a href="XGBoostalgorithm.html#cb231-38" tabindex="-1"></a>               ylim<span class="op">=</span>(<span class="fl">0.001</span>, <span class="fl">1.05</span>))</span></code></pre></div>
<div class="inline-figure"><img src="71-MachineLearing_XGBoost_files/figure-html/unnamed-chunk-20-7.png" width="100%"></div>
<ul>
<li>classification report</li>
</ul>
<div class="sourceCode" id="cb232"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb232-1"><a href="XGBoostalgorithm.html#cb232-1" tabindex="-1"></a><span class="kw">def</span> print_class_report(predictions, alg_name):</span>
<span id="cb232-2"><a href="XGBoostalgorithm.html#cb232-2" tabindex="-1"></a></span>
<span id="cb232-3"><a href="XGBoostalgorithm.html#cb232-3" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Classification Report for </span><span class="sc">{0}</span><span class="st">:'</span>.<span class="bu">format</span>(alg_name))</span>
<span id="cb232-4"><a href="XGBoostalgorithm.html#cb232-4" tabindex="-1"></a>    <span class="bu">print</span>(classification_report(predictions, </span>
<span id="cb232-5"><a href="XGBoostalgorithm.html#cb232-5" tabindex="-1"></a>            y_test, </span>
<span id="cb232-6"><a href="XGBoostalgorithm.html#cb232-6" tabindex="-1"></a>            target_names <span class="op">=</span> group_names))</span>
<span id="cb232-7"><a href="XGBoostalgorithm.html#cb232-7" tabindex="-1"></a></span>
<span id="cb232-8"><a href="XGBoostalgorithm.html#cb232-8" tabindex="-1"></a>class_report <span class="op">=</span> print_class_report(predicted, <span class="st">'XGBoost'</span>)</span>
<span id="cb232-9"><a href="XGBoostalgorithm.html#cb232-9" tabindex="-1"></a><span class="co">#&gt; Classification Report for XGBoost:</span></span>
<span id="cb232-10"><a href="XGBoostalgorithm.html#cb232-10" tabindex="-1"></a><span class="co">#&gt;               precision    recall  f1-score   support</span></span>
<span id="cb232-11"><a href="XGBoostalgorithm.html#cb232-11" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb232-12"><a href="XGBoostalgorithm.html#cb232-12" tabindex="-1"></a><span class="co">#&gt;            B       0.97      0.96      0.97       104</span></span>
<span id="cb232-13"><a href="XGBoostalgorithm.html#cb232-13" tabindex="-1"></a><span class="co">#&gt;            M       0.94      0.96      0.95        67</span></span>
<span id="cb232-14"><a href="XGBoostalgorithm.html#cb232-14" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb232-15"><a href="XGBoostalgorithm.html#cb232-15" tabindex="-1"></a><span class="co">#&gt;     accuracy                           0.96       171</span></span>
<span id="cb232-16"><a href="XGBoostalgorithm.html#cb232-16" tabindex="-1"></a><span class="co">#&gt;    macro avg       0.96      0.96      0.96       171</span></span>
<span id="cb232-17"><a href="XGBoostalgorithm.html#cb232-17" tabindex="-1"></a><span class="co">#&gt; weighted avg       0.96      0.96      0.96       171</span></span></code></pre></div>
</div>
<div id="feature-importance" class="section level3" number="14.3.10">
<h3>
<span class="header-section-number">14.3.10</span> Feature Importance<a class="anchor" aria-label="anchor" href="#feature-importance"><i class="fas fa-link"></i></a>
</h3>
<div class="sourceCode" id="cb233"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb233-1"><a href="XGBoostalgorithm.html#cb233-1" tabindex="-1"></a>plt.figure(figsize <span class="op">=</span> (<span class="dv">16</span>, <span class="dv">12</span>))</span>
<span id="cb233-2"><a href="XGBoostalgorithm.html#cb233-2" tabindex="-1"></a><span class="co">#&gt; &lt;Figure size 1600x1200 with 0 Axes&gt;</span></span>
<span id="cb233-3"><a href="XGBoostalgorithm.html#cb233-3" tabindex="-1"></a></span>
<span id="cb233-4"><a href="XGBoostalgorithm.html#cb233-4" tabindex="-1"></a>xgb.plot_importance(xgb_final)</span>
<span id="cb233-5"><a href="XGBoostalgorithm.html#cb233-5" tabindex="-1"></a><span class="co">#&gt; &lt;Axes: title={'center': 'Feature importance'}, xlabel='F score', ylabel='Features'&gt;</span></span>
<span id="cb233-6"><a href="XGBoostalgorithm.html#cb233-6" tabindex="-1"></a></span>
<span id="cb233-7"><a href="XGBoostalgorithm.html#cb233-7" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="inline-figure"><img src="71-MachineLearing_XGBoost_files/figure-html/unnamed-chunk-22-9.png" width="100%"></div>
</div>
<div id="save-model" class="section level3" number="14.3.11">
<h3>
<span class="header-section-number">14.3.11</span> Save model<a class="anchor" aria-label="anchor" href="#save-model"><i class="fas fa-link"></i></a>
</h3>
<p>save a machine learning model using Python’s pickle module</p>
<div class="sourceCode" id="cb234"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb234-1"><a href="XGBoostalgorithm.html#cb234-1" tabindex="-1"></a><span class="im">import</span> pickle</span>
<span id="cb234-2"><a href="XGBoostalgorithm.html#cb234-2" tabindex="-1"></a></span>
<span id="cb234-3"><a href="XGBoostalgorithm.html#cb234-3" tabindex="-1"></a><span class="co">''' </span></span>
<span id="cb234-4"><a href="XGBoostalgorithm.html#cb234-4" tabindex="-1"></a><span class="co"># save classification model as a pickle file</span></span>
<span id="cb234-5"><a href="XGBoostalgorithm.html#cb234-5" tabindex="-1"></a><span class="co">model_pkl_file = "XGBoost.pkl"  </span></span>
<span id="cb234-6"><a href="XGBoostalgorithm.html#cb234-6" tabindex="-1"></a></span>
<span id="cb234-7"><a href="XGBoostalgorithm.html#cb234-7" tabindex="-1"></a><span class="co">with open(model_pkl_file, 'wb') as file:  </span></span>
<span id="cb234-8"><a href="XGBoostalgorithm.html#cb234-8" tabindex="-1"></a><span class="co">    pickle.dump(xgb_final, file)</span></span>
<span id="cb234-9"><a href="XGBoostalgorithm.html#cb234-9" tabindex="-1"></a></span>
<span id="cb234-10"><a href="XGBoostalgorithm.html#cb234-10" tabindex="-1"></a></span>
<span id="cb234-11"><a href="XGBoostalgorithm.html#cb234-11" tabindex="-1"></a><span class="co"># load model from pickle file</span></span>
<span id="cb234-12"><a href="XGBoostalgorithm.html#cb234-12" tabindex="-1"></a><span class="co">with open(model_pkl_file, 'rb') as file:  </span></span>
<span id="cb234-13"><a href="XGBoostalgorithm.html#cb234-13" tabindex="-1"></a><span class="co">    rfc_final = pickle.load(file)</span></span>
<span id="cb234-14"><a href="XGBoostalgorithm.html#cb234-14" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb234-15"><a href="XGBoostalgorithm.html#cb234-15" tabindex="-1"></a><span class="co">#&gt; ' \n# save classification model as a pickle file\nmodel_pkl_file = "XGBoost.pkl"  \n\nwith open(model_pkl_file, \'wb\') as file:  \n    pickle.dump(xgb_final, file)\n\n\n# load model from pickle file\nwith open(model_pkl_file, \'rb\') as file:  \n    rfc_final = pickle.load(file)\n'</span></span></code></pre></div>
</div>
</div>
<div id="session-info-7" class="section level2" number="14.4">
<h2>
<span class="header-section-number">14.4</span> Session info<a class="anchor" aria-label="anchor" href="#session-info-7"><i class="fas fa-link"></i></a>
</h2>
<div class="sourceCode" id="cb235"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb235-1"><a href="XGBoostalgorithm.html#cb235-1" tabindex="-1"></a><span class="im">import</span> session_info</span>
<span id="cb235-2"><a href="XGBoostalgorithm.html#cb235-2" tabindex="-1"></a></span>
<span id="cb235-3"><a href="XGBoostalgorithm.html#cb235-3" tabindex="-1"></a></span>
<span id="cb235-4"><a href="XGBoostalgorithm.html#cb235-4" tabindex="-1"></a>session_info.show()</span>
<span id="cb235-5"><a href="XGBoostalgorithm.html#cb235-5" tabindex="-1"></a><span class="co">#&gt; -----</span></span>
<span id="cb235-6"><a href="XGBoostalgorithm.html#cb235-6" tabindex="-1"></a><span class="co">#&gt; IPython             8.14.0</span></span>
<span id="cb235-7"><a href="XGBoostalgorithm.html#cb235-7" tabindex="-1"></a><span class="co">#&gt; matplotlib          3.7.2</span></span>
<span id="cb235-8"><a href="XGBoostalgorithm.html#cb235-8" tabindex="-1"></a><span class="co">#&gt; numpy               1.23.3</span></span>
<span id="cb235-9"><a href="XGBoostalgorithm.html#cb235-9" tabindex="-1"></a><span class="co">#&gt; pandas              2.0.3</span></span>
<span id="cb235-10"><a href="XGBoostalgorithm.html#cb235-10" tabindex="-1"></a><span class="co">#&gt; seaborn             0.12.2</span></span>
<span id="cb235-11"><a href="XGBoostalgorithm.html#cb235-11" tabindex="-1"></a><span class="co">#&gt; session_info        1.0.0</span></span>
<span id="cb235-12"><a href="XGBoostalgorithm.html#cb235-12" tabindex="-1"></a><span class="co">#&gt; sklearn             1.3.0</span></span>
<span id="cb235-13"><a href="XGBoostalgorithm.html#cb235-13" tabindex="-1"></a><span class="co">#&gt; skopt               0.9.0</span></span>
<span id="cb235-14"><a href="XGBoostalgorithm.html#cb235-14" tabindex="-1"></a><span class="co">#&gt; xgboost             1.7.6</span></span>
<span id="cb235-15"><a href="XGBoostalgorithm.html#cb235-15" tabindex="-1"></a><span class="co">#&gt; -----</span></span>
<span id="cb235-16"><a href="XGBoostalgorithm.html#cb235-16" tabindex="-1"></a><span class="co">#&gt; Python 3.9.16 | packaged by conda-forge | (main, Feb  1 2023, 21:50:49) [Clang 14.0.6 ]</span></span>
<span id="cb235-17"><a href="XGBoostalgorithm.html#cb235-17" tabindex="-1"></a><span class="co">#&gt; macOS-10.16-x86_64-i386-64bit</span></span>
<span id="cb235-18"><a href="XGBoostalgorithm.html#cb235-18" tabindex="-1"></a><span class="co">#&gt; -----</span></span>
<span id="cb235-19"><a href="XGBoostalgorithm.html#cb235-19" tabindex="-1"></a><span class="co">#&gt; Session information updated at 2023-12-06 21:26</span></span></code></pre></div>
</div>
<div id="reference-11" class="section level2" number="14.5">
<h2>
<span class="header-section-number">14.5</span> Reference<a class="anchor" aria-label="anchor" href="#reference-11"><i class="fas fa-link"></i></a>
</h2>
<ul>
<li><p><a href="https://towardsdatascience.com/binary-classification-xgboost-hyperparameter-tuning-scenarios-by-non-exhaustive-grid-search-and-c261f4ce098d">Binary Classification: XGBoost Hyperparameter Tuning Scenarios by Non-exhaustive Grid Search and Cross-Validation</a></p></li>
<li><p><a href="https://towardsdatascience.com/feature-selection-using-random-forest-26d7b747597f">Feature Selection Using Random forest</a></p></li>
</ul>
</div>
</div>



  <div class="chapter-nav">
<div class="prev"><a href="randomforestalgorithm.html"><span class="header-section-number">13</span> Random Forest Algorithm</a></div>
<div class="next"><a href="Metageomics.html"><span class="header-section-number">15</span> Metageomics</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li>
<a class="nav-link" href="#XGBoostalgorithm"><span class="header-section-number">14</span> XGBoost Algorithm</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#data-preparation"><span class="header-section-number">14.0.1</span> Data Preparation</a></li>
<li><a class="nav-link" href="#data-description"><span class="header-section-number">14.0.2</span> Data Description</a></li>
<li><a class="nav-link" href="#data-preprocessing"><span class="header-section-number">14.0.3</span> Data Preprocessing</a></li>
<li><a class="nav-link" href="#data-partition"><span class="header-section-number">14.0.4</span> Data Partition</a></li>
<li><a class="nav-link" href="#feature-selection"><span class="header-section-number">14.0.5</span> Feature Selection</a></li>
<li><a class="nav-link" href="#model-training"><span class="header-section-number">14.0.6</span> Model training</a></li>
<li><a class="nav-link" href="#python-environment"><span class="header-section-number">14.0.7</span> python environment</a></li>
</ul>
</li>
<li><a class="nav-link" href="#loading-required-packages"><span class="header-section-number">14.1</span> Loading required packages</a></li>
<li><a class="nav-link" href="#data-preparation-1"><span class="header-section-number">14.2</span> Data Preparation</a></li>
<li>
<a class="nav-link" href="#xgboost-classification"><span class="header-section-number">14.3</span> XGBoost classification</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#transforming-label"><span class="header-section-number">14.3.1</span> Transforming label</a></li>
<li><a class="nav-link" href="#principal-component-analysis"><span class="header-section-number">14.3.2</span> Principal component analysis</a></li>
<li><a class="nav-link" href="#data-partition-1"><span class="header-section-number">14.3.3</span> Data partition</a></li>
<li><a class="nav-link" href="#feature-selection-1"><span class="header-section-number">14.3.4</span> Feature selection</a></li>
<li><a class="nav-link" href="#base-model"><span class="header-section-number">14.3.5</span> Base model</a></li>
<li><a class="nav-link" href="#k-cross-validataion-for-n_estimators"><span class="header-section-number">14.3.6</span> K cross validataion for n_estimators</a></li>
<li><a class="nav-link" href="#tuning-parameters"><span class="header-section-number">14.3.7</span> Tuning parameters</a></li>
<li><a class="nav-link" href="#build-final-classifier"><span class="header-section-number">14.3.8</span> Build final classifier</a></li>
<li><a class="nav-link" href="#evaluating-model-performance"><span class="header-section-number">14.3.9</span> Evaluating model performance</a></li>
<li><a class="nav-link" href="#feature-importance"><span class="header-section-number">14.3.10</span> Feature Importance</a></li>
<li><a class="nav-link" href="#save-model"><span class="header-section-number">14.3.11</span> Save model</a></li>
</ul>
</li>
<li><a class="nav-link" href="#session-info-7"><span class="header-section-number">14.4</span> Session info</a></li>
<li><a class="nav-link" href="#reference-11"><span class="header-section-number">14.5</span> Reference</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/HuaZou/DraftNotes/blob/main/71-MachineLearing_XGBoost.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/HuaZou/DraftNotes/edit/main/71-MachineLearing_XGBoost.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>生物信息随记</strong>" was written by Hua Zou. It was last built on 2023-08-24 and updated on 2023-12-06.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
